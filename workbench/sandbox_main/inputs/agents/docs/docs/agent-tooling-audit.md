# Аудит инструментария для локального агента (Llama3 8B Instruct Q4_K_M)

## 1. Обзор исходных данных
Имеющиеся сведения:
- Модель: Meta-Llama-3-8B-Instruct (квантование Q4_K_M, GGUF V3, 8.03B параметров).
- Контекст train: 8192 токенов; runtime настроен 4096 → наблюдаются truncation предупреждения (>4096).
- Полный offload 33 слоёв в VRAM (требует ~5.7 GiB); доступно ~15.9 GiB.
- Использование кастомного порта Ollama: 11435 (`OLLAMA_HOST=http://127.0.0.1:11435`).
- Open WebUI доступен по `http://localhost:3000`.
- Логи фиксируют GPU discovery таймауты (периодические) и entering low vram mode.

## 2. Недостающая / потенциально полезная информация (гепы)
| Категория | Геп | Ценность | Комментарий |
|-----------|-----|----------|-------------|
| Лицензия модели | Точный текст лицензии Meta-Llama-3 | Высокая | Нужно для дистрибуции/коммерции |
| Параметры генерации | Рекоменд. диапазоны `temperature`, `top_k`, `top_p`, `repeat_penalty` | Средняя | Оптимизация качества/стабильности |
| Скорость | Эмпирические ток/с CPU/GPU при разных контекстах | Средняя | Планирование SLA агента |
| Контекст расширение | Реальные требования VRAM при 8192 | Высокая | Решение о повышении `OLLAMA_CONTEXT_LENGTH` |
| Качество квантования | Сравнение Q4_K_M vs Q5_K_M на бенчмарках русск. задач | Средняя | Решение о смене квантования |
| Безопасность | Наличие встроенных safety фильтров (есть ли системные guardrails) | Средняя | Требует внешнего цензора? |
| Fine‑tune | Поддержка merge LoRA в GGUF (процедура, инструменты) | Средняя | План подготовки кастомной LoRA |
| Embeddings | Рекоменд. локальная модель для эмбеддингов (MiniLM, BGE, Llama3 text-embed) | Высокая | Для RAG качества |
| RAG кеш | Выбор формата хранения chunkов/векторов (SQLite + FAISS / Chroma / Milvus) | Высокая | Производительность/простота |
| Мониторинг | Стандартные метрики: ток/с, латентность, GPU util, память | Средняя | Дашборд/алерты |
| Тесты качества | Набор промптов regression (eval harness) | Высокая | Отслеживание деградации после изменений |
| Сжатие контекста | Алгоритмы резюмирования: rank, extract+rewrite | Средняя | Предотвращение усечения |
| Мульти-модель | План fallback (например, локальная + облачная) | Низкая | Резерв при нагрузке |
| Плагины | Список must-have Open WebUI плагинов | Низкая | Оптимизация UX |

## 3. Рекомендованные поисковые запросы (EN/RU)
| Цель | Запросы |
|------|---------|
| Лицензия | `Llama 3 8B Instruct license`, `Meta Llama 3 license terms`, `лицензия Llama 3 использование коммерция` |
| Параметры генерации | `Llama 3 recommended temperature top_k top_p`, `Llama3 8B Q4_K generation settings` |
| Контекст VRAM | `Llama3 8B context 8192 VRAM requirements`, `ollama context length llama3 performance` |
| Квантование сравнение | `Q4_K_M vs Q5_K_M quality llama`, `llama3 q4_k_m benchmark russian` |
| Safety | `Llama 3 safety filters instruct`, `Llama3 moderation built-in` |
| LoRA merge | `merge lora llama3 gguf`, `llama.cpp apply lora 8b` |
| Embeddings | `best local embedding model 2025`, `Llama 3 embedding model release` |
| RAG store | `local vector db faiss chroma performance`, `chroma vs milvus local rag` |
| Eval harness | `llama local eval prompt set`, `open source llm regression testing toolkit` |
| Context compression | `llm conversation summarization algorithm open source`, `prompt compression llama` |
| GPU discovery issues | `ollama failure during GPU discovery timeout`, `ollama multiple runner ports fix` |

## 4. Аудит инструментария (категории)

### 4.1 Критично (Must Have)
1. Управление моделью: Ollama CLI/API.
2. Веб интерфейс: Open WebUI (чат, RAG, плагины).
3. Логирование/диагностика: парсинг `server.log` + базовый мониторинг ток/с.
4. Контекстное управление: модуль резюмирования/сжатия диалога (extract + summarize).
5. Векторное хранилище: локальный FAISS или Chroma (минимальный стек) для RAG.
6. Эмбеддинг модель: локальная лёгкая (например `bge-small-en` / RU адаптация) + интерфейс.
7. Тест регрессии промптов: JSON/YAML набор эталонных запросов и ожидаемых характеристик (стиль/факты).
8. Скрипт health-check (пинг `/api/tags`, латентность, загрузка VRAM).
9. Управление конфигурацией: файл с параметрами генерации (`temperature`, `top_p`, ограничения контекста).
10. Процедура перезапуска и резервного копирования (документ + PowerShell скрипт).

### 4.2 Терпимо (Should Have / позже)
1. Авто переключение контекста 4096↔8192 с оценкой памяти.
2. Авто адаптивный температурный контроллер (снижение при повторениях).
3. Интеграция LoRA загрузки/включения (выбор адаптера).
4. Базовый dashboard (Prometheus exporter: ток/с, запросы/мин, VRAM usage).
5. Система тегирования историй (метаданные диалогов). 
6. Механизм fallback на облачный API (только при таймауте > threshold).
7. Набор метрик качества: BLEU/ROUGE для ответов на фиксированный набор QA.
8. Автоматическое очищение старых runner процессов (watchdog).
9. Скрипт сравнения квантований (Q4_K_M vs Q5_K_M) на чек-листе промптов.
10. Авто выгрузка длинных веток бесед в архив с резюме.

### 4.3 Опционально (Nice to Have)
1. UI настройка параметров генерации внутри Open WebUI (синхронизация конфигов).
2. Плагины расширенного поиска (web/meta) с кэшированием.
3. Интеграция с локальным графом знаний (RDF/Neo4j).
4. Расширенный менеджер персон (персонажи с параметрами стиля) как слой над промпт шаблоном.
5. Набор визуализации attention (исследование модели).
6. Авто-анализ токсичности / политических тем (внешние классификаторы).
7. Batch генерация для оффлайн задач (много промптов → CSV результат).
8. Экспериментальный контекст компрессор на векторном ранжировании (semantic key sentence extraction).
9. Авто выбор квантования по типу задачи (брейнсторм vs точность фактов).
10. Локальный web sandbox для инструментов (функции Python из чата).

## 5. Риски и рекомендации
| Риск | Митигирование |
|------|---------------|
| Транкация контекста → потеря смысла | Внедрить многоступенчатое резюмирование + динамическое увеличение `OLLAMA_CONTEXT_LENGTH` |
| GPU discovery таймауты | Проверить драйверы, обновить Ollama, ограничить параллелизм (`OLLAMA_NUM_PARALLEL=1`) |
| Лицензионная неопределённость | Найти текст лицензии, добавить в документацию раздел compliance |
| Отсутствие эмбеддинг модели | Выбрать и протестировать компактную модель (размер < 300MB) |
| Отсутствие тестов качества | Создать baseline eval пакет (фактические вопросы, стиль, краткость) |
| Рост латентности при увеличении контекста | Ввести эвристику «резюме каждые N сообщений» |

## 6. Приоритет внедрения (пошагово)
1. Добавить модуль резюмирования (critical #4).
2. Подключить эмбеддинги + минимальный FAISS (critical #5–6).
3. Создать eval промпт набор (critical #7).
4. Health-check скрипт (critical #8).
5. Конфигурационный файл параметров генерации (critical #9).
6. Бэкап/перезапуск скрипт (critical #10).
7. Dashboard экспорт (терпимо #4).
8. Квантование сравнительный тест (терпимо #9).
9. Fallback облачный (терпимо #6).
10. Персонажи / расширения (опционально #4).

## 7. Следующие шаги
- Подтвердить приоритеты.
- Выполнить поиск по ключевым запросам и обновить разделы (лицензия, параметры генерации, эмбеддинги).
- Создать директорию `AGENTS/docs/reference/eval/` с baseline промптами.

---
Последнее обновление: 2025-11-21.
