Аудит практической зрелости "Пути C-2": Generalized Memory Management (GMEM)




I. Итоговая оценка: Практическая зрелость «Пути C-2» (GMEM)




A. Заключительные выводы о жизнеспособности GMEM в промышленности


Анализ "Пути C-2", технологии Generalized Memory Management (GMEM), показывает, что она не вписывается в бинарную классификацию "академический проект" или "отраслевой стандарт". GMEM представляет собой третью, все более распространенную категорию: зрелое, готовое к эксплуатации, но специфичное для экосистемы решение.
Технология активно продвигается и интегрирована в дистрибутив openEuler 1, однако она полностью отсутствует в mainline-ядре Linux и не поддерживается более широкой экосистемой (включая Red Hat, SUSE, Canonical, NVIDIA и AMD).
Критически важно, что основной дизайн GMEM, который стремится объединить управление памятью ЦП и устройства на уровне виртуального адресного пространства процесса, считается ведущими разработчиками ядра Linux фундаментально несовместимым с вариантами использования виртуализации, такими как KVM и QEMU.2


B. Прямые ответы: GMEM как нишевый проект в сравнении с отраслевым стандартом


Отвечая на основной вопрос аудита — "Это академический проект... или промышленный стандарт?" — прямой ответ таков: GMEM является нишевым промышленным решением.
Он достиг статуса "production ready", но только в строго определенном контексте дистрибутивов openEuler 24.03 LTS и 24.09.1 Он не является отраслевым стандартом, поскольку не получил принятия в mainline-ядре 3 и был фактически отвергнут ключевыми представителями сообщества разработчиков ядра.2
Первоначальный бинарный вопрос (академический vs. стандартный) упускает из виду новую реальность "форкнутых" или экосистемно-специфичных промышленных стандартов. GMEM представляет собой стратегический шаг openEuler, направленный на оптимизацию для высокоприоритетных рабочих нагрузок ИИ, даже если эта оптимизация достигается ценой расхождения с mainline-ядром.
Эта дивергенция является не случайностью, а намеренным выбором. С одной стороны, openEuler называет GMEM "оптимальным решением" и "ключевой функцией" 1, что подтверждает его серьезность и готовность к эксплуатации. С другой стороны, ведущие разработчики mainline-ядра, такие как Кристиан Кёниг, категорически отвергают его архитектурный подход.2 Сочетание этих фактов означает, что GMEM — это не провалившийся проект, а намеренно расходящийся путь. Он существует в параллельной вселенной, которая не пересекается с mainline.


C. Стратегическая рекомендация: Переоценка GMEM для задач виртуализации


Данные аудита неопровержимо доказывают, что GMEM не является решением для живой миграции KVM с использованием GPU. Он был разработан для совершенно другого набора проблем (обучение ИИ, обработка больших данных) 1, и его архитектура препятствует использованию в сценариях виртуализации.2
Рекомендация: Аудит "Пути C-2" (GMEM) для этой цели должен быть немедленно прекращен. Ресурсы должны быть перенаправлены на исследование альтернативных, одобренных mainline-ядром технологий, таких как Heterogeneous Memory Management (HMM), которые являются единственным жизнеспособным путем для достижения этой цели.


Таблица 1: Заявленные возможности GMEM в сравнении с аудиторской реальностью




Категория аудита (Запрос)
	Гипотеза пользователя
	Аудиторская реальность (на основе данных)
	Ключевые источники
	Зрелость
	Промышленный стандарт (как KVM) | Готово к эксплуатации, в mainline-ядре 2025
	Готово к эксплуатации только в openEuler; отвергнуто mainline-ядром
	1
	Основной вариант использования
	Живая миграция KVM/QEMU с GPU
	Официально не поддерживается; дизайн несовместим с KVM
	1
	Поддержка дистрибутивов
	Red Hat, SUSE, Canonical
	Нулевая поддержка; найденные упоминания - ложные срабатывания
	6
	Поддержка оборудования
	NVIDIA, AMD
	Нулевая поддержка; активно блокируется разработчиком AMD
	2
	

II. Архитектура GMEM и статус «готовности к эксплуатации»: Реализация в openEuler


Чтобы понять разрыв между ожиданиями и реальностью, необходимо проанализировать, чем GMEM является на самом деле, основываясь на его фактической реализации в openEuler.


A. Анализ GMEM как «ключевой функции» в openEuler


GMEM не является второстепенным компонентом или экспериментальной функцией. В документации openEuler 24.09 он прямо назван "Ключевой функцией" (Key Feature).1 Он позиционируется как "оптимальное решение для управления памятью в ОС для ИИ" и "инновация архитектуры управления памятью в ядре Linux".1 Это подтверждает его статус "production ready" и стратегическую важность внутри экосистемы openEuler.


B. Деконструкция фреймворка GMEM


Архитектура GMEM состоит из трех основных компонентов:
1. Логическая система картирования (Logical mapping system): Это ядро GMEM. Его задача — "маскировать различия между способами доступа ЦП и ускорителя к адресам памяти".1 Это достигается путем предоставления API верхнего уровня в ядре, которые позволяют драйверу ускорителя создавать логические таблицы страниц, абстрагируя управление памятью.1
2. Remote Pager: Этот компонент представляет собой фреймворк для взаимодействия хост-ускоритель.1 Он реализован как отдельный, независимый драйвер ядра (remote_pager.ko).10 Его цель — предоставить абстрактный уровень для "упрощения адаптации устройств", позволяя сторонним ускорителям подключаться к системе GMEM.10 Он управляет каналами сообщений, подкачкой памяти и предварительной выборкой.1
3. Пользовательские API: GMEM предоставляет API как на уровне ядра, так и в пространстве пользователя.
   * Ядро: Для выделения "единой виртуальной памяти" используется стандартный системный вызов mmap с новым флагом MMAP_PEER_SHARED.10
   * Пользовательское пространство: Библиотека libgmem предоставляет API, такие как hmadvise (для семантики предварительной выборки памяти) 10, а также gmemPrefetch (для явной предварительной выборки) и gmemFreeEager (для освобождения страниц).5


C. Выявленные варианты использования (ИИ/HPC) в сравнении с отсутствующими вариантами использования (виртуализация)


Наиболее показательным результатом аудита является анализ фактических вариантов использования GMEM, задокументированных openEuler.
Явно заявленные варианты использования 1:
Документация openEuler 24.09 четко определяет два основных сценария применения:
1. "Обучение и логический вывод базовых моделей": GMEM используется для "прозрачного расширения емкости гетерогенной памяти" и, что наиболее важно, для "автоматического превышения лимита HBM (HBM overcommitment)".
2. "Совместное использование больших объемов памяти": Используется для "приложений поиска и рекомендаций и больших данных", устраняя узкие места при миграции памяти между устройствами.1
Показательное отсутствие:
Ни в одном из проанализированных документов openEuler, посвященных GMEM (включая технические описания, примечания к выпуску и README библиотеки) 11, никогда не упоминаются "KVM", "QEMU" или "живая миграция" в качестве варианта использования или даже совместимой функции.
Это "нелающая собака" аудита. Полное отсутствие упоминания KVM/QEMU в официальной документации по GMEM, в то время как варианты использования ИИ подробно описаны, доказывает, что технология не была разработана для этой цели. Первоначальная гипотеза пользователя не просто не подтверждена; она прямо опровергается заявленными целями технологии.
Более того, openEuler открыто позиционирует GMEM как конкурентное решение, заявляя, что "с превышением лимита памяти производительность обучения базовых моделей на 60% выше, чем у NVIDIA".1 Это показывает, что GMEM — это стек, предназначенный для конкуренции с CUDA/UVM от NVIDIA в области ИИ, а не общий инструмент виртуализации.


D. Вердикт: «Готовность к эксплуатации» только в рамках экосистемы openEuler для рабочих нагрузок ИИ


GMEM полностью готов к эксплуатации ("production ready"), но его сфера применения узко определена: повышение производительности ИИ и больших данных на платформе openEuler. Он не является и никогда не предназначался для того, чтобы быть общецелевым фреймворком управления памятью.


III. Центральный конфликт: Борьба GMEM за включение в Mainline-ядро и его статус


Этот раздел отвечает на вопросы о "статусе в mainline-ядре 2025" и "GMEM vs HMM". Он объясняет, почему GMEM изолирован от остальной части экосистемы Linux.


A. Расследование: RFC-патч GMEM 2023 года и его отклонение сообществом ядра


Примерно в ноябре 2023 года в список рассылки amd-gfx (связанный с разработкой драйверов AMD) был представлен RFC-патч (Request for Comments) для GMEM.2 Автор утверждал, что GMEM может упростить разработку для новых поставщиков ускорителей и мог бы "упростить реализацию AMDKFD", если бы существовал ранее.2


B. Глубокий технический анализ: Почему дизайн GMEM фундаментально конфликтует с управлением памятью в Mainline-ядре


Этот RFC-патч был встречен категорическим неприятием со стороны ведущих разработчиков ядра, в частности Кристиана Кёнига, известного разработчика подсистемы AMD GPU.
Ключевой аргумент Кёнига заключался в том, что "управление памятью ЦП и устройства абсолютно не должно смешиваться", и что "подобные идеи проваливались много раз" за последнее десятилетие.2
Этот конфликт носит фундаментальный архитектурный характер:
* Подход Mainline (HMM): Heterogeneous Memory Management (HMM) — это одобренный mainline-ядром подход. Он работает, представляя память устройства (например, VRAM) ядру ЦП как обычную системную память (путем создания фиктивных struct page для нее). Это позволяет существующим механизмам ЦП (таким как fork, swap и, теоретически, отслеживание грязных страниц KVM) "просто работать" с памятью устройства.
* Подход GMEM: GMEM делает обратное. Он не представляет память устройства ЦП; он привязывает управление памятью устройства непосредственно к виртуальному адресному пространству процесса ЦП 2 через такие механизмы, как MMAP_PEER_SHARED.10
Кёниг утверждал, что подход GMEM нарушает "мантру Linux о том, что все является файлом", и "плохо интегрируется с файловой системой", которая требует, например, блокировок страниц (page locks) при обратной записи, чего модель GMEM не учитывает.2


C. Миф о «статусе в Mainline-ядре 2025»: Отсутствие доказательств


Запрос пользователя о "GMEM" "mainline status" 2025 3 не дал абсолютно никаких релевантных результатов. Архивы Linux Kernel Mailing List (LKML) за 2024 и 2025 годы 3 и другие связанные списки 12 насыщены обсуждениями BPF, io_uring, RISC-V, AMD и Qualcomm, но о GMEM нет ни единого упоминания.
Это молчание оглушительно. После жаркого и окончательного идеологического отклонения в конце 2023 года 2, полное отсутствие GMEM в обсуждениях ядра в 2024 и 2025 годах доказывает, что RFC-патч провалился. Сообщество не стало его дорабатывать; оно его проигнорировало.
Вывод: GMEM не находится на пути к включению в mainline-ядро. "Статус в Mainline-ядре 2025" — не существует. openEuler решил поддерживать GMEM как внешний (out-of-tree) патч, по сути, создав форк подсистемы управления памятью для своих нужд.


D. Сравнительный анализ: GMEM против Heterogeneous Memory Management (HMM)


GMEM и HMM — это два конкурирующих и взаимоисключающих подхода к одной и той же проблеме.
* HMM — это одобренный mainline-ядром, хотя и чрезвычайно сложный путь. На него (и связанные с ним улучшения, такие как GPUVM и mmu_notifier) делают ставку AMD и сообщество ядра.2
* GMEM — это альтернативный путь, выбранный openEuler, который, по их мнению, проще для их вариантов использования (ИИ), но который, по мнению разработчиков mainline-ядра, игнорирует критические краевые случаи, такие как I/O и виртуализация.2


IV. Критическая точка отказа: Несовместимость GMEM с живой миграцией KVM/QEMU


Этот раздел напрямую отвечает на Категорию 2 запроса, используя выводы из Части III, чтобы объяснить, почему гипотеза о живой миграции неверна.


A. Анализ основной гипотезы пользователя: GMEM для живой миграции GPU


Запросы пользователя, составляющие основу этого аудита, были сосредоточены на "GMEM" "KVM" "QEMU" "live migration".7
Собранные материалы по этим запросам не дали ни одного положительного результата, связывающего GMEM с KVM.
* 15 обсуждает VSM (Virtual Secure Memory) на KVM Forum, что не имеет отношения к GMEM.
* 17 и 7 — это отчеты о сбоях, где упоминается QEMU, но они не связаны с GMEM. В 7 упоминается VM с именем "gmem-vm", что является случайным совпадением, а не использованием технологии.


B. Опровержение на уровне ядра: Почему виртуализация (KVM, QEMU, XEN) представляет собой основной недостаток дизайна в модели GMEM


Это критический вывод: GMEM не просто не поддерживает KVM; его дизайн активно мешает ему.
В своем публичном отклонении RFC-патча 2 Кристиан Кёниг специально назвал "QEMU, KVM, XEN" и "обработку виртуализации" в качестве "дизайнерской проблемы №1".
Он объяснил, что этим системам виртуализации не нужно, чтобы адресное пространство устройства отражало виртуальное адресное пространство хост-процесса QEMU (что является основой GMEM). Напротив, им нужен механизм для управления физическим адресным пространством гостя, которое сопоставлено с VRAM.
Проблема живой миграции GPU заключается в отслеживании "грязных" страниц внутри VRAM гостя. Модель HMM (с struct page для памяти устройства) создана для решения этой проблемы, позволяя расширить существующие механизмы отслеживания грязных страниц KVM. Модель GMEM (с MMAP_PEER_SHARED 10 в хост-процессе) полностью игнорирует эту проблему.
Автор GMEM в своем ответе 2 заявил, что "KVM... использует два разных MMU в одном адресном пространстве, что соответствует дизайну GMEM". Это заявление в лучшем случае вводит в заблуждение и демонстрирует непонимание (или намеренное игнорирование) основной проблемы миграции GPU, что еще раз подтверждает, что GMEM является тупиковым путем для этой цели.


C. Отсутствие доказательств: Отсутствие интеграции KVM/QEMU в openEuler


Даже в собственной документации openEuler 1 существует четкое административное разделение. Существует "Руководство пользователя по виртуализации", в котором упоминается "Живая миграция VM". И есть отдельная документация по GMEM, в которой упоминается "Обучение ИИ". Эти два раздела никогда не пересекаются. Библиотека libgmem 5 не имеет API для KVM.


D. Вывод: GMEM не является жизнеспособным путем для запрашиваемого варианта использования живой миграции


Гипотеза пользователя, лежащая в основе этого аудита, окончательно опровергнута. GMEM не имеет никакого отношения к живой миграции KVM и фундаментально несовместим с ней на архитектурном уровне.


V. Анализ внедрения в оборудовании и экосистеме (Перспектива на 2025 год)


Этот раздел отвечает на Категории 1 и 3, оценивая поддержку GMEM за пределами openEuler. Вывод — ее не существует.


A. Основные дистрибутивы (Red Hat, SUSE, Canonical): Нулевая поддержка


Запросы на внедрение GMEM в Red Hat, SUSE и Canonical не дали ни одного релевантного результата. Все найденные упоминания являются ложными срабатываниями.
* Red Hat: Нет упоминаний.
* SUSE: Результаты являются явными ложными срабатываниями. 6 — это старый CVE для функции "gmalloc". 18 — это упоминание "gmem" в контексте библиотеки glib. 7 — это отчет о сбое VM с именем хоста "gmem-vm". Ничто из этого не является технологией GMEM.
* Canonical (Ubuntu): Результаты являются еще более очевидными и окончательными ложными срабатываниями. 8 и 9 относятся к "GMEM BHK-21", что является "Glasgow Minimum Essential Medium" — средой для культивирования биологических клеток. 19 относится к "gmem" как сокращению от "global memory bank" в документации AMD Vitis (FPGA).
Тот факт, что наиболее релевантные результаты для "Canonical GMEM" относятся к биологии, является окончательным и неопровержимым доказательством того, что GMEM не имеет абсолютно никакого присутствия или поддержки в экосистеме Canonical/Ubuntu.


B. Драйверы производителей оборудования: NVIDIA и AMD: Активное неприятие


NVIDIA: Нет никаких свидетельств поддержки. Как отмечалось ранее, openEuler позиционирует GMEM как конкурента стеку NVIDIA (CUDA/UVM), утверждая о 60% приросте производительности.1 NVIDIA не имеет стимула поддерживать конкурирующий стек управления памятью.
AMD: Это самый убедительный случай.
1. Автор GMEM предложил свою технологию как способ упрощения драйвера AMD (AMDKFD).2
2. Кристиан Кёниг, который категорически отверг GMEM 2, является аффилированным с AMD разработчиком ядра и одним из ведущих специалистов по подсистеме AMD GPU.
Это не просто отсутствие поддержки со стороны AMD; это активное и публичное отклонение технологии ведущим разработчиком драйверов AMD. AMD явно придерживается mainline-подхода HMM/GPUVM. Следовательно, AMD никогда не будет поддерживать GMEM в своем mainline-драйвере AMDKFD/ROCm.


C. Вердикт по экосистеме: GMEM остается изолированной технологией


GMEM — это технологический остров. Он существует исключительно в рамках openEuler и не имеет мостов к mainline-ядру, основным дистрибутивам или основным производителям оборудования.


VI. Стратегическое заключение аудита и перспективные рекомендации




A. Итоговая оценка зрелости «Пути C-2» (GMEM)


"Путь C-2" (GMEM) является зрелым и готовым к эксплуатации, но только для узкоспециализированного варианта использования (обучение ИИ/HPC) в рамках изолированной экосистемы (openEuler).
* Он не является отраслевым стандартом.
* Он не находится на пути к включению в mainline-ядро в 2025 году или когда-либо еще.
* Он фундаментально непригоден для предполагаемой цели (живая миграция KVM/GPU) из-за дизайнерского решения, которое было явно отвергнуто сообществом разработчиков ядра Linux и производителями оборудования.


B. Рекомендуемый разворот: Альтернативные пути для живой миграции GPU


Расследование "Пути C-2" (GMEM) для этой цели должно быть немедленно прекращено. Оно основано на ложной предпосылке.
Будущие аудиты (например, "Этап 9") должны быть перенаправлены на исследование единственного жизнеспособного, хотя и сложного, пути: Heterogeneous Memory Management (HMM) и связанных с ним технологий в mainline-ядре (например, улучшений mmu_notifier и GPUVM). Именно там сосредоточены усилия AMD, NVIDIA (через HMM) и всего сообщества разработчиков ядра.


C. Анализ рисков продолжения исследования «Пути C-2»


Продолжение исследования GMEM для виртуализации несет три основных риска:
1. Риск изоляции: Принятие GMEM приведет к жесткой привязке к ядру openEuler, отрезая организацию от mainline-инноваций, патчей безопасности и более широкой экосистемы дистрибутивов и оборудования.
2. Риск поддержки: Организация будет нести 100% бремя поддержки несовместимого с mainline-ядром патча для сценария виртуализации, для которого его авторы даже не предназначили его.
3. Технологический тупик: Это путь в никуда. Он никогда не получит поддержки от KVM, QEMU, Red Hat, SUSE, Canonical, NVIDIA или AMD. Это стратегическая ошибка для любой цели, связанной с виртуализацией.
Источники
1. key-features | openEuler documentation | v24.09, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
2. [RFC PATCH 0/6] Supporting GMEM (generalized memory ..., дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
3. - Linux-kselftest-mirror - lists.linaro.org, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
4. By Author - Linux-Kernel Archive, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
5. openEuler/libgmem - Gitee, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
6. CVE-2017-9406 Common Vulnerabilities and Exposures | SUSE, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
7. CVE-2024-26976 Common Vulnerabilities and Exposures - SUSE, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
8. A Central Role for Canonical PRC1 in Shaping the 3D Nuclear Landscape - Edinburgh Research Explorer, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
9. Single-cell analysis of dup15q syndrome reveals developmental and postnatal molecular changes in autism - NIH, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
10. openEuler 23.09 Technical White Paper, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
11. openEuler 24.03 LTS SP2 Technical White Paper, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
12. By Author - Linux-Kernel Archive, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
13. Linux Plumbers Conference 2023 (13-15 November 2023) · Indico, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
14. Talks at Linaro Connect 2025 - Kite, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
15. Linux Plumbers Conference 2023 (13-15 November 2023) · Indico, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
16. Merlin's Schedule | Sessions | FOSSASIA Summit 2024 | eventyay, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
17. Updated software packages - Security Advisory Details | openEuler, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
18. MicroOS - openSUSE Mailing Lists, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
19. Mapping Kernel Ports to Memory - 2025.1 English - UG1700, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]