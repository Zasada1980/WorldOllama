Анализ технической осуществимости "Пути C": Современные подходы к открытой "живой" миграции GPU в средах KVM/QEMU (2024-2025 гг.)




I. Исполнительное Резюме: Оценка Технической Осуществимости «Пути C»




A. Подтверждение Директивы и Оценка «Серого Пути»


Настоящий отчет подготовлен в ответ на директиву о немедленном прекращении исследований «Серого Пути» (реверс-инжиниринг и взлом драйверов) и запуске «Пути C» — исследования технической осуществимости создания современного, открытого движка «живой» миграции GPU на принципах gMig.
Анализ текущего ландшафта (2024-2025 гг.) полностью подтверждает стратегическую целесообразность этого решения. Исследование показывает, что недавний прогресс в этой области, в частности, в Proxmox VE 8.4, представляет собой не открытую разработку, а интеграцию проприетарных API.1 Как показывают детали реализации, эта функциональность «живой миграции с опосредованными устройствами, такими как NVIDIA vGPU» 1 полностью зависит от поддержки проприетарных драйверов и лицензионных соглашений NVIDIA vGPU.1 Таким образом, «Серый Путь» остается тупиком «кошки-мышки», ведущим не к созданию независимого открытого решения, а к более глубокой интеграции с закрытыми технологиями.


B. Ключевой Вывод: Появление Двух Новых «C-Путей»


Исследование «Пути C» (gMig 2.0) выявило, что ландшафт 2024-2025 гг. предлагает не один, а два принципиально разных и жизнеспособных вектора для R&D. Оба вектора решают фундаментальную проблему оригинального gMig — «слепое» отслеживание состояния VRAM.
1. Путь C-1: Уровень Приложения (Компилятор/IR) — Проект HetGPU
Наиболее значимым открытием является академический проект HetGPU, представленный в июне 2025 г. (arXiv:2506.15993).4 Эта система представляет собой настоящий «gMig 2.0». Она реализует гетерогенную (NVIDIA/AMD/Intel) бинарную живую миграцию. Важно, что HetGPU решает проблему не на уровне гипервизора (как gMig), а на уровне компилятора и runtime, используя «механизм захвата/восстановления состояния» на уровне промежуточного представления (IR).5 Это позволяет приложению кооперативно сериализовать свое состояние, обходя необходимость в поддержке со стороны драйвера.
2. Путь C-2: Уровень Ядра (Гипервизор) — Фреймворк GMEM
Отвечая на запрос Категории 2, наше исследование показало, что Heterogeneous Memory Management (HMM), на который возлагались надежды, действительно устарел и признан «непопулярным» и «пораженным проблемами».7 Его истинным преемником является Generalized Memory Management (GMEM).9 Этот фреймворк, разрабатываемый в рамках openEuler (на базе ядра Linux 6.4+), предоставляет «единое виртуальное адресное пространство» и компонент «Remote Pager».7 Это именно те хуки ядра, которые необходимы для создания прозрачного (для приложений) механизма миграции на уровне хоста, позволяя гипервизору управлять VRAM как обычной памятью.


C. Оценка Категории 3 (AMD/Intel)


Анализ (Категория 3) показывает, что первоначальное предположение о простоте реализации живой миграции на открытых драйверах AMD/Intel в настоящее время ошибочно. Зрелые, открытые хуки для миграции полного состояния GPU (включая регистры и внутренние конвейеры) в стеках AMD ROCm 11 или Intel SR-IOV 12 отсутствуют. Эта задача не решена ни одним из вендоров в их открытых стеках.


D. Стратегическая Рекомендация


R&D-усилия должны быть немедленно перефокусированы. Рекомендуется разделить исследования на два параллельных направления:
   1. Краткосрочное (C-1): Немедленная и глубокая оценка кода проекта HetGPU 13 как наиболее многообещающего, готового к адаптации решения, способного обеспечить гетерогенную миграцию.
   2. Долгосрочное (C-2): Стратегическое R&D-исследование по созданию прототипа механизма миграции QEMU на базе фреймворка GMEM 7 как фундаментальной, прозрачной для приложений технологии будущего.


II. Анализ Ландшафта «gMig 2.0»: Существующие Решения (Категория 1)




A. Базовый Уровень 2018: gMig и Проблема «Слепого» Чекпоинтинга


Проект gMig (2018 г.) 14 был фундаментальной работой, которая доказала принципиальную возможность «живой» миграции GPU в средах полной виртуализации (KVM/QEMU) даже при использовании проприетарных драйверов. Его основной вклад заключался в демонстрации осуществимости захвата и восстановления полного состояния VRAM.
Однако ключевой проблемой gMig, которую должен решить любой «gMig 2.0», была его эвристическая и хрупкая природа. Не имея доступа к внутренним механизмам драйвера NVIDIA, gMig полагался на технику «Software Dirty Page».15 Этот механизм, по сути, «вслепую» отслеживал изменения в VRAM на уровне гипервизора, что было неэффективно и подвержено ошибкам при изменении версий драйвера. Любое современное решение должно заменить эту эвристику надежным механизмом отслеживания.


B. Находка 1: «Ложный Рассвет» — Proxmox 8.4 и Проприетарные Хуки NVIDIA


На первый взгляд, недавний релиз Proxmox VE 8.4 (ноябрь 2024 г.) является прямым ответом на запрос. В анонсах 1 прямо указано, что релиз, основанный на QEMU 9.2.0, включает «живую миграцию с опосредованными устройствами, такими как NVIDIA vGPU».
Однако углубленный анализ показывает, что это не открытое решение «Пути C». Во-первых, документация Proxmox указывает, что эта функция требует «поддержки оборудования и драйверов» и что «в настоящее время известно, что только GPU NVIDIA поддерживают живую миграцию».1 Во-вторых, эта функциональность полностью соответствует возможностям, предоставляемым проприетарным программным обеспечением NVIDIA vGPU 2 и требующим соответствующего лицензирования и конфигурации на хостах.3
Вывод: Proxmox 8.4 / QEMU 9.x не создали открытый механизм. Они интегрировали проприетарные API миграции, предоставляемые NVIDIA. Это подтверждает исходную директиву о том, что данный путь является коммерческим «Серым Путем», а не стратегической R&D-разработкой.


C. Находка 2: Истинный «gMig 2.0» — Проект HetGPU (arXiv: 2506.15993)


Наиболее значимым и прямым ответом на запрос Категории 1 является академический проект HetGPU, представленный в июне 2025 г..5 Это исследование (arXiv:2506.15993v1) описывает «новую систему, включающую компилятор, runtime и слой абстракции, которые вместе позволяют выполнять единый бинарный файл GPU на оборудовании NVIDIA, AMD, Intel и Tenstorrent».4
Ключевым для «Пути C» является то, что архитектура HetGPU изначально проектировалась с учетом «необходимости сериализации состояния для живой миграции» и включает «механизм захвата/восстановления состояния».4
В отличие от gMig, HetGPU решает проблему не на уровне гипервизора, а на уровне компилятора и бинарной трансляции. Это позволяет ему работать поверх любых драйверов (включая проприетарные) без их модификации. Важно, что проект имеет публичный репозиторий на GitHub (Multi-V-VM/hetGPU) 13, что делает его доступным для немедленной R&D-оценки и адаптации. HetGPU представляет собой наиболее прямое и современное воплощение «gMig 2.0».


D. Таблица 1: Сравнительный Анализ Подходов к Живой Миграции GPU (2018-2025)




Подход
	Механизм Захвата Состояния VRAM
	Механизм Захвата Состояния Ядра
	Открытый Исходный Код?
	Поддержка Вендоров
	Ключевая Зависимость
	gMig (2018) 15
	«Software Dirty Page» (Слепое отслеживание на хосте)
	Перехват API (эвристика)
	Да
	Только NVIDIA (взломанный)
	Хрупкость эвристики, версия драйвера
	NVIDIA vGPU 2
	Проприетарный хук драйвера
	Проприетарный хук драйвера
	Нет
	Только NVIDIA
	Проприетарные API и лицензии NVIDIA
	Proxmox 8.4 1
	Интеграция NVIDIA vGPU API
	Интеграция NVIDIA vGPU API
	Нет (Интеграция)
	Только NVIDIA
	Зависимость от NVIDIA vGPU 1
	HetGPU (2025) 4
	Кооперативная выгрузка (уровень IR)
	Кооперативная сериализация регистров (уровень IR) 5
	Да 13
	NVIDIA, AMD, Intel 4
	Компилятор HetGPU и runtime
	GMEM-based (Теор.)
	«Remote Pager» (Перехват Page Fault ядра) 7
	Не решено (требует доп. механизма)
	Да (Фреймворк)
	Агностик
	Ядро Linux 6.4+ с GMEM 8
	

III. Базовые Технологии (1): «Путь C-1» и Деконструкция HetGPU (Категория 2)




A. Смена Парадигмы: От «Слепого» Копирования к «Кооперативному» Захвату


Фундаментальная проблема gMig 15 заключалась в том, что гипервизор (хост) пытался «вслепую» угадать и скопировать состояние гостевого GPU. Проект HetGPU 4 полностью переворачивает эту модель. Он использует связку компилятора и runtime, чтобы приложение само сериализовало свое состояние в предсказуемых, безопасных точках.
Этот «кооперативный» подход устраняет необходимость в реверс-инжиниринге драйвера или наличии специальных хуков в ядре. Вместо того чтобы перехватывать вызовы CUDA или отслеживать страницы VRAM, HetGPU модифицирует само приложение на уровне промежуточного представления (IR) или бинарного кода, заставляя его выгружать свое состояние по внешнему триггеру.


B. Глубокий Анализ Механизма Захвата/Восстановления Состояния HetGPU


Детальный анализ 5 показывает, как HetGPU реализует этот механизм для гетерогенной миграции. Процесс разделен на захват (checkpoint) и восстановление (resume).


1. Захват (Checkpoint)


Процесс инициируется внешним вызовом (например, hetgpuCheckpoint()).
   1. Триггер: Runtime системы HetGPU устанавливает специальный pause_flag в глобальной памяти GPU.5
   2. Кооперативная Пауза: Компилятор HetGPU заранее вставляет в код GPU-ядра (на уровне hetIR) проверки этого флага. Эти проверки размещаются в стратегических точках, таких как «глобальные барьеры» или в каждой 'X' итерации цикла.5
   3. Выгрузка Состояния: Как только потоки GPU (warps) доходят до барьера и обнаруживают флаг, они сами выполняют код, который был внедрен компилятором. Этот код «копирует регистры в глобальную память» и либо переходит к выходу из ядра, либо ожидает.5
   4. Инструментарий (NVIDIA): Для проприетарных бинарных файлов NVIDIA, где прямое редактирование IR невозможно, HetGPU использует динамический инструментарий NVBit. NVBit позволяет «внедрять код в работающее ядро» в точках, соответствующих барьерам, заставляя его выполнить ту же операцию выгрузки регистров.5
   5. Инструментарий (AMD/Intel): На открытых платформах задача проще. Поскольку HetGPU контролирует IR, код выгрузки состояния (проверка флага, копирование регистров) просто встраивается в ядро на этапе компиляции.5
   6. Сбор Данных: После того как все потоки выгрузили свое состояние в глобальную память, runtime хоста копирует эти буферы состояния и содержимое VRAM на CPU, формируя полный снапшот.5


2. Восстановление (Resume)


Процесс восстановления (hetgpuRestore()) происходит на целевом GPU, который может быть от другого вендора.
   1. Сегментация Ядра: HetGPU рассматривает исходное ядро как серию «сегментов», разделенных барьерами. Миграция всегда происходит между сегментами.5
   2. Перезапуск: На целевом GPU запускается не исходное ядро, а специальное ядро-«возобновитель», соответствующее следующему сегменту.
   3. Загрузка Состояния: Это ядро принимает сохраненный снапшот (буферы с регистрами и VRAM) в качестве входных данных.
   4. «Контрабанда» Состояния (The "Smuggling" Trick): Ключевая проблема — как загрузить сохраненные значения обратно в регистры каждого потока. HetGPU использует общую (shared) память GPU. Запускается специальный пролог: один поток (или несколько) копирует данные из входного буфера снапшота в массив в shared памяти. После __syncthreads(), каждый поток читает свое значение из shared памяти и загружает его в свои приватные регистры. После этого ядро переходит к выполнению кода следующего сегмента.5
Этот механизм гениален в своей универсальности. Он решает проблему миграции на NVIDIA, не нарушая EULA (поскольку не модифицирует драйвер), и одновременно решает проблему на AMD/Intel, не дожидаясь, пока они реализуют недостающие хуки миграции.


IV. Базовые Технологии (2): «Путь C-2» и Эволюция API Ядра (Категория 2)




A. Технический Тупик: HMM (Heterogeneous Memory Management)


Запрос Категории 2 справедливо идентифицировал управление памятью как ключевую проблему gMig. Однако фокус на HMM, который был актуален в 2018-2020 гг., сегодня не оправдан. HMM был представлен в RHEL 7 как «Technology Preview» 19, но он так и не получил широкого распространения.
Современные (2024 г.) технические документы 7 прямо называют HMM «пораженным проблемами плохой программируемости, производительности и переносимости». Он также «непопулярен в большинстве сообществ ОС» и «сильно зависит от ручной настройки».
Вывод: HMM — мертвый путь. R&D-усилия не должны быть сосредоточены на нем.


B. Настоящий Преемник: GMEM (Generalized Memory Management)


Исследование выявило настоящего преемника HMM — GMEM (Generalized Memory Management).7 Этот фреймворк, активно развиваемый в openEuler (на базе ядра Linux 6.4+), позиционируется как «новая опция», решающая проблемы HMM.9
GMEM — это «централизованный механизм управления гетерогенными подключениями памяти».7 Его цель — «декоплировать реализации, связанные с CPU, от аппаратно-независимых механизмов управления памятью», позволяя драйверам регистрировать свои функции и передавая управление памятью ядру ОС.9
Ключевой механизм GMEM 7:
   1. Единое Виртуальное Адресное Пространство (UVA): GMEM объединяет адресные пространства ОС и ускорителя. Разработчикам больше не нужно вручную управлять миграцией данных.
   2. Флаг MMAP_PEER_SHARED: Для создания этого единого пространства GMEM добавляет в системный вызов mmap новый флаг MMAP_PEER_SHARED.7
   3. Remote Pager: Это ключевой компонент. Это «фреймворк взаимодействия» (реализованный как remote_pager.ko), который позволяет «мигрировать целевое пространство памяти между хостом и ускорителем с использованием процедуры обработки сбоев страниц (page fault) ядра».7 Он также позволяет прозрачно использовать DRAM хоста в качестве кэша для HBM ускорителя (memory overcommitment).21
Вывод: GMEM — это и есть тот фундаментальный API уровня ядра, который был нужен gMig. Он предоставляет гипервизору механизм для прозрачного управления VRAM гостя как обычной памятью, используя стандартные обработчики page fault для отслеживания «грязных» страниц. Это «Путь C-2» — создание прозрачного для приложений механизма миграции на уровне гипервизора.


C. Оценка vfio-pci и Хуков QEMU 9.x


Современные версии QEMU (9.x) 1 обладают развитой инфраструктурой миграции, включая миграцию состояния устройств vfio-pci. Однако анализ документации 12 показывает, что эта функциональность в основном ограничена сетевыми устройствами (например, Mellanox SR-IOV VF).
Документация Red Hat 12 прямо указывает, что живая миграция не поддерживается для:
   * Устройств SR-IOV (за исключением упомянутых сетевых карт).
   * Опосредованных устройств, таких как vGPU (за исключением проприетарного решения NVIDIA).
Текущие хуки vfio-pci 23 достаточны для миграции конфигурационного пространства PCI-устройства, но не для захвата его внутреннего рабочего состояния (содержимое регистров, кэшей, состояние конвейеров). Это подтверждает, что для миграции GPU требуется либо кооперативный подход уровня приложения (HetGPU), либо фундаментальный подход уровня управления памятью (GMEM).


D. Таблица 2: Оценка API Управления Памятью Ядра для Миграции GPU




API / Фреймворк
	Статус (2024-2025)
	Основной Механизм
	Ключевой Компонент для Миграции
	Пригодность для «gMig 2.0»
	HMM 7
	Устаревший / Проблемный
	Зеркалирование адресного пространства
	mmap / devm_memremap_pages
	Низкая. «Непопулярен», «плохая программируемость».8
	GMEM 9
	Активный / Развивающийся
	Единое виртуальное адресное пространство
	MMAP_PEER_SHARED 8, «Remote Pager» 7
	Высокая. Разработан для управления памятью ускорителей ядром, вкл. миграцию через page faults.7
	

V. Анализ Осуществимости у Конкретных Вендоров (Категория 3)


Запрос Категории 3 был основан на предположении, что открытые драйверы (AMD, Intel) облегчат задачу миграции по сравнению с закрытым стеком NVIDIA. Анализ показывает, что это предположение неверно.


A. Intel: Устаревание GVT-g и Пробел в SR-IOV


   * GVT-g: Технология Intel GVT-g (виртуализация на уровне ПО) действительно была открытой 28 и интегрирована в ядро Linux. Однако эта технология «устарела» (deprecated) 29 и не развивается.
   * SR-IOV: Нынешняя стратегия Intel — аппаратная виртуализация через SR-IOV.30 Однако, в отличие от сетевых адаптеров, для которых существуют решения по живой миграции 24, для графических VF (virtual functions) Intel такой механизм в открытом виде отсутствует. Документация Red Hat 12 явно исключает миграцию SR-IOV (кроме Mellanox) и vGPU (кроме NVIDIA) из поддерживаемых.
Вывод: Путь Intel в настоящее время является тупиком для открытой живой миграции.


B. AMD: Отсутствие Хуков Миграции в ROCm/AMDKFD


Анализ открытого стека AMD ROCm и драйвера ядра AMDKFD 11 не выявил никаких существующих или разрабатываемых механизмов, хуков или API, связанных с живой миграцией vGPU или passthrough в KVM.
Единственный обнаруженный связанный проект — gCROP 33 — упоминается как система для чекпоинтинга (не миграции) на GPU AMD. Однако в том же источнике отмечается, что он «требует значительных модификаций приложения» и «не поддерживает одновременный чекпоинт GPU». Это нежизнеспособное решение для универсальной живой миграции в KVM.
Вывод: Путь AMD в настоящее время является тупиком.


C. Гетерогенный Вывод


Предположение Категории 3 оказалось неверным. Проблема заключается не в лицензии на драйвер (открытый vs. закрытый), а в его архитектуре. Ни AMD, ни Intel не разработали свои открытые драйверы с учетом необходимости сериализации и восстановления полного внутреннего состояния GPU для целей миграции гипервизора.
Этот вывод делает проект HetGPU 4 еще более важным. Он был создан именно потому, что ни один из вендоров (включая тех, у кого открытые драйверы) не предоставляет необходимого универсального решения. HetGPU решает эту проблему для всех вендоров единым методом на уровне компилятора.


VI. Стратегические Рекомендации по Развитию «Пути C»


На основе проведенного анализа, ниже представлены стратегические рекомендации для R&D-отдела.


A. Рекомендация 1: Подтвердить Прекращение «Серого Пути» (Подтверждено)


Решение о прекращении исследований «Серого Пути» является верным. Ландшафт 2024-2025 гг. 1 показывает, что этот путь ведет только к проприетарной интеграции API NVIDIA, а не к созданию независимого открытого решения.


B. Рекомендация 2: Не Воссоздавать gMig (2018)


Оригинальный подход gMig («слепое» отслеживание VRAM через "Software Dirty Page" 15) технологически устарел. Проблема сместилась с дампинга состояния на уровне хоста на сериализацию состояния на уровне приложения/компилятора (Путь C-1: HetGPU) или управление состоянием на уровне ядра (Путь C-2: GMEM). R&D-усилия по воссозданию "Software Dirty Page" будут потрачены впустую.


C. Рекомендация 3: «Путь C-1» (Краткосрочный R&D) — Немедленная Оценка HetGPU


   * Действие: Выделить R&D-команду для немедленной загрузки, компиляции и оценки репозитория Multi-V-VM/hetGPU.13
   * Цель: Воспроизвести результаты статьи (arXiv:2506.15993).4 Провести глубокий аудит кода механизма захвата/восстановления.5 Оценить зрелость HetGPU и его пригодность для интеграции в существующий KVM/QEMU-стек. Это наиболее многообещающий и прямой «gMig 2.0».


D. Рекомендация 4: «Путь C-2» (Долгосрочный R&D) — Исследование GMEM


   * Действие: Выделить вторую, исследовательскую команду для работы с GMEM.7
   * Цель: Начать прототипирование нового механизма миграции QEMU, который использует GMEM (в частности, «Remote Pager» и MMAP_PEER_SHARED 8) для прозрачного управления и миграции VRAM гостевой ВМ. Это долгосрочная, высокорискованная, но стратегически важная ставка на создание прозрачного (не требующего модификации приложений) решения.


E. Рекомендация 5: «Путь Компромисса» (Оценка, не Разработка)


   * Действие: Отделу интеграции (не R&D) следует оценить готовое решение Proxmox 8.4 / QEMU 9.x 1, полностью осознавая, что это потребует проприетарного лицензирования NVIDIA vGPU 3 и не соответствует мандату «открытого исходного кода». Это «покупное» решение, а не «разрабатываемое».


F. Рекомендация 6: Де-приоритизация Категории 3


   * Действие: Немедленно прекратить все R&D-усилия, направленные на поиск или создание хуков миграции в существующих стеках AMD ROCm и Intel SR-IOV. Данные 29 однозначно показывают, что это тупик. Ресурсы должны быть перенаправлены на Рекомендации 3 и 4.
Источники
   1. Distribution Release: Proxmox 9.0 "Virtual Environment ..., дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   2. Virtual GPU Software User Guide - NVIDIA Docs, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   3. Configuring and managing virtualization | Red Hat Enterprise Linux | 9, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   4. HetGPU: The pursuit of making binary compatibility towards GPUs - arXiv, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   5. HetGPU: The pursuit of making binary compatibility towards ... - arXiv, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   6. [2506.15993] HetGPU: The pursuit of making binary compatibility towards GPUs - arXiv, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   7. openEuler 24.03 LTS SP2 Technical White Paper - 1 Introduction, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   8. openEuler 23.09 Technical White Paper, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   9. GMEM: Generalized OS Memory Management for Accelerators - Weixi Zhu, Huawei, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   10. Supporting GMEM (generalized memory management) for external memory devices - LWN.net, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   11. Hardware accelerators | OpenShift Container Platform | 4.18 - Red Hat Documentation, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   12. Chapter 12. Migrating virtual machines | Configuring and managing virtualization | Red Hat Enterprise Linux | 9, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   13. Yiwei Yang vickiegpt - GitHub, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   14. Cloud Computing and High Performance Computing (HPC) Advances for Next Generation Internet - MDPI, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   15. Fast and Scalable VMM Live Upgrade in Large Cloud Infrastructure - ResearchGate, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   16. Virtual GPU Software - NVIDIA Docs Hub, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   17. HetGPU: The pursuit of making binary compatibility towards GPUs - ResearchGate, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   18. Hetgpu: The Pursuit of Making Binary Compatibility Towards Gpus | PDF | Graphics Processing Unit | Computer Engineering - Scribd, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   19. 7.8 Release Notes | Red Hat Enterprise Linux | 7, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   20. Red Hat Enterprise Linux 7 7.8 Release Notes, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   21. Introduction to GMEM - openEuler Docs, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   22. Generalized Memory Management - openEuler, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   23. QEMU/KVM Virtual Machines - Proxmox VE, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   24. SR-IOV Live Migration - NVIDIA Docs, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   25. Chapter 5. Postinstallation configuration | Introduction to Virtualization | OpenShift Container Platform | 4.18 | Red Hat Documentation, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   26. Support Intel IGD(Integrated Graphics Device) passthrough · Issue #11338 - GitHub, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   27. 11.8. Using virtual functions (VFs) with DPDK and RDMA modes | Networking | OpenShift Container Platform | 4.5 | Red Hat Documentation, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   28. Analyzing GPU Performance in Virtualized Environments: A Case Study - MDPI, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   29. Intel i915 sr-iov mode for Flex 170 + Updated for Proxmox 9 PVE Kernel 6.14.8, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   30. How to Efficiently Share GPU Resources? - ZStack, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   31. Proxmox VE Administration Guide, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   32. 13th Gen Intel Framework Laptop internal GPU SR-IOV to Windows 11 via KVM+Looking Glass==Success!, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]
   33. PhoenixOS: Concurrent OS-level GPU Checkpoint and Restore with Validated Speculation, дата последнего обращения: ноября 7, 2025, [URL_REMOVED]