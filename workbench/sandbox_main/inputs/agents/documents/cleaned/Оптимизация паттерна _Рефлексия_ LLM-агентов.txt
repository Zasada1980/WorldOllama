Баланс между точностью и экономичностью: количественный анализ паттерна «Рефлексия» в производственных LLM-агентах




Краткий обзор


Проблема: Паттерн «Рефлексия», представляющий собой цикл «Генерация -> Критик», демонстрирует значительное повышение надежности и точности LLM-агентов. Однако он сопряжен со значительными издержками, включая увеличение задержки и стоимости API-вызовов, что вступает в противоречие с производственными принципами эффективности и экономичности.1
Основной вывод: Универсальное применение рефлексии неэффективно. Оптимальный подход заключается в условном вызове критика, где экономичные валидаторы выступают в роли «стражей», контролирующих доступ к дорогостоящему процессу рефлексии.
Ключевые решения: Готовые к производству архитектуры используют детерминированные инструменты (например, статические анализаторы кода), динамическую маршрутизацию агентов, каскады LLM (использование более дешевых моделей для предварительных проверок) и ансамбли из нескольких агентов-критиков для управления компромиссом между затратами и качеством.3
Количественное воздействие: В то время как рефлексия может повысить точность на 10–30% и более в сложных задачах 2, стратегическое внедрение позволяет смягчить связанное с этим двукратное или трехкратное увеличение затрат, достигая высокого качества без ущерба для масштабируемости.
Стратегическая рекомендация: Выбор стратегии рефлексии должен быть адаптирован к конкретным требованиям приложения, таким как допустимый уровень ошибок, задержки и затрат. Спектр решений варьируется от полного отсутствия рефлексии для чат-ботов в реальном времени до сложных систем с несколькими критиками для аналитических задач с высокими ставками.
________________


Раздел 1: Таксономия архитектур самокоррекции




1.1 Основополагающий паттерн: Генерация, Рефлексия, Уточнение


В основе самокоррекции лежит паттерн «Рефлексия» — итеративный цикл генерации, самооценки и уточнения.2 Этот подход позволяет перевести поведение LLM с реактивного, инстинктивного мышления «Системы 1» на более методичный и обдуманный процесс «Системы 2».1 Цикл состоит из трех основных этапов:
1. Генерация: Агент-генератор создает первоначальный результат.
2. Рефлексия: Агент-критик (или рефлектор) оценивает этот результат на соответствие определенным критериям.
3. Уточнение: Полученная обратная связь используется для улучшения результата в последующих итерациях.8
Этот процесс является фундаментальным для агентного ИИ, поскольку он обеспечивает возможность исправления ошибок и постепенного улучшения качества.2


1.2 Глубокий анализ фреймворков: от простых циклов до сложных агентов


Паттерн «Рефлексия» — это не единая техника, а целый спектр архитектур с различной сложностью, стоимостью и возможностями.
* Self-Refine: Этот фреймворк представляет собой простейшую форму, в которой одна и та же LLM выступает в роли генератора, поставщика обратной связи и уточнителя в рамках одного цикла.9 Он является легковесным, не требует дополнительных моделей или обучающих данных и полагается на few-shot prompting для управления этапами обратной связи и уточнения.
* Reflexion: Этот фреймворк вводит концепцию «вербального обучения с подкреплением», где обратная связь преобразуется в лингвистические резюме, которые сохраняются в буфере эпизодической памяти.7 Он четко разделяет роли Исполнителя (Actor), который генерирует действия, Оценщика (Evaluator), который оценивает результат, и модели Саморефлексии (Self-Reflection), которая генерирует вербальные подсказки для следующей попытки. Такой структурированный подход делает его высокоэффективным для задач, требующих обучения методом проб и ошибок, таких как программирование и последовательное принятие решений.14
* CRITIC (Critique-Guided Improvement): Этот фреймворк делает акцент на использовании внешних инструментов для обоснования процесса критики.2 Агент взаимодействует с инструментами (например, поисковыми системами, интерпретаторами кода) для проверки собственных результатов, генерируя структурированную критику на основе внешней обратной связи.19 Это делает его особенно мощным для исправления фактических неточностей и логических ошибок, когда внутренних знаний модели недостаточно. Фреймворк часто использует двухкомпонентную модель «актер-критик», где критик специально обучен предоставлять детализированную и действенную обратную связь.19


1.3 Систематическая классификация


Основываясь на исследовании CorrectBench 18, можно классифицировать эти методы по трем основным категориям, что позволяет структурированно подходить к оценке их стоимости и сложности:
* Внутренняя коррекция (Intrinsic Correction): Полагается исключительно на внутренние знания LLM для выявления и исправления ошибок (например, базовый Self-Refine, самокоррекция без инструментов).18 Это самый дешевый метод, но он ограничен имеющимися у модели знаниями и не может исправить, например, фактические галлюцинации, требующие внешней проверки.
* Внешняя коррекция (External Correction): Использует внешние ресурсы, такие как инструменты, API или базы знаний, для проверки и исправления результатов (например, CRITIC, Reflexion с инструментами).18 Этот метод более мощный, но влечет за собой дополнительные затраты и задержки, связанные с вызовами инструментов.
* Коррекция с помощью дообучения (Fine-tuned Correction): Включает дообучение модели специально на задачах исправления ошибок.18 Этот подход может быть очень эффективным, но требует значительных объемов обучающих данных и вычислительных ресурсов, что делает его наиболее затратным на начальном этапе.
Эволюция от простых циклов (Self-Refine) к агентам с дополненной памятью (Reflexion) и критикам, основанным на инструментах (CRITIC), отражает более широкую тенденцию в ИИ: переход от статической, одношаговой генерации к динамическим, состоянийным процессам рассуждений, которые более точно имитируют человеческое решение проблем. Это означает, что управление состоянием и интеграция инструментов (например, с помощью фреймворков, таких как LangGraph) становятся ключевой компетенцией для создания продвинутых систем ИИ.


Раздел 2: Определение границы качества и производительности: анализ бенчмарков самокоррекции




2.1 Обзор бенчмарков: измерение влияния рефлексии


Для оценки эффективности самокоррекции были разработаны специализированные бенчмарки. Наиболее известным является CorrectBench, который систематически оценивает внутренние, внешние и дообученные методы в задачах на здравый смысл, математические рассуждения и генерацию кода.18 Другой важный бенчмарк — Self-Correction Bench, который использует контролируемое внедрение ошибок для изучения феномена «слепого пятна самокоррекции», показывая, что LLM лучше справляются с исправлением внешних ошибок, чем своих собственных.26 Стандартные бенчмарки, такие как HumanEval (программирование), HotPotQA (рассуждения) и AlfWorld (принятие решений), также используются для демонстрации значительного прироста производительности фреймворков, таких как Reflexion.2


2.2 Эмпирические результаты: синтез прироста производительности


* Основные улучшения: Фреймворки рефлексии стабильно демонстрируют значительный прирост качества. Например, Reflexion достиг точности 91% (pass@1) на HumanEval, превзойдя передовой базовый показатель GPT-4 в 80%.2 Self-Refine показал среднее улучшение примерно на 20 абсолютных процентных пунктов в семи различных задачах, что было подтверждено как человеческими оценками, так и автоматическими метриками.2 Фреймворк CRITIC повысил точность на 10–30% в различных задачах.2
* Зависимость от задачи: Результаты CorrectBench показывают, что самокоррекция наиболее эффективна для сложных задач, требующих рассуждений.18 Для более простых задач, где базовая модель и так показывает высокую точность, прирост менее выражен.
* Закон убывающей отдачи: Исследования фреймворка Reflexion выявили феномен, названный «ранней остановкой рефлексии» (Early Stop Reflection), когда наиболее значимые улучшения происходят на начальных итерациях.29 Последующие циклы рефлексии часто приводят к повторяющимся или бесполезным советам, что ведет к выходу производительности на плато. Это говорит о том, что один хорошо выполненный шаг рефлексии может обеспечить наилучшее соотношение затрат и выгод.
* Значение возможностей модели: CorrectBench также показал, что высокопроизводительные LLM для рассуждений (например, DeepSeek-R1) демонстрируют ограниченное улучшение от дополнительной самокоррекции, при этом неся высокие временные затраты.18 Это означает, что по мере роста мощности базовых моделей предельная полезность простых паттернов рефлексии может снижаться.


Таблица 2.1: Сравнительная производительность фреймворков самокоррекции


Фреймворк
	Бенчмарк/Задача
	Метрика
	Базовая производительность
	Производительность после рефлексии
	Абсолютное улучшение (%)
	Типичные затраты
	Reflexion
	HumanEval
	pass@1 Точность
	80% (GPT-4)
	91%
	11%
	1-3 итерации
	Reflexion
	AlfWorld
	Успешность выполнения
	~70% (ReAct)
	92%
	22%
	12 итераций
	Reflexion
	HotPotQA
	Точность
	~30% (ReAct)
	50%
	20%
	1-2 итерации
	Self-Refine
	Различные задачи
	Предпочтения человека
	(Базовый уровень)
	Улучшение на ~20%
	~20%
	1-2 итерации
	CRITIC
	Различные задачи
	Точность
	(Базовый уровень)
	Улучшение на 10-30%
	10-30%
	+1 вызов LLM и вызовы инструментов за итерацию
	Примечание: Данные синтезированы из нескольких источников 2 и могут варьироваться в зависимости от конкретной модели и конфигурации.
Данные показывают, что эффективность рефлексии нелинейна. Она следует кривой убывающей отдачи, где первые одна-две итерации приносят наибольшую пользу. Это наблюдение меняет стратегический фокус для производственных систем. Вместо создания сложных, многоитерационных циклов рефлексии, внимание следует уделить разработке высокоэффективного одного шага рефлексии. Этот единственный шаг должен запускаться условно, чтобы максимизировать соотношение его влияния к затратам. Цель — не бесконечное уточнение, а целенаправленная, высокоэффективная коррекция.


Раздел 3: Производственная дилемма: анализ полной стоимости рефлексии




3.1 Прямые затраты: API-вызовы и задержка


Фундаментальная стоимость рефлексии заключается в том, что она по своей сути умножает количество API-вызовов. Один цикл «генерация-критика-уточнение» превращает один вызов LLM как минимум в два или три.1 Это напрямую влияет на задержку. Для приложений, требующих ответа в реальном времени, таких как чат-боты, эта дополнительная задержка может быть неприемлемой.1 Например, генерация, занимающая 500 мс, с рефлексией превращается в процесс длительностью 1500+ мс.


3.2 Совокупные затраты: разрастание траектории и эскалация токенов


Критически важной, но часто упускаемой из виду проблемой является «разрастание траектории» (trajectory bloat).31 В агентных рабочих процессах контекст (история мыслей, действий и наблюдений) растет с каждым шагом. Каждый цикл рефлексии добавляет в этот контекст результат генератора и обратную связь критика. Это означает, что не только увеличивается количество API-вызовов, но и каждый последующий вызов обрабатывает большее количество входных токенов, делая их все более дорогими и медленными.31
Исследование AgentDiet предоставляет количественные данные по этой проблеме, показывая, что бесполезная, избыточная или устаревшая информация широко распространена в траекториях агентов, и что сокращение этой траектории может уменьшить количество входных токенов на 40-60% без ущерба для производительности.31 Это подтверждает серьезность проблемы затрат и указывает на то, что стоимость рефлексии нелинейна, а имеет тенденцию к экспоненциальному росту в многошаговых задачах.


3.3 Скрытые затраты: «слепое пятно самокоррекции» и неэффективная обратная связь


Рефлексия не гарантирует улучшения. Феномен «слепого пятна самокоррекции» показывает, что LLM систематически не могут исправить ошибки в собственном выводе, которые они легко обнаруживают во внешнем тексте.26 Это означает, что плохо спроектированные циклы рефлексии могут повлечь за собой полные затраты, не принося никакой пользы.
Решение оказалось тонким: оно заключается в активации способности к самокоррекции. Было обнаружено, что простое добавление маркера, такого как «Wait», снижает количество «слепых пятен» на 89.3%.27 Это подчеркивает, что инженерия промптов для этапа критики нетривиальна и несет в себе скрытые «затраты на проектирование». Более того, без надлежащего руководства (например, внешних инструментов или структурированной обратной связи) генерируемая обратная связь может быть общей или бесполезной, что приводит к пустым циклам.32
Таким образом, ценность рефлексии не является врожденным свойством LLM, а раскрывается благодаря архитектуре цикла обратной связи. Способ формулирования и представления обратной связи модели так же важен, как и сам акт рефлексии. Это означает, что инженерные усилия должны быть сосредоточены на разработке эффективных «персон» критиков и триггеров активации, а не просто на создании наивного цикла.


Раздел 4: Готовые к производству архитектуры для экономичной рефлексии




4.1 Подтверждение гипотезы: условная рефлексия с помощью детерминированных валидаторов


Этот паттерн является самым прямым решением проблемы, поставленной в запросе. Он предполагает использование быстрого, дешевого и детерминированного инструмента для проверки вывода генератора перед тем, как принять решение о вызове дорогостоящего LLM-критика.
Пример: Валидация кода с помощью Pyright.3
* Архитектура: Агент на основе графа (реализованный в LangGraph) следует условному потоку:
   1. Основной агент генерирует код на Python.
   2. Результат передается в узел критики.
   3. Этот узел запускает Pyright, статический анализатор типов. Это локальный, не-LLM, детерминированный процесс — чрезвычайно быстрый и дешевый.
   4. Условный переход: Если Pyright не находит ошибок, процесс завершается. Если он находит ошибки, отчет о них форматируется в новое пользовательское сообщение и отправляется обратно основному агенту для следующей попытки.
* Значение: Это идеальное воплощение принципа Бритвы Оккама. Дорогостоящий LLM-критик используется только тогда, когда дешевый валидатор доказывает, что результат ошибочен.


4.2 Динамическая маршрутизация и каскады LLM


Этот паттерн использует LLM в качестве «маршрутизатора» для принятия решения о том, какого агента или модель вызвать следующей, обеспечивая более гибкое и интеллектуальное управление, чем фиксированное детерминированное правило.
Пример: SelectorGroupChat в AutoGen.4
* Неэффективный базовый вариант: RoundRobinGroupChat, где основной_агент и агент_критик безусловно сменяют друг друга. Критик вызывается всегда, что неэффективно.
* Оптимизированная архитектура: SelectorGroupChat использует LLM для выбора следующего «спикера» на основе истории диалога и описаний агентов. Это позволяет системе вызывать агента_критика только тогда, когда контекст предполагает необходимость проверки, или когда основной_агент завершил значительную часть работы.
Каскады LLM 6 являются мощным подпаттерном для динамической маршрутизации.
* Архитектура:
   1. Агент-генератор создает результат.
   2. Результат сначала отправляется агенту-критику 1-го уровня, работающему на небольшой, быстрой и дешевой модели (например, Llama-3-8B, Gemini-Flash). Этот критик обрабатывает простые, очевидные ошибки.
   3. Если критик 1-го уровня не находит проблем или помечает проблему как «сложную», результат передается агенту-критику 2-го уровня, работающему на флагманской модели (например, GPT-4o, Claude 3.7 Sonnet) для более детального анализа.
* Значение: Этот подход следует правилу 80/20, используя дешевые ресурсы для решения большинства простых проблем и сохраняя дорогие ресурсы для критически важных задач. В одном из исследований многоагентная система достигла снижения затрат на 94.2% при одновременном повышении успешности по сравнению с одним агентом на базе GPT-4, используя такой каскадный подход.34


4.3 Ансамбли из нескольких агентов-критиков


Вместо одного монолитного критика этот паттерн декомпозирует задачу критики на несколько специализированных ролей.
Пример: Специализированные агенты-рецензенты.5
* Архитектура:
   1. Агент-писатель генерирует пост для блога.
   2. Черновик отправляется параллельно трем агентам-специалистам: SEO-рецензенту, юридическому рецензенту и этическому рецензенту. Каждый из них — это более дешевая LLM с узкоспециализированным системным промптом и, возможно, специализированными инструментами.
   3. Мета-рецензент агрегирует их обратную связь.
   4. Агрегированная критика отправляется обратно агенту-писателю для доработки.
* Значение: Этот подход предлагает два преимущества: параллелизацию, которая может сократить общую задержку по сравнению с последовательной проверкой одним критиком, и специализацию, которая позволяет использовать меньшие, дообученные или сильно настроенные дешевые модели, способные превзойти дорогую модель общего назначения в узких задачах.
Все эти паттерны — детерминированные валидаторы, динамическая маршрутизация, каскады и ансамбли — являются реализациями одного мощного принципа: интеллектуального шлюзования (intelligent gating). Основная идея заключается в том, чтобы разместить дешевый и быстрый «шлюз» перед дорогим и медленным ресурсом, чтобы гарантировать, что этот ресурс используется только тогда, когда его мощность действительно необходима. Необходимость в таких сложных, условных рабочих процессах объясняет рост популярности фреймворков, таких как LangGraph.1 Простые линейные цепочки недостаточны для создания производственных, экономически эффективных агентов. Будущее агентного ИИ лежит в состоянийных, графовых архитектурах, которые могут управлять сложными потоками управления, условной логикой и взаимодействиями между гетерогенными агентами и инструментами.


Раздел 5: Стратегические рекомендации и план внедрения




5.1 Система принятия решений для выбора стратегии рефлексии


Выбор архитектуры рефлексии не является абсолютным, а зависит от конкретных требований приложения. Ключевые факторы, которые следует учитывать:
* Сложность задачи: Требует ли задача простой генерации или сложных, многошаговых рассуждений? (Высокая сложность говорит в пользу более сильной рефлексии).
* Допустимость ошибок: Являются ли ошибки неудобством (например, в чат-боте) или критическим сбоем (например, в медицинской диагностике, финансовом анализе)? (Низкая допустимость требует рефлексии).
* Бюджет задержки: Приложение работает в реальном времени или асинхронно? (Низкий бюджет задержки ограничивает возможности рефлексии).
* Чувствительность к затратам: Является ли приложение высоконагруженным сервисом с низкой маржой или низкообъемным, но высокоценным? (Высокая чувствительность к затратам требует эффективной рефлексии).
* Наличие валидаторов: Существуют ли дешевые, детерминированные валидаторы для задачи (например, статические анализаторы кода, валидаторы JSON-схем)? (Их наличие делает условную рефлексию очень привлекательной).


Таблица 5.1: Матрица принятия решений для выбора стратегии рефлексии


Архетип приложения
	Типичная допустимость ошибок
	Бюджет задержки
	Оптимальная стратегия рефлексии
	Обоснование / Ключевые соображения
	Чат-бот в реальном времени
	Высокая
	Низкий
	Отсутствует или условная (по флагу пользователя)
	Задержка является первостепенной; рефлексия применяется только для явно помеченных пользователем ошибок.
	Генерация контента (например, посты в блогах)
	Средняя
	Высокий
	Каскад LLM или ансамбль критиков
	Качество важно, но не критично. Каскад с дешевой моделью для базовых правок и дорогой для стилистики является сбалансированным решением.
	Ассистент по генерации кода
	Низкая
	Средний
	Условная (детерминированный валидатор)
	Корректность кода имеет решающее значение. Использование статического анализатора (например, Pyright) в качестве шлюза является высокоэффективным.
	Анализ данных с высокими ставками
	Очень низкая
	Высокий
	Полная (ансамбль из нескольких агентов)
	Точность имеет первостепенное значение. Затраты на многоагентную проверку (например, статистическую, логическую, доменную) оправданы.
	

5.2 План внедрения: лучшие практики


* Промптинг критика: Промпт критика имеет решающее значение. Он должен устанавливать четкую персону (например, «Вы — старший юрисконсульт, проверяющий договор на соответствие нормам»), предоставлять конкретные, действенные критерии критики и избегать общих отзывов.5 Исследование «слепого пятна самокоррекции» 26 показывает, что формулирование критики как внешней оценки более эффективно.
* Управление состоянием и памятью: Используйте состоянийный графовый фреймворк, такой как LangGraph, для управления потоком и сохранения истории диалога.1 Для фреймворков, подобных Reflexion, убедитесь, что рефлексии сохраняются в доступном буфере памяти для информирования будущих попыток.14
* Определение условий завершения: Циклы должны иметь четкие критерии выхода для предотвращения бесконечных (и дорогостоящих) итераций. Это может быть фиксированное количество итераций 35, явный сигнал одобрения от критика (например, ответ «APPROVE», как в примере AutoGen 4) или успешное прохождение валидатора.3
* Наблюдаемость (Observability): Внедрите надежное логирование и мониторинг для отслеживания затрат, задержек и показателей успешности для каждого компонента архитектуры рефлексии. Это необходимо для постоянной оптимизации.6
Источники
1. Reflection Agents - LangChain Blog, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
2. Agentic AI from First Principles: Reflection | Towards Data Science, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
3. langchain-ai/langgraph-reflection - GitHub, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
4. Teams — AutoGen - Microsoft Open Source, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
5. AI Agents with Reflection: Outperform Top LLMs in Performance and Work Offline, Reducing TCO - Prasun Mishra, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
6. How to reduce 78%+ of LLM Cost - AI Jason, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
7. Reflexion: Language Agents with Verbal Reinforcement Learning - Princeton University, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
8. What is Agentic AI Reflection Pattern? - Analytics Vidhya, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
9. Self-Refine: Iterative Refinement with Self-Feedback, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
10. (PDF) Self-Refine: Iterative Refinement with Self-Feedback - ResearchGate, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
11. Reflexion Pattern — agent-patterns 0.1.1 documentation, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
12. Self-Refine: Iterative Refinement with Self-Feedback, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
13. [2303.17651] Self-Refine: Iterative Refinement with Self-Feedback - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
14. Reflexion | Prompt Engineering Guide, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
15. [2303.11366] Reflexion: Language Agents with Verbal Reinforcement Learning - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
16. Reflexion: Language Agents with Verbal Reinforcement ... - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
17. [NeurIPS 2023] Reflexion: Language Agents with Verbal Reinforcement Learning - GitHub, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
18. Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
19. The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
20. Enhancing LLM Agents via Critique-Guided Improvement - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
21. [2503.16024] The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
22. Can LLMs Correct Themselves? A Benchmark of Self ... - OpenReview, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
23. Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
24. [2510.16062] Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
25. Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs | Cool Papers, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
26. [R] Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs - Reddit, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
27. Revealing and Addressing the Self-Correction Blind Spot in LLMs - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
28. London AI4Code: "Reflexion: Language Agents with Verbal Reinforcement Learning" with Noah Shinn - Luma, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
29. DORA: Dynamic Optimization Prompt for Continuous Reflection of LLM-based Agent - ACL Anthology, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
30. Trade-offs in LLM Benchmarking: Speed vs. Accuracy - Latitude, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
31. Improving the Efficiency of LLM Agent Systems through Trajectory Reduction - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
32. When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs - ACL Anthology, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
33. When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs | Transactions of the Association for Computational Linguistics, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
34. A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks - arXiv, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
35. Reflection - GitHub Pages, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
36. LangGraph — Architecture and Design | by Shuvrajyoti Debroy | Medium, дата последнего обращения: октября 31, 2025, [URL_REMOVED]
37. LangChain/LangGraph: Build Reflection Enabled Agentic | by TeeTracker - Medium, дата последнего обращения: октября 31, 2025, [URL_REMOVED]