Расширенное Архитектурное Обоснование Недоступности Функции "Импортировать Код" в Управляемых Средах AI Агентов




I. Исполнительное Резюме: Неотъемлемая Роль Безопасности в Архитектуре AI Агентов


Невозможность использования функции прямого импорта кода в настройках AI-агента, особенно при развертывании в корпоративных облачных средах, таких как Azure AI Foundry или OpenAI Assistants API, представляет собой не техническое ограничение, а фундаментальный, намеренно внедренный принцип проектирования систем безопасности (Security-by-Design). Этот подход строго соответствует современной концепции Zero Trust и является обязательным требованием для масштабируемых и регулируемых отраслей, включая EdTech, к которой относится репозиторий Zasada1980/Pedagogical-AI-Agent.1
Прямая загрузка и исполнение произвольного пользовательского кода (Remote Code Execution, RCE) представляет критически неприемлемый вектор атаки, который угрожает целостности платформы, изоляции между клиентами и, что наиболее важно, конфиденциальности чувствительных данных студентов (PII).2 Таким образом, платформа принудительно устанавливает архитектурный барьер, требуя, чтобы вся пользовательская бизнес-логика была развернута как внешний, строго типизированный и аутентифицированный сервис.
Ключевой Вывод: Недоступность "импорта кода" означает, что разработчик должен мигрировать от локального паттерна "сценариев" (скриптового кода) к корпоративному паттерну "инструментов как сервисов" (Tools-as-a-Service). Это требует инкапсуляции функциональности, содержащейся в GitHub репозитории Zasada1980, в строго типизированные, внешне развернутые RESTful API, описанные через спецификацию OpenAPI 3.0, или в Serverless-функции, такие как Azure Functions.3 Ядро агента должно лишь вызывать код через сетевой интерфейс, но никогда не исполнять его напрямую.


II. Контекстный Анализ: От Сценария EdTech до Корпоративного Развертывания




A. Функциональные Требования Педагогического AI Агента


Проект Pedagogical-AI-Agent требует высокой степени сложности, характерной для корпоративных приложений EdTech. Базовый чат-интерфейс недостаточен; необходим AI, который может интегрироваться с существующими институциональными системами, обрабатывать многошаговые процессы и принимать контекстуальные решения.1
Функциональность агента в образовательной сфере включает:
1. Интеграция с Институциональными Системами (LMS/SIS): Для предоставления персонализированного руководства студенту, например, при ответе на вопрос “Какие курсы мне следует выбрать?”, агент должен выполнять комплексные задачи. Они включают получение доступа к академическим стенограммам, проверку выполнения предварительных требований, подтверждение соответствия требованиям для выпуска и анализ потенциальных конфликтов расписания.1 Эта необходимость в доступе к частной, защищенной информации диктует требования к безопасности и аутентификации, которые невозможно удовлетворить через произвольный, импортированный скрипт.5
2. Многошаговые Рабочие Процессы: Задачи, такие как планирование учебной программы или детальная обратная связь, требуют последовательного выполнения нескольких действий: анализ текущего прогресса, выявление оставшихся требований, предложение последовательностей курсов и обновление рекомендаций по мере принятия решений студентами.1 Такие рабочие процессы требуют стабильного, масштабируемого вызова внешней бизнес-логики, которая должна быть изолирована от самого LLM-ядра.
3. Переход от Прототипа к Производственной Архитектуре: Репозиторий Zasada1980/Pedagogical-AI-Agent 6, вероятно, содержит код, разработанный с использованием гибких Python-фреймворков для создания агентов, таких как LangChain, LangGraph или CrewAI.7 В этих средах разработчик часто вызывает Python-функции напрямую. Однако при переносе этого кода в управляемую корпоративную среду, предназначенную для обслуживания "тысяч concurrent users" 9, этот локальный паттерн прямого исполнения кода становится архитектурно нежизнеспособным, так как он нарушает модель безопасности и масштабируемости платформы. Платформа принуждает к использованию безопасных, стандартизированных методов интеграции, которые гарантируют надежность, необходимую для EdTech-приложений.


B. Архитектурное Различие: "Исполнение Кода" vs. "Вызов Функции"


В управляемых AI-платформах существует строгое архитектурное разделение между двумя основными механизмами, позволяющими агенту взаимодействовать с кодом, и ни один из них не соответствует концепции "импорта кода" в настройках агента.
1. Code Interpreter / Sandbox (Вычисления): Это инструмент, который позволяет крупной языковой модели (LLM) генерировать и выполнять Python-код внутри строго изолированной, временной, безсетевой вычислительной песочницы.10 Цель этого инструмента — выполнение математических операций, анализ данных или отладка кода, сгенерированного самим LLM.12 Важно, что этот код генерируется моделью в ответ на запрос, а не загружается пользователем как часть конфигурации агента.
2. Custom Functions / Tools (Интеграция): Это основной механизм для интеграции бизнес-логики. Он позволяет агенту вызывать внешний, предварительно развернутый сервис (API) для выполнения конкретных задач, таких как взаимодействие с базами данных или отправка сообщений.3 Этот метод использует спецификацию OpenAPI для описания интерфейса внешнего сервиса, обеспечивая предсказуемость, аутентификацию и сетевую изоляцию.
Проблема, с которой сталкивается пользователь, заключается в непонимании этого фундаментального перехода: корпоративная архитектура требует, чтобы код, разработанный для интеграции с внешними системами (SIS/LMS) 1, был вынесен из ядра агента, инкапсулирован в микросервис и описан через OpenAPI. Это необходимо для того, чтобы платформа могла управлять безопасностью, масштабированием и сетевыми политиками этого кода, который теперь является внешним "инструментом".


III. Корневая Причина: Архитектура Безопасности и Governance


Невозможность прямого импорта кода является ключевым элементом стратегии платформенной безопасности, направленной на предотвращение критических угроз и обеспечение корпоративного управления (Governance).


A. Угроза Удаленного Выполнения Кода (RCE) как Критический Вектор


Прямой импорт кода в управляемую среду агента немедленно создал бы серьезную уязвимость RCE. Если бы платформа разрешила загрузку произвольного Python-скрипта из репозитория Zasada1980, злоумышленник мог бы получить возможность выполнить команды операционной системы хоста или получить неконтролируемый доступ к облачным ресурсам.
1. Нарушение Изоляции Клиентов (Tenant Separation): В многопользовательской облачной среде, где агенты разных клиентов работают на одной и той же инфраструктуре, прямой RCE может позволить злоумышленнику преодолеть границы изоляции и получить доступ к данным или ресурсам других клиентов.
2. Несанкционированный Доступ к PII: В контексте образовательных технологий 1, импортированный код мог бы быть использован для несанкционированного доступа к конфиденциальным базам данных (PII), содержащим студенческие записи и успеваемость, что является критическим нарушением соответствия нормативным требованиям.2 В отличие от кода, генерируемого LLM для Code Interpreter, импортированный пользовательский код является неконтролируемой угрозой, и платформа не может гарантировать его безопасность.
3. Принуждение к Внешней Аутентификации: Требование использовать внешние REST API с аутентификацией, как упоминается в контексте Oracle Cloud, где требуется присвоение привилегии ORA_FND_TRAP_PRIV для использования внешних инструментов 14, подтверждает: вызов кода должен быть привилегированным, контролируемым действием, а не встроенной функцией.


B. Корпоративное Управление (Governance) и Соответствие Нормативным Требованиям


Корпоративные платформы, такие как Azure AI Foundry, внедряют архитектурные требования, которые обеспечивают безопасность на уровне предприятия, делая запрет на импорт кода необходимым для соблюдения политик.
1. Управление Идентификацией и Доступом (Entra Agent ID): В Azure AI Foundry каждый агент получает уникальный идентификатор Entra Agent ID, который используется для строгого контроля доступа к данным и ресурсам.2 Импортированный код, работающий внутри контекста LLM, не может быть должным образом аутентифицирован или связан с этим ID, что исключает возможность применения политик Zero Trust.
2. Политики Защиты Данных (DLP и Purview): Агенты, развернутые в Foundry, должны соблюдать политики защиты данных (DLP) и метки конфиденциальности Microsoft Purview.2 Если код выполняется напрямую внутри агента, платформа теряет контроль над потоком данных, и невозможно обеспечить соблюдение этих политик. Запрет на импорт кода является архитектурным инструментом, который предотвращает потерю контроля над данными.
3. Принцип Наименьших Привилегий (PoLP): Предоставление агенту разрешения на выполнение произвольного кода нарушает PoLP. Использование внешних управляемых функций, описанных через OpenAPI 3, позволяет администратору ограничить агента минимально необходимым набором действий (например, только GET запрос к эндпоинту транскрипта студента), что является основой безопасной корпоративной архитектуры.


C. Ограничения Ресурсов и Изоляция Sandboxing


Даже в случаях, когда исполнение кода разрешено (например, Code Interpreter), платформы налагают чрезвычайно строгие ограничения, что подтверждает необходимость изоляции и контроля над ресурсами.
Например, Code Interpreter в OpenAI Assistants ограничивает исполнение кода 20 прикрепленными файлами, максимальным размером файла 512 МБ и лимитом в 5,000,000 токенов на файл.15 Azure AI Foundry имеет схожие лимиты в 10,000 файлов и 512 МБ.16 Более того, исполнение Code Interpreter влечет за собой дополнительные расходы сверх токенизированных сборов.11
Такие ограничения показывают, что любая работа с кодом должна быть высоко сфокусированной, кратковременной и ресурсоемкой. Попытка импорта большого, комплексного кода из репозитория Zasada1980 в этот контекст была бы неэффективной и привела бы к нарушению строгих квот и, как следствие, к нестабильности критически важного EdTech-решения.1
Таким образом, запрет на прямой импорт кода — это архитектурный выбор, который принуждает разработчика к использованию безопасной, децентрализованной микросервисной архитектуры, отделяющей бизнес-логику от LLM-ядра.
Таблица 1: Сравнение Профилей Риска: Прямое Исполнение Кода vs. Вызов Управляемой Функции


Критерий Безопасности
	Прямой Импорт/Исполнение Кода
	Управляемый Вызов Функции (OpenAPI/Azure Function)
	Обоснование Запрета (Корневая Причина)
	Угроза RCE (Remote Code Execution)
	Критически высокая (возможность выполнения произвольного кода).
	Низкая (вызываются только заранее определенные, проверенные эндпоинты).
	Предотвращение несанкционированного доступа к основной системе хостинга.
	Утечка Данных (DLP/Purview)
	Высокая (неконтролируемый доступ к файловой системе или сетевым ресурсам).
	Низкая (доступ к данным контролируется облачными политиками и Entra Agent ID 2).
	Обеспечение соответствия требованиям EdTech (GDPR, FERPA, конфиденциальность студентов).
	Управление Ресурсами/Квоты
	Низкое (сложно контролировать память, время выполнения, CPU).
	Высокое (автоматическое масштабирование, лимиты RPM/RPH налагаются платформой 17).
	Обеспечение надежности и прогнозируемости расходов.
	Аутентификация
	Отсутствует или примитивна.
	Строгая (требуется Managed Identity, API Key или OAuth).3
	Обеспечение нулевого доверия (Zero Trust) к логике агента.
	

IV. Технические Альтернативы: Внедрение Пользовательской Логики через Инструменты (Tools)


Поскольку прямой импорт кода заблокирован из соображений безопасности и архитектуры, разработчику необходимо принять паттерн Function Calling. Этот подход требует, чтобы функциональность из Python-репозитория была обернута в вызываемые инструменты.


A. Архитектура Function Calling и Роль OpenAPI


Function Calling — это процесс, при котором LLM, проанализировав намерение пользователя, генерирует структурированный JSON-объект, содержащий аргументы, необходимые для вызова заранее описанного внешнего API.
1. Строгое Описание Функции: Успешность этого процесса полностью зависит от качества и точности описания внешней логики. LLM использует это описание, чтобы "решить, когда и как использовать инструмент".3
2. OpenAPI 3.0 как Язык Описания: Корпоративные платформы, такие как Azure AI Foundry и Google ADK, стандартизировали этот процесс, требуя, чтобы внешние RESTful API были описаны с использованием спецификации OpenAPI 3.0.3 Этот подход не только стандартизирует интерфейс, но и принуждает к использованию лучших инженерных практик, включая версионирование и модульность.
3. Ключевые Элементы Спецификации: Спецификация OpenAPI должна включать имя инструмента (часто производное от operationId), подробное описание для LLM и строгую схему параметров, которая определяет входные и выходные данные.13 Этот процесс миграции трансформирует несвязанные Python-функции в стандартизированные, повторно используемые "инструменты", что критически важно для многоагентных систем и архитектуры Agent-to-Agent (A2A), где различные агенты могут использовать одни и те же базовые API.19


B. Стратегия 1: Использование Serverless-Функций (Azure Functions)


Serverless-архитектура, реализованная через Azure Functions (или AWS Lambda), является наиболее подходящей для размещения бизнес-логики агента, поскольку она обеспечивает автоматическое масштабирование, управляемую изоляцию и нативную интеграцию с Azure AI Foundry.4
1. Преимущества Serverless: Логика, необходимая Pedagogical-AI-Agent (например, сложные алгоритмы расчета успеваемости или планирования учебного пути), может быть преобразована в набор Serverless-функций. Это обеспечивает экономичную модель оплаты по мере использования, что соответствует требованиям масштабируемости образовательного решения.1
2. Модели Интеграции в Azure AI Foundry:
   * HTTP-триггеры через OpenAPI: Это наиболее гибкий и распространенный метод. Azure Function развертывается как HTTP-эндпоинт, а ее интерфейс описывается через OpenAPI-спецификацию.3 Агент вызывает эту функцию синхронно, ожидая немедленного ответа.
   * Queue-based (Асинхронная) Интеграция: Для сложных, длительных многошаговых рабочих процессов, требуемых EdTech 1, Azure AI Foundry поддерживает прямую интеграцию с функциями, запускаемыми по триггеру очереди.4 Агент отправляет асинхронный запрос в очередь, а функция обрабатывает его в фоновом режиме. Этот метод позволяет избежать таймаутов и квот, связанных с синхронными вызовами. Для HTTP-триггерных функций, которые не поддерживаются напрямую, может быть реализована функция-обертка, использующая очереди.4


C. Требования к Аутентификации и Авторизации (Zero Trust)


При использовании внешних функций, вопросы аутентификации и авторизации решаются на уровне облачной платформы, что исключает риски, связанные с неконтролируемым кодом.
1. Managed Identity (Управляемое Удостоверение): Это рекомендуемый корпоративный стандарт. Вместо использования секретных API-ключей, агент использует свое уникальное Entra Agent ID 2 для получения временного токена, который позволяет ему безопасно вызывать внешние Azure Functions или API.3 Это является краеугольным камнем архитектуры Zero Trust.
2. Политики Доступа: Независимо от выбранной платформы, привилегии для использования внешних REST API должны быть явно присвоены администратором, что видно на примере требований к безопасности Oracle.14 В Azure AI Foundry безопасность дополнительно усиливается за счет частной сетевой изоляции, гарантируя, что агенты взаимодействуют с чувствительными данными в рамках строго определенных сетевых границ.2
Таблица 2: Методы Интеграции Пользовательского Кода в Управляемые AI Агенты


Метод Интеграции
	Механизм/Тип Выполнения
	Типичная Платформа
	Профиль Безопасности
	Применимость к Логике EdTech (Zasada1980)
	Прямой Импорт Кода
	Прямое исполнение произвольного скрипта в ядре агента.
	Не поддерживается в Production.
	Высочайший риск RCE, не соответствует Governance.
	Неприменим.
	Code Interpreter (Sandbox)
	LLM генерирует код, который выполняется в изолированной песочнице.
	OpenAI Assistants, Azure AI Foundry.
	Высокая изоляция, но ограничен по сети/длительности.11
	Только для вычислений (расчет GPA), не для интеграции с внешними API.
	OpenAPI/Function Calling (REST)
	Агент вызывает внешний HTTP-сервис, описанный через OpenAPI 3.0.3
	Azure AI Foundry, Google ADK.
	Отличный: контролируемый доступ, требует аутентификации.
	Идеально: обертывание синхронных запросов к SIS/LMS.
	Serverless Functions (Queue)
	Агент ставит задачу в очередь; внешняя функция асинхронно обрабатывает запрос.21
	Azure AI Foundry + Azure Functions.
	Отличный: высокая масштабируемость и изоляция.
	Идеально для длительных, ресурсоемких, многошаговых процессов.1
	

V. Операционные Ограничения и Управление Жизненным Циклом Кода


Запрет на импорт кода не только обеспечивает безопасность, но и является механизмом принуждения к использованию лучших инженерных практик, необходимых для операционной надежности и масштабируемости EdTech-решения.


A. Управление Квотами и Производительностью


Управляемые платформы жестко ограничивают скорость работы агентов, что делает неэффективный или неконтролируемый импортированный код непригодным для использования.
1. Лимиты Вызовов (RPM/RPH): Платформы, такие как Microsoft Copilot Studio, налагают ограничения на количество запросов в минуту (RPM), которые могут быть отправлены агенту (например, 8,000 RPM для платного плана).17 Любой вызов внешнего инструмента, инициированный агентом, засчитывается в эту квоту. Неконтролируемое исполнение кода легко исчерпало бы эти лимиты, что привело бы к сбоям и отказам в обслуживании для студентов.17
2. Проектирование для Масштабируемости: Для педагогического агента, требующего масштабирования для институционального внедрения 1, использование Serverless-функций, вызванных через OpenAPI, позволяет платформе автоматически управлять ресурсами и распределять нагрузку. Это гарантирует стабильную работу, в отличие от непредсказуемой нагрузки, которую мог бы создать импортированный код. Более того, Code Interpreter, хотя и доступен, является дорогим ресурсом 11, что дополнительно стимулирует вынос комплексной логики в более экономичные Serverless-сервисы.


B. Управление Жизненным Циклом Разработки (DevOps)


Разделение логики агента на внешний сервис (через OpenAPI) упрощает и стандартизирует процессы разработки и эксплуатации, что является обязательным условием для "production-ready AI agents".9
1. Независимое Версионирование: Когда код из репозитория Zasada1980 инкапсулирован в Azure Function, его можно обновлять, тестировать и версионировать независимо от основного ядра агента.4 Обновление бизнес-логики (например, изменение правил проверки предварительных требований) не требует полного переразвертывания или переконфигурации самого LLM-агента.
2. Мониторинг и Трассировка: Управляемые Serverless-среды предоставляют нативные инструменты для журналирования и трассировки вызовов, что критически важно для отладки сложных, многошаговых рабочих процессов.1 Прямой импорт кода лишил бы разработчиков этой прозрачности и возможности аудита, что недопустимо для систем, работающих с конфиденциальными данными.
3. Принуждение к Стандартизации: Невозможность импорта кода принуждает разработчика к принятию стандартной для отрасли практики декомпозиции (Decoupling) и созданию надежных API, которые могут быть описаны через OpenAPI. Это способствует созданию модульных и совместимых инструментов, повышая общую архитектурную зрелость проекта.


VI. Дорожная Карта и Заключительные Рекомендации по Миграции Кода Zasada1980


Для успешной миграции функциональности Pedagogical-AI-Agent в управляемую облачную среду, необходимо строго следовать архитектуре "Инструменты как Сервисы".


A. Этап 1: Декомпозиция и Инкапсуляция Логики (Code Decoupling)


1. Идентификация Инструментов: Провести аудит существующего Python-кода и четко выделить блоки, отвечающие за бизнес-логику (например, check_prerequisites, update_transcript).
2. Создание Сервисного Уровня: Каждая выделенная функция должна быть преобразована в отдельный, сфокусированный Serverless-сервис, используя Azure Functions (или аналог) с HTTP-триггерами. Это обеспечивает изоляцию, необходимую для безопасного доступа к внешним системам (SIS/LMS).1


B. Этап 2: Описание и Развертывание Инструментов (OpenAPI Implementation)


1. Создание Спецификации OpenAPI: Для каждого нового эндпоинта Serverless-сервиса необходимо создать точную спецификацию OpenAPI 3.0. Это описание служит контрактом между LLM-ядром и внешней бизнес-логикой.13
2. Развертывание и Безопасность: Развернуть Serverless-функции и настроить аутентификацию. Рекомендуется использовать Managed Identity для обеспечения безопасности, что позволяет агенту использовать свое Entra Agent ID для безопасного вызова API.2


C. Этап 3: Регистрация в Настройках Агента (Agent Configuration)


1. Регистрация Инструмента: В портале управления агентом (например, Azure AI Foundry Agent Service) необходимо перейти в раздел настройки инструментов (Tools/Actions).
2. Выбор OpenAPI: Вместо недоступной функции "импортировать код" необходимо выбрать опцию "OpenAPI 3.0 specified tool".3
3. Привязка Спецификации и Аутентификации: Указать URL или загрузить файл OpenAPI, а также привязать настроенный метод аутентификации.


D. Рекомендация для Асинхронных Задач


Для сложных и потенциально длительных задач, которые могут превысить синхронные лимиты (например, расчет комплексного плана обучения на несколько семестров), рекомендуется использовать асинхронный паттерн. Настроить Azure Function на использование триггера очереди (Queue trigger) 4, а OpenAPI-спецификацию настроить таким образом, чтобы агент отправлял запрос в эту очередь. Этот подход обеспечивает необходимую отказоустойчивость и масштабируемость для критических EdTech-процессов.


VII. Заключение


Недоступность функции "импортировать код" является преднамеренным архитектурным решением, которое принуждает разработчика к использованию корпоративных стандартов безопасности и масштабируемости. Для успешного развертывания Pedagogical-AI-Agent в управляемой облачной среде необходимо отказаться от парадигмы локального исполнения кода и принять парадигму Function Calling. Это требует декомпозиции исходного кода в безопасные, стандартизированные Serverless-функции или RESTful API, описанные через OpenAPI 3.0, с обязательной настройкой управляемой аутентификации. Такой подход гарантирует, что агент сможет безопасно и масштабируемо взаимодействовать с конфиденциальными институциональными данными, соответствуя требованиям корпоративного управления и регулирования EdTech-сферы.
Источники
1. Build and scale adoption of AI agents for education with Strands Agents, Amazon Bedrock AgentCore, and LibreChat | Artificial Intelligence - AWS, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
2. Agent Factory: Creating a blueprint for safe and secure AI agents | Microsoft Azure Blog, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
3. How to use the OpenAPI spec tool - Azure AI Foundry - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
4. Use Azure Functions with Azure AI Foundry Agent Service - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
5. How to Build an Education AI Agent: 7-Step GenUI Guide - Thesys, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
6. дата последнего обращения: января 1, 1970, [URL_REMOVED]
7. I created an AI Agent to build README files, here is what I learn. | by Filipe Pacheco, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
8. AI Agents educational repo : r/PromptEngineering - Reddit, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
9. The Complete Guide to Building Production-Ready AI Agents: A Step-by-Step Implementation | by Rachoork - Medium, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
10. code interpreter tool - OpenAI Platform, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
11. How to use Azure OpenAI Assistants Code Interpreter - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
12. How to Build an AI Coding Agent with Python and Gemini - freeCodeCamp, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
13. OpenAPI tools - Agent Development Kit - Google, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
14. Access Requirements for AI Agent Studio - Oracle Help Center, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
15. AI assistants file limits - API - OpenAI Developer Community, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
16. Quotas and limits for Azure AI Foundry Agent Service - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
17. Quotas and limits for Copilot Studio - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
18. How to enable Custom Functions and OpenAPI 3.0 specified tools in Azure AI Foundry Agent Actions? Currently, only the Code Interpreter option is available. - Microsoft Q&A, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
19. bhakthan/AI_Agent_School: An interactive educational platform for understanding AI agents, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
20. Use AI tools and models in Azure Functions | Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
21. How to use Azure Functions with the Azure AI Foundry Agent Service - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]