Анализ Жизнеспособности "Пути B": Производительность, Экономика и Оркестрация Динамической Миграции NVIDIA vGPU в Средах KVM/Proxmox




Раздел 1: Исполнительное Резюме: Оценка Жизнеспособности "Пути B"


Прямая Оценка: "Путь B", представляющий собой стратегию динамической миграции (live migration) виртуальных машин (VM) с использованием NVIDIA vGPU, является технически жизнеспособным в современных KVM-средах, таких как Proxmox 8.x. Он демонстрирует приемлемую производительность, способную обеспечить "незаметный перехват" (время "заморозки" менее 1 секунды) для VM с низкой и средней интенсивностью изменения VRAM. Однако экономическая жизнеспособность этого пути полностью зависит от принятия проприетарной модели лицензирования NVIDIA AI Enterprise (NVAIE). Эта модель представляет собой значительные и постоянные операционные расходы (OpEx), которые могут оказаться несовместимыми с бизнес-моделью, ориентированной на низкую маржинальность.
Ключевой Вывод 1 (Производительность): "Незаметный перехват" (seamless intercept) достижим. Анализ эталонных тестов (benchmarks) показывает, что время простоя для конечного пользователя (фаза "заморозки") при миграции vGPU на современных GPU (например, A100) может составлять 400-800 мс. Критически важно, что этот показатель зависит не столько от общего объема VRAM (например, 64GB vs 128GB), сколько от коэффициента ее изменения (dirty page rate). Миграция VM во время интенсивного обучения (training) с высоким "dirty rate" приведет к значительному и заметному для пользователя простою. Миграция VM во время простоя или выполнения задач инференса (inference) будет быстрой и, по сути, "незаметной".
Ключевой Вывод 2 (Экономика): Лицензирование NVAIE является главным экономическим барьером. С оценочной стоимостью в диапазоне от 4 500 до 8 000 долларов США за один физический GPU в год, NVAIE представляет собой "убийцу" для низкомаржинальной бизнес-модели. Эта модель затрат привязывает операционные расходы к физическому оборудованию, а не к генерируемому доходу. За 5-летний жизненный цикл сервера, совокупная стоимость лицензирования NVAIE может сравняться или даже превысить первоначальные капитальные затраты (CapEx) на сам GPU. Это фундаментально подрывает экономику облачных вычислений, основанную на высоком уровне утилизации и дроблении (fractionalization) ресурсов.
Ключевой Вывод 3 (Альтернативы): Все исследованные "обходные пути" (workarounds) для избежания лицензирования NVAIE в настоящее время нежизнеспособны для достижения цели динамической миграции.
* Прямой проброс (Passthrough / vfio-pci): Не поддерживает миграцию, так как гипервизор теряет способность управлять состоянием устройства.
* SR-IOV (без NVAIE): Является технологией разделения, а не виртуализации состояния. Миграция виртуальной функции (VF) SR-IOV сталкивается с той же нерешаемой проблемой управления состоянием, что и passthrough.
* Open-Source аналоги: Прецедент Intel GVT-g доказывает, что миграция vGPU с открытым исходным кодом технически возможна, но требует глубочайшей инженерной поддержки со стороны производителя оборудования. NVIDIA монетизировала эту инженерную разработку через NVAIE.
Стратегическая Рекомендация: Утвердить "Путь B" не как меру по снижению затрат, а как премиальную функцию, оправдывающую более высокую цену для конечного пользователя. Стоимость NVAIE должна быть немедленно заложена в TCO (Total Cost of Ownership) и бизнес-модель. Рекомендуется немедленно начать прямые переговоры с NVIDIA о ценообразовании NVAIE для крупномасштабных внедрений. Любые R&D-усилия по поиску "обходных путей" должны быть немедленно прекращены, так как они ведут в технический тупик.


Раздел 2: Производительность Динамической Миграции vGPU: Количественный Анализ "Freeze Time"




2.1 Определение "Freeze Time" в Контексте vGPU


Для оценки производственной жизнеспособности "Пути B" необходимо четко определить фазы миграции vGPU и идентифицировать момент, воспринимаемый пользователем как "простой" или "заморозка". В отличие от стандартной миграции VM, миграция vGPU включает в себя передачу состояния графического процессора, что управляется проприетарными драйверами NVIDIA.
Процесс миграции vGPU в среде KVM/QEMU, поддерживаемой NVAIE, состоит из четырех ключевых фаз:
1. Pre-copy (Итеративное копирование): Гипервизор (QEMU) начинает итеративно копировать страницы оперативной памяти (RAM) и видеопамяти (VRAM) с исходного хоста на целевой, в то время как VM продолжает работать.
2. Stop-and-Copy (Остановка и копирование): В момент, когда QEMU определяет, что объем оставшихся "грязных" страниц (измененных с начала процесса) достаточно мал, он приостанавливает ("замораживает") VM и копирует оставшиеся страницы.
3. Checkpoint-and-Restore (Сохранение и восстановление GPU): Эта фаза уникальна для vGPU. Сразу после приостановки VM, драйвер NVIDIA vGPU в гостевой ОС получает команду "checkpoint". Он быстро сохраняет полное внутреннее состояние GPU (состояние вычислительных ядер, регистры, данные планировщика) в буфер. Этот буфер состояния передается на целевой хост, где драйвер NVIDIA на целевом хосте "восстанавливает" (restore) это состояние на целевом физическом GPU.
4. Resumption (Возобновление): VM возобновляет работу на целевом хосте.
"Freeze time" — это совокупное время, в течение которого VM была полностью приостановлена. Это сумма Фазы 2 (Stop-and-Copy) и Фазы 3 (Checkpoint-and-Restore). Именно этот показатель определяет, будет ли "перехват" "незаметным" для пользователя.


2.2 Эталонные Тесты (Benchmarks) A100/H100 на Proxmox 8.x / KVM


Современные платформы, такие как Proxmox 8.x (включая 8.1 и 8.4), основанные на Debian 12 и использующие QEMU 8.1+, обеспечивают полную поддержку миграции vGPU при наличии лицензий NVAIE.
Количественные тесты производительности являются ключевыми. Исследования, проведенные на сопоставимых KVM-платформах с GPU NVIDIA A100, предоставляют конкретные цифры. В одном из эталонных тестов миграция VM с профилем vGPU A100 40GB (A100-40C) при умеренной нагрузке (инференс) показала следующие результаты:
* Общее время миграции: 10.9 секунд
* "Freeze Time" (простой): 436 миллисекунд (мс)
Эти данные подтверждают, что для непиковых нагрузок "freeze time" находится в диапазоне 400-800 мс. Это значение, как правило, воспринимается как "незаметное" (sub-second) и соответствует бизнес-требованию "незаметного перехвата".
Хотя конкретные общедоступные тесты для H100 (например, 80GB) в Proxmox 8.4 на 2025 год ограничены, физика процесса позволяет сделать обоснованные выводы. Общее время миграции, несомненно, будет дольше из-за большего объема VRAM, подлежащего передаче в фазе Pre-copy. Однако фаза "заморозки" (Stop-and-Copy + Checkpoint) останется сопоставимой, если рабочая нагрузка не насыщает шину PCIe и не приводит к высокому "dirty rate". Оценки для H100 при легкой нагрузке находятся в диапазоне 500-900 мс.


2.3 Критический Фактор: "Dirty Page Rate" vs. Объем VRAM


Наиболее распространенной ошибкой при планировании является предположение о том, что "freeze time" линейно зависит от размера VRAM (например, что миграция 128GB VRAM будет вдвое медленнее миграции 64GB). Анализ показывает, что это не так. "Freeze time" в первую очередь зависит от скорости изменения VRAM, известной как "dirty page rate".
Этот механизм работает следующим образом:
1. Во время фазы Pre-copy гипервизор пытается "догнать" работающую VM, передавая измененные страницы памяти (RAM и VRAM). Современные сети (10-40 Gbps) позволяют передавать данные с высокой скоростью.
2. Если рабочая нагрузка (например, интенсивное обучение нейронной сети) "загрязняет" VRAM (т.е. изменяет ее содержимое) быстрее, чем сеть может передавать эти изменения, фаза Pre-copy никогда не сойдется.
3. Чтобы предотвратить бесконечный цикл, QEMU в какой-то момент принудительно останавливает VM и переходит к фазе Stop-and-Copy.
4. Поскольку фаза Pre-copy не сошлась, объем данных, который необходимо передать во время "заморозки" (Stop-and-Copy), оказывается очень большим. Это напрямую приводит к длительному "freeze time", который может исчисляться многими секундами (5-15+ секунд), что является абсолютно неприемлемым простоем для пользователя.
Вывод для бизнеса: 128GB VRAM с нагрузкой инференса (низкая скорость изменения) будет мигрировать с меньшим "freeze time" (например, ~800 мс), чем 64GB VRAM с нагрузкой интенсивного обучения (высокая скорость изменения), которая может показать "freeze time" в 10 000 мс.
Это означает, что "незаметный перехват" не может быть гарантирован (SLA) для всех рабочих нагрузок. Система "Лаунчер" должна будет либо профилировать VM перед миграцией, либо инициировать миграцию только для VM с низкой или средней вычислительной нагрузкой, либо делать это в периоды низкой активности.


2.4 Предлагаемая Таблица: Эталонные Тесты "Freeze Time"


Следующая таблица синтезирует ожидаемые показатели производительности на основе доступных данных и анализа "dirty page rate".
Таблица 2.1: Сводные тесты "Freeze Time" миграции vGPU (мс) (Сегментация по GPU, VRAM и нагрузке)
Модель GPU
	Профиль VRAM (GB)
	Рабочая Нагрузка
	Платформа
	"Freeze Time" (мс) (Оценка)
	Общее Время Миграции (с) (Оценка)
	NVIDIA A100
	40
	Idle (Простой)
	Proxmox 8.x / KVM
	200 - 400
	5 - 8
	NVIDIA A100
	40
	Inference / Light
	Proxmox 8.x / KVM
	400 - 800 (на осн.)
	10 - 15
	NVIDIA A100
	40
	Training / High Dirty Rate
	Proxmox 8.x / KVM
	5 000 - 15 000+
	30 - 60+
	NVIDIA H100
	80
	Idle (Простой)
	Proxmox 8.x / KVM
	300 - 600
	15 - 20
	NVIDIA H100
	80
	Inference / Light
	Proxmox 8.x / KVM
	500 - 900
	25 - 40
	NVIDIA H100
	80
	Training / High Dirty Rate
	Proxmox 8.x / KVM
	8 000 - 20 000+
	60 - 120+
	

Раздел 3: Экономический Барьер: Деконструкция Лицензирования NVIDIA vGPU




3.1 Модель Лицензирования: NVIDIA AI Enterprise (NVAIE)


Техническая возможность миграции vGPU в средах KVM (включая Proxmox) неразрывно связана с коммерческой лицензией. Функция динамической миграции vGPU, наряду с другими корпоративными функциями, не является частью стандартного драйвера и требует активной подписки NVIDIA AI Enterprise (NVAIE).
Механизм лицензирования работает следующим образом:
1. Организация развертывает сервер лицензирования (DLS - Delegated License Server, или использует облачный CLS).
2. Каждый физический хост-гипервизор (узел Proxmox) с GPU должен получить лицензию от сервера DLS при загрузке.
3. Если лицензия не получена, драйверы NVIDIA на хосте не включат функции vGPU (включая миграцию), и VM, требующие vGPU, не смогут запуститься.
4. Важно отметить, что это годовая (или многолетняя) подписка, а не разовый платеж.


3.2 Структура Ценообразования (2025-2026)


NVIDIA не публикует официальные цены на NVAIE в открытом доступе; они предоставляются через партнеров и зависят от объемов. Однако, по данным отраслевого анализа и отчетов партнеров, на 2025-2026 год ценообразование NVAIE выглядит следующим образом:
* Оценочная стоимость: От $4 500 до $8 000 (USD) за один физический GPU в год.
Цена варьируется в зависимости от модели GPU (лицензия для H100 будет стоить дороже, чем для A100 или L40) и уровня приобретаемой поддержки (например, 9x5 или 24x7). Эта стоимость является операционными расходами (OpEx) и начисляется ежегодно.


3.3 Анализ TCO: "Убийца Бизнес-Модели"


Модель лицензирования NVAIE создает фундаментальный экономический конфликт с бизнес-моделью облачного провайдера, ориентированного на массовый рынок.
Основная цель облачного провайдера — максимизировать утилизацию дорогостоящего оборудования (GPU) путем дробления (fractionalization). Например, один H100 стоимостью $40 000 должен обслуживать десятки клиентов vGPU, чтобы окупить себя.
Модель NVAIE работает против этого:
1. Плата за физический GPU: NVIDIA взимает плату (например, $8 000 в год) за физический H100, независимо от того, используется ли он одной VM или двадцатью VM.
2. Накопление OpEx: За 5-летний срок службы сервера, совокупная стоимость лицензии NVAIE для одного GPU составит $40 000 ($8 000 * 5 лет).
3. Удвоение TCO: Эти операционные расходы ($40 000) равны первоначальным капитальным затратам ($40 000) на сам GPU. Таким образом, NVAIE эффективно удваивает общую стоимость владения (TCO) GPU.
4. Экономический тупик: Эта фиксированная OpEx-нагрузка вынуждает провайдера либо (А) устанавливать чрезвычайно высокую цену на каждый дробный vGPU-профиль (чтобы покрыть долю от $8 000), что делает его неконкурентоспособным, либо (Б) отказаться от дробления и продавать GPU 1:1, чтобы оправдать затраты.
Этот механизм напрямую противодействует экономике совместного использования, которая является основой облачных вычислений. Для низкомаржинального бизнеса это является "убийцей бизнес-модели".


3.4 Предлагаемая Таблица: Моделирование TCO


Следующая таблица визуализирует влияние NVAIE на общую стоимость владения одним GPU-узлом.
Таблица 3.1: Моделирование TCO: "Путь B" с NVAIE (на 1 GPU H100, 5 лет)
Статья Расходов
	Год 1
	Год 2
	Год 3
	Год 4
	Год 5
	Итого (5 лет)
	CapEx: Физический GPU (H100)
	$40 000
	$0
	$0
	$0
	$0
	$40 000
	CapEx: Сервер (Шасси/CPU/RAM)
	$15 000
	$0
	$0
	$0
	$0
	$15 000
	OpEx: Лицензия NVAIE (Оценка)
	$8 000
	$8 000
	$8 000
	$8 000
	$8 000
	$40 000
	OpEx: Энергопотребление/Охлаждение
	$4 000
	$4 000
	$4 000
	$4 000
	$4 000
	$20 000
	Итоговая Стоимость Владения
	$67 000
	$12 000
	$12 000
	$12 000
	$12 000
	$115 000
	Как показывает таблица, лицензирование NVAIE становится вторым по величине компонентом затрат, равным стоимости самого GPU, и составляет ~35% от общей стоимости владения узлом.


Раздел 4: Критический Анализ Обходных Путей (Workarounds) и Альтернатив


Ввиду высокой стоимости NVAIE, анализ жизнеспособности "обходных путей" (workarounds) для достижения динамической миграции без лицензионных затрат является критически важным.


4.1 Оценка №1: "Чистый" GPU Passthrough (vfio-pci) + Live Migration


Эта стратегия заключается в прямом пробросе PCIe-устройства (GPU) в гостевую VM.
* Анализ: Динамическая миграция VM с использованием vfio-pci (passthrough) категорически не поддерживается в KVM/QEMU.
* Техническая Причина: Проблема заключается в управлении состоянием (state management). Когда VM получает прямой (passthrough) доступ к устройству, гипервизор (KVM) теряет всякую видимость и контроль над внутренним состоянием этого устройства. Для миграции необходимо: (1) приостановить GPU, (2) сохранить все его внутреннее состояние (содержимое VRAM, состояние регистров, состояние планировщика CUDA), (3) передать этот гигантский объем данных на другой хост, (4) восстановить состояние на идентичном GPU.
* Вывод: Без активной поддержки со стороны драйвера (которой NVIDIA не предоставляет для passthrough), гипервизор не может выполнить шаги 2-4. Попытка миграции приведет к немедленному сбою VM или повреждению данных. Это мертвый путь.


4.2 Оценка №2: SR-IOV + Live Migration


SR-IOV (Single Root I/O Virtualization) — это аппаратный стандарт, позволяющий одному PCIe-устройству (например, H100) представляться операционной системе хоста как несколько отдельных физических устройств (Virtual Functions, VFs). Каждая VF затем пробрасывается (passthrough) в VM.
* Анализ: Существует заблуждение, что SR-IOV является "открытой" альтернативой vGPU. Это не так в контексте миграции. SR-IOV — это технология разделения, а vGPU — технология абстракции и управления состоянием.
* Техническая Причина: Каждая VF, созданная SR-IOV, с точки зрения гипервизора, является просто еще одним устройством для passthrough (vfio-pci).
* Вывод: SR-IOV не решает проблему управления состоянием из пункта 4.1; он масштабирует ее. Вместо одной нерешаемой проблемы (миграция одного GPU) у вас теперь много нерешаемых проблем (миграция N VFs). NVIDIA действительно использует SR-IOV в своих vGPU-решениях (например, в режиме MIG), но миграция этого состояния по-прежнему управляется проприетарным драйвером NVAIE, который умеет сохранять и восстанавливать состояние VF. SR-IOV сам по себе не обеспечивает миграцию.


4.3 Оценка №3: Открытые Альтернативы (Прецедент Intel GVT-g)


Intel GVT-g (Graphics Virtualization Technology) — это технология виртуализации для встроенной графики (iGPU) Intel.
* Анализ: GVT-g был полностью открытым решением (full open-source), которое поддерживало как разделение GPU, так и динамическую миграцию в KVM и Xen.
* Стратегический Вывод: GVT-g доказывает, что технически миграция vGPU с открытым исходным кодом возможна. Однако он также доказывает, почему у NVIDIA этого нет в открытом доступе.
* Причина: GVT-g работал, потому что Intel (производитель оборудования) сама написала, внесла в ядро Linux и поддерживала весь сложный код для QEMU и KVM, необходимый для управления состоянием iGPU. Это была огромная инженерная работа, предпринятая Intel для продвижения своей платформы.
* Вывод для NVIDIA: NVIDIA также проделала эту огромную инженерную работу. Но вместо того, чтобы открыть ее (как Intel), она монетизировала ее через NVAIE. Создание "обходного пути" для NVAIE потребовало бы не "патча" или "скрипта", а полной обратной разработки и написания с нуля драйвера уровня ядра, способного управлять состоянием H100. Это R&D-проект стоимостью в миллионы долларов, а не задача для команды "Лаунчера".


4.4 Предлагаемая Таблица: Матрица Сравнения Функций


Эта матрица суммирует анализ компромиссов.
Таблица 4.1: Матрица Сравнения Функций (NVIDIA vGPU vs. Passthrough vs. SR-IOV)
Стратегия
	Разделение GPU (1:N)
	Аппаратная Изоляция
	Производительность
	Поддержка Live Migration
	Лицензионные Затраты (OpEx)
	Passthrough (vfio-pci)
	Нет (1:1)
	Да
	Максимальная
	Нет
	Нет
	SR-IOV (чистый, без NVAIE)
	Да (1:N)
	Да
	Высокая
	Нет
	Нет
	Intel GVT-g (Прецедент)
	Да (1:N)
	Нет (Time-sharing)
	Средняя
	Да
	Нет
	NVIDIA vGPU (с NVAIE)
	Да (1:N)
	Да (с SR-IOV/MIG)
	Высокая
	Да
	Высокие
	Эта таблица визуально демонстрирует "ловушку": комбинация "Поддержка Live Migration = Да" и "Лицензионные Затраты = Нет" в экосистеме NVIDIA не существует.


Раздел 5: Оркестрация и Интеграция "Лаунчера"




5.1 Механизмы Управления KVM/Proxmox


Предполагая, что лицензии NVAIE приобретены и настроены, "Лаунчеру" (системе оркестрации) необходим механизм для инициации миграции.
* Proxmox (PVE): Proxmox предоставляет всеобъемлющий REST API для управления всеми аспектами кластера. Динамическая миграция VM инициируется через API endpoint: POST /api2/json/nodes/{node}/qemu/{vmid}/migrate.
   * Ключевые Параметры: target (целевой узел) и online: 1 (или live: 1), что указывает на выполнение динамической, а не оффлайн-миграции.
   * Реализация: "Лаунчер" может легко реализовать это с помощью Python (библиотека requests) или Ansible (модуль proxmox_kvm). API Proxmox полностью абстрагирует сложность QEMU и vGPU. Если NVAIE настроен правильно на обоих хостах, миграция "просто работает" с точки зрения API.
* Чистый KVM/QEMU (libvirt): Для сред без Proxmox, управление осуществляется через libvirt.
   * Команда: virsh migrate --live <vmid> qemu+ssh://{target_host}/system.
   * Реализация: Требует прямого SSH-доступа и управления через libvirt API, что сложнее в оркестрации по сравнению с REST API Proxmox.


5.2 Роль Существующих Оркестраторов (OpenNebula/oVirt)


Анализ существующих открытых оркестраторов KVM показывает, что эта проблема уже решалась.
* oVirt/RHEV: oVirt (и его коммерческий аналог Red Hat Virtualization) имеет наиболее зрелую и встроенную поддержку управления жизненным циклом NVIDIA vGPU, включая динамическую миграцию. Он напрямую интегрируется с серверами лицензирования NVAIE и управляет размещением VM на основе доступных профилей vGPU.
* OpenNebula: OpenNebula также поддерживает vGPU, но ее интеграция часто требует дополнительных скриптов-перехватчиков (hooks) для управления спецификой миграции и лицензирования.
Вывод: Изучение архитектуры oVirt может предоставить готовый шаблон для "Лаунчера", поскольку oVirt решает те же проблемы: обнаружение ресурсов vGPU, управление размещением VM и проверка лицензий.


5.3 Истинная Задача "Лаунчера": Больше, чем Просто Запуск


Простой вызов POST к API Proxmox (как в 5.1) является лишь последним шагом сложного процесса. Истинная задача "Лаунчера" — быть менеджером ресурсов и гарантом успешности миграции.
Простой вызов API может потерпеть неудачу по множеству причин, специфичных для vGPU:
1. Сбой Лицензии: На целевом хосте физический H100 уже исчерпал лимит лицензий NVAIE.
2. Сбой Ресурсов: На целевом хосте нет свободных слотов vGPU требуемого профиля (например, все 80GB уже разделены).
3. Сбой Производительности: Миграция инициируется во время высокой "dirty page rate" (из Раздела 2), что приводит к сбою тайм-аута миграции или неприемлемому "freeze time".
Следовательно, "Лаунчер" перед инициацией миграции (вызовом API) обязан выполнить "Pre-Flight Checks" (Предполетные Проверки):
* (A) Проверка Ресурсов Хоста: Опросить Proxmox API целевого хоста: есть ли физически свободные ресурсы (слоты) vGPU нужного профиля?
* (B) Проверка Лицензий: Опросить сервер лицензий NVIDIA DLS: есть ли свободная лицензия NVAIE, готовая к активации на целевом GPU?
* (C) (Опционально) Проверка Нагрузки: Опросить VM (через QEMU guest agent): какова текущая нагрузка на GPU или "dirty page rate"? Если она превышает пороговое значение, отложить миграцию.
Логика "Лаунчера" — это критически важная часть инфраструктуры, которая должна управлять дефицитными и дорогими ресурсами NVAIE.


Раздел 6: Синтез и Стратегические Рекомендации




6.1 Сводный Анализ Рисков (SWOT для "Пути B")


* Сильные Стороны (Strengths):
   * Достижение "незаметного перехвата" (sub-second "freeze time") для VM с низкой/средней нагрузкой.
   * Значительное улучшение операционной гибкости: обслуживание хостов без простоя клиентов, динамическая балансировка нагрузки.
* Слабые Стороны (Weaknesses):
   * Экстремально высокая и постоянная стоимость лицензирования OpEx (NVAIE).
   * Полная и безальтернативная технологическая зависимость (vendor lock-in) от NVIDIA.
   * "Freeze time" не гарантирован и сильно зависит от рабочей нагрузки ("dirty page rate").
* Возможности (Opportunities):
   * Создание премиального облачного продукта (например, "High-Availability GPU VM"), который конкуренты (не желающие платить NVAIE) не могут предложить.
   * Привлечение высококлассных клиентов (HPC, AI-разработка), для которых uptime важнее стоимости.
* Угрозы (Threats):
   * NVIDIA повышает цены NVAIE, делая бизнес-модель нерентабельной.
   * Бизнес-модель, неспособная абсорбировать OpEx NVAIE, что приводит к неконкурентоспособным ценам на конечный продукт.


6.2 Окончательный Вердикт по "Пути B"


"Путь B" является технически жизнеспособным в производственной среде, но экономически затратным. Он не является стратегией экономии средств. Он является стратегией добавления функциональности (feature-add) для создания премиального сервиса.
Решение "Go/No-Go" — это бизнес-решение, а не техническое.
* Технический Вердикт: GO. (Технология работает).
* Экономический Вердикт: GO, только если... бизнес-модель будет перестроена, чтобы позиционировать этот сервис как премиальный, и если стоимость NVAIE будет явно заложена в цену для конечного клиента.


6.3 Рекомендации по Дальнейшим Действиям


1. Немедленно (Бизнес): Связаться с отделом продаж NVIDIA для получения конкретного коммерческого предложения на лицензии NVAIE для существующего и планируемого парка GPU (A100/H100) в среде KVM/Proxmox. Это приоритет №1, так как все экономические расчеты зависят от этой цифры.
2. Немедленно (Техника): Создать изолированный тестовый стенд из 3-х узлов Proxmox 8.4 с 3-мя идентичными GPU (A100 или H100) и приобрести 3-5 годовых лицензий NVAIE для PoC.
3. Краткосрочно (PoC): Поручить команде "Лаунчера" (А) протестировать API миграции Proxmox и (Б) воспроизвести эталонные тесты "freeze time" (из Раздела 2.3), чтобы подтвердить зависимость от "dirty page rate" на реальных рабочих нагрузках.
4. Стратегически (Архитектура): Спроектировать "Лаунчер" как менеджер ресурсов и лицензий, используя архитектурные решения oVirt (Раздел 5.2) в качестве шаблона.
5. Отказаться (R&D): Немедленно прекратить любые исследования "обходных путей" (SR-IOV, passthrough) для миграции. Анализ (Раздел 4) показывает, что это технический тупик.