Экспертное Руководство: Разработка Инструментария для Корпоративных ИИ-Агентов




I. Стратегический Контекст и Архитектура Агентского Инструментария




А. Роль Инструментов в Агентских ИИ-Системах: От Прототипа к Производству


Современные корпоративные платформы по разработке искусственного интеллекта претерпели значительные изменения, отойдя от парадигмы статических промптов (Stateless Prompts) к созданию масштабируемых и расширяемых (Extensible) агентских систем.1 В рамках этой эволюции ИИ-агент становится не просто генератором текста, а исполнительным модулем, способным взаимодействовать с внешней средой через специализированный инструментарий (tools).
Ключевым фокусом для разработчиков и предприятий является скорость, с которой можно интегрировать сотни внешних API, сервисов и источников данных, обеспечивая при этом возможность повторного использования этих интеграций в различных командах и средах выполнения, а также строгий централизованный контроль.1
Платформы, такие как Azure AI Foundry, позиционируют себя как доверенная «Фабрика Агентов» (Agent Factory), предоставляющая унифицированные, корпоративные инструменты и фреймворки, необходимые для масштабирования ИИ ответственным образом.2 Этот подход требует, чтобы инструменты представляли собой не просто код, а управляемые, версионируемые активы, гарантирующие безопасность и прозрачность.2
Microsoft Agent Framework, находящийся в публичном предварительном просмотре, является примером такого унифицированного подхода. Он обеспечивает корпоративную основу для оркестрации сложных многоагентных систем, интегрируясь с любым API через стандарт OpenAPI и поддерживая динамические подключения инструментов с помощью Model Context Protocol (MCP).3 Использование открытых стандартов и протоколов для интеграции является стратегическим императивом, поскольку это позволяет организациям отделить логику инструмента от базовой модели (LLM), обеспечивая гибкость в выборе моделей (например, GPT-4, Gemini, Llama) и сред выполнения (Azure Functions, Kubernetes) без необходимости переписывать всю интеграционную логику. Таким образом, спецификация инструмента, а не его код, становится критически важным артефактом в процессе разработки MLOps.


B. Таксономия Инструментария Агента и Принципы Интеграции


Агентский инструментарий может быть классифицирован по его основному функционалу и архитектуре 4:
1. Custom API Endpoint Calling Tool (REST API Wrappers): Это наиболее универсальный тип, позволяющий агенту вызывать собственные REST API или API облачных служб, таких как OCI API. Интеграция с такими инструментами обязательно описывается через спецификацию OpenAPI.4
2. Retrieval-Augmented Generation (RAG Tool): Инструменты RAG предназначены для извлечения релевантных документов или данных из одного или нескольких баз знаний. Агент использует эту информацию для генерации контекстно-обогащенных ответов в естественном языке.4 Разработчикам, однако, рекомендуется сначала рассмотреть возможность использования стандартных API-инструментов. Более сложные RAG-фреймворки следует применять только в тех случаях, когда простой, стандартный подход к инструментам не обеспечивает необходимого результата.5
3. Code Interpreters: Эти инструменты позволяют агенту выполнять программный код (чаще всего Python) для выполнения математических расчетов, анализа данных или визуализации.6 Их использование налагает жесткие требования к безопасности. Например, Code Interpreter от OpenAI использует изолированную среду Docker (песочницу) для безопасного выполнения скриптов.6 Важно, что для обеспечения конфиденциальности и предотвращения эксфильтрации данных такие среды работают без подключения к Интернету.7
Интеграция с Серверными Платформами. Серверные функции (например, Azure Functions) являются предпочтительной средой для размещения логики инструментов благодаря их масштабируемости и гибкости.8
* Для функций, вызываемых HTTP-триггерами, интеграция с агентом требует, чтобы функция была описана через спецификацию OpenAPI 3.0 и зарегистрирована как вызываемый инструмент в конфигурации агента.8
* Для асинхронных рабочих процессов, таких как обработка сообщений, Azure AI Foundry поддерживает нативную интеграцию через триггеры Azure Storage Queues.8
Разработчикам, использующим серверные среды, следует обратить внимание на то, что разработка инструментария смещается в сторону подхода "Specification-First" MLOps. Усилия концентрируются на строгом определении интерфейса (спецификации OpenAPI), который становится основным, версионируемым артефактом, определяющим как функциональность, так и периметр безопасности. Сама большая языковая модель (LLM) выступает исключительно как уровень планирования и логического вывода поверх этого строго определенного интерфейса.


II. Стандарт Спецификации: Использование OpenAPI 3.0 для Определения Инструмента




A. Императив Открытых Стандартов и Интерфейса LLM


Для обеспечения совместимости, повторного использования и управляемости в корпоративных средах, использование открытых стандартов стало обязательным. Спецификация OpenAPI 3.0 служит обязательным структурированным представлением функции (Function Declaration), которое LLM использует для выполнения процесса, известного как Function Calling (или Tool Use).9
Процесс Function Calling позволяет модели функционировать как мост между естественным языком и реальными действиями или данными.11
1. Клиентское приложение отправляет пользовательский запрос вместе с объявлениями функций (Function Declarations).
2. Модель анализирует запрос и определяет, требуется ли вызов инструмента. Если требуется, модель генерирует структурированный JSON-объект, содержащий имя функции и параметры.
3. Ключевой момент: Модель не выполняет функцию. Исполнение кода функции остается ответственностью клиентского приложения, которое обрабатывает JSON-ответ модели.11


B. Требования к Схеме OpenAPI 3.0 (FunctionDeclaration)


Объявление функции, передаваемое модели, должно строго соответствовать формату JSON Schema Object, отражающему спецификацию OpenAPI 3.0.12 Отклонение от этих стандартов может привести к неточному выбору инструмента или генерации некорректных аргументов.
1. Имя Функции (name):
   * Является обязательным полем и должно быть уникальным.
   * Должно начинаться с буквы или подчеркивания. Допустимые символы: A-Z, a-z, 0-9, подчеркивания (_), точки (.) и тире (-). Максимальная длина имени составляет 64 символа.12
   * Конвенция именования: Поскольку инструмент представляет собой действие, выполняемое агентом, предпочтительно использовать глаголы или глагольные фразы (например, get_weather, launchMissiles, formatUsername), а не существительные.13
2. Описание Функции (description):
   * Хотя формально может быть помечено как опциональное, подробное описание и назначение функции настоятельно рекомендуется для обеспечения эффективности.12
   * Модель использует это описание для принятия решения о том, как и когда вызывать функцию.15 Качество описания инструмента (иногда называемое "prompt-engineering the tool description") является одним из наиболее эффективных методов влияния на поведение агента.16
3. Параметры (parameters):
   * Параметры описываются в формате JSON Schema Object.10 Схема должна описывать объект, где свойства являются параметрами функции.10
   * Структура: Включает type (должен быть OBJECT), properties (описание индивидуальных параметров) и массив required (список обязательных параметров).10
   * Типизация данных: Необходимо явно указывать тип данных для каждого параметра. Поддерживаемые типы включают STRING, INTEGER, BOOLEAN, NUMBER, ARRAY, и OBJECT.12 Строгая типизация критически важна для предотвращения конфликтов формата, которые могут возникать при неформализованном мышлении LLM.18
Тщательное определение схемы JSON, требуемой OpenAPI, действует как система формальных ограничений. Путем строгого определения типов данных и обязательных полей, разработчики по сути внедряют "формализованное мышление" в процесс принятия решений LLM.18 Это значительно уменьшает двусмысленность и повышает надежность системы, обеспечивая предсказуемые шаблоны ввода/вывода.
Таблица 1: Основные Требования к Объявлению Функции OpenAPI 3.0 (для LLM Tool Use)


Компонент
	Статус
	Ограничения/Формат
	Влияние на Производительность Агента
	Function name
	Обязательно
	Начинается с буквы/подчеркивания; A-Z, 0-9, _, ., - (Макс. 64 символа). Используйте глаголы. 12
	Критично для выбора инструмента (Tool Selection). Неправильное имя снижает точность.
	Function description
	Настоятельно Рекомендуется
	Подробное, недвусмысленное строковое описание назначения. 10
	Основной элемент для LLM, чтобы определить когда и как использовать инструмент.
	parameters
	Опционально
	JSON Schema Object (OpenAPI 3.0), тип OBJECT. 12
	Обеспечивает корректность генерируемых аргументов (Argument Correctness).
	required
	Опционально
	Массив строковых имен параметров, которые модель должна предоставить. 10
	Повышает надежность вызова, предотвращая ошибки из-за недостатка информации.
	type (внутри properties)
	Обязательно
	STRING, INTEGER, BOOLEAN, NUMBER, ARRAY, OBJECT. 12
	Предотвращает конфликты формата и ошибки обработки данных. 18
	

III. Лучшие Практики Разработки Инструментов и Инженерное Совершенство




A. Проектирование для Эффективности LLM и Производительности


Эффективность агента напрямую зависит от качества и количества предоставленного ему контекста и инструментария.
Снижение Сложности Пространства Инструментов. Чрезмерное количество доступных инструментов увеличивает когнитивную нагрузку на LLM при планировании. Это может привести к снижению точности выбора инструмента (Tool Selection Accuracy) и увеличению времени отклика, особенно при обработке сложных многошаговых запросов.18 Экспериментальные данные подтверждают, что предоставление агенту меньшего, но более релевантного набора инструментов существенно повышает успех выполнения задачи и снижает потребление энергии и задержку.19
Оптимизация Токеновой Эффективности. Ответы, возвращаемые инструментом, могут быстро заполнить контекстное окно LLM, что приводит к усечению важной информации или увеличению затрат на обработку. Для управления этим процессом рекомендуется внедрять механизмы пагинации, фильтрации, выбора диапазона или усечения (truncation) ответов.16 Например, некоторые платформы ограничивают ответы инструмента 25 000 токенами по умолчанию.16 Разработчики должны "промпт-инжинирить" описания инструментов таким образом, чтобы агент предпочитал токеноэффективные стратегии — например, выполняя несколько небольших, целенаправленных поисковых запросов вместо одного широкого.16
Динамическое Обнаружение Инструментов. Для масштабируемости и гибкости, особенно в многоагентных системах, рекомендуется использовать такие протоколы, как Model Context Protocol (MCP). MCP позволяет агенту запрашивать сервер во время выполнения, чтобы динамически обнаружить, какие инструменты доступны, а затем выбрать и вызвать соответствующий инструмент.21 Эта архитектура критически важна, поскольку она отделяет LLM-приложение от фиксированного набора инструментов, обеспечивая архитектурную гибкость.


B. Внедрение Надежной Обработки Ошибок (Error Handling)


Способность агента восстанавливаться после неудачного вызова инструмента (Error Recovery Capabilities) является важным показателем его надежности.22 Эффективная обработка ошибок инструмента должна быть спроектирована таким образом, чтобы ускорить самокоррекцию агента.
Проектирование Полезных Сообщений об Ошибках. Когда инструмент возвращает ошибку (например, из-за неверной проверки входных данных), ответ, направляемый LLM, должен быть действенным и конкретным.16 Вместо возврата нечитаемых кодов ошибок или трассировок стека, ответ должен четко указывать на то, какие улучшения агент должен внести в свой следующий вызов (например, "Не хватает обязательного параметра 'location' в типе STRING").16
Такой подход, при котором сообщения об ошибках предоставляют контекстное руководство, напрямую влияет на экономику выполнения агента. Чем лучше сообщение об ошибке, тем меньше попыток и токенов тратит агент на исправление своей ошибки, снижая общие затраты и задержку.16


C. Примеры Интеграции


Для создания и развертывания инструментов в корпоративных средах часто используются SDK и платформенные возможности:
1. Python SDK (Azure AI Agents / Semantic Kernel): Разработчики могут использовать объекты OpenApiTool в Python SDK. Спецификация OpenAPI (в формате JSON или YAML) передается напрямую в качестве аргумента. Этот подход поддерживает различные методы аутентификации, включая анонимную (OpenApiAnonymousAuthDetails), а также управляемые удостоверения (OpenApiManagedAuthDetails) и кастомные подключения.15
2. Автоматическая Генерация Спецификаций: Для автоматизации рабочего процесса MLOps существуют плагины (например, для Serverless Framework), которые могут автоматически генерировать спецификацию OpenAPI 3.0 на основе определения функции, включая схемы для моделей запросов (requestModels) и ответов (responseModels).25 Это позволяет поддерживать актуальность документации и спецификации синхронно с кодом функции.


IV. Уровень Доверия: Корпоративная Безопасность и Управление


В корпоративном ИИ доверие становится определяющей проблемой.2 Безопасность и управление должны быть интегрированы в процесс разработки с самого начала (концепция "Shift Left").2 Это требует, чтобы инструменты обладали пятью ключевыми качествами безопасного агента: уникальная идентичность, защита данных по замыслу, встроенные средства контроля, оценка и прозрачность.2


A. Аутентификация и Авторизация для Инструментов


Переход от использования статических API-ключей к динамическим и управляемым удостоверениям является обязательным требованием для корпоративных систем.
Managed Identity (Управляемое Удостоверение). В средах Azure Managed Identity является предпочтительным методом. Этот подход позволяет агенту получать токен доступа к другим службам Azure (например, Azure AI Services, базы данных), используя удостоверение, управляемое платформой, без необходимости разработчику вручную хранить или управлять секретами в коде.15 Аутентификация настраивается на уровне платформы путем выбора опции "managed identity" и указания аудитории (например, [URL_REMOVED]).15
OAuth 2.0 и Model Context Protocol (MCP). MCP использует OAuth для обеспечения унифицированного потока получения токена для любой совместимой службы, устраняя проблему "разрастания учетных данных" (credential sprawl), характерную для ранних интеграций.26
Специализированные Решения для Агентов. Поставщики решений, такие как Auth0, предлагают расширенные функции для обеспечения безопасности агентов 27:
* Agent Identity (Идентичность Агента): Предоставление выделенных удостоверений для самого ИИ-агента.
* Token Vault: Безопасное хранение токенов API (Google, Slack, GitHub) от имени конечного пользователя, позволяя агенту совершать действия (например, отправлять сообщения или обновлять заказы) с гранулярным контролем.
* Asynchronous Authorization: Внедрение механизмов «человек в контуре» (Human-in-the-Loop, HITL) для критических или чувствительных действий, требующих явного одобрения пользователя, что обеспечивает аудируемость.27
Таким образом, агент должен функционировать, имея двойную идентичность: как независимо авторизованный сервис (Managed Identity) для доступа к внутренним системам, и как прокси для конечного пользователя (OAuth/Token Vault) для доступа к данным пользователя. Это требует разработки сложных, гранулярных политик авторизации.
Таблица 2: Сравнительные Методы Аутентификации Инструментов в Корпоративных Агентах


Метод
	Контекст Безопасности
	Пример Платформы
	Управление и Контроль
	API Key/Basic Auth
	Низкий (Статические учетные данные, высокий риск утечки).
	Простые плагины, тестовые среды.
	Плохое. Отсутствует централизованное управление жизненным циклом.
	Managed Identity
	Высокий (Управляется платформой).
	Azure AI Foundry, Azure Functions. 15
	Отлично. Доступ управляется через роли IAM, высокий уровень доверия, не требует кода для управления ключами.
	OAuth 2.0 / MCP
	Высокий (Динамический, токен-ориентированный).
	Microsoft Agent Framework, Auth0. 3
	Превосходно для Agent-to-User и Agent-to-Agent взаимодействия. Гранулярный контроль, поддержка HITL и Token Vault.
	

B. Изоляция Сети и Предотвращение Утечки Данных (DLP)


Корпоративные ИИ-агенты требуют строгой сетевой изоляции для защиты конфиденциальных данных и предотвращения угроз эксфильтрации.
Managed Network Isolation. В Azure AI Foundry стандартная настройка включает управляемую изоляцию сети (Managed Network Isolation).28 Это рекомендуемый подход, обеспечивающий:
* Отсутствие публичного исходящего трафика (No public egress): Фундаментальная инфраструктура предотвращает несанкционированный исходящий трафик, что критически важно для минимизации риска эксфильтрации данных.28
* Инъекция Контейнера (Container Injection): Платформа может внедрять подсеть в частную виртуальную сеть (VNet) клиента. Это позволяет агентам безопасно обращаться к частным ресурсам Azure (таким как базы данных или хранилища), которые не обнаруживаются из Интернета, при условии наличия необходимых учетных данных и авторизации.28
* Private Link: Используется для изоляции PaaS-сервисов (рабочее пространство, Key Vault, реестр контейнеров), обеспечивая безопасный доступ внутри виртуальной сети.29
В этой архитектуре сетевой периметр, определяемый Private Link и VNet, становится основным инструментом управления. Поскольку архитектура физически предотвращает публичный исходящий трафик, она обеспечивает принцип «Разрешать только одобренный исходящий трафик» (Allow only approved outbound mode), что принципиально снижает риск утечки данных во время вывода (inference-time leakage).
Data Loss Prevention (DLP). Предотвращение утечки данных требует многоуровневого подхода.2
1. Ограничение Ввода: Внедрение проверки ввода для маскировки (redaction) или блокировки чувствительных паттернов данных (например, номеров кредитных карт или SSN) перед тем, как они будут переданы LLM в составе промпта.30
2. Контроль Доступа: Применение ролевого контроля доступа (RBAC) и многофакторной аутентификации (MFA) для доступа к интерфейсам LLM.30
3. Мониторинг в Реальном Времени: Использование инструментов DLP для непрерывного отслеживания промптов и генерируемых ответов на предмет обнаружения чувствительных данных. Логи LLM должны быть интегрированы с системами SIEM (Security Information and Event Management) для централизованного анализа и оповещения об аномалиях.30


V. Операционализация Инструментов: MLOps, Тестирование и Непрерывная Верификация


Для поддержания надежности и актуальности корпоративных агентов инструменты должны быть интегрированы в строгий конвейер MLOps.


A. MLOps CI/CD Конвейер для Агентских Систем


MLOps для агентов выходит за рамки традиционного CI/CD для программного обеспечения.32
1. Непрерывное Тестирование (CT): Помимо тестирования кода и компонентов, конвейер должен включать тестирование и валидацию данных, схем данных и самой модели.32
2. Деплоймент Конвейера: Зрелые системы MLOps (Уровень 1) развертывают не только обученную модель в качестве API, но и весь конвейер тренировки/развертывания, который может автоматически и рекуррентно запускаться для предоставления обновленных сервисов.32 Для инструментов это означает, что любое изменение в логике функции или спецификации должно автоматически запускать тестирование и деплоймент.
3. GitOps: Интеграция с GitOps обеспечивает автоматизированный деплоймент. Изменения, зафиксированные в Git (включая спецификации OpenAPI и конфигурации промптов), автоматически инициируют конвейеры CI/CD, которые включают автоматические тесты, валидацию и механизмы быстрого отката.33


B. Строгие Фреймворки Оценки Инструментария Агента


Надежный конечный результат агента не обязательно означает безупречный процесс выбора инструмента. Поэтому тестирование агентских систем требует декомпозиции на измеримые компоненты.22
Декомпозиционное Тестирование. Тесты должны быть разделены для оценки:
* Точности выбора инструмента (Tool Selection Accuracy).
* Корректности планирования (Planning Coherence).
* Обработки многоходовых диалогов.
* Способности восстановления после ошибок.22
Ключевые Метрики Инструмента. Для оценки самого инструментария используются две основные метрики 35:
1. Tool Selection Accuracy (Точность Выбора Инструмента): Измеряет, насколько точно агент выбрал правильный инструмент (или последовательность инструментов) для выполнения запроса. Это метрика, проверяющая семантику решения агента, то есть его способность понять описание инструмента.34
2. Argument Correctness (Корректность Аргументов): Оценивает способность LLM сгенерировать синтаксически и семантически корректные параметры для выбранного инструмента. Низкий показатель корректности аргументов часто указывает на проблемы на уровне синтаксиса — например, неправильное использование типов данных или игнорирование обязательных полей, определенных в JSON Schema.35
Разделение этих метрик позволяет точно определить корневую причину сбоя: низкая точность выбора инструмента указывает на проблему с описанием инструмента (промпт-инжинирингом), тогда как низкая корректность аргументов указывает на проблему с формальной спецификацией (OpenAPI JSON Schema).
Смягчение Позиционного Смещения (Positional Bias). Исследования показали, что LLM подвержены позиционному смещению, когда инструменты, расположенные в начале списка объявлений функций, выбираются чаще, чем это соответствует их объективной необходимости.34 Фреймворки тестирования MLOps должны учитывать это явление и включать ротацию порядка инструментов в тестовых наборах для гарантированной проверки того, что агент основывает свое решение на описании, а не на позиции.34
Таблица 3: Фреймворк Оценки Производительности Инструментов ИИ-Агента


Метрика
	Определение
	Тип Оценки
	Значение для Разработки Инструмента
	Tool Selection Accuracy
	Определяет, выбран ли правильный инструмент для поставленной задачи. 34
	Компонентный (Exact Match).
	Тестирует качество описания инструмента (description) и эффективность стратегии планирования LLM.
	Argument Correctness
	Проверяет, являются ли сгенерированные параметры синтаксически и семантически корректными для вызова инструмента. 35
	Компонентный (LLM-as-a-Judge или Exact Match).
	Проверяет надежность схемы parameters в OpenAPI и способность LLM использовать типы данных.
	Planning Coherence
	Оценивает логическую последовательность шагов (вызовов инструментов) в сложных, многоходовых задачах. 22
	Агентский (LLM-as-a-Judge).
	Выявляет, может ли агент адаптировать свое "формализованное мышление" к сложным зависимостям вызовов. 18
	Error Recovery Capabilities
	Способность агента восстановиться после ошибки инструмента (например, неправильного ввода или усеченного ответа). 16
	Поведенческий (Сценарный).
	Проверяет, насколько хорошо спроектированы сообщения об ошибках инструмента, чтобы направлять агента.
	

C. Версионирование и Трассировка (Versioning and Traceability)


Из-за не-детерминированного характера LLM-выводов, автоматическое версионирование и трассировка являются критически важными.36
Версионирование Функциональной Зависимости. Инструменты, такие как Lilypad, автоматически присваивают номер версии LLM-вызовам. Любое изменение в коде инструмента, промпте или даже пользовательских классах, с которыми он взаимодействует (называемое "function closure"), должно автоматически увеличивать номер версии.36 Это обеспечивает полную трассируемость и воспроизводимость.
Непрерывная Верификация. MLOps-конвейер должен обеспечивать непрерывную верификацию. Поскольку модели могут быстро меняться и по-разному интерпретировать инструкции 37, любое изменение в базовой модели, спецификации инструмента или промпте должно автоматически инициировать перезапуск всего существующего набора тестов для предотвращения нежелательных регрессий поведения агента.37 Таким образом, конвейер MLOps трансформируется в непрерывную систему поведенческого аудита, а не только статического контроля качества.


VI. Заключение и Рекомендации


Разработка инструментария для корпоративных ИИ-агентов в современных платформах, таких как Azure AI Foundry, требует обязательного перехода от разовой интеграции к стандартизированному, управляемому и безопасному процессу. Ключевые выводы и рекомендации для разработчиков включают:
1. Принятие Спецификации как Контракта (OpenAPI Imperative): Спецификация OpenAPI 3.0 является не просто документацией, а функциональным контрактом (JSON Schema), который LLM использует для планирования. Разработчики должны уделять первостепенное внимание детальному описанию функций (используя глагольную конвенцию) и строгой типизации параметров, чтобы обеспечить высокую точность генерации аргументов и снизить число синтаксических ошибок.
2. Приоритизация Безопасности Архитектуры: Корпоративные инструменты должны быть построены на принципах нулевого доверия. Рекомендуется использовать Managed Identity для доступа к ресурсам платформы и протоколы, совместимые с OAuth/MCP, для авторизации от имени пользователя. Сетевая изоляция, обеспечивающая отсутствие публичного исходящего трафика (no public egress) и использование Private Link, является обязательной для предотвращения утечки данных.
3. Проектирование для Эффективности: Количество инструментов должно быть оптимизировано для снижения сложности пространства выбора. Ответы инструментов должны быть токеноэффективными (с использованием пагинации и фильтрации), а сообщения об ошибках — действенными и направляющими, чтобы минимизировать количество и стоимость итераций планирования агента.
4. Внедрение MLOps для Поведения Агента: Разработка инструментов требует фреймворков непрерывного тестирования (CT), которые оценивают не только код, но и поведенческие метрики агента, такие как Tool Selection Accuracy и Argument Correctness. Эти тесты должны автоматически перезапускаться при изменении базовой модели или спецификации инструмента для предотвращения регрессий.
Источники
1. Agent Factory: Building your first AI agent with the tools to deliver real-world outcomes, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
2. Agent Factory: Creating a blueprint for safe and secure AI agents | Microsoft Azure Blog, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
3. Introducing Microsoft Agent Framework | Microsoft Azure Blog, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
4. Overview of Generative AI Agents Service - Oracle Help Center, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
5. Why Shouldn't Use RAG for Your AI Agents - And What To Use Instead : r/AI_Agents - Reddit, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
6. AI 101 : Breaking Down Code Interpreters | by Alozie Igbokwe - Medium, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
7. Exploring OpenAI's ChatGPT Code Interpreter: A Deep Dive into its Capabilities - Unite.AI, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
8. Use Azure Functions with Azure AI Foundry Agent Service - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
9. Introduction to function calling | Generative AI on Vertex AI - Google Cloud, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
10. FunctionDeclaration | Generative AI on Vertex AI - Google Cloud, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
11. Function calling with the Gemini API | Google AI for Developers, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
12. Function calling reference | Generative AI on Vertex AI - Google Cloud, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
13. Do you use nouns for classnames that represent callable objects? - Stack Overflow, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
14. Function naming conventions, when use verbs and when use nouns? - Reddit, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
15. How to use the OpenAPI spec tool - Azure AI Foundry - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
16. Writing effective tools for AI agents—using AI agents - Anthropic, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
17. How LLM APIs use the OpenAPI spec for function calling | by Sirsh Amarteifio - Medium, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
18. ToolACE: Winning the Points of LLM Function Calling - arXiv, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
19. Less is More: Optimizing Function Calling for LLM Execution on Edge Devices - arXiv, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
20. Best practices with large language models (LLMs) | Generative AI on Vertex AI, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
21. Function calling using LLMs - Martin Fowler, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
22. How to Test AI Agents Effectively - Galileo AI: The AI Observability and Evaluation Platform, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
23. Test and troubleshoot agent behavior - Amazon Bedrock - AWS Documentation, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
24. Azure AI Agents client library for Python | Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
25. Serverless OpenAPI Documentation Plugin, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
26. Agent-to-agent OAuth: a guide for secure AI agent connectivity with MCP - Stytch, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
27. Auth0 for AI Agents: Secure Agentic Apps | Auth0, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
28. How to use a virtual network with the Azure AI Foundry Agent Service - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
29. Plan for network isolation - Azure Machine Learning - Microsoft Learn, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
30. Data Leakage Prevention (DLP) for LLMs: Safeguarding Sensitive Data, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
31. Data Loss Prevention (DLP): A Complete Guide for the GenAI Era - Lakera, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
32. MLOps: Continuous delivery and automation pipelines in machine learning - Google Cloud, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
33. CI/CD for AI: Integrating with GitOps and ModelOps Principles - [x]cube LABS, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
34. Evaluating Agent Tool Selection — Testing if First Really is the Worst | by ODSC, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
35. LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide - Confident AI, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
36. Five Tools to Help You Leverage Prompt Versioning in Your LLM Workflow | Mirascope, дата последнего обращения: октября 22, 2025, [URL_REMOVED]
37. How to test AI agents effectively (5 tips) - Merge.dev, дата последнего обращения: октября 22, 2025, [URL_REMOVED]