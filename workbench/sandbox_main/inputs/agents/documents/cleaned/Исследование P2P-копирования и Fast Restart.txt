Технический отчет: Proof-of-Concept для P2P-зеркалирования (Трек 1) и Fast Restart (Трек 3) в vLLM/PyTorch




I. Введение: Техническое Обоснование и Стратегия PoC


Данный отчет детализирует технические компоненты, API и передовые методологии (SOTA), необходимые для немедленного начала Proof-of-Concept (PoC) по двум критическим направлениям: Трек 1 (MVP "P2P-Зеркалирование") и Трек 3 (Premium "Fast Restart").
Цели и Архитектурные Требования:
1. Трек 1 (P2P-Зеркалирование): Цель — обеспечение высокой доступности (High Availability, HA) инференс-сервера. Это требует инкрементальной и почти синхронной репликации состояния, в первую очередь KV-кэша, на резервный GPU. Основная задача — минимизировать накладные расходы на перехват и передачу данных, чтобы не замедлять генерацию следующего токена.
2. Трек 3 (Fast Restart): Цель — быстрое восстановление после сбоя (Disaster Recovery, DR) или эластичное масштабирование. Это требует асинхронного сохранения полного состояния приложения (веса модели, состояние оптимизатора, KV-кэш, скомпилированные CUDA-графы и контексты GPU) и его последующего быстрого восстановления.
Ключевые Технические Барьеры:
* Трек 1: Главной проблемой является производительность. Необходимо перехватывать изменения в KV-кэше на каждом шаге генерации токена и копировать их на другой GPU. Сложность усугубляется использованием в vLLM механизма PagedAttention 1, который управляет KV-кэшем в виде не-континуальных блоков, что делает простой перехват тензоров невозможным.
* Трек 3: Традиционные методы сохранения (torch.save) страдают от медленной сериализации (часто с использованием pickle) 3 и высоких накладных расходов на дисковый I/O. Восстановление "холодного" инстанса vLLM также требует значительного времени на JIT-компиляцию CUDA-кернелов, захват CUDA-графов и инициализацию аллокатора VRAM, даже если веса загружаются быстро.5
Данный документ предоставляет конкретные API, SOTA-техники и примеры кода, необходимые для реализации PoC по обоим трекам.


II. Трек 1 (MVP): Реализация "P2P-Зеркалирования" KV-кэша




Часть 1: Фундамент P2P-копирования – Анализ API и Производительности


Для достижения почти синхронной репликации KV-кэша PoC должен использовать прямое P2P-копирование между GPU.


Критический компонент: cudaMemcpyPeerAsync


Ключевым API для PoC является cudaMemcpyPeerAsync.7
* Peer: Означает, что копирование происходит напрямую между VRAM двух разных GPU, используя выделенный интерконнект (NVLink или PCIe). Данные не проходят через CPU или системную память, что критически снижает задержку.9
* Async: Вызов API является неблокирующим. Он немедленно возвращает управление хост-потоку, в то время как операция копирования ставится в очередь и выполняется в указанном CUDA-потоке (stream).7 Это позволяет перекрывать операции репликации с основными вычислениями (генерацией следующего токена) на GPU.


Сравнительный анализ производительности: NVLink против PCIe


Выбор интерконнекта является решающим фактором для Трека 1. NVLink обеспечивает значительно большую пропускную способность (до 900 ГБ/с на H100) по сравнению с PCIe 5.0 (до 128 ГБ/с).9 Однако для репликации на каждом токене задержка (latency) важнее пропускной способности.
Анализ эталонных тестов p2pBandwidthLatencyTest 10 на системах с A100 (использующих NVLink 3-го поколения и PCIe 4.0) дает следующие количественные показатели 10:
________________
Таблица 2.1: Сравнительная производительность P2P-копирования (NVLink vs. PCIe)
Источник данных: Синтез из 10 (вывод p2pBandwidthLatencyTest). "P2P=Enabled (High)" интерпретируется как NVLink. "P2P=Disabled" или "P2P=Enabled (Low)" интерпретируется как PCIe (или fallback через CPU).


Метрика
	Интерконнект (Интерпретация)
	Производительность
	Анализ
	Задержка (Latency)
	PCIe 4.0 (P2P=Disabled)
	13.72 - 21.75 мкс
	Слишком высоко для репликации на каждом токене.
	Задержка (Latency)
	NVLink (P2P=Enabled)
	2.22 - 2.58 мкс
	На порядок ниже. Допустимо в рамках бюджета одного шага генерации.
	Пропускная способность (Bidirectional)
	PCIe 4.0 (P2P=Enabled)
	~18.8 - 19.3 ГБ/с
	Потенциальное узкое место.
	Пропускная способность (Bidirectional)
	NVLink (P2P=Enabled)
	~515 - 517 ГБ/с
	В ~27 раз выше. Позволяет копировать большие блоки кэша.
	________________
Эти данные показывают, что использование NVLink — это не оптимизация, а фундаментальное требование для Трека 1. Задержка PCIe в ~20 мкс 10 сама по себе сопоставима со временем генерации токена в быстрых моделях, что делает синхронную репликацию невозможной. Задержка NVLink в ~2.2 мкс 10 является допустимой.
PoC должен выполняться на узле с прямым NVLink-соединением между GPU, что можно проверить с помощью утилиты nvidia-smi topo -m.
Для упрощения PoC можно использовать высокоуровневые абстракции, такие как SymmetricMemory в PyTorch, которая позволяет выполнять P2P-копирование через стандартный синтаксис tensor1.copy_(tensor2).11


Часть 2: Архитектура Перехвата (Interception) KV-кэша в PyTorch


Для репликации KV-кэша необходимо сначала перехватить его изменения.


Обзор механизма хуков (Hooks) в PyTorch


PyTorch предоставляет API для "перехвата" вызовов forward и backward у любого nn.Module.12
* register_forward_hook(hook): Выполняется после завершения forward(). Хук имеет сигнатуру hook(module, input, output).12 Он может просматривать и, опционально, модифицировать output.14
* register_forward_pre_hook(hook): Выполняется перед forward(). Хук имеет сигнатуру hook(module, input).12
(Метод Tensor.register_hook(hook) 16 нерелевантен, так как он отслеживает градиенты во время обучения, а не инференса).


Прототип PoC (Простой случай: Hugging Face)


В стандартных моделях Hugging Face (HF) KV-кэш (past_key_value) возвращается как часть кортежа output.17 Мы можем зарегистрировать register_forward_hook на каждом блоке внимания 19, чтобы получить доступ к этому кэшу.
Примерный код PoC (синтез 12):


Python




# Буфер для тензоров, ожидающих P2P-репликации
replication_queue =

def kv_cache_interceptor_hook(module, input, output):
   # В моделях HF 'output' часто является кортежем:
   # (hidden_states, past_key_value,...)
   # Нам нужен 'past_key_value' , который сам является (key, value)
   current_kv_cache = output 
   
   # --- PoC Вариант Б: Инкрементальный (требует управления состоянием) ---
   # Хук по своей природе 'stateless', поэтому мы должны хранить 
   # состояние (длину) в самом модуле.
   last_seq_len = getattr(module, 'last_seen_len', 0)
   
   # Извлекаем только *новые* токены из полного KV-кэша
   new_key_state = current_kv_cache[:, :, last_seq_len:, :]
   new_value_state = current_kv_cache[:, :, last_seq_len:, :]
   
   # Обновляем состояние для следующего вызова
   module.last_seen_len = current_kv_cache.shape
   
   # Добавляем инкремент в очередь на P2P-копирование
   # (здесь должна быть вызвана `cudaMemcpyPeerAsync` или NIXL)
   replication_queue.append((new_key_state, new_value_state))
   
   # Возвращаем оригинальный 'output' без изменений
   return output

# Регистрация хука на каждом слое внимания
for layer in model.model.layers:
   layer.self_attn.register_forward_hook(kv_cache_interceptor_hook)



SOTA-пример: Фреймворк KVPress


Исследование (arXiv:2510.00636) 21 представляет KVPress, PyTorch-библиотеку для сжатия KV-кэша.21 KVPress использует идентичную архитектуру: он прикрепляет PyTorch forward hooks к каждому слою внимания, чтобы перехватывать KV-пары и применять к ним алгоритмы сжатия.21 Наш PoC Трека 1, по сути, является KVPress, но с заменой "сжатия" на "репликацию". Исходный код KVPress 22 должен служить образцом для реализации перехватчика.


Критическая проблема: Несовместимость хуков с vLLM PagedAttention


Вышеописанный PoC не будет работать с vLLM "из коробки". vLLM не использует континуальные тензоры для KV-кэша.1
* vLLM использует PagedAttention 2, где KV-кэш разбит на "блоки" (pages) , которые хранятся не-континуально в VRAM.
* Сопоставление логических токенов с физическими блоками памяти управляется "block table" (таблицей блоков).
* register_forward_hook на слое PagedAttention не вернет понятный тензор (key, value). Он вернет метаданные, используемые кастомными CUDA-кернелами.
Для "зеркалирования" vLLM мы не можем использовать неинтрузивные хуки PyTorch. PoC должен модифицировать исходный код vLLM, в частности KVCacheManager 25 или механизмы аллокации PagedAttention. Когда vLLM выделяет новый блок и записывает в него, именно в этот момент необходимо инициировать P2P-копирование этого блока и обновить "block table" на резервном GPU.


Часть 3: Интеграция и SOTA-решения для P2P-трансфера KV-кэша


vLLM уже использует P2P-трансфер для функции "Disaggregated Prefill" 26, и PoC может адаптировать эти существующие механизмы.


Механизм 1: vLLM p2p_nccl_connector


vLLM имеет встроенный p2p_nccl_connector 26, который использует NCCL для P2P-связи.
* Он поддерживает метод PUT_ASYNC.26
* PUT_ASYNC — это асинхронный метод, который использует выделенный поток для отправки KV-кэша, не блокируя основной процесс.26 Принимающий экземпляр также использует выделенный поток для приема.26
* Применение в PoC: Мы можем адаптировать этот коннектор. Вместо одного большого PUT_ASYNC после prefill (как в Disaggregated Prefill), PoC должен вызывать его инкрементально для каждого нового блока PagedAttention.


Механизм 2: LMCache и NIXL


LMCache — это внешняя система кэширования, интегрируемая с vLLM.28
* Для P2P-шаринга LMCache использует NIXL (NVIDIA Inference Xfer Library).29
* NIXL — это SOTA-библиотека, специально разработанная для оптимизированной P2P-передачи данных между инстансами.29
* Применение в PoC: NIXL 29 представляет собой более зрелое и, возможно, более производительное SOTA-решение для P2P-трансфера, чем встроенный коннектор vLLM.


III. Трек 3 (Premium): SOTA-методы для "Fast Restart"


Трек 3 требует сохранения и восстановления полного состояния приложения, включая не только веса, но и KV-кэш, CUDA-контексты и скомпилированные графы.


Часть 1: Фреймворк-нативное асинхронное C/R (PyTorch/FSDP)


Традиционный torch.save 3 блокирует GPU и является медленным. SOTA-решением в PyTorch (особенно для FSDP) является torch.distributed.checkpoint (DCP).30


Механизм async_save (DCP)


Механизм dcp.async_save 31 оптимизирован для минимизации простоя GPU:
1. Вычисления на GPU кратковременно приостанавливаются.
2. Данные (веса модели, состояние оптимизатора 3) асинхронно копируются из VRAM в CPU-буферы (pinned memory).31
3. Вычисления на GPU немедленно возобновляются.34
4. Выделенные CPU-потоки параллельно записывают данные из CPU-буферов на диск (например, в хранилище).34
Производительность: Этот подход сокращает "downtime" (время простоя) GPU в 10-20 раз. В одном примере для 7B-модели время простоя сократилось со 148.8 до 6.3 секунд.30
Ограничение для Трека 3: DCP предназначен для отказоустойчивости тренировки.35 Он сохраняет только state_dict модели и оптимизатора.31 Он не сохраняет:
1. KV-кэш (состояние инференса).
2. CUDA-контексты.
3. Скомпилированные torch.compile графы.
4. JIT-скомпилированные CUDA-кернелы.
Таким образом, DCP async_save (полный пример в 31) является SOTA для асинхронного сохранения весов, но не решает проблему "Fast Restart" для инференс-сервера vLLM, которому требуется восстановление полного контекста GPU.5


Часть 2: C/R на уровне Приложения и Драйвера (CRIUgpu и Альтернативы)


Истинный "Fast Restart" требует сохранения полного состояния процесса, включая память GPU и CUDA-контексты.6


Базовая технология: NVIDIA cuda-checkpoint + CRIU


Современный SOTA-подход основан на комбинации CRIU (Checkpoint/Restore in Userspace) и утилиты NVIDIA cuda-checkpoint (требуется драйвер 550+ 36).
* CRIU: Стандартный инструмент Linux для "заморозки" (снапшота) CPU-процесса, включая его память, файловые дескрипторы и т.д..36
* cuda-checkpoint: Утилита NVIDIA, которая позволяет CRIU работать с CUDA-приложениями.36
Механизм C/R (синтез 36):
1. Блокировка: cuCheckpointProcessLock() (или cuda-checkpoint --toggle --pid <PID>) вызывается, блокируя новые вызовы CUDA API и ожидая завершения текущих операций в CUDA-потоках.36
2. Снапшот GPU: cuCheckpointProcessCheckpoint() копирует всю VRAM в RAM (host memory) и освобождает ресурсы GPU.36
3. Снапшот CPU: Процесс становится "CPU-only".6 criu dump вызывается для сохранения состояния CPU-процесса (включая дамп VRAM, который теперь находится в RAM).
4. Восстановление: criu restore восстанавливает CPU-процесс, затем cuCheckpointProcessRestore() выделяет VRAM, копирует состояние обратно на GPU и разблокирует API.36


SOTA-реализации: CRIUgpu и Modal


Два проекта реализуют этот механизм:
1. CRIUgpu: Исследовательский проект (представлен на KubeCon 2025 39) 41, который интегрирует cuda-checkpoint в CRIU через плагины.43 Он создает единый CPU-GPU снапшот 6 и заявляет о нулевых накладных расходах в штатном режиме.6
2. Modal "GPU Memory Snapshots": Коммерческая, работающая в продакшене реализация, использующая те же API NVIDIA.38 Modal сообщает о восстановлении 70B-моделей менее чем за 5 секунд.46 Их опыт подтверждает, что этот подход сохраняет JIT-скомпилированные артефакты (torch.compile), CUDA-графы и загруженные кернелы.38


Разрешение противоречия в запросе (Ключевой вывод)


В запросе пользователя указано: "обходя cuda-checkpoint". Это, вероятно, связано с устаревшей информацией.
* Старая проблема: Официальная документация cuda-checkpoint (для драйвера 550) явно заявляла: "no support for UVM or IPC memory".36
* PyTorch активно использует IPC (Inter-Process Communication), например, для DataLoader с num_workers > 0.47 Это делало старую версию cuda-checkpoint несовместимой с PyTorch.
* SOTA-решение (2025 г.): Эта проблема решена. В обсуждении на GitHub от февраля 2025 г. 47 пользователи подтверждают, что "checkpoint/restore for PyTorch works as expected with CRIU and driver version 570.86.10".47
Следовательно, PoC для Трека 3 должен использовать cuda-checkpoint, но обязательно на драйвере версии 570+.47


Часть 3: SOTA-решения для быстрой загрузки vLLM (Альтернативный C/R)


В дополнение к системному C/R (CRIU) существуют SOTA-методы C/R на уровне приложения, специфичные для vLLM.


Решение 1: Быстрая загрузка (Не C/R)


Эти методы ускоряют "холодный" старт, но не сохраняют состояние GPU (графы, KV-кэш).
* load_format="sharded_state" 48: Использует скрипт save_sharded_state.py 51 для сохранения весов в разделенном (sharded) формате. При загрузке каждый GPU-воркер читает только свой шард, избегая чтения полной модели.50 Это ускоряет только загрузку весов.
* load_format="tensorizer" 48: Использует SOTA-библиотеку CoreWeave tensorizer.54 Он десериализует тензоры напрямую из хранилища (S3, диск) в VRAM, минуя CPU RAM.53 Это обеспечивает чрезвычайно быструю загрузку весов, но по-прежнему не является C/R.5


Решение 2: SOTA C/R на уровне приложения — vLLM "Sleep Mode"


Наиболее перспективным SOTA-решением для Трека 3 является "Sleep Mode", представленный vLLM 26 октября 2025 года.55
* Концепция: Это не системный снапшот (как CRIU). Процесс vLLM не завершается, а переводится в режим гибернации.55
* Механизм 55:
   * Level 1 (Сон): Выгружает веса модели в CPU RAM, сбрасывает KV-кэш.
   * Level 2 (Глубокий сон): Сбрасывает веса и KV-кэш.
* Ключевое преимущество (Почему это SOTA) 55: При "пробуждении" vLLM сохраняет (preserves) самые дорогие для инициализации компоненты, которые tensorizer и sharded_state не сохраняют:
   1. Инициализированный CUDA-аллокатор.
   2. Захваченные CUDA-графы (Graph capturing).
   3. JIT-скомпилированные CUDA-кернелы (FlashInfer, TorchInductor и т.д.).
* Это устраняет "скрытые затраты" холодного старта 5 и обеспечивает по-настоящему теплый рестарт.
* Производительность: В 18-200 раз быстрее, чем полная перезагрузка.55
* API 55:
   * Запуск сервера: vllm serve... --enable-sleep-mode.55
   * Сон: curl -X POST 'localhost:8001/sleep?level=2'.55
   * Пробуждение: curl -X POST 'localhost:8001/wake_up'.55


Часть 4: Интеграция GPU-сжатия (Трек 4)


Для ускорения C/R (как DCP, так и CRIUgpu) необходимо уменьшить объем данных, передаваемых на диск. SOTA-технологией для этого является NVIDIA nvCOMP.56
* Технология: nvCOMP — это библиотека для GPU-ускоренного сжатия/декомпрессии (LZ4, Snappy, ZSTD и др.).56
* Интеграция с PyTorch: nvCOMP предоставляет Python API 56, которое может работать напрямую с тензорами PyTorch 56 через протокол __cuda_array_interface__.58
Пример кода интеграции (из 58):


Python




import torch
import nvidia.nvcomp as nvcomp

# 1. Исходный тензор на GPU (например, часть state_dict)
data_gpu = torch.randn(1024*1024, dtype=torch.float16, device="cuda:0")

# 2. Создание кодека (например, LZ4)
codec = nvcomp.Codec(algorithm="LZ4")

# 3. Обертывание тензора PyTorch (zero-copy)
# nvcomp.as_array принимает любой объект с __cuda_array_interface__
nvarr_d = nvcomp.as_array(data_gpu)

# 4. Сжатие (выполняется полностью на GPU)
compressed_arr_gpu = codec.encode(nvarr_d)

# 5. Декомпрессия (также на GPU)
# data_type="<f2" соответствует float16
decompressed_arr_gpu = codec.decode(compressed_arr_gpu, data_type="<f2")



Аппаратное ускорение Blackwell


Архитектура NVIDIA Blackwell (2024+) включает выделенный аппаратный движок декомпрессии (DE).60 nvCOMP (v4.2+) автоматически использует этот DE 56, достигая скорости декомпрессии 600 ГБ/с.60 Это означает, что восстановление (декомпрессия) из сжатого чекпоинта становится практически бесплатным с точки зрения вычислений.


Интеграция в Трек 3


* Для DCP: В пайплайне async_save 31, после копирования GPU -> CPU, CPU-буфер может быть сжат (либо CPU-версией zstd, либо отправлен обратно на GPU для nvCOMP) перед записью на диск.
* Для CRIUgpu: После того как cuda-checkpoint скопировал VRAM в RAM 36, этот дамп в RAM может быть сжат (оптимально, с использованием nvCOMP на GPU) перед записью на диск. При восстановлении будет использоваться nvCOMP (в идеале с DE Blackwell 60) для декомпрессии.


IV. Синтез и Рекомендации по Реализации PoC




Рекомендации для PoC Трека 1 (P2P-Зеркалирование)


1. Оборудование: PoC должен использовать узел с прямыми соединениями NVLink. Производительность PCIe (~20 мкс задержки) 9 недостаточна.
2. API Трансфера: Рекомендуется интегрировать LMCache с NIXL 29 как SOTA-механизм P2P-передачи.
3. Перехват: PoC не должен использовать хуки PyTorch (register_forward_hook), так как они несовместимы с PagedAttention. Вместо этого, PoC должен модифицировать исходный код KVCacheManager 25 в vLLM, чтобы инициировать P2P-трансфер NIXL 29 для каждого нового выделенного блока KV-кэша.


Рекомендации для PoC Трека 3 (Fast Restart)


PoC должен сравнить три SOTA-метода:
1. DCP async_save 31: Реализовать в качестве базового уровня для бенчмаркинга асинхронного сохранения весов. Интегрировать nvCOMP 59 для GPU-сжатия CPU-буфера перед записью на диск.
2. CRIUgpu 42: Реализовать как системное C/R. Критический тест: Проверить утверждение 47, что драйвер NVIDIA 570+ успешно восстанавливает PyTorch-процессы, включая те, что используют IPC (например, DataLoader с num_workers > 0), что было невозможно с драйвером 550.36
3. vLLM "Sleep Mode" 55: Реализовать как C/R на уровне приложения. Это наиболее перспективный SOTA-метод (Октябрь 2025 г.), поскольку он единственный из трех сохраняет скомпилированные графы/кернелы 55, что является ключом к теплому рестарту.
Финальный вывод: PoC, вероятно, покажет, что "Sleep Mode" 55 является лучшим решением для управляемого "теплого" рестарта (например, при переключении моделей), в то время как CRIUgpu 42 является лучшим решением для неуправляемого (DR) восстановления после полного сбоя процесса или узла. Оба механизма комплементарны и необходимы для полнофункциональной Premium-инфраструктуры.
Источники
1. What is PagedAttention? - Hopsworks, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
2. The Architecture Behind vLLM: How PagedAttention Improves Memory Utilization - Medium, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
3. Saving and Loading Models — PyTorch Tutorials 2.9.0+cu128 documentation, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
4. Alternatives to persist millions of tensors of different shapes? [closed] - Stack Overflow, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
5. Using CRIU to Reduce Cold Start Latency for LLM Tasks - General - vLLM Forums, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
6. GPU Container Checkpoint/Restore with CRIUgpu: Zero-Downtime Live Migration for ML Workloads - DevZero, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
7. cudaMemcpyPeerAsync - NVIDIA CUDA Library, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
8. CUDA API REFERENCE MANUAL - NVIDIA, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
9. How does the NVLink interface compare to PCIe in terms of bandwidth and latency for large language models? - Massed Compute, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
10. Benchmark bandwidth and latency of P2P NVIDIA GPUs (NVLINK vs ..., дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
11. PyTorch SymmetricMemory: Harnessing NVLink Programmability ..., дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
12. PyTorch Hooks. Sometimes there are many ways to do the… | by Mriganka Nath | Analytics Vidhya | Medium, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
13. PyTorch 101: Understanding Hooks - DigitalOcean, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
14. torch.nn.modules.module.register_module_forward_hook — PyTorch 2.9 documentation, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
15. Use forward_pre_hook to modify nn.Module parameters - autograd - PyTorch Forums, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
16. torch.Tensor.register_hook — PyTorch 2.9 documentation, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
17. KV Caching from Scratch — Pytorch | by Ali Shafique | Medium, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
18. Implementing KV-Caching from Scratch | Detailed LLM Inference Optimization - Towards AI, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
19. How exactly the forward and backward hooks work in PyTorch - Stack Overflow, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
20. How should be used register_forward_hook? - PyTorch Forums, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
21. KV Cache Compression by Estimating Attention from Future Queries Distribution - arXiv, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
22. NVIDIA/kvpress: LLM KV cache compression made easy - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
23. Introduction to vLLM and PagedAttention | Runpod Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
24. Paged Attention - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
25. [RFC]: KV cache offloading · Issue #19854 · vllm-project/vllm - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
26. P2P NCCL Connector - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
27. Disaggregated Prefill and KV Cache Storage in vLLM - November 14, 2024 - YouTube, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
28. LMCache Examples - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
29. P2P KV Cache Sharing | LMCache, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
30. Reducing Model Checkpointing Times by Over 10x with PyTorch Distributed Asynchronous Checkpointing, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
31. Asynchronous Saving with Distributed Checkpoint (DCP) — PyTorch ..., дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
32. Meta PyTorch Team 2024 H2 Roadmaps, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
33. torch.distributed.checkpoint — PyTorch 2.9 documentation, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
34. 6x faster Async Checkpointing in PyTorch, using Cached Plans, no GIL contention, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
35. Managing a PyTorch Training Process with Checkpoints and Early Stopping - MachineLearningMastery.com, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
36. Checkpointing CUDA Applications with CRIU | NVIDIA Technical Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
37. Container Checkpoint/Restore with CRIU - DevZero, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
38. GPU Memory Snapshots: Supercharging Sub-second Startup | Modal Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
39. Efficient Transparent Checkpointing of A... - KubeCon + CloudNativeCon Europe 2025, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
40. (PDF) Efficient Transparent Checkpointing of AI/ML Workloads in Kubernetes, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
41. CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads - arXiv, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
42. arXiv:2502.16631v1 [cs.DC] 23 Feb 2025, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
43. [KubeCon 2025] Efficient Transparent Checkpointing of AI/ML Workloads in Kubernetes.pptx - Radostin Stoyanov, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
44. [2502.16631] CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads - arXiv, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
45. [D] Implementing GPU snapshotting to cut cold starts for large models by 12x - Reddit, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
46. Running 50+ LLMs per GPU with sub-5s snapshot load times — anyone exploring model scheduling like this? : r/CUDA - Reddit, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
47. pytorch support · Issue #4 · NVIDIA/cuda-checkpoint - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
48. load - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
49. Load Sharded State - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
50. Save Sharded State - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
51. Save Sharded State - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
52. Tensorize vLLM Model - Read the Docs, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
53. Loading models with CoreWeave's Tensorizer - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
54. Decrease PyTorch Model Load Times with CoreWeave's Tensorizer, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
55. Zero-Reload Model Switching with vLLM Sleep Mode | vLLM Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
56. NVIDIA nvCOMP - NVIDIA Developer, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
57. NVIDIA/nvcomp: Repository for nvCOMP docs and examples. nvCOMP is a library for fast lossless compression/decompression on the GPU that can be downloaded from [URL_REMOVED] - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
58. Python API — nvCOMP - NVIDIA Docs, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
59. memory was not free. nvcomp python api · Issue #206 · NVIDIA/CUDALibrarySamples, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
60. Speeding Up Data Decompression with nvCOMP and the NVIDIA Blackwell Decompression Engine | NVIDIA Technical Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]