Архитектурный фреймворк для метакогнитивного агента-пилота с динамическим решением проблем на основе АРИЗ




Раздел 1: Основы автономии агента: метапознание и рефлексия




1.1. Введение в метапознание агента: способность к самооценке


В основе по-настоящему автономного ИИ-агента лежит метапознание — способность модели осознавать собственные возможности и ограничения.1 Эта способность является не просто дополнительной функцией, а фундаментальным требованием для эффективной и надежной работы. Без точной самооценки агент рискует действовать неэффективно, совершать ошибки или вводить пользователей в заблуждение, слепо доверяя неверным результатам. Метапознание в контексте больших языковых моделей (LLM) проявляется в двух ключевых формах:
1. Внутренняя калибровка неопределенности: Это способность LLM оценивать степень своей уверенности в конкретном ответе или сгенерированном результате. Исследования показывают, что, хотя LLM обладают внутренними сигналами неопределенности, их выраженная уверенность часто бывает неоткалиброванной, что приводит к несоответствию между заявленной уверенностью и фактической точностью. Однако эту проблему можно значительно смягчить с помощью контролируемой тонкой настройки (supervised fine-tuning). Такая настройка улучшает калибровку (согласованность между уверенностью и точностью) и дискриминацию (способность присваивать более высокую уверенность правильным ответам по сравнению с неверными) как внутри одной области знаний, так и при переносе на новые, например, на медицинские или юридические рассуждения.2
2. Оценка внешних возможностей: Это способность агента определять, следует ли ему использовать внешний инструмент (например, поисковую систему, калькулятор или интерпретатор кода) или попытаться решить задачу, опираясь исключительно на свои внутренние знания. Необдуманное и неизбирательное обращение к инструментам приводит к увеличению задержек и потенциальным ошибкам из-за некорректного взаимодействия с внешними системами. Стратегия MeCo (Metacognition) предлагает подход, не требующий тонкой настройки, для количественной оценки этой самооценки. Она позволяет агенту анализировать высокоуровневые когнитивные сигналы в пространстве представлений модели, чтобы принимать взвешенное решение о необходимости вызова инструмента, тем самым повышая общую эффективность и надежность.1
Таким образом, хорошо откалиброванное метапознание служит для агента системой раннего предупреждения. Низкая внутренняя уверенность сигнализирует о необходимости более тщательной проверки ответа, а осознание пределов своих знаний — о необходимости обратиться за помощью к внешним инструментам.


1.2. Паттерн рефлексии: действенный цикл самосовершенствования


Метапознание становится действенным через механизм рефлексии. Рефлексия — это процесс, в ходе которого агент анализирует свои прошлые действия и их результаты с целью самокоррекции и улучшения стратегии.3 Этот паттерн, выделенный Эндрю Ыном (Andrew Ng) как один из ключевых наряду с планированием, использованием инструментов и многоагентным взаимодействием, является ИИ-аналогом человеческой интроспекции или так называемого «Системного 2» мышления — медленного и deliberative (обдуманного).3
Вместо того чтобы просто инстинктивно реагировать на запросы, рефлексивный ИИ делает паузу для анализа проделанной работы. Этот процесс можно описать как циклический рабочий процесс: генерация → критика → улучшение.3
1. Генерация: Агент создает первоначальный результат (например, фрагмент кода, план действий, текст) в ответ на поставленную задачу.4
2. Критика (Рефлексия): Агент запускает механизм самооценки, задавая себе контрольные вопросы, такие как: «Точен ли этот ответ?», «Существует ли лучший способ решения?», «Логика в этом выводе имеет смысл?».5 Он выявляет ошибки, неоптимальные шаги или несоответствия поставленной цели.3
3. Улучшение: На основе самокритики агент корректирует свою стратегию и генерирует улучшенную версию результата. Этот цикл повторяется итеративно до тех пор, пока не будет достигнут желаемый уровень качества или не сработает критерий остановки.4
Ключевое преимущество этого паттерна заключается в том, что он позволяет агенту учиться на собственном опыте без необходимости получения новых внешних обучающих данных или переобучения весов модели. Уроки, извлеченные из неудачных действий или неэффективных рассуждений, сохраняются в памяти агента и используются для информирования будущих циклов планирования, что приводит к постепенному повышению производительности.3


1.3. Архитектурная реализация: модель «Генератор-Критик»


Канонической архитектурой для реализации паттерна рефлексии является модель «Генератор-Критик».6 Эта модель разделяет процесс на две функциональные роли, которые могут быть реализованы как отдельные модули или даже как два взаимодействующих агента:
* Генератор: Отвечает за создание основного результата. Его задача — выполнить поставленную задачу на основе текущей информации.6
* Критик: Представляет собой отдельный вызов LLM, который оценивает работу генератора. Этот подход, известный как «LLM-как-судья» (LLM-as-a-judge), является надежным методом оценки, поскольку он позволяет использовать естественный язык для формулирования критериев и рубрик оценки.7 Если работа признана неудовлетворительной, критик формулирует обратную связь, которая направляется обратно генератору для следующей итерации.6
Фреймворки, поддерживающие циклические и состоятельные рабочие процессы, идеально подходят для реализации этой архитектуры.
* LangGraph: Позволяет строить графы, где узлы представляют генератора и критика. Общее состояние (AgentState), которое хранит описание проблемы, текущий ответ и историю критики, передается между узлами. Условные ребра в графе направляют поток управления: если критик выносит вердикт «требуется доработка», поток возвращается к узлу генератора, замыкая цикл самокоррекции.6
* AutoGen: Предлагает альтернативную реализацию, где пара агентов, например, «кодер» (coder) и «рецензент» (reviewer), взаимодействуют друг с другом. Кодер генерирует код, а рецензент его критикует. Этот диалог продолжается до тех пор, пока рецензент не одобрит результат, что является условием завершения цикла.8
Эффективность всего цикла рефлексии напрямую зависит от качества метакогнитивных сигналов. Именно сигналы о низкой уверенности 2 или осознании пределов своих возможностей 1 служат триггерами для запуска критической оценки. Без этих сигналов агент не сможет понять, когда именно необходимо остановиться и переосмыслить свои действия, что приведет к неэффективным или неверным циклам рефлексии. Таким образом, развитие метакогнитивных способностей является первым и наиболее важным шагом на пути к созданию по-настоящему автономных, самокорректирующихся систем.


Раздел 2: Динамическое формирование стратегии: планирование, маршрутизация и адаптация


После того как агент наделен способностью к самооценке, следующим шагом является разработка механизмов для анализа задач и динамического выбора наилучшей стратегии их выполнения. Этот процесс начинается с интеллектуального анализа входящего запроса и завершается оркестрацией сложных рабочих процессов.


2.1. Интеллектуальный анализ запросов: декомпозиция сложности


Современные ИИ-системы все чаще сталкиваются с длинными, сложными запросами, содержащими несколько взаимосвязанных намерений, которые трудно обработать стандартными методами.9 Решением этой проблемы является декомпозиция запроса — процесс, при котором LLM интеллектуально разбивает сложную задачу на несколько более мелких, атомарных подзадач.9
* Фреймворк ReDI (Reasoning-enhanced query understanding through Decomposition and Interpretation) является примером такого подхода. Он использует трехэтапный конвейер: (i) разбивает сложный запрос на целевые подзапросы для точного охвата всех намерений пользователя; (ii) обогащает каждый подзапрос семантическими интерпретациями для улучшения соответствия между запросом и документами; и (iii) объединяет результаты для получения итогового ответа.9
* Современные RAG-системы (Retrieval-Augmented Generation) также активно используют этот принцип. Например, «агентурный поиск» (agentic retrieval) в Azure AI Search использует LLM для разбиения сложных запросов на сфокусированные подзапросы, которые выполняются параллельно. Это позволяет генерировать структурированный, обоснованный данными ответ с цитатами.11
* Адаптивный RAG (Adaptive RAG) развивает эту идею еще дальше. Прежде чем выполнять поиск, система сначала анализирует сложность запроса. Для простых вопросов, на которые LLM может ответить самостоятельно, этап поиска пропускается, что экономит ресурсы. Для сложных запросов запускается многоэтапный поиск по нескольким источникам данных.12
Этот первоначальный анализ позволяет агенту преобразовать неструктурированный, многогранный запрос в четкий, выполнимый план действий.


2.2. Паттерн «Маршрутизатор/Диспетчер»: выбор правильного протокола


После декомпозиции задачи на подзапросы агент должен решить, как обрабатывать каждый из них. Эту функцию выполняет агент-маршрутизатор (Router Agent) или диспетчер (Dispatcher).13
* Маршрутизатор — это, по сути, вызов LLM, который анализирует намерение подзапроса и направляет его к соответствующему инструменту, функции или рабочему процессу. Например, получив запрос «каково произведение 10 и 2», маршрутизатор определит, что требуется математическая операция умножения, и вызовет соответствующий инструмент.13
* Паттерн LLM-Dispatcher расширяет эту концепцию, действуя как интеллектуальный контроллер трафика для ИИ-запросов. Он может не только выбирать нужный инструмент, но и маршрутизировать запросы к разным LLM в зависимости от их производительности, стоимости и доступности в реальном времени. Такой диспетчер может автоматически обрабатывать отказы, перенаправляя запрос к следующей лучшей модели, если основная недоступна или превысила лимиты.14
Этот механизм добавляет в архитектуру агента критически важный слой принятия решений, позволяя ему гибко выбирать из библиотеки доступных протоколов и настроек для решения каждой конкретной подзадачи.


2.3. Фреймворки для оркестрации динамических рабочих процессов


Для реализации сложных, условных рабочих процессов, управляемых маршрутизаторами и диспетчерами, используются специализированные многоагентные фреймворки.
* Иерархический процесс CrewAI: Эта модель особенно актуальна для сложных проектов. В ней автоматически создается агент-менеджер (manager_llm), который координирует рабочий процесс. В отличие от последовательного выполнения задач, менеджер динамически распределяет подзадачи между специализированными агентами на основе их возможностей, а также проверяет результаты их работы. Это очень похоже на то, как менеджер проекта в человеческой команде делегирует задания экспертам.15
* Microsoft Agent Framework: Этот фреймворк, являющийся преемником AutoGen и Semantic Kernel, предлагает графо-ориентированные рабочие процессы. Они позволяют соединять нескольких агентов и функции в единую систему, поддерживая условную маршрутизацию, принятие решений на основе моделей и параллельное выполнение задач. Это дает разработчикам явный контроль над путями выполнения многоагентных операций.17
* LangChain/LangGraph: Эти библиотеки предоставляют фундаментальные строительные блоки для создания таких систем с нуля. В частности, LangGraph, с его способностью управлять состоянием и определять циклы, идеально подходит для реализации сложных условных логик и итеративных циклов, таких как рефлексия или многоэтапное решение проблем.6
Все эти подходы — декомпозиция, маршрутизация и оркестрация — формируют новый архитектурный слой, который можно назвать «агентурным промежуточным ПО» (agentic middleware). Этот слой находится между необработанным вводом пользователя и основными инструментами выполнения агента. Его функция — преобразовать неструктурированное намерение в структурированный, выполнимый план. Развитие ИИ-агентов, вероятно, будет смещаться от создания монолитных «всемогущих» агентов к оркестрации этих специализированных промежуточных компонентов.


Раздел 3: Протокол АРИЗ: вычислительная основа для изобретательского решения проблем


Когда агент сталкивается с проблемой, которую не удается решить простыми корректировками стратегии, ему требуется принципиально новый подход. Вместо того чтобы идти на компромисс и снижать производительность, агент должен найти изобретательное решение. Для этой цели идеально подходит Теория Решения Изобретательских Задач (ТРИЗ), а ее наиболее мощный инструмент — Алгоритм Решения Изобретательских Задач (АРИЗ).


3.1. Введение в ТРИЗ и концепцию технических противоречий


ТРИЗ — это структурированная, основанная на знаниях методология для инноваций, разработанная на основе анализа сотен тысяч патентов.20 Центральная идея ТРИЗ заключается в том, что изобретательские проблемы и их решения повторяются в разных отраслях и науках, и что в основе любой сложной проблемы лежит противоречие, которое нужно разрешить, а не обойти.21
Ключевым понятием для агента является техническое противоречие. Оно возникает, когда попытка улучшить один параметр системы (например, скорость) приводит к недопустимому ухудшению другого параметра (например, надежности или точности).20 Задача агента-пилота при столкновении с неразрешимой проблемой — сформулировать ее именно в этих терминах. Например: «Мой текущий протокол обработки данных работает быстро, но генерирует неточные результаты. Противоречие: улучшение параметра ‘Скорость’ ухудшает параметр ‘Точность’».
LLM идеально подходят для этой задачи. Благодаря своей обширной базе знаний они могут помочь отобразить конкретную проблему на один из 39 обобщенных инженерных параметров ТРИЗ (таких как «Скорость», «Мощность», «Надежность», «Точность измерения» и т.д.), тем самым переводя частную проблему на универсальный язык ТРИЗ.23


3.2. АРИЗ: Алгоритм Решения Изобретательских Задач


АРИЗ является центральным аналитическим инструментом ТРИЗ, предназначенным для решения самых сложных, нестандартных задач, которые не поддаются другим методам.24 Это пошаговый алгоритм, главная цель которого — преобразовать исходную, запутанную проблему в простую и ясную модель конфликта, где решение становится очевидным.24
Классическая версия АРИЗ-85-В/С состоит из девяти частей, которые можно сгруппировать по целям 24:
* Части 1-3: Анализ и переформулирование проблемы. На этом этапе происходит глубокий анализ системы, выявляются ресурсы, строится модель задачи и формулируются техническое и физическое противоречия.
* Части 4-6: Устранение противоречия. Здесь используются ресурсы системы, база знаний ТРИЗ (стандарты, эффекты, принципы) для поиска решения. Если проблема не решается, она преобразуется.
* Части 7-9: Анализ и развитие решения. Найденное решение проверяется, развивается его максимальное использование и анализируется весь пройденный путь для извлечения уроков.
В следующей таблице представлено, как абстрактные шаги АРИЗ-85 могут быть преобразованы в конкретные вычислительные действия для агента-пилота.
Таблица 1: Отображение шагов АРИЗ-85 на действия агента-пилота
Часть АРИЗ-85
	Цель
	Вычислительное действие для агента-пилота
	1. Анализ задачи и системной среды
	Анализ и переформулирование исходной проблемы
	Сгенерировать промпт для LLM: «Опиши операционную среду задачи. Определи главный полезный продукт (ГПП) системы и основной конфликт, препятствующий его достижению. Сформулируй мини-задачу».
	2. Анализ ресурсов и создание модели задачи
	Анализ и переформулирование исходной проблемы
	Сгенерировать промпт для LLM: «Проанализируй все доступные ресурсы (вещественно-полевые, пространственные, временные). Сформулируй техническое противоречие (ТП-1) в терминах 39 параметров ТРИЗ: ‘Если {параметр А} улучшается, то {параметр Б} ухудшается’».
	3. Определение Идеального Конечного Результата (ИКР)
	Анализ и переформулирование исходной проблемы
	Сгенерировать промпт для LLM: «Сформулируй Идеальный Конечный Результат (ИКР-1), где полезная функция выполняется сама по себе, без затрат и вреда. Затем сформулируй физическое противоречие (ФП), определив элемент, который должен обладать двумя противоположными свойствами для достижения ИКР».
	4. Решение задачи с использованием ресурсов
	Устранение противоречия
	Сгенерировать промпт для LLM: «Проанализируй ресурсы, особенно в оперативной зоне и в оперативное время. Как можно использовать эти ресурсы для разрешения физического противоречия?»
	5. Использование информационной базы знаний
	Устранение противоречия
	Выполнить поиск по матрице противоречий ТРИЗ на основе ТП-1. Сгенерировать промпт для LLM: «Матрица противоречий предлагает следующие изобретательские принципы: {список принципов}. Примени каждый из этих принципов для генерации гипотетических решений исходной проблемы».
	6. Изменение или переформулирование задачи
	Устранение противоречия
	Сгенерировать промпт для LLM: «Если решение не найдено, переформулируй задачу. Как можно решить ее ‘от ИКР’? Как можно изменить надсистему или подсистему, чтобы устранить исходное противоречие?»
	7. Анализ и выбор лучшего решения
	Анализ и развитие решения
	Сгенерировать промпт для LLM-критика: «Оцени сгенерированные решения по критериям: полнота разрешения противоречия, простота, использование ресурсов, отсутствие новых проблем. Выбери наиболее перспективное решение».
	8. Развитие максимального использования решения
	Анализ и развитие решения
	Сгенерировать промпт для LLM: «Возьми выбранное решение. Как можно расширить его применение? Как оно изменит надсистему? Разработай план внедрения этого нового подхода/протокола».
	9. Анализ всего процесса решения
	Анализ и развитие решения
	Сгенерировать промпт для LLM: «Проанализируй весь пройденный путь от исходной проблемы до финального решения. Какие шаги были ключевыми? Какие ошибки были допущены? Сформулируй извлеченные уроки для будущих задач».
	

3.3. Автоматизация АРИЗ с помощью LLM: от теории к практике


Преобразование сложной методологии АРИЗ в исполняемый код стало возможным благодаря последним достижениям в области LLM. Исследовательские проекты, такие как AutoTRIZ и TRIZ-GPT, демонстрируют практические подходы к автоматизации этого процесса.
* Система AutoTRIZ предлагает четкий четырехэтапный рабочий процесс, который агент может эмулировать 23:
   1. Идентификация проблемы: LLM уточняет и структурирует исходное описание проблемы от пользователя.
   2. Обнаружение противоречия: LLM сопоставляет проблему с улучшающимся и ухудшающимся параметрами ТРИЗ.
   3. Извлечение принципов: LLM использует Матрицу Противоречий для поиска релевантных Изобретательских Принципов.
   4. Генерация решения: LLM использует найденные принципы в качестве творческих стимулов для генерации конкретных, применимых решений.
* Исследование TRIZ-GPT подтверждает эффективность этого подхода, показывая, что рабочий процесс, использующий пошаговые рассуждения и тщательно разработанные промпты, может генерировать решения, которые тесно совпадают с решениями, предложенными экспертами-людьми.20
* Многоагентный подход: Решение задач по ТРИЗ также может быть организовано как совместная работа команды специализированных агентов. Например, агент-аналитик формулирует проблему, агент-специалист по ТРИЗ находит противоречия и принципы, а агент-эксперт в предметной области адаптирует общие решения к конкретному контексту. Вся эта работа координируется агентом-менеджером проекта.21
АРИЗ, будучи детерминированным алгоритмом, предоставляет жесткую структуру или «каркас», который направляет вероятностные рассуждения LLM по логическому пути. Это превращает открытую творческую задачу («придумай новый способ») в серию ограниченных, детерминированных шагов. LLM предоставляет обширные знания о мире и лингвистическую гибкость для выполнения каждого шага, в то время как АРИЗ обеспечивает логическую структуру, которая предотвращает галлюцинации и отклонения, направляя LLM к нетривиальному, изобретательскому решению.21


Раздел 4: Единая архитектура для агента-пилота на базе АРИЗ


Для создания агента, который может не только выполнять задачи, но и интеллектуально реагировать на неудачи, требуется интегрированная архитектура, объединяющая стандартное выполнение, рефлексивную коррекцию и изобретательское решение проблем. Предлагается иерархическая модель реагирования на сбои, которая эмулирует человеческий подход к решению проблем: от простых исправлений до глубокого творческого переосмысления.


4.1. Иерархическая модель реагирования на сбои


Эта модель состоит из трех вложенных циклов, каждый из которых активируется в зависимости от серьезности возникшей проблемы. Такая структура позволяет агенту экономно расходовать вычислительные ресурсы, прибегая к более сложным и затратным методам только тогда, когда это действительно необходимо.
* Цикл 1 (Внутренний): Цикл выполнения ReAct. Это стандартное рабочее состояние агента, основанное на парадигме «Рассуждай-Действуй» (Reason-Act).27 Агент последовательно рассуждает о следующем шаге, выбирает инструмент и действует. Этот цикл является наиболее «дешевым» с точки зрения вычислений и используется для рутинного выполнения задач.
* Цикл 2 (Средний): Цикл рефлексии/коррекции. Этот цикл запускается метакогнитивным сигналом — например, низкой уверенностью в результате, ошибкой инструмента или отрицательной оценкой от внутреннего критика. Агент приостанавливает выполнение, анализирует свои последние действия и пытается внести простое стратегическое изменение: использовать другой инструмент, переформулировать запрос или изменить параметры.6 Этот цикл имеет умеренную вычислительную стоимость.
* Цикл 3 (Внешний): Изобретательский цикл АРИЗ. Этот цикл является последним средством и активируется только тогда, когда цикл рефлексии многократно терпит неудачу. Повторяющиеся сбои указывают на фундаментальный недостаток в текущем подходе — на наличие «технического противоречия». Агент эскалирует проблему до полного протокола АРИЗ, чтобы сгенерировать принципиально новую стратегию решения, а не просто скорректировать существующую.24 Этот цикл является наиболее «дорогим» и энергозатратным.
Такая иерархическая структура воплощает принцип сохранения «когнитивной энергии». Агент не перепланирует всю свою деятельность с нуля после каждой мелкой ошибки. Вместо этого он применяет наиболее адекватный по сложности и затратам механизм реагирования, что делает его не только более эффективным, но и более устойчивым и производительным в долгосрочной перспективе.


4.2. Управление состоянием и потоком управления с помощью LangGraph


Фреймворк LangGraph идеально подходит для реализации предложенной иерархической архитектуры благодаря своей способности управлять персистентным состоянием и определять условные переходы между узлами графа.6
* Управление состоянием: Состояние (State) агента должно включать не только данные о задаче, но и метаданные о его операционном режиме. Оно может быть определено как объект, содержащий поля, такие как current_strategy (текущая стратегия), reflection_attempts (количество попыток рефлексии), metacognitive_flags (флаги метапознания, например, low_confidence), current_contradiction (текущее сформулированное противоречие) и active_inventive_principles (активные изобретательские принципы).
* Поток управления: Логика агента представляется в виде графа, где узлы — это действия (например, execute_tool, critique_output, invoke_ariz_solver), а ребра — это условная логика, реализующая иерархическую модель. Например, ребро, выходящее из узла critique_output, может вести обратно к execute_tool, если найдено простое исправление. Однако если счетчик reflection_attempts превышает заданный порог (например, 3), другое условное ребро направит поток к узлу invoke_ariz_solver, инициируя внешний цикл.
* Интеграция человека в процесс (Human-in-the-Loop): Сложные решения, особенно на этапе эскалации к АРИЗ, могут потребовать человеческого вмешательства. Фреймворки, такие как LangGraph и CrewAI, поддерживают эту возможность. LangGraph позволяет динамически прерывать выполнение графа, чтобы запросить ввод у пользователя, например, для подтверждения сформулированного противоречия или выбора наиболее перспективного решения из предложенных.15 Это обеспечивает дополнительный уровень контроля и безопасности при решении критически важных задач.
Таким образом, сочетание иерархической модели реагирования и мощного фреймворка для управления состоянием, такого как LangGraph, позволяет создать надежного и адаптивного агента-пилота, способного не только следовать инструкциям, но и творчески преодолевать непредвиденные трудности.


Раздел 5: План реализации: Python, агентные фреймворки и Visual Studio


Этот раздел представляет собой практическое руководство по созданию, настройке и управлению агентом-пилотом, описанным в предыдущих разделах. Он включает в себя шаблоны конфигурации, инструкции по настройке среды разработки и примеры кода для взаимодействия с агентом.


5.1. Конституция агента: определение основных инструкций


«Конституция» агента — это его системный промпт (system prompt), который жестко определяет его роль, цели, ограничения и протоколы поведения. Для обеспечения ясности, структурированности и простоты обслуживания рекомендуется использовать формат YAML для определения этих инструкций.28
Пример шаблона конституции агента в формате YAML:


YAML




# constitution.yaml
name: "ARIZ-Powered Pilot Agent"
persona: >
 You are a metacognitive pilot agent. Your primary function is to execute complex tasks by analyzing them,
 selecting appropriate protocols, and using tools. You are equipped with self-reflection and inventive
 problem-solving capabilities.

goal: >
 To successfully complete the user's task by dynamically adapting your strategy. If you encounter a problem,
 you must find an alternative solution without sacrificing performance or quality, using the ARIZ protocol
 when necessary.

constraints:
 - You must always analyze the task's complexity before starting.
 - You must monitor your own performance and confidence levels.
 - You must not repeat a failed action more than 3 times with the same strategy.

failure_response_protocol:
 - level_1_react:
     trigger: "Standard operation."
     action: "Execute task using the Reason-Act cycle."
 - level_2_reflection:
     trigger: "Tool error, low confidence signal, or negative critique after an action."
     action: "Pause execution. Enter the 'generate-critique-improve' loop. Attempt to correct the strategy up to 3 times."
 - level_3_ariz:
     trigger: "Failure of the Reflection loop (3 consecutive failed attempts)."
     action: >
       Halt all current actions. Formulate the problem as a TRIZ technical contradiction.
       Invoke the full ARIZ-85 protocol to generate a fundamentally new strategy.
       Present the new strategy for approval before proceeding.

Конфигурация конкретных параметров агента, таких как используемая LLM, доступные инструменты и API-ключи, зависит от выбранного фреймворка.
* AutoGen: Использует JSON-файл или переменную окружения OAI_CONFIG_LIST для определения списка доступных моделей.30
* CrewAI: Часто использует agents.yaml для определения ролей, целей и предысторий агентов, в то время как инструменты и LLM задаются в коде Python.36
* MetaGPT: Использует файл config2.yaml для централизованного управления конфигурацией LLM, включая api_type, model и api_key.42
Выбор фреймворка для реализации циклической архитектуры агента является ключевым решением. В таблице ниже приведено сравнение наиболее подходящих вариантов.
Таблица 2: Сравнение агентных фреймворков для циклических архитектур


Критерий
	LangGraph
	CrewAI (Иерархический)
	Microsoft Agent Framework
	Управление состоянием
	Явное и персистентное. Состояние (State) является центральным объектом, передаваемым между узлами.
	Неявное. Контекст передается от задачи к задаче, но управление сложным состоянием требует дополнительной логики.
	Надежное управление состоянием на основе потоков, подходит для долгосрочных сценариев.17
	Поддержка циклических рабочих процессов
	Встроенная. Графовая структура по своей природе поддерживает циклы и условные переходы, что идеально для рефлексии и АРИЗ.
	Ограниченная. Основной процесс — делегирование, а не итеративные циклы. Реализация циклов возможна, но не является основной парадигмой.
	Поддерживается через графо-ориентированные рабочие процессы с условной маршрутизацией.17
	Простота реализации условной логики
	Высокая. Условные ребра (conditional_edges) позволяют легко направлять поток на основе состояния.
	Умеренная. Логика делегирования определяется агентом-менеджером, но сложная условность требует кастомной реализации.
	Высокая. Явный контроль над путями выполнения, поддерживается принятие решений на основе моделей.17
	Интеграция человека в процесс
	Встроенная. Поддерживает динамические прерывания (interrupts) для получения ввода от пользователя в любом узле.[19]
	Поддерживается. Агенты могут запрашивать ввод у пользователя, если в задаче установлен флаг human_input.[15]
	Поддерживается. Разработано для сценариев с участием человека в цикле (human-in-the-loop).17
	Модульность
	Высокая. Каждый узел — это независимая функция, что способствует повторному использованию кода.
	Высокая. Агенты и задачи являются модульными компонентами, которые можно легко комбинировать.
	Высокая. Рабочие процессы можно разбивать на многоразовые компоненты.17
	Рекомендация: LangGraph является наиболее подходящим фреймворком для реализации предложенной иерархической архитектуры благодаря его нативной поддержке циклов и явному управлению состоянием.


5.2. Настройка среды с помощью Visual Studio Code и Dev Containers


Для обеспечения воспроизводимости и простоты настройки среды разработки рекомендуется использовать VS Code с расширением Dev Containers и Docker.
Предварительные требования:
1. Установите([URL_REMOVED]).
2. Установите([URL_REMOVED]).48
3. В VS Code установите расширение([URL_REMOVED]).50
Шаг 1: Создайте Dockerfile
В корне вашего проекта создайте файл Dockerfile для определения контейнера. Этот файл будет использовать официальный образ Python, устанавливать Poetry и копировать зависимости проекта.


Dockerfile




# Dockerfile
# Используем официальный образ Python
FROM python:3.11-slim

# Устанавливаем переменные окружения
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1
ENV POETRY_VERSION=1.8.2

# Устанавливаем системные зависимости
RUN apt-get update && apt-get install -y --no-install-recommends curl

# Устанавливаем Poetry
RUN curl -sSL [URL_REMOVED] | python3 -

# Добавляем Poetry в PATH
ENV PATH="/root/.local/bin:$PATH"

# Устанавливаем рабочую директорию
WORKDIR /app

# Копируем файлы управления зависимостями
COPY pyproject.toml poetry.lock./

# Устанавливаем зависимости проекта, не создавая виртуальное окружение внутри контейнера
RUN poetry config virtualenvs.create false && \
   poetry install --no-root --no-dev

# Копируем остальной код приложения
COPY..

# Открываем порт для FastAPI
EXPOSE 8000

50
Шаг 2: Создайте devcontainer.json
В корне проекта создайте папку .devcontainer и в ней файл devcontainer.json. Этот файл указывает VS Code, как собрать и настроить контейнер разработки.


JSON




//.devcontainer/devcontainer.json
{
 "name": "ARIZ Pilot Agent Dev Container",
 "build": {
   "dockerfile": "../Dockerfile",
   "context": ".."
 },
 "customizations": {
   "vscode": {
     "settings": {
       "python.defaultInterpreterPath": "/usr/local/bin/python"
     },
     "extensions": [
       "ms-python.python",
       "ms-python.vscode-pylance",
       "ms-azuretools.vscode-docker"
     ]
   }
 },
 "forwardPorts": ,
 "postCreateCommand": "poetry install",
 "remoteUser": "root"
}

49
Объяснение devcontainer.json:
* build: Указывает VS Code использовать Dockerfile в корневой директории для сборки образа.
* customizations: Настраивает среду VS Code внутри контейнера.
   * settings: Устанавливает интерпретатор Python по умолчанию.
   * extensions: Автоматически устанавливает необходимые расширения.
* forwardPorts: Пробрасывает порт 8000 из контейнера на локальную машину, чтобы можно было получить доступ к API агента.
* postCreateCommand: Выполняет команду poetry install после создания контейнера, чтобы установить все зависимости, включая dev-зависимости.
После создания этих файлов VS Code предложит вам открыть проект в контейнере (Reopen in Container).


5.3. Инструкции для консоли Visual Studio


После того как среда разработки запущена в контейнере, все взаимодействие с агентом происходит через интегрированный терминал VS Code.
Шаг 1: Сборка и запуск контейнера
VS Code автоматически соберет и запустит контейнер при первом открытии. Для последующих запусков можно использовать палитру команд (Ctrl+Shift+P) и выбрать Dev Containers: Rebuild and Reopen in Container для пересборки или Dev Containers: Reopen in Container для быстрого перезапуска.
Шаг 2: Запуск сервера агента
Предполагается, что у вас есть FastAPI-приложение (main.py), которое служит интерфейсом для агента. Запустите его из терминала VS Code:


Bash




uvicorn main:app --host 0.0.0.0 --port 8000 --reload

Шаг 3: Взаимодействие с агентом
Создайте Python-скрипт client.py для отправки задач агенту и получения результатов. Этот скрипт будет использовать библиотеку requests для отправки POST-запросов на эндпоинт FastAPI.


Python




# client.py
import requests
import json

AGENT_URL = "[URL_REMOVED]"

def run_agent_task(task_description: str):
   """
   Отправляет задачу агенту и выводит его ответ.
   """
   payload = {"task": task_description}
   headers = {"Content-Type": "application/json"}

   try:
       response = requests.post(AGENT_URL, data=json.dumps(payload), headers=headers)
       response.raise_for_status()  # Вызовет исключение для кодов ошибок HTTP

       result = response.json()
       print("--- Agent Response ---")
       print(json.dumps(result, indent=2, ensure_ascii=False))
       print("----------------------")

   except requests.exceptions.RequestException as e:
       print(f"An error occurred: {e}")

if __name__ == "__main__":
   # Пример задачи для агента
   task = "Проанализируй последние тенденции в области многоагентных систем и составь краткий отчет."
   run_agent_task(task)

55
Запустите клиент из другого терминала VS Code:


Bash




python client.py

Шаг 4: Мониторинг и отладка
* Просмотр логов: Логи работы агента (его рассуждения, вызовы инструментов, циклы рефлексии) будут выводиться в терминале, где запущен uvicorn. Это основной способ наблюдения за его поведением в реальном времени.58
* Отладка: VS Code позволяет отлаживать код, работающий внутри контейнера.
   1. Создайте файл .vscode/launch.json со следующей конфигурацией для отладки FastAPI:
JSON
//.vscode/launch.json
{
 "version": "0.2.0",
 "configurations": [
   {
     "name": "Python: FastAPI",
     "type": "debugpy",
     "request": "launch",
     "module": "uvicorn",
     "args": [
       "main:app",
       "--host", "0.0.0.0",
       "--port", "8000",
       "--reload"
     ],
     "jinja": true
   }
 ]
}

59
   2. Установите точки останова (breakpoints) в коде вашего агента (например, в логике рефлексии или вызова АРИЗ).
   3. Перейдите на вкладку «Run and Debug» (Ctrl+Shift+D), выберите конфигурацию «Python: FastAPI» и нажмите F5.
   4. Отладчик подключится к процессу внутри контейнера, и вы сможете пошагово выполнять код, инспектировать переменные и анализировать поток принятия решений агентом.
Этот комплексный подход обеспечивает мощную, гибкую и воспроизводимую среду для разработки, тестирования и итеративного улучшения сложных ИИ-агентов.
Источники
   1. Adaptive Tool Use in Large Language Models with Meta-Cognition ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   2. [2510.05126] Improving Metacognition and Uncertainty Communication in Language Models - arXiv, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   3. #12: How Do Agents Learn from Their Own Mistakes? The Role of ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   4. What is Agentic AI Reflection Pattern? - Analytics Vidhya, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   5. Reflection Agent Prompting: Strategies for More Efficient Performance - Akira AI, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   6. A Deep Dive into LangGraph for Self-Correcting AI Agents ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   7. LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide - Confident AI, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   8. Reflection — AutoGen - Microsoft Open Source, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   9. Reasoning-enhanced Query Understanding through Decomposition and Interpretation, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   10. Query Decomposition: Understanding the User's Perspective - Sahaj Software, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   11. RAG and generative AI - Azure AI Search | Microsoft Learn, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   12. Adaptive RAG explained: What to know in 2025 - Meilisearch, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   13. Building a Router AI-Agent From Scratch : Understanding the Core ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   14. LLM-Dispatcher: The Smart Way to Route Your AI Requests | by Ashhad Ahsan Rehman | Oct, 2025 | Medium, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   15. FAQs - CrewAI, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   16. Ware are the Key Differences Between Hierarchical and Sequential Processes in CrewAI, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   17. Introduction to Microsoft Agent Framework, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   18. Build an Agent - LangChain docs, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   19. Auto resuming challenges in langgraph - LangChain Forum, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   20. TRIZ-GPT: An LLM-augmented method for problem-solving ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   21. A Multi-Agent LLM Approach for TRIZ-Based Innovation - arXiv, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   22. A Multi-Agent LLM Approach for TRIZ-Based Innovation - SciTePress, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   23. AutoTRIZ: Automating engineering innovation with ... - CityU Scholars, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   24. (PDF) An Introduction to ARIZ -The Algorithm of Inventive Problem ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   25. Solving the Problem of ARIZ Using ARIZ (Algorithm of Inventive Problem Solving): Case Study on Pipeline Maintenance System Desig, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   26. TRIZ-GPT: An LLM-Augmented Method For Problem-Solving - ASME Digital Collection, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   27. ReAct - Prompt Engineering Guide, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   28. YAML Prompt Studio: Integrated Editing Environment for AI Agent Development, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   29. Create an Agent from a Semantic Kernel Template | Microsoft Learn, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   30. config_list_from_json - AG2, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   31. LLM Configuration | AutoGen 0.2 - Microsoft Open Source, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   32. Using Gemini in AutoGen with Other LLMs - Microsoft Open Source, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   33. Autogen - Qdrant, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   34. Building AI Agent Applications Series - Using AutoGen to build your AI Agents, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   35. How to Use Microsoft AutoGen - DEV Community, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   36. crewAIInc/crewAI: Framework for orchestrating role-playing ... - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   37. Agents - CrewAI Documentation, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   38. rpabotsworld/crewAI: Examples for crewAI - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   39. scotthavird/crewai-template: A minimal, ready-to-use ... - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   40. A collection of examples that show how to use CrewAI framework to automate workflows. - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   41. Quickstart - CrewAI Documentation, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   42. FoundationAgents/MetaGPT: The Multi-Agent Framework ... - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   43. metagpt - PyPI, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   44. Setup - MetaGPT, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   45. Configuration - MetaGPT, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   46. LLM API Configuration - MetaGPT, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   47. Customize LLMs for roles or actions - MetaGPT, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   48. Developing inside a Container - Visual Studio Code, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   49. Dev Containers tutorial - Visual Studio Code, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   50. Setting Python Development Environment with VScode and Docker - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   51. max-pfeiffer/uvicorn-poetry-fastapi-project-template - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   52. AlbinLind/fastapi-template: A simple template using FastAPI ... - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   53. Create a Dev Container - Visual Studio Code, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   54. a5chin/python-poetry: This repository contains ... - GitHub, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   55. Using FastAPI to Build Python Web APIs - Real Python, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   56. Containerizing FastAPI Applications with Docker | Better Stack Community, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   57. Getting Started with Python HTTP Requests for REST APIs ..., дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   58. Python in a container - Visual Studio Code, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   59. Python debugging in VS Code, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]
   60. Debugging dockerized Python apps in VSCode - Redowan's Reflections, дата последнего обращения: ноября 1, 2025, [URL_REMOVED]