Архитектура и Реализация: «Ферми-Первый» Протокол для Продвинутых ИИ-Агентов




Часть 1: Проектирование «Ферми-Первого» Агента: Основной Блок Инструкций




1.1 Введение в архитектуру «Ферми-Первого» (Fermi-First Architecture)


Запрос на создание «идеальной инструкции» для ИИ-агента, который всегда применяет метод Ферми перед выполнением любой задачи, требует фундаментального переосмысления стандартной архитектуры агентов. Традиционные подходы, часто основанные на циклах «Reason-Act» (ReAct), нацелены на немедленное выполнение.1 Однако требование предварительного «Ферми-анализа» диктует создание новой когнитивной архитектуры.
Метод Ферми, в своей основе, — это не просто инструмент для количественных оценок (например, «сколько настройщиков пианино в Чикаго»).2 Это универсальный когнитивный фреймворк для решения проблем, основанный на трех столпах:
1. Декомпозиция: Разбиение сложной, казалось бы, нерешаемой проблемы на более мелкие, управляемые компоненты.4
2. Выявление Допущений: Явная идентификация и оценка всех неизвестных переменных и предположений, необходимых для построения модели.
3. Оценка и Синтез: Использование расчетов «на салфетке» (back-of-the-envelope) для получения оценки порядка величины, которая является «достаточно хорошей» для принятия решений.3
Применение этого фреймворка к каждой задаче (включая качественные) требует его абстрагирования. «Ферми-зация» качественной задачи, такой как «написать маркетинговое письмо», трансформируется из количественной оценки в оценку ресурсов, объема (scope) и ограничений.
Для реализации этого предложена Двухфазная Архитектура «Анализ-Верификация-Действие» (Analyze-Verify-Act, AVA). Эта архитектура заменяет немедленное исполнение принудительным когнитивным циклом:
1. Фаза 1: «Ферми-зация» (Fermi-zation). Агент получает запрос пользователя. Вместо его выполнения, он обязан провести анализ по методу Ферми (декомпозиция, допущения, оценка) и сгенерировать структурированный план.
2. Фаза 2: Выполнение (Execution). Агент представляет Фазу 1 пользователю для верификации (Human-in-the-Loop).7 Только после получения явного одобрения (или модификаций) от пользователя, агент приступает к выполнению задачи, используя верифицированный план как свой новый, незыблемый контекст.
Этот подход фундаментально меняет роль агента. Он превращается из «слепого исполнителя» в «коллаборатора-аналитика». Его основная функция — не дать немедленный ответ, а сначала прояснить проблему и согласовать план ее решения. Это обеспечивает предсказуемость, надежность и позволяет пользователю сохранять контроль над сложными, многоэтапными процессами.9


1.2 Основной Системный Промпт (Master System Prompt)


Для принудительного выполнения описанной двухфазной архитектуры требуется сложный, высокоструктурированный «Мастер-Промпт» (Master System Prompt). В отличие от простых инструкций, этот промпт функционирует как операционная система агента. Он использует XML-теги (best practice для моделей Anthropic и продвинутых моделей OpenAI) для четкого разграничения инструкций, протоколов, ограничений и схем данных.11 Эта структура критически важна для управления сложной условной логикой (например, адаптацией вывода под тип задачи) и, что самое главное, для управления состоянием агента, особенно во время пауз для верификации.15
Ниже приведена полная, готовая к внедрению инструкция.


Таблица 1: Полный блок инструкций «Ферми-Первого» Агента (Master System Prompt)




Компонент
	Содержание (Инструкция для LLM)
	<SYSTEM_PROMPT>
	

	<ROLE_DEFINITION>
	Вы — элитный Аналитик-Стратег. Ваша единственная цель — применять «Универсальный Протокол Ферми» (UFP) ко всем входящим запросам. Вы не являетесь ассистентом, отвечающим на вопросы. Вы — партнер по декомпозиции и планированию.
	<CORE_DIRECTIVE>
	ВНИМАНИЕ: ЭТО НЕЗЫБЛЕМОЕ ПРАВИЛО.НИКОГДА не отвечайте на запрос пользователя напрямую и не выполняйте его немедленно.ВСЕГДА сначала инициируйте Фазу 1: «Универсальный Протокол Ферми» (UFP).Ваш первый ответ пользователю всегда должен быть результатом UFP, обернутым в тег <FERMI_ANALYSIS>.
	<UNIVERSAL_FERMI_PROTOCOL_(UFP)>
	При получении <USER_REQUEST>, немедленно выполните следующие шаги:1. Классификация: Внутренне определите тип задачи (например, Количественная Оценка, Планирование Проекта, Анализ Рынка, Генерация Контента, Прогнозирование).162. Декомпозиция: Разбейте запрос на фундаментальные компоненты или шаги, необходимые для его решения.43. Идентификация Допущений: Четко перечислите все допущения (числовые, контекстные, по объему), которые вы делаете, чтобы сузить область проблемы.4. Оценка (Estimation): Предоставьте оценку (количественную или качественную) масштаба, сложности или требуемых ресурсов.5. План Выполнения: Сформулируйте пошаговый план (План), который вы будете использовать для выполнения запроса после верификации.
	<ADAPTIVE_OUTPUT_LOGIC>
	Вывод вашего <FERMI_ANALYSIS> должен адаптироваться к типу задачи:* WHEN (ЕСЛИ) задача = 'Количественная Оценка' (Классическая Ферми): THEN (ТО) <DECOMPOSITION> должен следовать 5-шаговой структуре 2 и заканчиваться оценкой порядка величины.2* WHEN (ЕСЛИ) задача = 'Планирование Проекта': THEN (ТО) <DECOMPOSITION> должен быть отформатирован как иерархическая 'Work Breakdown Structure (WBS)'.18* WHEN (ЕСЛИ) задача = 'Анализ Рынка': THEN (ТО) <DECOMPOSITION> должен быть структурирован как фреймворк 'TAM/SAM/SOM'.21* WHEN (ЕСЛИ) задача = 'Прогнозирование': THEN (ТО) <DECOMPOSITION> должен быть структурирован как 'Анализ Факторов и Весов'.24* WHEN (ЕСЛИ) задача = 'Генерация Контента' или 'Качественная Задача': THEN (ТО) <DECOMPOSITION> должен быть планом/структурой контента, а <ASSUMPTIONS> должны фокусироваться на Тоне, Аудитории и Цели (CTA).26* WHEN (ЕСЛИ) задача 'Слишком Неоднозначна' для UFP: THEN (ТО) <FERMI_ANALYSIS> должен состоять только из списка уточняющих вопросов для сбора недостающих данных.27
	<INTERACTION_MODEL_(HITL)>
	КРИТИЧЕСКИ ВАЖНЫЙ ПРОТОКОЛ ВЕРИФИКАЦИИ:1. После генерации полного ответа Фазы 1 (включая <FERMI_ANALYSIS>, <ASSUMPTIONS> и <PLAN>), вы обязаны завершить свой ответ только тегом: <AWAITING_VERIFICATION>2. ЗАПРЕЩЕНО генерировать какой-либо текст или выполнять какие-либо действия после этого тега. Вы должны полностью остановиться и ждать следующего ввода от пользователя.83. Фаза 2 (Выполнение): Вы возобновите работу только тогда, когда пользователь предоставит явное подтверждение (например, "Да", "Продолжай", "Принято") или модификации.4. Если пользователь предоставляет модификации (например, "Измени допущение X"), вы должны сначала сгенерировать обновленный <FERMI_ANALYSIS> и снова ждать верификации.5. После получения окончательного одобрения, вы используете верифицированный <PLAN> и <ASSUMPTIONS> как единственный источник правды для генерации финального ответа в теге <EXECUTION_RESPONSE>.
	<XML_SCHEMA_DEFINITION>
	Вы должны использовать следующие XML-теги для структурирования всех ваших ответов:<USER_REQUEST>: (Внутреннее использование) Здесь вы мысленно оборачиваете запрос пользователя.<FERMI_ANALYSIS>: Обертка для всего вашего ответа Фазы 1. <TASK_CLASSIFICATION>: Ваш вывод из шага 1 UFP. <DECOMPOSITION>: Вывод шага 2 UFP (адаптированный согласно <ADAPTIVE_OUTPUT_LOGIC>). <ASSUMPTIONS>: Вывод шага 3 UFP (в виде маркированного списка). <ESTIMATION>: Вывод шага 4 UFP (качественный или количественный). <PLAN>: Вывод шага 5 UFP (пошаговый план для Фазы 2).</FERMI_ANALYSIS><AWAITING_VERIFICATION>: (Сигнал остановки) Обязательный тег для завершения Фазы 1.8<EXECUTION_RESPONSE>: (Фаза 2) Обертка для вашего окончательного ответа после верификации.
	<CONSTRAINTS_AND_BOUNDARIES>
	1. Запрет Инструментов (Tools): Вам категорически запрещено использовать любые инструменты (например, web_search, code_interpreter) до Фазы 2. 2. Обоснование Инструментов: Если верифицированный <PLAN> требует инструмента, вы должны сначала объявить о его использовании (например, "ИСПОЛЬЗУЮ ИНСТРУМЕНТ: web_search для...").3. Явность: Никаких неявных допущений. Все должно быть указано в <ASSUMPTIONS>.4. Точность: Если для расчетов требуется математика (например, в <ESTIMATION>), вы должны указать в <PLAN>, что будете использовать code_interpreter (в Фазе 2) для обеспечения точности, поскольку LLM могут ошибаться в расчетах.31
	</SYSTEM_PROMPT>
	

	

Часть 2: Анатомия Мастер-Промпта: Деконструкция Ключевых Компонентов


Представленный Мастер-Промпт — это сложный инжиниринговый артефакт. Его эффективность зависит от синергии его компонентов.


2.1 Определение Роли и Основной Директивы (Role and Core Directive)


Выбор роли «Аналитик-Стратег» 23 вместо «Помощника» является критически важным.33 Это устанавливает немедленный контекст, который смещает модель от генерации ответов к их анализу. «Помощник» пытается немедленно удовлетворить запрос; «Аналитик» пытается немедленно его деконструировать.
«Основная Директива» («НИКОГДА не отвечайте... ВСЕГДА сначала...») — это механизм принуждения. Он вводит то, что можно назвать «принудительной когнитивной латентностью». В мире, стремящемся к уменьшению задержки (latency), эта архитектура намеренно ее увеличивает, требуя дополнительного цикла взаимодействия. Это не недостаток, а основная функция. Эта принудительная пауза заставляет модель перейти от быстрых, интуитивных (System 1) ответов к медленным, структурированным и логическим (System 2) рассуждениям, воплощенным в Протоколе Ферми.34 Эта директива является самой жесткой формой «контекстного управления» (context engineering).35


2.2 Управление Состоянием через Структурное Промптирование (XML-теги)


Использование XML-тегов 11 в этой архитектуре выходит далеко за рамки простого форматирования. XML-теги служат механизмом управления состоянием (State Management Mechanism), понятным как для LLM, так и для внешней системы-оркестратора.13
Когда агент выводит тег <AWAITING_VERIFICATION>, это не просто текст. Это машиночитаемый сигнал, эквивалент yield в программировании. Внешняя система, такая как фреймворк LangGraph 36 или кастомный оркестратор 37, должна быть настроена на перехват этого тега. При его обнаружении, система-оркестратор приостанавливает выполнение агента, сохраняет его текущее состояние (включая историю чата и сгенерированный <FERMI_ANALYSIS>) и переводит рабочий процесс в состояние «ожидания ввода пользователя».10
Этот подход превращает пассивный системный промпт в интерактивный, управляемый событиями рабочий процесс. Без этой XML-схемы и тега-сигнала, реализация принудительного цикла «Human-in-the-Loop» (HITL) была бы ненадежной, так как агент мог бы «проигнорировать» инструкцию остановиться.8


2.3 Обработка Условной Логики: Адаптация Протокола Ферми


Раздел <ADAPTIVE_OUTPUT_LOGIC> — это мозг агента. Он реализует условную логику (IF-THEN, или, в данном случае, WHEN-THEN) 40, которая делает «Универсальный Протокол Ферми» (UFP) действительно универсальным.
Агент не просто применяет один и тот же шаблон к каждой задаче. Он сначала выполняет внутреннюю классификацию 16, а затем выбирает наиболее подходящую структуру вывода (output schema) для своей декомпозиции.
* Для запроса «Запусти новый продукт» 45, агент не будет пытаться дать количественную оценку. Он распознает задачу «Планирование Проекта» и его <DECOMPOSITION> будет отформатирован как Work Breakdown Structure (WBS).18
* Для запроса «Оцени рынок» 47, он применит фреймворк TAM/SAM/SOM.49
* Для запроса «Предскажи продажи» 25, он применит «Анализ Факторов и Весов».25
Эта адаптивность, встроенная непосредственно в промпт, гарантирует, что Ферми-анализ всегда будет релевантным, структурированным и использовать лучшие отраслевые практики для конкретного типа задачи.


Часть 3: Фаза 1: Процесс «Ферми-зации» Задачи


Фаза 1 — это ядро интеллектуального вклада агента. Здесь происходит магия деконструкции.


3.1 Абстракция Ферми: От Количественного к Качественному


Центральная проблема при реализации этого агента — как «ферми-зировать» качественную или творческую задачу? Например, "Напиши мне маркетинговый email". Классический метод Ферми 2 здесь неприменим, так как нет ничего для количественной оценки.
Решение заключается в абстракции Ферми. Агент применяет прокси-оценку (proxy estimation): вместо оценки результата, он оценивает ресурсы, ограничения и объем задачи.
Рассмотрим процесс для запроса "Напиши маркетинговый email":
1. Задача: "Напиши маркетинговый email".
2. Применение UFP: Агент инициирует Фазу 1.
3. Вывод <FERMI_ANALYSIS>:
   * <TASK_CLASSIFICATION>Генерация Контента</TASK_CLASSIFICATION>`
   * <DECOMPOSITION> (План/Структура письма):
      1. Определение Целевой Аудитории (ЦА).
      2. Определение Ключевого Сообщения и Призыва к Действию (CTA).
      3. Формулирование 3-5 вариантов Темы (Subject Line).
      4. Написание Тела письма (Вступление, Ценностное предложение, CTA).
      5. Финальное Ревью на соответствие Тону.
   * <ASSUMPTIONS> (Критически важно для качественных задач):
      * "Я предполагаю, что Целевая Аудитория — это [существующие клиенты]."
      * "Я предполагаю, что Тон — [профессиональный, но дружелюбный]."
      * "Я предполагаю, что Цель (CTA) — [переход по ссылке на вебинар]."
   * <ESTIMATION> (Прокси-оценка):
      * "Сложность: Низкая."
      * "Ожидаемый объем: $\approx$ 150-200 слов."
      * "Ожидаемое время на генерацию (Фаза 2): $\approx$ 1 минута."
   * <PLAN>:
      1. Ожидать верификации ЦА, Тона и СТА.
      2. Сгенерировать email в соответствии с верифицированными допущениями.
   * </FERMI_ANALYSIS>
   * <AWAITING_VERIFICATION>
Этот процесс использует LLM для преобразования неструктурированного качественного запроса в набор структурированных, верифицируемых параметров.24 Пользователь теперь может просто сказать "Продолжай" или "Нет, ЦА — это новые лиды, а тон — срочный". Это предотвращает генерацию бесполезного вывода.


3.2 Декомпозиция Задач: CoT, PoT и WBS


Декомпозиция — это основа основ.31 Протокол Ферми динамически выбирает метод декомпозиции:
* Chain-of-Thought (CoT): Для простых и средних задач, декомпозиция естественным образом следует логике «Цепочки Мыслей» (Chain-of-Thought), где агент пошагово разбивает свое рассуждение.34
* Work Breakdown Structure (WBS): Как указано в условной логике, для задач, идентифицированных как «проекты» (например, «запустить блог», «организовать мероприятие», «разработать ПО»), агент обязан использовать иерархическую структуру WBS.18 Это не просто список; это древовидная декомпозиция результатов и работ.57
* Program-of-Thoughts (PoT): Агент «Ферми» знает о своих собственных ограничениях. LLM, по своей природе, являются стохастическими и плохо справляются с точной, детерминированной математикой.27 Поэтому, когда <FERMI_ANALYSIS> (например, при расчете TAM или классической задаче Ферми) требует точных вычислений, <PLAN> должен включать шаг по использованию интерпретатора кода (Program-of-Thoughts).31 Агент не пытается "решить в уме"; он планирует написать и выполнить код для получения точного ответа в Фазе 2.


Таблица 2: Адаптивная Карта Протокола Ферми (UFP Mapping)


Эта таблица демонстрирует адаптивность агента: как один и тот же «Универсальный Протокол Ферми» (UFP) динамически изменяет свой формат вывода в <DECOMPOSITION> в зависимости от классифицированного типа задачи.


Класс Задачи
	Описание Задачи
	Структура Вывода <DECOMPOSITION>
	Ключевые Допущения (Тип)
	Пример Запроса
	Классическая Оценка Ферми
	Количественная оценка "на салфетке"
	5-шаговая оценка 2:1. Компоненты2. Оценка компонентов3. Расчет4. Синтез5. Порядок величины
	Числовые оценки (средние, объемы, плотность населения)
	"Сколько настройщиков пианино в Чикаго?"
	Планирование Проекта
	Управление сложной, многоэтапной задачей
	Иерархический WBS 19:1.0 Инициация 1.1 Устав 2.0 Планирование 2.1 Объем ...
	Ресурсы, Время, Объем (Scope), Зависимости 18
	"Мне нужно запустить новый веб-сайт электронной коммерции."
	Анализ Рынка
	Оценка экономического потенциала
	Фреймворк TAM/SAM/SOM 22:- TAM (Total...) [Определение + Расчет]- SAM (Serviceable...) [Определение + Расчет]- SOM (Serviceable...) [Определение + Расчет]
	Сегменты ЦА, География, Средний чек (ARPU), Доля рынка 21
	"Оцени размер рынка для SaaS-инструмента, который помогает юристам."
	Прогнозирование
	Оценка вероятности будущего события
	Анализ Факторов и Весов 25:1. Базовая Ставка (Base Rate) 252. Позитивные Факторы (с весами)3. Негативные Факторы (с весами)4. Синтез и Вероятностный диапазон
	Значимость/Вес каждого фактора, Стабильность трендов 24
	"Какова вероятность, что мы достигнем 100 тыс. MAU в следующем году?"
	Генерация Контента (Качественная)
	Создание текста или креатива
	План/Структура Контента:1. Тезис/Цель2. Структура (Заголовки H1, H2)3. Ключевые пункты4. Призыв к Действию (CTA)
	Тон, Стиль, Аудитория (ЦА), Цель, Ключевые слова 26
	"Напиши статью для блога о будущем ИИ."
	

Часть 4: Фаза 2: Маршрутизация и Выполнение Задачи (Post-Fermi)




4.1 От Верификации к Исполнению


Фаза 2 начинается после того, как пользователь отвечает на <AWAITING_VERIFICATION> утвердительно. Этот ответ (например, «Да, план выглядит хорошо, продолжай») является триггером для системы-оркестратора 37 для «пробуждения» агента.
Ключевой момент: верифицированный <FERMI_ANALYSIS> (включая <PLAN> и <ASSUMPTIONS>) и все модификации пользователя конкатенируются и передаются агенту как новый, доминирующий контекст для Фазы 2. Агент теперь получает инструкцию: «Забудь предыдущий запрос. Твоя единственная задача — выполнить этот верифицированный план».
Это похоже на архитектуру «Планировщика» (Planner), как описано в 38, но с принудительным, внешним шагом верификации, который делает процесс надежным и предсказуемым.


4.2 Динамический Выбор Инструмента (Post-Fermi)


Эта архитектура решает одну из самых больших проблем современных ИИ-агентов: преждевременное, неверное или галлюцинаторное использование инструментов (tool use).
В стандартной модели ReAct агент может попытаться использовать web_search на основе плохо понятого запроса. В архитектуре «Ферми-Первого» Агента это невозможно по двум причинам:
1. Запрет в Фазе 1: Промпт-ограничение <CONSTRAINTS_AND_BOUNDARIES> явно запрещает использование любых инструментов до верификации.
2. Обоснование в Плане: Агент не может просто использовать инструмент. Он должен предложить его использование в своем <PLAN>.
Пример (из Примера 6.3):
* Запрос: "Оцени рынок для приложения по уходу за домашними животными".
* <PLAN> (в Фазе 1):
   1. Верифицировать структуру TAM/SAM/SOM.
   2. Для получения данных о TAM (общее кол-во владельцев животных), я буду использовать инструмент web_search для запроса отчетов APPA и IBISWorld.47
   3. ...
* <AWAITING_VERIFICATION>
Пользователь теперь видит не только план декомпозиции, но и план сбора данных. Он одобряет не только что делать, но и как это делать. Только после этого одобрения агент получает "разрешение" на вызов инструмента web_search в Фазе 2.8 Это обеспечивает беспрецедентный уровень контроля и предотвращает бесполезные или дорогостоящие вызовы API.


Часть 5: Протоколы Интерактивной Верификации (Human-in-the-Loop)




5.1 Обязательный Цикл Подтверждения (Mandatory Confirmation Loop)


Внедрение «Человека-в-цикле» (Human-in-the-Loop, HITL) в этой архитектуре — это не «дополнительная функция» или «лучшая практика».7 Это неотъемлемая, неразрывная часть когнитивного цикла агента.
Надежность этого цикла обеспечивается не просто инструкцией «пожалуйста, спроси», а жестким, машиночитаемым протоколом 61:
1. Инструкция: Агенту приказано завершить свой вывод тегом <AWAITING_VERIFICATION>.8
2. Действие: Он генерирует <FERMI_ANALYSIS> и выводит <AWAITING_VERIFICATION>.
3. Сигнал: Внешний оркестратор 36 обнаруживает этот тег.
4. Пауза: Оркестратор приостанавливает дальнейшую генерацию или выполнение агента.
5. Ожидание: Система ожидает следующего ввода от пользователя.
Этот механизм решает распространенную проблему «слишком услужливых» агентов 39, которые продолжают выполнение, даже основываясь на совершенно неверных первоначальных предположениях, что приводит к каскадным ошибкам.


5.2 Обработка Неоднозначности и Запрос Данных


Что произойдет, если запрос пользователя слишком неоднозначен для проведения Ферми-анализа? Например, "Расскажи мне о рынке".
Агент, следующий традиционной модели, мог бы сгенерировать общий ответ. Агент «Ферми-Первый» не может этого сделать. Его <CORE_DIRECTIVE> требует декомпозиции и допущений. Попытка их сформулировать немедленно провалится.
Именно для этого в <ADAPTIVE_OUTPUT_LOGIC> включен запасной (fallback) механизм:
WHEN (ЕСЛИ) задача 'Слишком Неоднозначна' для UFP:
THEN (ТО) <FERMI_ANALYSIS> должен состоять только из списка уточняющих вопросов для сбора недостающих данных.27
Пример:
* Запрос: "Расскажи мне о рынке".
* Фаза 1 (Вывод агента):
<FERMI_ANALYSIS>
<TASK_CLASSIFICATION>Слишком Неоднозначно</TASK_CLASSIFICATION> Запрос не может быть декомпозирован без дополнительной информации. Чтобы провести Ферми-анализ (например, TAM/SAM/SOM), мне необходимы уточнения. Невозможно сделать обоснованные допущения. `
   1. Запросить у пользователя уточняющие данные.
   2. Ожидать ответа.
   3. Перезапустить UFP с новым, уточненным запросом.
</PLAN>
<ESTIMATION>Уточняющие Вопросы:
   4. О каком географическом рынке идет речь (например, США, Мир, EMEA)?
   5. О какой отрасли или продуктовой категории идет речь (например, ПО, автомобили, кофе)?
   6. Какова цель вашего анализа (например, общий обзор, поиск конкурентов, оценка для инвесторов)?
</ESTIMATION>
</FERMI_ANALYSIS>
<AWAITING_VERIFICATION>
Этот механизм превращает агента из пассивного исполнителя в проактивного сборщика информации 63, гарантируя, что ни один цикл обработки не будет потрачен впустую из-за нечетких входных данных.


Часть 6: Применение на Практике: Тематические Исследования для Различных Задач


Ниже приведены четыре примера, демонстрирующие работу архитектуры «Ферми-Первый» с различными типами задач.


6.1 Пример 1: Классическая Количественная Оценка


      * Запрос: "Сколько мячей для гольфа поместится в стандартный школьный автобус?"
      * Фаза 1 (Вывод агента):
<FERMI_ANALYSIS>
<TASK_CLASSIFICATION>Классическая Оценка Ферми</TASK_CLASSIFICATION> ` (5-шаговая оценка 2):
         1. Оценка внутреннего объема школьного автобуса.
         2. Оценка объема одного мяча для гольфа.
         3. Оценка коэффициента плотности упаковки (packing density) для сфер.
         4. Расчет: (Объем Автобуса * Коэффициент Упаковки) / Объем Мяча.
         5. Определение порядка величины.
</DECOMPOSITION>
<ASSUMPTIONS>
         6. "Стандартный школьный автобус": Я предполагаю объем $\approx$ 200 кубических метров (после удаления сидений).
         7. "Мяч для гольфа": Я предполагаю объем $\approx$ 40 кубических сантиметров.
         8. "Коэффициент Упаковки": Я предполагаю случайную укладку сфер, $\approx$ 64% ($0.64$).
</ASSUMPTIONS>
<ESTIMATION>На основе этих допущений, оценка составляет порядка $10^7$ (десятки миллионов) мячей.</ESTIMATION>
<PLAN>
         9. Верифицировать допущения по объему автобуса, мяча и коэффициенту упаковки.
         10. Выполнить точный расчет в Фазе 2 с использованием code_interpreter для избежания ошибок.31
</PLAN>
</FERMI_ANALYSIS>
<AWAITING_VERIFICATION>
            * Анализ: Демонстрирует базовый протокол UFP, явное указание допущений и планирование использования code_interpreter для точной математики.32


6.2 Пример 2: Комплексное Планирование Проекта (WBS)


            * Запрос: "Мне нужно запустить новый SaaS-продукт. Составь план".
            * Фаза 1 (Вывод агента):
<FERMI_ANALYSIS>
<TASK_CLASSIFICATION>Планирование Проекта</TASK_CLASSIFICATION> (Формат WBS [19, 20, 58]):1.0. Инициация Проекта 1.1. Определение Концепции и Целей Продукта 18 1.2. Анализ Заинтересованных Сторон 1.3. Устав Проекта (Project Charter) 2.0. Планирование и Проектирование 2.1. Определение Объема (Scope) и Требований (MVP) 2.2. Архитектурное Проектирование (Tech Stack) 2.3. UX/UI Дизайн (Wireframes, Mockups) 2.4. План Ресурсов и Бюджет 3.0. Разработка (Execution) 3.1. Настройка Среды (Dev/Stage/Prod) 3.2. Разработка Backend (API, Базы данных) 3.3. Разработка Frontend (Интерфейс) 4.0. Тестирование и QA ... 5.0. Запуск (Deployment) и Go-to-Market ... `
               1. Я предполагаю, что 'SaaS-продукт' — это B2B веб-приложение.
               2. Я предполагаю, что у вас есть базовая команда (PM, 2 инженера, 1 дизайнер).
               3. Я предполагаю, что фаза 'Инициация' (1.0) уже частично завершена.
</ASSUMPTIONS>
<ESTIMATION>Качественная оценка: Это сложный проект (High-Complexity), требующий $\approx$ 4-6 месяцев для запуска MVP с указанной командой.</ESTIMATION>
<PLAN>
               4. Верифицировать допущения о типе продукта, команде и стадии.
               5. После одобрения, я могу детализировать любой из пунктов WBS (например, "Детализируй 2.3").
</PLAN>
</FERMI_ANALYSIS>
<AWAITING_VERIFICATION>
                  * Анализ: Демонстрирует, как <ADAPTIVE_OUTPUT_LOGIC> (Инсайт 4) срабатывает, преобразуя Ферми-анализ в стандартную для управления проектами структуру WBS.18


6.3 Пример 3: Анализ и Оценка Рынка (TAM/SAM/SOM)


                  * Запрос: "Оцени размер рынка для приложения по уходу за домашними животными в США".
                  * Фаза 1 (Вывод агента):
<FERMI_ANALYSIS>
<TASK_CLASSIFICATION>Анализ Рынка</TASK_CLASSIFICATION> ` (Фреймворк TAM/SAM/SOM 21):
                     1. TAM (Total Addressable Market): Общий доход от услуг по уходу за домашними животными в США. [Формула: (Кол-во домохозяйств с животными) * (Средние годовые расходы на услуги)].
                     2. SAM (Serviceable Available Market): Сегмент TAM, который доступен через мобильные приложения..
                     3. SOM (Serviceable Obtainable Market): Реалистичная доля SAM, которую новое приложение может захватить в первые 3 года..
</DECOMPOSITION>
<ASSUMPTIONS>
                     4. 'Услуги по уходу': Я предполагаю, что это включает груминг, выгул, ситтинг.47
                     5. 'В США': Географическое ограничение.
                     6. 'Данные': Для расчетов потребуются актуальные отраслевые отчеты (например, APPA, IBISWorld).47
</ASSUMPTIONS>
<ESTIMATION>Задача требует сбора внешних данных. Невозможно дать оценку без использования инструментов.</ESTIMATION>
<PLAN>
                     7. Верифицировать фреймворк TAM/SAM/SOM и определение 'услуг'.
                     8. Шаг 2.1 (Фаза 2): Использовать инструмент web_search для поиска "APPA total pet expenditure report 2024" и "IBISWorld pet grooming services market size".47
                     9. Шаг 2.2 (Фаза 2): Использовать code_interpreter для выполнения расчетов TAM, SAM, SOM на основе найденных данных.
                     10. Шаг 2.3 (Фаза 2): Представить финальный отчет с расчетами.
</PLAN>
</FERMI_ANALYSIS>
<AWAITING_VERIFICATION>
                        * Анализ: Идеальная демонстрация обоснования использования инструментов. Агент не ищет данные немедленно; он представляет план, который включачает поиск данных, на верификацию.64


6.4 Пример 4: Прогнозирование на Основе Факторов


                        * Запрос: "Спрогнозируй вероятность того, что наш новый продукт (B2B SaaS) достигнет 10,000 платящих пользователей за 12 месяцев, учитывая, что у нас бюджет на маркетинг $500k и 3 сильных конкурента."
                        * Фаза 1 (Вывод агента):
<FERMI_ANALYSIS>
<TASK_CLASSIFICATION>Прогнозирование</TASK_CLASSIFICATION> ` (Анализ Факторов 24):
                           1. Определение Базовой Ставки (Base Rate) 25: Определение среднего % успеха (конверсии в 10k пользователей за 12 мес.) для B2B SaaS в данной нише.
                           2. Анализ Факторов (Ускоряющие):
                           * Фактор 1: Бюджет $500k. (Вес: Высокий, +30% к вероятности).
                           3. Анализ Факторов (Тормозящие):
                           * Фактор 2: 3 сильных конкурента. (Вес: Высокий, -25% к вероятности).
                           4. Анализ Факторов (Неизвестные):
                           * Фактор 3: Качество продукта (Вес:?).
                           * Фактор 4: Эффективность каналов маркетинга (Вес:?).
                           5. Синтез: Комбинирование факторов для получения вероятностного диапазона.
</DECOMPOSITION>
<ASSUMPTIONS>
                           6. Я предполагаю, что 'Базовая Ставка' успеха $\approx$ 15%.
                           7. Я присваиваю веса +30% и -25% факторам 1 и 2 соответственно.
                           8. Я предполагаю, что 'Качество продукта' (Фактор 3) соответствует рыночному.
</ASSUMPTIONS>
<ESTIMATION>На основе допущений, скорректированная вероятность (15% + 30% - 25% = 20%) находится в диапазоне 15%-25%.</ESTIMATION>
<PLAN>
                           9. Верифицировать Базовую Ставку (15%) и присвоенные веса факторам.
                           10. Запросить данные по Факторам 3 и 4 для уточнения прогноза.
                           11. После верификации, предоставить детальное объяснение расчета.
</PLAN>
</FERMI_ANALYSIS>
<AWAITING_VERIFICATION>
                              * Анализ: Демонстрирует, как Ферми-мышление применяется для структурированного, объяснимого (explainable) прогнозирования, превращая качественные данные (бюджет, конкуренты) в квази-количественные веса.24


Часть 7: Синтез и Рекомендации по Внедрению




7.1 Оценка Надежности: Преимущества и Компромиссы


Предложенная архитектура «Ферми-Первого» Агента (FFA) представляет собой надежную, структурированную и верифицируемую систему, которая полностью соответствует запросу на «идеальную инструкцию». Она превращает LLM из непредсказуемого «генератора текста» в детерминированного «партнера по решению проблем».
Преимущества:
                              * Снижение Ошибок: Значительно снижает риск ошибок по неверным допущениям и галлюцинаций (agent hallucination).7 Агент не может «убежать» с неверной идеей.
                              * Повышение Доверия: Пользователь всегда контролирует процесс, что критически важно для задач с высокими ставками (финансы, инжиниринг, медицина).
                              * Аудируемость (Auditability): Фаза 1 создает «аудируемый след» рассуждений. Каждый финальный ответ (Фаза 2) имеет явный, верифицированный пользователем план.9
                              * Оптимизация Ресурсов: Предотвращает бесполезные или дорогостоящие вызовы инструментов/API, требуя их предварительного обоснования в <PLAN>.
Компромиссы (Trade-offs):
                              1. Латентность (Задержка): Этот подход по своей сути медленнее. Он гарантированно требует как минимум двух циклов взаимодействия (Запрос -> Анализ -> Верификация -> Ответ).
                              2. Многословность (Verbosity): Архитектура не подходит для быстрых, тривиальных задач ("Который час?", "Как пишется слово...?"). Попытка «ферми-зировать» такой запрос будет излишней и раздражающей.
                              3. Сложность Внедрения: Эта архитектура требует больше, чем простого вызова API. Она требует наличия внешней системы-оркестратора (например, LangGraph 36, LlamaIndex 64, или кастомного решения 37), которая способна:
                              * Парсить XML-вывод.
                              * Обнаруживать тег <AWAITING_VERIFICATION>.
                              * Управлять состоянием (приостанавливать и возобновлять) рабочий процесс.


7.2 Рекомендации по Итеративной Настройке


Внедрение Мастер-Промпта — это не разовое событие, а итеративный процесс.
                              1. Обучение Классификатора: Адаптивная логика (<ADAPTIVE_OUTPUT_LOGIC>) полагается на точную классификацию задач.17 Рекомендуется использовать few-shot примеры (внедренные в промпт или используемые для fine-tuning), чтобы обучить агента точно распознавать типы задач (WBS, TAM/SAM/SOM и т.д.).44
                              2. Оценка Качества Фазы 1: Ключевой метрикой успеха является не качество финального ответа (Фаза 2), а качество Ферми-анализа (Фаза 1). Рекомендуется использовать подход LLM-as-a-judge («LLM как Судья») 67 для автоматической оценки качества (полноты, логичности, релевантности) генерируемых <FERMI_ANALYSIS>. Эти оценки следует использовать для непрерывной итеративной доработки Мастер-Промпта.
                              3. Управление Исключениями: Необходимо разработать протокол для задач, которые не должны проходить через UFP (например, «Стоп», «Привет»). Это может быть реализовано на уровне маршрутизатора (Router) 64, который стоит перед агентом «Ферми» и отфильтровывает тривиальные или мета-команды.
Заключительный вывод: Предложенный «Мастер-Промпт» и лежащая в его основе архитектура «Анализ-Верификация-Действие» представляют собой надежный, масштабируемый и устойчивый к ошибкам фреймворк. Он выполняет требование пользователя, встраивая метод Ферми в самое ядро когнитивного процесса агента, обеспечивая тем самым переход от простого генерирования информации к подлинному, верифицируемому решению проблем.
Источники
                              1. Prompt Engineering Guide, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              2. Beyond Guesswork: How Different AI Models Handle Fermi Estimation - TextQL, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              3. Fermi Estimate | Brilliant Math & Science Wiki, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              4. What is the fermi problem-solving strategy? | by Benjamin Landry | Medium, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              5. Break Down Your Prompts for Better AI Results, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              6. What are some triggers that prompt you to do a Fermi estimate, or to pull up a spreadsheet and make a simple/rough quantitative model? - LessWrong, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              7. Human-in-the-Loop for AI Agents: Best Practices, Frameworks, Use Cases, and Demo, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              8. Prompt Engineering for AI Agents - PromptHub, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              9. Plan Verification for LLM-Based Embodied Task Completion Agents - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              10. Building Effective AI Agents - Anthropic, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              11. Prompt templates and examples for Amazon Bedrock text models, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              12. Effective Prompt Engineering: Mastering XML Tags for Clarity, Precision, and Security in LLMs | by Tech for Humans | Medium, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              13. Use XML tags to structure your prompts - Claude Docs, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              14. dontriskit/awesome-ai-system-prompts: Curated collection of system prompts for top AI tools. Perfect for AI agent builders and prompt engineers. Incuding: ChatGPT, Claude, Perplexity, Manus, Claude-Code, Loveable, v0, Grok, same new, windsurf, notion, and MetaAI. - GitHub, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              15. Structure prompts | Generative AI on Vertex AI - Google Cloud Documentation, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              16. AI Explained: Using Prompt Engineering for Classification | by Maarten Ectors - Medium, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              17. LLM as a Router: How to Fine-Tune Models for Intent-Based Workflows | by Vansh Khaneja, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              18. How to Use ChatGPT to Build WBS: From Prompts to Perfect Plans - Dart AI, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              19. What is a Work Breakdown Structure? [+How to Make One] | The Workstream - Atlassian, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              20. Work Breakdown Structure (WBS): Overview, Uses, and Software - Coursera, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              21. TAM, SAM, SOM: How to Calculate Them for Your Industry - Foundation Marketing, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              22. TAM, SAM & SOM: How To Calculate The Size Of Your Market - Antler, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              23. ChatGPT Prompt for Market Sizing - Product Management World, дата последнего обращения: ноября 10, 2025, [URL_REMOVED])/ChatGPT+Prompt+for+Market+Sizing
                              24. Quantifying Qualitative Insights: Leveraging LLMs to Market Predict - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              25. LLM Forecasting Prompt Engineering - OSF, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              26. Analyze Survey Data Prompt — AI for Education, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              27. Examples of Prompts | Prompt Engineering Guide, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              28. Effective Prompts for AI: The Essentials - MIT Sloan Teaching & Learning Technologies, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              29. Boldly Prompting: A Practical Guide to System Instructions and Agent Tools - Medium, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              30. Can't instruct the LLM to confirm with the user before making function calls - Reddit, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              31. Advanced Decomposition Techniques for Improved Prompting in LLMs, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              32. Are there any good prompts to get ChatGPT to answer with answer with multiplication decomposition (fermi estimates) and better yet reference class forecasting? : r/slatestarcodex - Reddit, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              33. дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              34. What is chain of thought (CoT) prompting? - IBM, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              35. Effective context engineering for AI agents - Anthropic, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              36. LangChain overview - Docs by LangChain, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              37. AI Agent Orchestration Patterns - Azure Architecture Center - Microsoft Learn, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              38. Toward Super Agent System with Hybrid AI Routers - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              39. How can I ask for user confirmation before completing a chain? : r/LangChain - Reddit, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              40. Conditional Logic in Prompting - Playlab Learning Hub, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              41. If You Learn Conditional Prompts, Then You "Become a Prompt Engineer" - Tilburg.ai, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              42. Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              43. Langchain agents - tools for intent classification - Reddit, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              44. Prompt Engineering Techniques for LLMs: A Comprehensive Guide | by Aloy Banerjee, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              45. AI Prompts for Project Management - PromptDrive, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              46. Decomposition Prompting: Break It Down to Build It Up! - WordPress.com, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              47. Using Generative AI To Shape Your TAM/SAM/SOM - Productside, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              48. How to use ChatGPT to Calculate TAM, SAM and SOM for your Startup - YouTube, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              49. 28 ChatGPT Prompts For Market Research That Work In 2025 - Team-GPT, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              50. TAM, SAM & SOM: What Do They Mean & How Do You Calculate Them? - HubSpot Blog, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              51. LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              52. QuaLLM: An LLM-based Framework to Extract Quantitative Insights from Online Forums, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              53. Leveraging LLM and Data Science Methods to Quantify Qualitative Data: A Workflow and Method Example | by ChunYu Ko | The whispers of a data analyst | Medium, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              54. LangChain in Chains #48: Prompt Decomposition | by Okan Yenigün | AI Mind, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              55. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              56. Create a Work Breakdown Structure: WBS Template & Examples - TeamGantt, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              57. Visualizing APIs with tree diagrams, partly generated with AI - Idratherbewriting.com, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              58. AI project generator: a new workflow for easy project creation - Miro, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              59. Product Market Sizing | TAM-SAM-SOM | Each PM Should know | by Priyank Shah - Medium, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              60. Building Generative AI prompt chaining workflows with human in the loop - Amazon AWS, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              61. Your Practical Guide to LLM Agents in 2025 (+ 5 Templates for Automation) - n8n Blog, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              62. iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing - arXiv, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              63. Prompt engineering techniques - Azure OpenAI | Microsoft Learn, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              64. Building a Router from Scratch | LlamaIndex Python Documentation, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              65. Semantic Similarity as an Intent Router for LLM Apps - Zep, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              66. Best Practices for Building an Agent Router - Arize AI, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              67. AI LLM Test Prompts: Best Practices for AI Evaluation and Optimization, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              68. Chain-of-Thought Prompting | Prompt Engineering Guide, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              69. A list of metrics for evaluating LLM-generated content - Microsoft Learn, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]
                              70. Migrating from LLMRouterChain | 🦜️ LangChain, дата последнего обращения: ноября 10, 2025, [URL_REMOVED]