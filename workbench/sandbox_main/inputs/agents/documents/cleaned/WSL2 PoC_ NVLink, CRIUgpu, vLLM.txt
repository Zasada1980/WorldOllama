Отчет о валидации PoC (Этап 13): Оценка поддержки SOTA-технологий (NVLink, CRIUgpu, vLLM Sleep Mode) в WSL2




I. Сводка о состоянии PoC и ключевые выводы




A. Общая оценка


Отчет представляет собой окончательную оценку Proof-of-Concept (PoC) для Этапа 13. Анализ документации, отраслевых отчетов и технических данных за 2024-2025 гг. показывает, что, хотя базовая поддержка NVIDIA CUDA в Windows Subsystem for Linux 2 (WSL2) 1 функциональна для рабочих нагрузок разработки и сценариев с одним GPU, она демонстрирует фундаментальные архитектурные ограничения и критическую нестабильность.
Эти ограничения делают WSL2 непригодной для производственного развертывания запрошенных SOTA-технологий (NVLink, CRIUgpu и vLLM Sleep Mode).


B. Итоги валидации (Трек 1: Local-HA / NVLink)


* Статус: NO-GO (Блокирующий фактор)
* Обоснование: Поддержка NVLink полностью отсутствует в архитектуре паравиртуализации GPU (GPU-PV) в WSL2. Анализ документации NVIDIA и Microsoft не выявил ни одного упоминания поддержки NVLink.1 Коммуникации между GPU принудительно даунгрейдятся до стандартного P2P (Peer-to-Peer) через шину PCIe. Это полностью нивелирует все преимущества высокопроизводительной топологии "Local-HA" и, как сообщается, приводит к сбоям в фреймворках, зависящих от NCCL, при много-GPU обучении в WSL2.5


C. Итоги валидации (Трек 3: CRIUgpu)


* Статус: NO-GO (Блокирующий фактор)
* Обоснование: Валидация выявила двойной отказ на двух разных уровнях стека.
   1. Отказ на уровне ядра: Базовая утилита CRIU (Checkpoint/Restore In Userspace) 6 несовместима со специализированным ядром Linux, поставляемым Microsoft для WSL2.7 Отчеты пользователей подтверждают, что docker checkpoint (который использует CRIU) зависает или терпит неудачу в WSL2.8
   2. Отказ на уровне драйвера: Новая технология CRIUgpu 10 зависит от низкоуровневых API драйвера NVIDIA (таких как cuda-checkpoint) 12 для дампа состояния VRAM. Архитектура WSL2 GPU-PV, основанная на Windows Display Driver Model (WDDM), не предоставляет эти низкоуровневые API. Отчеты о сбоях nvidia-container-runtime во время чекпоинта подтверждают этот вывод.14
Сохранение состояния VRAM CUDA-процесса в WSL2 в настоящее время невозможно.


D. Итоги валидации (Трек 3: vLLM Sleep Mode)


* Статус: NO-GO (Высокий риск / Нестабильность)
* Обоснование: Функция –enable-sleep-mode в vLLM 15 существует и предназначена для достижения цели "теплого рестарта" путем сохранения JIT-скомпилированных ядер и CUDA-графов.16 Однако анализ отчетов об ошибках выявил критическую нестабильность, делающую ее непригодной для production:
   1. Сбои при паралеллизме данных (DP): Вызов "сна" приводит к падению движка vLLM при использовании data parallelism.17
   2. Сбои при доступе: Сервер падает, если получает запрос во время нахождения в "спящем режиме".18
Эта нестабильность усугубляется фундаментальным ограничением WSL2 на использование pinned memory (закрепленной памяти) 19, что снижает общую производительность и надежность асинхронных операций памяти.


E. Ключевые блокирующие факторы и стратегические риски


* Главный вывод: Архитектурная модель WSL2 (GPU-PV поверх WDDM) фундаментально несовместима с требованиями к прямому, низкоуровневому доступу к оборудованию, которые необходимы для SOTA-технологий HPC и MLOps, таких как NVLink и CRIUgpu. WSL2 предоставляет абстракцию CUDA, а не прямой доступ к GPU.
* Стратегический риск: Использование WSL2 в качестве производственной платформы для этих треков создает недопустимый риск. Трек 1 (Local-HA) будет работать со значительно сниженной (PCIe) производительностью. Трек 3 (CRIUgpu) неработоспособен. Трек 3 (vLLM Sleep Mode) подвержен непредсказуемым сбоям.


II. Анализ архитектуры виртуализации GPU в WSL2 (Стек 2024-2025 гг.)




A. Архитектура драйвера: WDDM, GPU-PV и фундаментальный компромисс


Ключ к пониманию всех сбоев PoC лежит в архитектуре того, как WSL2 получает доступ к GPU. WSL2 не использует прямой проброс PCIe (PCIe passthrough), который предоставлял бы гостевой ОС Linux эксклюзивный доступ к оборудованию.
Вместо этого WSL2 использует модель паравиртуализации GPU (GPU-PV).20 Эта система работает следующим образом:
1. Хост (Windows): Драйвер NVIDIA на хост-системе Windows 11 работает в режиме WDDM (Windows Display Driver Model).21 Этот режим является многопользовательским и предназначен для совместного использования GPU несколькими процессами и операционными системами (Windows и всеми ее гостями WSL2).
2. Гость (WSL2): Внутри дистрибутива Linux библиотека libcuda.so представляет собой "заглушку" (stub).4 Она не взаимодействует с оборудованием напрямую.
3. Транспорт: Когда приложение CUDA (например, vLLM) выполняется в WSL2, вызовы API CUDA перехватываются этой заглушкой и транслируются через шину виртуальной машины (VMBUS) к хост-драйверу WDDM, который уже выполняет фактическую работу на GPU.23
Существует фундаментальный конфликт между двумя режимами работы драйверов NVIDIA: WDDM (для графики, виртуализации и совместного использования) и TCC (Tesla Compute Cluster, для эксклюзивных, высокопроизводительных compute-задач).24 Технологии SOTA HPC, такие как NVLink и API cuda-checkpoint, неявно требуют TCC-подобного, низкоуровневого, эксклюзивного доступа к оборудованию.
Архитектура WSL2 GPU-PV по своей конструкции основана на WDDM, что делает ее неспособной предоставлять этот уровень доступа. Прямым доказательством этого архитектурного ограничения являются отчеты пользователей о профессиональных картах (например, NVIDIA L4), которые работают только в режиме TCC.25 Чтобы заставить их работать с WSL2, пользователи вынуждены переключать карту в режим MCDM (WDDM-like), что часто приводит к сбоям драйвера. Это доказывает, что WDDM является жестким требованием для WSL2, а TCC-подобные функции — недоступны.


B. Критическое ограничение 1: Отсутствие поддержки Unified Memory (UVM)


Официальная документация NVIDIA по WSL2 предельно ясна в отношении этого ограничения. В ней говорится: "Full Managed Memory Support is not available on Windows native and therefore WSL 2 will not support it for the foreseeable future. UVM full features will not be available...".4
Это не просто незначительное неудобство. Unified Virtual Memory (UVM) является основой многих современных CUDA-приложений, которые полагаются на автоматическое управление страницами (page faulting) и миграцию данных между CPU и GPU по требованию. Отсутствие этой функции в WSL2 означает, что любое приложение, зависящее от UVM, либо не запустится, либо будет вынуждено вернуться к ручному управлению памятью, что может привести к значительному снижению производительности и высокому использованию системной памяти.4


C. Критическое ограничение 2: Деградация Pinned Memory (Page-Locked Memory)


Анализ отчетов об ошибках vLLM выявил критическое предупреждение, которое vLLM выдает при запуске в WSL2: WARNING... Using 'pin_memory=False' as WSL is detected. This may slow down the performance..19
Это предупреждение является не просто оптимизацией, а обходным путем для фундаментального ограничения WSL2. NVIDIA подтверждает это в своей документации, цитируемой в отчете об ошибке: "Pinned system memory... availability for applications is limited".19
Pinned memory (закрепленная память) является основой для высокопроизводительных асинхронных операций, таких как cudaMemcpyAsync. Когда память "закреплена", она гарантированно не будет выгружена (swapped out) ОС, что позволяет GPU напрямую обращаться к ней через DMA (Direct Memory Access), не вмешивая CPU.
Отключение этой функции (pin_memory=False) в vLLM — это не выбор, а необходимость в WSL2. Это заставляет vLLM возвращаться к более медленным, синхронным или, по крайней мере, кэшируемым передачам данных. Это создает серьезное узкое место на шине PCIe и, вероятно, является первопричиной каскадных сбоев в более сложных асинхронных функциях, таких как "Sleep Mode", особенно в сочетании с паралеллизмом данных. Платформа начинается с нестабильного и низкопроизводительного фундамента для операций памяти.


D. Базовая производительность: Сравнение WSL2 с Bare-Metal (Phoronix 2025)


Даже без учета специфических для GPU ограничений, платформа WSL2 по своей сути имеет накладные расходы. Независимые бенчмарки, проведенные Phoronix в сентябре 2025 года на Windows 11 25H2, показали, что Ubuntu 24.04 в WSL2 обеспечивает в среднем 87% производительности от bare-metal установки Ubuntu 24.04 LTS на том же оборудовании.26
В отчете Phoronix отмечается, что основное снижение производительности связано с рабочими нагрузками, включающими операции ввода-вывода (I/O).26 Это согласуется с архитектурными накладными расходами на трансляцию вызовов файловой системы и системных вызовов через VMBUS. Таким образом, платформа WSL2 начинается с дефицита производительности в ~13% еще до учета специфических для GPU ограничений WDDM, UVM и pinned memory.
________________


Таблица 1: Сводка архитектуры и ограничений GPU в WSL2 (Стек 2024-2025)




Компонент
	Архитектура в WSL2
	Статус поддержки
	Ключевое влияние на PoC
	GPU Driver Model
	WDDM (Хост) + GPU-PV (Гость) 20
	Штатный режим
	Фундаментальный конфликт: Режим WDDM несовместим с низкоуровневыми требованиями TCC для SOTA-технологий.
	Доступ к GPU
	Паравиртуализированный (Трансляция вызовов) 4
	Штатный режим
	Высокие накладные расходы и отсутствие прямого доступа к оборудованию.
	Unified Memory (UVM)
	Не поддерживается 4
	Отказ
	Сбой или деградация производительности для приложений, зависящих от UVM.
	Pinned Memory
	Ограничено / Не поддерживается 19
	Деградация
	Снижение производительности cudaMemcpyAsync. Вероятная причина нестабильности vLLM "Sleep Mode".
	NVLink Fabric
	Не поддерживается
	Отказ
	Провал Трека 1. Коммуникации даунгрейдятся до PCIe.
	CUDA Checkpoint API
	Не предоставляется
	Отказ
	Провал Трека 2. Невозможность дампа состояния VRAM.
	________________


III. Валидация Трека 1: "Local-HA" (NVLink и P2P-коммуникации)




A. Официальный статус: Поддержка NVLink в WSL2 (Анализ документации)


Цель этого трека — валидировать высокоскоростные коммуникации между GPU, в частности, NVLink.
Проведен исчерпывающий анализ официальной документации NVIDIA (включая руководства по CUDA на WSL, заметки о драйверах и документацию NIM) 1 и Microsoft (включая блоги разработчиков и документацию по WSL) 2 за 2024-2025 гг.
Результат однозначен: ни в одном официальном документе не упоминается термин "NVLink" в контексте WSL2.
Учитывая стратегическую важность NVLink для много-GPU HPC и ИИ-нагрузок, которую NVIDIA активно продвигает 29, это молчание является доказательством отсутствия поддержки. Вся документация по GPU в WSL2 явно или неявно ссылается на стандартное взаимодействие через PCIe. Архитектура WDDM/GPU-PV не предназначена для виртуализации или проброса низкоуровневой фабрики, такой как NVLink.
Заключение: NVLink не пробрасывается, не виртуализируется и не поддерживается в WSL2.


B. Анализ P2P-коммуникаций: Функциональность cudaMemcpyPeerAsync


Запрос на валидацию cudaMemcpyPeerAsync является проверкой Peer-to-Peer (P2P) доступа. В отсутствие NVLink, система может вернуться к P2P-доступу через шину PCIe.
Это создает потенциальную "ловушку" для валидации: тесты, такие как p2pBandwidthLatencyTest из CUDA Samples 30, скорее всего, будут выполнены успешно. Однако они будут измерять пропускную способность PCIe, а не NVLink. В то время как NVLink 5-го поколения обеспечивает пропускную способность 1800 ГБ/с 29, PCIe 5.0 x16 ограничен ~64 ГБ/с.
Таким образом, хотя cudaMemcpyPeerAsync может работать (т.е. не возвращать ошибку), он будет работать в режиме, который полностью нивелирует цель "Local-HA" по достижению максимальной пропускной способности.
Более того, реальные отчеты пользователей подтверждают, что даже этот P2P-режим через PCIe нестабилен в WSL2. Пользователь в Reddit-сообществе 5 прямо заявляет о "постоянных проблемах с NCCL" при попытке распределенного обучения на нескольких GPU (с NVLink) в WSL2. NVIDIA NCCL (NVIDIA Collective Communications Library) 31 является основой для "Local-HA" и распределенного обучения. Его сбой является прямым следствием отсутствия NVLink и, возможно, нестабильной реализации P2P через PCIe в виртуализированной среде.


C. Оценка NIXL (NVIDIA Inference Xfer Library) как альтернативы P2P


NIXL (NVIDIA Inference Xfer Library) — это библиотека, предназначенная для ускорения P2P-коммуникаций в инференс-фреймворках, таких как vLLM.33 Она предоставляет абстракцию для перемещения данных и может использовать такие технологии, как GPUDirect RDMA.34
Однако NIXL не решает фундаментальную проблему. Это библиотека, которая использует базовые аппаратные возможности (P2P, GPUDirect). Если базовые возможности (NVLink) отсутствуют или деградировали (PCIe P2P в WSL2), NIXL также будет работать в деградированном режиме или потерпит неудачу. Она не может создать P2P-связь, которой нет на уровне гипервизора.


D. Заключение (Трек 1): Вердикт "NO-GO"


Топология "Local-HA" полностью зависит от высокоскоростной шины NVLink. WSL2 не поддерживает NVLink. Любые много-GPU операции будут вынуждены использовать значительно более медленную шину PCIe, что полностью нивелирует цель "Local-HA" и, как показывают отчеты, приводит к проблемам совместимости с NCCL. Трек 1 не может быть реализован в WSL2.


IV. Валидация Трека 2: CRIUgpu (Чекпоинт и восстановление CUDA)




A. Обзор технологии: CRIU, cuda-checkpoint и CRIUgpu


Цель этого трека — валидировать возможность чекпоинта (сохранения) и восстановления CUDA-процесса, включая его состояние VRAM. Этот процесс требует совместной работы трех ключевых технологий, появившихся в 2024-2025 гг.:
1. CRIU (Checkpoint/Restore In Userspace): Стандартная утилита Linux для заморозки состояния процесса (PID, файловые дескрипторы, память CPU) и сохранения его на диск.6
2. NVIDIA cuda-checkpoint: Новая утилита от NVIDIA (появившаяся, например, в драйвере версии 550+ 12), которая использует недавно добавленные API драйвера 13 для дампа состояния GPU (контексты CUDA, выделения памяти в VRAM и т.д.).
3. CRIUgpu: Новый (2025 г.) плагин для CRIU, который интегрирует и координирует оба процесса. Он "замораживает" CPU-процесс с помощью CRIU и одновременно использует cuda-checkpoint для дампа GPU-состояния, создавая единый согласованный чекпоинт.10


B. Анализ совместимости: Двойной отказ (Kernel и Driver)


Успех CRIUgpu зависит от двух независимых компонентов: CRIU должен работать в ядре Linux, а cuda-checkpoint должен иметь доступ к API драйвера. Анализ показывает, что в WSL2 оба компонента терпят неудачу независимо друг от друга.


1. Отказ на уровне ядра (CRIU vs. WSL2 Kernel)


CRIU не является обычным приложением; это низкоуровневый инструмент, который глубоко интегрирован с ядром Linux и требует наличия специфических функций и конфигураций ядра (например, CONFIG_MEMFD_CREATE=y).6
WSL2 не использует стандартное ядро Linux (mainline). Он использует кастомное, долгосрочно поддерживаемое (LTSC) ядро, собранное и поставляемое Microsoft.7 Это ядро оптимизировано для WSL2, но не обязательно включает все функции, необходимые для HPC-утилит, таких как CRIU.
Прямые отчеты пользователей подтверждают эту несовместимость. Пользователи на Stack Overflow и GitHub сообщают, что docker checkpoint (который является высокоуровневой оберткой для CRIU) зависает или терпит неудачу в среде WSL2.8 В отчете об ошибке CRIU 9 упоминается ошибка Function not implemented при вызове memfd_create, что является явным признаком отсутствия необходимой функции в ядре WSL2.


2. Отказ на уровне драйвера (GPU-PV vs. cuda-checkpoint API)


Даже если бы ядро WSL2 поддерживало CRIU, технология CRIUgpu все равно потерпела бы неудачу.
Утилита cuda-checkpoint 12 и ее API 13 требуют прямого, TCC-подобного (см. Раздел II.A) доступа к драйверу для выполнения низкоуровневых операций по приостановке и дампу GPU-контекста.
Как установлено, архитектура WSL2 GPU-PV 20 — это абстракция высокого уровня. Драйвер-заглушка в WSL2 4 транслирует вызовы CUDA к хост-драйверу WDDM 21, который управляет GPU в режиме совместного использования. Этот WDDM-драйвер не предоставляет низкоуровневые API-перехваты, необходимые для cuda-checkpoint.
"Дымящийся пистолет" этого сбоя найден в отчете об ошибке GitHub.14 При попытке docker checkpoint для GPU-контейнера (в среде, которая, вероятно, включает nvidia-container-runtime), пользователь получает ошибку: criu failed: type NOTIFY errno 0... nvidia-container-runtime did not terminate successfully. Это прямое доказательство того, что среда выполнения NVIDIA (nvidia-container-runtime) не может успешно взаимодействовать с CRIU для чекпоинта GPU-контекста.


C. Заключение (Трек 2): Вердикт "NO-GO"


Технология CRIUgpu в настоящее время (2024-2025 гг.) фундаментально несовместима с WSL2. Отказ происходит как на уровне ядра Linux (CRIU не поддерживается ядром WSL2), так и на уровне драйвера GPU (API cuda-checkpoint не предоставляются через WDDM/GPU-PV). Сохранение и восстановление состояния VRAM CUDA-процесса в WSL2 невозможно.
________________


Таблица 2: Матрица совместимости CRIUgpu и WSL2




Компонент
	Требование
	Статус в WSL2 (2024-2025)
	Доказательство (Источник)
	CRIU (Userspace Utility)
	Специфические функции ядра Linux (напр., memfd_create)
	Отказ
	Кастомное ядро WSL2 не включает необходимые syscalls. 7
	cuda-checkpoint (NVIDIA API)
	Низкоуровневый доступ к драйверу (API cuCheckpointProcessLock)
	Отказ
	Драйвер WDDM/GPU-PV не предоставляет API для дампа состояния. 13
	CRIUgpu (Plugin)
	Успешная работа CRIU и cuda-checkpoint
	Отказ
	Зависит от двух вышеуказанных компонентов, которые не работают. 10
	________________


V. Валидация Трека 3: vLLM "Sleep Mode" (Сохранение JIT-ядер)




A. Архитектура "Sleep Mode" и ее цель


Цель этого трека — валидировать, что vLLM Sleep Mode (активируемый флагом –enable-sleep-mode 15) корректно сохраняет артефакты "теплого старта", в частности JIT-скомпилированные ядра.
"Sleep Mode" предназначен для решения проблемы "холодного старта" при переключении между моделями. Официальный блог vLLM (октябрь 2025 г.) 16 объясняет, что "холодный старт" — это не только загрузка весов. Он включает в себя несколько дорогостоящих этапов, которые "Sleep Mode" позволяет избежать, сохраняя процесс живым:
1. Настройка аллокатора VRAM.
2. Захват CUDA-графов (CUDA graph capture).
3. JIT-компиляция GPU-ядер (DeepGEMM, FlashInfer, TorchInductor и т.д.).
4. Разогрев кэша.
"Sleep Mode" имеет два уровня: Level 1 (сбрасывает веса в CPU RAM) и Level 2 (сбрасывает веса полностью).15 Цель валидации (сохранение JIT-ядер и CUDA-графов) применима к обоим уровням.


B. Анализ производительности: "Теплый рестарт" (Wake) vs. "Холодный старт" (Load)


В идеальных условиях (т.е. на bare-metal Linux) эта функция работает исключительно хорошо. Бенчмарки vLLM 16 показывают, что "пробуждение" (warm restart) из "сна" в 18-200 раз быстрее, чем полная "холодная" перезагрузка. Например, для модели Qwen3-Coder-30B "пробуждение" занимает 2.87 секунды по сравнению с 47.4 секундами "холодного старта".16
Более того, производительность инференса "теплой" модели на 61-88% выше, чем у "холодной".16 Это доказывает, что JIT-скомпилированные ядра и CUDA-графы действительно сохраняются, что и является целью нашего PoC.
Таким образом, в теории, функция –enable-sleep-mode достигает заявленной цели. Вопрос в том, работает ли она стабильно в WSL2.


C. Оценка стабильности: Анализ критических сбоев (GitHub Issues)


Именно здесь валидация PoC для WSL2 проваливается. Несмотря на то, что код существует и работает в идеальных условиях, анализ общедоступных отчетов об ошибках показывает, что эта функция критически нестабильна в сложных сценариях, необходимых для production.
* Критическая ошибка 1: Сбой при паралеллизме данных (DP).
Отчет об ошибке 17 описывает фатальный сценарий: "when using data parallelism, calling sleep immediately after the rollout causes the vLLM engine to crash." Это прямой блокиратор для любой много-GPU конфигурации, что делает его несовместимым с развертыванием "Local-HA" (даже если бы мы смирились с отсутствием NVLink).
* Критическая ошибка 2: Сбой при обращении к "спящей" модели.
Отчет об ошибке 18 описывает еще один производственный блокиратор: "Server crashes when making completion requests to a sleeping model." В асинхронном производственном сервере, обслуживающем несколько моделей, возникновение "гонки состояний" (race condition) между входящим запросом и процессом "пробуждения" неизбежно. Этот сбой делает функцию нежизнеспособной.
* Критическая ошибка 3: Сбои на новом оборудовании (Blackwell).
Отчет об ошибке 40 (июль 2025 г.) показывает сбой vLLM при запуске (во время инициализации WorkerProc) только при добавлении флага –enable-sleep-mode на новых GPU Blackwell (RTX PRO 6000). Это указывает на хрупкость этой функции и отсутствие ее готовности к новому поколению оборудования.
* Критическая ошибка 4: Некорректная загрузка весов (Level 2).
Отчет об ошибке 41 (апрель 2025 г.) показывает, что Level 2 sleep "cannot load weights properly" после пробуждения, возвращая искаженный (corrupted) вывод. Это ошибка целостности данных.


D. Заключение (Трек 3): Вердикт "NO-GO" (Высокий риск)


Хотя "Sleep Mode" теоретически сохраняет JIT-ядра 16, эта функция практически нестабильна и изобилует критическими ошибками, блокирующими производственное использование.17
Фундаментальная проблема WSL2 с pinned memory (см. Раздел II.C) 19 создает "зыбкую почву" для асинхронных операций. Эта базовая нестабильность, вероятно, способствует или усугубляет нестабильность высокоуровневых функций vLLM. Использование –enable-sleep-mode в WSL2 несет недопустимо высокий риск сбоев в производственной среде.


VI. Итоговая оценка PoC и стратегические рекомендации




A. Синтез результатов: Итоговая карта валидации PoC


Результаты PoC Этапа 13 однозначны. Каждая из трех исследуемых SOTA-технологий сталкивается с блокирующими проблемами в среде WSL2, которые делают производственное развертывание невозможным или крайне рискованным.
________________


Таблица 3: Итоговая карта валидации PoC (Этап 13: WSL2)




Трек PoC
	SOTA-Технология
	Цель валидации
	Статус
	Ключевой блокирующий фактор (Техническое резюме)
	Трек 1 (Local-HA)
	NVLink / cudaMemcpyPeerAsync
	Высокоскоростной P2P-доступ между GPU.
	RED (NO-GO)
	Архитектурное отсутствие поддержки. Модель WDDM/GPU-PV 20 не пробрасывает и не виртуализирует фабрику NVLink. Технология не поддерживается.
	Трек 3 (CRIU)
	CRIUgpu / cuda-checkpoint
	Чекпоинт состояния VRAM CUDA-процесса.
	RED (NO-GO)
	Двойной отказ (Kernel + Driver). 1) Кастомное ядро WSL2 7 несовместимо с CRIU.8 2) Драйвер GPU-PV 4 не предоставляет API cuda-checkpoint.14
	Трек 3 (vLLM)
	vLLM "Sleep Mode"
	Сохранение JIT-ядер и CUDA-графов для "теплого рестарта".
	RED (NO-GO)
	Критическая нестабильность. Функция вызывает сбои в производственных сценариях, включая паралеллизм данных 17 и обработку запросов во время "сна".18
	________________


B. Стратегические рекомендации по дальнейшим действиям


   1. Немедленно остановить PoC на WSL2: Данные, собранные на Этапе 13, однозначно показывают, что WSL2 является тупиковым путем для производственного развертывания требуемых SOTA-технологий. Дальнейшие инвестиции в устранение неполадок в этой среде нецелесообразны.
   2. Пересмотр архитектуры: Фундаментальная проблема — это абстракция (GPU-PV) и совместное использование (WDDM). Наши SOTA-требования (NVLink, CRIUgpu) требуют эксклюзивного и прямого контроля над оборудованием.
   3. Рекомендуемые альтернативные пути валидации:
   * Путь А (Предпочтительный): Bare-Metal Linux (Ubuntu 24.04 LTS). Этот путь устраняет все ограничения, выявленные в данном отчете (несовместимость ядра, проблемы с драйвером WDDM, отсутствие NVLink, ограничения pinned memory). Он представляет собой отраслевой стандарт для производственных SOTA-нагрузок.
   * Путь Б (Альтернатива): Windows Server 2025 с Hyper-V DDA (Direct Device Assignment). В отличие от WSL2 GPU-PV, DDA позволяет полностью и эксклюзивно пробросить PCIe-устройство (GPU) в гостевую VM (Linux). Это предоставляет гостевой ОС TCC-подобный доступ к GPU, что потенциально решает проблемы NVLink и CRIUgpu. Этот путь требует иной архитектуры хоста (Windows Server вместо Windows 11) и настройки VM.
   4. Окончательный вердикт: WSL2 является мощным и эффективным инструментом для разработки, отладки и запуска одно-GPU приложений.1 Однако он не является производственной платформой, готовой к требованиям высокопроизводительных, много-GPU SOTA-нагрузок, валидируемых на Этапе 13.
Источники
   1. CUDA on Windows Subsystem for Linux (WSL) - NVIDIA Developer, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   2. Enable NVIDIA CUDA on WSL 2 - Microsoft Learn, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   3. Getting Started — NVIDIA NIM on WSL2, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   4. CUDA on WSL User Guide, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   5. I have spent 7+ hours trying to get WSL2 to work with Multi-GPU training - is it basically impossible on windows? lol - Reddit, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   6. CRIU, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   7. How to use the Microsoft Linux kernel v6 on WSL2, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   8. Newest 'criu' Questions - Stack Overflow, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   9. Cross Compilation for ARM #1986 - checkpoint-restore/criu - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   10. GPU Container Checkpoint/Restore with CRIUgpu: Zero-Downtime Live Migration for ML Workloads - DevZero, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   11. Cedana vs. CRIUgpu for GPU Checkpoint/Restore, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   12. Checkpointing CUDA Applications with CRIU | NVIDIA Technical Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   13. What does 'does not support GPU migration" mean specifically? · Issue #18 · NVIDIA/cuda-checkpoint - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   14. How to use the "--enable-external-masters" option in the Docker checkpoint feature (integrated with CRIU)? · Issue #2472 - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   15. Sleep Mode - vLLM, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   16. Zero-Reload Model Switching with vLLM Sleep Mode, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   17. [Bug]: Crash occurs when calling sleep while running vLLM engine in data parallel mode · Issue #24879 - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   18. [Bug]: vLLM engine crashes then restarts and loads the model on sleep if a chat request is made · Issue #15483 - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   19. WSL performance issue with pin_memory=False · Issue #1084 · vllm ..., дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   20. GPU support - Docker Docs, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   21. WDDM Architecture - Windows drivers | Microsoft Learn, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   22. Windows Display Driver Model - Wikipedia, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   23. Leveling up CUDA Performance on WSL2 with New Enhancements | NVIDIA Technical Blog, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   24. Which NVIDIA Windows Driver do I need? WDDM vs. TCC - YouTube, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   25. Enabling WSL2 on TCC gpu (L4) by switching to MCDM - NVIDIA Developer Forums, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   26. The Performance Cost To Ubuntu WSL2 On Windows 11 25H2 - Phoronix, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   27. The Performance Cost To Ubuntu WSL2 On Windows 11 25H2 - Phoronix, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   28. GPU accelerated ML training in WSL - Microsoft Learn, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   29. Scaling AI Inference Performance and Flexibility with NVIDIA NVLink and NVLink Fusion, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   30. Benchmark bandwidth and latency of P2P NVIDIA GPUs (NVLINK vs PCI) - GitHub Gist, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   31. Benchmarking — NVIDIA GB200 NVL Multi-Node Tuning Guide, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   32. Expected bandwidth results? 8x A100 GPUs over NVLink · Issue #149 · NVIDIA/nccl-tests, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   33. ai-dynamo/nixl: NVIDIA Inference Xfer Library (NIXL) - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   34. NVIDIA Dynamo, A Low-Latency Distributed Inference Framework for Scaling Reasoning AI Models, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   35. NVIDIA Dynamo Accelerates llm-d Community Initiatives for Advancing Large-Scale Distributed Inference, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   36. Insights into GPUDirect Data Transfer through NIXL Benchmarking - Computer Science - Illinois Institute of Technology, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   37. CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads - arXiv, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   38. Release Notes for Windows Subsystem for Linux kernel - Microsoft Learn, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   39. Sleep Mode Guide - vllm-ascend - Read the Docs, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   40. [Bug]: vLLM crashes when using --enable-sleep-mode with ... - GitHub, дата последнего обращения: ноября 8, 2025, [URL_REMOVED]
   41. [Bug]: After wake up from level 2 sleep, model cannot load weights ..., дата последнего обращения: ноября 8, 2025, [URL_REMOVED]