Оценка производительности Python-приложений в среде Gramine + Intel SGX




Краткий обзор


Данный отчет представляет собой всесторонний анализ практической осуществимости и производительности запуска Python-приложений (агентов) в изолированной среде исполнения (TEE), созданной с помощью Gramine и технологии Intel Software Guard Extensions (SGX). Целью является оценка готовности данной технологии к промышленному использованию в контексте архитектуры, требующей верифицируемого Доказательства Исполнения (Proof of Execution, PoE).
Анализ показывает, что производительность стека Gramine + SGX сильно зависит от типа рабочей нагрузки. Для вычислительно-интенсивных (CPU-bound) задач, рабочий набор которых полностью помещается в кэш страниц анклава (Enclave Page Cache, EPC), накладные расходы минимальны и могут составлять всего 3–10 %. Однако для задач, интенсивно использующих операции ввода-вывода (I/O-bound) или системные вызовы, наблюдается критическое снижение производительности с замедлением от 200 % до более чем 1900 %.
Ключевым фактором, определяющим производительность, является размер EPC. Превышение доступного объема EPC приводит к катастрофическому падению производительности из-за подкачки страниц. Современное серверное оборудование с поддержкой SGXv2, оснащенное большим объемом EPC (до 1 ТБ), значительно снижает остроту этой проблемы для многих приложений, однако объем используемой памяти остается основным архитектурным ограничением.
Подход Gramine «lift-and-shift», позволяющий запускать неизмененные Linux-приложения, является гарантией функциональной совместимости, но не производительности. Gramine достигает этой совместимости путем трансляции системных вызовов Linux в дорогостоящие переходы границ анклава, что является основным источником накладных расходов для нетривиальных приложений.
Итоговая рекомендация: Технология является условно готовой к промышленному использованию. Успешное внедрение зависит от проектирования Python-агентов как долгоживущих, вычислительно-интенсивных процессов, минимизирующих количество переходов границ анклава. Наивная попытка «поднять и перенести» приложение с большим количеством операций ввода-вывода обречена на неудачу. Данный отчет предлагает необходимые архитектурные паттерны и руководство по оптимизации производительности для достижения жизнеспособного решения.


1. Архитектурные основы производительности в Intel SGX


Для понимания данных о производительности, представленных в последующих разделах, необходимо проанализировать фундаментальные характеристики базового оборудования. Эти характеристики объясняют, почему определенные операции в среде SGX являются по своей природе дорогостоящими.


1.1. Накладные расходы на переходы границ анклава: ECALL и OCALL


Анклав представляет собой изолированную среду исполнения. Любое взаимодействие с внешним миром, например, обращение к операционной системе для выполнения операций ввода-вывода, должно пересекать эту границу с помощью специальных инструкций: ECALL (вход в анклав) и OCALL (выход из анклава для вызова недоверенного кода). Эти переходы не являются простыми вызовами функций; это дорогостоящие операции переключения контекста на уровне центрального процессора.1 Каждый переход включает в себя сброс кэшей ЦП, инвалидацию буферов трансляции адресов (TLB) и выполнение проверок безопасности, что требует тысяч тактов процессора (от 8 000 до 12 000 тактов на пару EEXIT/EENTER).2
Тесты производительности показывают, что эти накладные расходы наиболее заметны при выполнении небольших и частых операций. Для малых массивов данных издержки на переключение контекста преобладают над временем фактических вычислений, что приводит к «огромным накладным расходам».1 По мере увеличения размера входных данных (например, более 256 КБ) эта фиксированная стоимость амортизируется за счет более длительных вычислений, и накладные расходы становятся «незначительными».1
Эта характеристика аппаратного обеспечения SGX формирует ключевое архитектурное требование: необходимость амортизировать стоимость переходов границ анклава. Поскольку каждый переход является фиксированной и высокой по стоимости операцией, любая жизнеспособная архитектура приложения должна быть спроектирована таким образом, чтобы максимизировать объем полезной работы, выполняемой внутри анклава между каждым переходом. Это напрямую противоречит типичной структуре многих приложений, ориентированных на ввод-вывод (например, простые веб-сервисы или скрипты), которые выполняют множество небольших взаимодействий с операционной системой.


1.2. Подсистема памяти: шифрование, целостность и эффекты кэширования


Вся память внутри анклава, находящаяся в EPC, шифруется и защищается от нарушения целостности с помощью движка шифрования памяти (Memory Encryption Engine, MEE) центрального процессора.3 Доступ к этой памяти сопряжен с дополнительными издержками, особенно при промахах кэша, когда данные необходимо извлечь из оперативной памяти, расшифровать и проверить.3 Это может проявляться в виде снижения пропускной способности для приложений с интенсивным использованием памяти, которые превышают емкость кэша. Один из тестов производительности зафиксировал снижение пропускной способности при работе с массивами размером более 8 МБ (размер кэша L3 в тестовой среде), что указывает на дополнительные промахи кэша при доступе к зашифрованной памяти анклава.1 Это подчеркивает, что даже для вычислительно-интенсивных задач шаблоны доступа к памяти являются критическим фактором производительности.


1.3. Кэш страниц анклава (EPC): жесткая граница производительности


EPC — это ограниченная, зарезервированная BIOS область физической памяти (Processor Reserved Memory, PRM), в которой должны размещаться весь код и данные анклава.3 Управление EPC осуществляется ЦП с помощью аппаратной структуры метаданных, называемой картой кэша страниц анклава (EPCM).6
Если рабочий набор приложения превышает доступный размер EPC, операционная система вынуждена прибегать к подкачке страниц (пейджингу) — выгрузке страниц анклава в недоверенную оперативную память и их последующей загрузке обратно. Этот процесс чрезвычайно медленный из-за криптографических операций, необходимых для защиты выгружаемых страниц.3
Тесты производительности последовательно демонстрируют резкое, обрывоподобное падение производительности при превышении лимита EPC. В тесте функции find_max производительность «драматически» падает для массивов размером более 64 МБ.1 Для модели машинного обучения размером 1.4 ГБ на платформе SGXv1 (с ~90 МБ доступного EPC) время вывода было почти в 5 раз больше из-за пейджинга.3


1.4. SGXv1 и SGXv2: эволюция поколений и ее практическое влияние


Второе поколение SGX (SGXv2), доступное на современных процессорах серверного класса (например, 3rd Gen Xeon Scalable), внесло критически важные усовершенствования по сравнению с SGXv1.3
Ключевые улучшения включают:
* Значительно увеличенный размер EPC: С ~90 МБ полезного пространства в SGXv1 до 1 ТБ на сокет в SGXv2, что фактически устраняет проблему пейджинга EPC для широкого спектра приложений.3
* Динамическое управление памятью анклава (EDMM): Позволяет динамически выделять память анклава (через mmap, brk), обеспечивая гибкость, отсутствовавшую в статической модели памяти SGXv1. Однако прямолинейное внедрение EDMM может привести к значительным накладным расходам (замедление до 58 % в тесте GCBench) из-за стоимости изменения отображения страниц, хотя это можно смягчить с помощью оптимизаций.10
* Поддержка многосокетных ЦП: Позволяет анклавам использовать ресурсы нескольких ЦП, увеличивая количество доступных ядер и общий объем EPC.3
Влияние этих улучшений огромно. Модель машинного обучения, которая работала в 5 раз медленнее на SGXv1 из-за пейджинга, демонстрирует «незначительные накладные расходы» на SGXv2.3 Этот скачок между поколениями делает возможным рассмотрение SGX для более крупных, реальных приложений, таких как агенты на Python.
Следовательно, выбор поколения оборудования SGX (и, в частности, размера EPC) является не деталью реализации, а основным архитектурным ограничением, определяющим саму возможность проекта. Оценка программного обеспечения (Gramine + Python) не может проводиться в отрыве от аппаратной платформы. Ответ на вопрос «готово ли решение к промышленному использованию?» полностью зависит от оборудования, на котором оно будет развернуто, что имеет серьезные последствия для планирования затрат и инфраструктуры.


2. Gramine как библиотечная ОС: функциональность ценой производительности


В этом разделе анализируется влияние на производительность самой системы Gramine, которая выступает в роли критически важного, но дорогостоящего слоя абстракции между неизмененным Python-приложением и ограничивающим аппаратным обеспечением SGX.


2.1. Эмуляция среды Linux: издержки трансляции системных вызовов


Основная функция Gramine — запуск неизмененных Linux-приложений путем перехвата их системных вызовов (например, open, read, socket) и их эмуляции либо трансляции в OCALLs к недоверенной хост-ОС.4 Каждый системный вызов, который не может быть полностью обработан внутри библиотечной ОС Gramine, приводит как минимум к одной паре дорогостоящих операций выхода из анклава и повторного входа (EEXIT + EENTER). Это является фундаментальным источником накладных расходов Gramine для приложений, интенсивно использующих ввод-вывод.4
Данные для Gramine-TDX (аналогичной архитектуры) показывают, что производительность может упасть до 6 % от нативной для нагрузок с интенсивным использованием сети и файловой системы, поскольку безопасность имеет приоритет над оптимизацией этой виртуальной аппаратной коммуникации.16 Это служит количественным показателем серьезности издержек на трансляцию системных вызовов. Таким образом, обещание Gramine «lift-and-shift» — это удобство с точки зрения функциональности, которое скрывает фундаментальную архитектурную трансформацию. Оно неявно преобразует профиль ввода-вывода приложения в профиль переходов границ анклава, что является наихудшим сценарием производительности для SGX.


2.2. Зависимость накладных расходов от рабочей нагрузки: CPU-bound и I/O-bound


Штраф за производительность при использовании Gramine прямо пропорционален частоте системных вызовов приложения.
* Вычислительно-интенсивные (CPU-bound) нагрузки: Приложения, выполняющие интенсивные вычисления в памяти (например, умножение матриц, криптографические операции), после инициализации делают мало системных вызовов. Для них накладные расходы Gramine невелики, часто менее 10–25 %.8 Одна из HPC-нагрузок показала накладные расходы всего в 4–17 %.18
* Нагрузки с интенсивным вводом-выводом (I/O-bound): Приложения, которые часто читают/пишут файлы, обращаются к сети или взаимодействуют с ОС, серьезно страдают. Биоинформатические рабочие нагрузки (с большим объемом файлового ввода-вывода) показали замедление от 283 % до 1971 % для малых входных данных.19 Сетевые нагрузки могут снизить производительность до 6 % от нативной, то есть более чем в 15 раз медленнее.16


2.3. Целостность файловой системы и производительность: цена sgx.trusted_files


Для обеспечения целостности файлов приложения, загружаемых в анклав, Gramine вычисляет их хэши и перечисляет их в манифесте в секции sgx.trusted_files. Во время выполнения Gramine должен перечитывать и проверять эти файлы по их хэшам, чтобы защититься от подмены со стороны недоверенной хост-ОС. Этот процесс проверки, особенно хэширование, является вычислительно затратным. Важно отметить, что в протестированной версии Gramine отсутствует кэш страниц для доверенных файлов. Это означает, что для такого приложения, как веб-сервер Nginx, каждый запрос к файлу может инициировать полное чтение с хоста и повторную проверку хэш-сумм его фрагментов.20
Тест производительности Nginx, обслуживающего файл размером 10 КБ из доверенного файлового монтирования, показал снижение пропускной способности примерно на 55 % по сравнению с нативной работой. Основной причиной была идентифицирована функция mbedtls_sha256_update, на которую приходилось около 60 % накладных расходов. Когда это хэширование было закомментировано, падение производительности сократилось всего до ~7 %.20 Это дает четкое количественное измерение компромисса между целостностью и производительностью для файлового ввода-вывода.
Гарантии безопасности Gramine, такие как целостность доверенных файлов, находятся в прямом и измеримом конфликте с производительностью. Это не ошибка, а фундаментальный компромисс в дизайне. Угроза модели SGX предполагает, что хост-ОС является вредоносной.4 Следовательно, любые данные, считываемые с файловой системы хоста (например, Python-скрипт или библиотека), не могут быть доверенными без проверки. Механизм sgx.trusted_files в Gramine реализует эту проверку с помощью криптографического хэширования.20 Тест Nginx 20 показывает, что эта проверка является самым большим источником накладных расходов на ввод-вывод. Это означает, что для системы «Альфа-Редактор» каждый модуль Python, каждая библиотека и каждый файл данных, требующий защиты целостности, будет нести эти издержки производительности при доступе. Выбор стоит не между «быстрым» и «медленным» вводом-выводом, а между «безопасным» и «небезопасным», что имеет серьезные последствия для производительности.


3. Профиль производительности Python-приложений в Gramine-SGX


Этот раздел посвящен специфическим проблемам запуска среды выполнения Python в ограниченной среде SGX, переходя от общих принципов TEE к вопросам, связанным с конкретным языком.


3.1. Задержка при запуске и инициализации: усугубление проблемы «холодного старта»


Запуск Python известен своей относительной медлительностью по сравнению с компилируемыми языками, так как он включает инициализацию виртуальной машины и импорт необходимых модулей.22 В Gramine-SGX этот процесс усугубляется. Каждый доступ к файлу для импорта модулей (.py, .pyc) становится потенциальным OCALL, и каждый файл должен быть проверен, если он является доверенным. Это может значительно увеличить время «холодного старта».
Нативный запуск Python 3.7 может занимать ~15 мс, причем значительная часть времени уходит на импорт модуля site.22 Простой скрипт на Python может выполняться 30–70 мс в нативной среде.23 Хотя прямых тестов запуска Python в Gramine не представлено, рабочая нагрузка PyTorch в Gramine-SGX демонстрировала проблему «холодного старта», при которой начальные эпохи обучения были значительно медленнее, прежде чем стабилизироваться на постоянной (хотя и более высокой, чем нативная) скорости выполнения.24 Это указывает на значительные первоначальные затраты на инициализацию и возможную JIT-компиляцию внутри анклава.


3.2. Выполнение в рантайме: взаимодействие интерпретатора Python, C-расширений и SGX


Значительная часть производительности Python в числовых или интенсивных задачах обеспечивается C-расширениями (например, NumPy, Pandas), которые включают вызовы из интерпретатора Python в скомпилированный C-код.25 Внутри анклава весь стек вызовов (ВМ Python -> C-библиотека) находится в защищенной памяти. Основные проблемы с производительностью возникают не из-за самих вызовов, а из-за системных вызовов, которые делают C-расширения. Например, библиотека, которая читает файл или открывает сетевой сокет, инициирует дорогостоящий путь трансляции системных вызовов в Gramine.
Ключевым принципом оптимизации является перенос как можно большего объема работы в C-расширение, чтобы минимизировать переходы между Python и C.25 Этот принцип усиливается в SGX, где цель состоит в том, чтобы весь «горячий» цикл, включая выполнение C-расширения, оставался внутри анклава без выполнения OCALL.


3.3. Управление памятью и сборка мусора в анклаве


CPython использует подсчет ссылок и поколенческий сборщик мусора (GC) для управления памятью.26 Это включает частые выделения/освобождения объектов и периодический обход графов объектов для поиска и освобождения циклических ссылок.
В среде Gramine-SGX это может привести к следующим издержкам:
1. Выделение памяти: Частые выделения небольших объемов памяти, характерные для Python, могут быть затронуты слоем управления памятью Gramine (например, его реализацией brk и mmap поверх EDMM), который, как известно, является более дорогостоящим, чем нативные вызовы ОС.10
2. Обход GC: Фаза «mark-and-sweep» сборщика мусора включает чтение больших участков кучи приложения. Этот доступ к памяти, происходящий в зашифрованном EPC, будет подвержен накладным расходам MEE, что потенциально замедлит циклы GC.
Специализированный тест для сборки мусора, GCBench, запущенный в Gramine с базовой реализацией EDMM, показал замедление до 58 % по сравнению со статической моделью выделения памяти SGX1.10 Хотя это не прямой тест Python, он убедительно свидетельствует о том, что рабочие нагрузки с интенсивным управлением памятью, характерные для Python, будут испытывать значительные штрафы за производительность из-за взаимодействия среды выполнения языка и подсистемы памяти TEE.
Сама среда выполнения Python, с ее динамической загрузкой модулей и сборкой мусора, представляет собой рабочую нагрузку с интенсивным использованием ввода-вывода и памяти, которая по своей природе плохо подходит для необработанной среды SGX. Динамические импорты (import) — это операции файлового ввода-вывода, которые в Gramine-SGX чрезвычайно дороги.16 Автоматическое управление памятью (GC) — это операция с интенсивным обходом памяти, которая также несет накладные расходы в защищенной среде.10 Таким образом, те самые функции, которые делают Python языком высокого уровня, становятся значительными источниками проблем с производительностью при запуске в Gramine-SGX.


4. Количественный анализ производительности: обзор тестов


Этот раздел объединяет и представляет численные данные из исследовательских материалов, чтобы обеспечить количественную основу для итоговой оценки.


4.1. Микротесты: изоляция стоимости примитивных операций


* Накладные расходы ECALL/OCALL: Стоимость простого вызова функции в анклав чрезвычайно высока для малых входных данных, но становится незначительной для данных размером >256 КБ.1
* Копирование памяти: Операция memcpy внутри анклава демонстрирует значительное замедление для буферов размером >64 КБ.1
* Криптографические операции: Шифрование AES с использованием оптимизированной библиотеки Intel может достигать высокой пропускной способности (2150 МБ/с), но это все равно составляет менее половины (около 43 %) от нативной производительности, что демонстрирует накладные расходы даже для вычислительно-интенсивных, аппаратно-ускоренных задач.1


4.2. Макротесты: производительность в сложных приложениях


* HPC/Научные вычисления:
   * Накладные расходы в целом низки для вычислительно-интенсивных нагрузок: менее 10 % на пропускную способность и 20 % на задержку.17
   * Биоинформатические инструменты (Bowtie2, Minimap2), которые интенсивно используют ввод-вывод, показывают экстремальные накладные расходы для малых входных данных (замедление до 1971 %), но умеренные для больших (15–57 %).19
* Вывод в машинном обучении (Inference):
   * Для моделей, помещающихся в EPC, накладные расходы очень низки. AlexNet на SGXv2 работал всего на 3 % медленнее, чем нативно.3
   * Рабочая нагрузка PyTorch в Gramine-SGX после периода «холодного старта» стабилизировалась на скорости примерно на 30 % ниже нативной.24
* Веб-сервисы / Сетевой ввод-вывод:
   * Пропускная способность Nginx упала примерно на 55 % из-за накладных расходов на проверку доверенных файлов.20
   * Производительность Redis была улучшена на 58 % за счет использования функции Exitless, что подчеркивает серьезные издержки системных вызовов по умолчанию для сетевых операций.2
   * Общие сетевые нагрузки могут демонстрировать падение производительности до 6 % от нативной.16


4.3. Таблица: сводка накладных расходов на производительность (Gramine-SGX по сравнению с нативной средой)




Тип нагрузки
	Описание и ключевая метрика
	Размер входных данных/нагрузки
	Наблюдаемые накладные расходы/замедление
	Доминирующий узкий проход
	Источник(и)
	Простой вызов функции
	find_max в массиве
	Малый (<256 КБ)
	«Огромные накладные расходы»
	Переключение контекста ECALL/OCALL
	1
	Простой вызов функции
	find_max в массиве
	Большой (>256 КБ)
	«Незначительные»
	Вычисления
	1
	Криптография
	Шифрование AES128-GCM
	Большие сообщения
	~57 % медленнее (43 % от нативной)
	MEE / неоптимизированная криптография
	1
	ML Inference
	Модель AlexNet
	80 МБ
	3 % медленнее
	Вычисления / MEE
	3
	ML Training
	PyTorch (ResNet18)
	Набор данных MNIST
	~30 % медленнее (стационарное состояние)
	Трансляция системных вызовов / MEE
	24
	Биоинформатика (I/O)
	Bowtie2 / Minimap2
	Малый
	283 % – 1971 % медленнее
	Трансляция системных вызовов (файловый I/O)
	19
	Биоинформатика (I/O)
	Bowtie2 / Minimap2
	Большой
	15 % – 57 % медленнее
	Трансляция системных вызовов (файловый I/O)
	19
	Веб-сервер (I/O)
	Nginx
	Файл 10 КБ
	~55 % ниже пропускная способность
	Проверка доверенных файлов (хэширование)
	20
	In-Memory DB (Net I/O)
	Redis
	Н/Д
	>58 % (без Exitless)
	Трансляция системных вызовов (сетевой I/O)
	2
	Общий I/O
	Интенсивные сетевые/файловые операции
	Н/Д
	До 94 % медленнее (6 % от нативной)
	Трансляция системных вызовов
	16
	Данные тестов последовательно показывают, что гранулярность рабочей нагрузки является самым важным предиктором накладных расходов. Мелкие, частые задачи наказываются очень сильно, в то время как крупные, монолитные задачи — нет.1 Это прямое следствие амортизации фиксированной стоимости переходов границ анклава. Это означает, что два Python-агента с одинаковыми общими вычислительными требованиями могут иметь кардинально разную производительность в SGX. Агент, обрабатывающий 1 МБ данных за один вызов функции, будет быстрым. Агент, обрабатывающий тот же 1 МБ данных, делая 1000 вызовов по 1 КБ каждый, будет недопустимо медленным.
В совокупности тесты показывают, что Gramine+SGX предлагает высокую производительность не для общего назначения, а для очень специфического архитектурного паттерна: «анклав как сопроцессор». Рабочие нагрузки, которые показывают хорошие результаты (HPC, ML-вывод на больших тензорах), рассматривают анклав как специализированный ускоритель: они загружают данные один раз (один дорогостоящий переход), выполняют длительные, сложные вычисления полностью внутри и извлекают результат (еще один дорогостоящий переход). Напротив, рабочие нагрузки с плохой производительностью (веб-серверы, интерактивные скрипты) рассматривают анклав как среду ОС общего назначения, ожидая частых взаимодействий с внешними ресурсами с низкой задержкой.


5. Практическое руководство по внедрению и оптимизации


Этот раздел переводит теоретическое понимание и данные тестов в практические рекомендации для пользователя.


5.1. Структурирование манифеста Gramine для Python-приложений


Манифест — это конфигурационный файл в формате TOML, который определяет среду приложения внутри Gramine.13
* Конфигурация точки входа: libos.entrypoint должен указывать на исполняемый файл интерпретатора Python в файловой системе Gramine (например, /usr/bin/python3.8).28
* Монтирование файловой системы: Интерпретатор Python, его стандартная библиотека, site-packages (включая все зависимости) и скрипты самого агента должны быть смонтированы в виртуальную файловую систему анклава с помощью fs.mounts.28
* Доверенные и разрешенные файлы: Это критически важное решение с точки зрения безопасности и производительности. Весь код Python и библиотеки, необходимые для целостности PoE, должны быть перечислены в sgx.trusted_files. Это влечет за собой накладные расходы на проверку, описанные в разделе 2.3. Нечувствительные данные или конфигурации можно монтировать как sgx.allowed_files для повышения производительности.20
* Конфигурация SGX: Ключевые параметры, такие как sgx.enclave_size, должны быть достаточно большими, чтобы вместить среду выполнения Python, все библиотеки и кучу приложения, чтобы избежать пейджинга EPC.33 sgx.max_threads должен быть настроен для поддержки требований приложения к параллелизму.2
Ниже приведен аннотированный шаблон манифеста, основанный на доступных примерах, с рекомендациями для Python-приложения.35


Ini, TOML




# Уровень логирования; для продакшена использовать "error"
loader.log_level = "{{ log_level }}"

# Точка входа - интерпретатор Python внутри виртуальной файловой системы анклава
libos.entrypoint = "/usr/bin/python3.8"

# Переменные окружения, необходимые для Python и связанных библиотек
loader.env.LD_LIBRARY_PATH = "/lib:{{ arch_libdir }}:/usr/{{ arch_libdir }}"
loader.env.PYTHONPATH = "/app"

# Монтирование файловой системы
fs.mounts = [
 # Монтирование среды выполнения Gramine и стандартной библиотеки C
 { path = "/lib", uri = "file:{{ gramine.runtimedir() }}" },
 { path = "{{ arch_libdir }}", uri = "file:{{ arch_libdir }}" },
 { path = "/usr/{{ arch_libdir }}", uri = "file:/usr/{{ arch_libdir }}" },
 
 # Монтирование интерпретатора Python и его стандартной библиотеки
 { path = "/usr/bin/python3.8", uri = "file:/usr/bin/python3.8" },
 { path = "{{ python.stdlib }}", uri = "file:{{ python.stdlib }}" },
 { path = "{{ python.platstdlib }}", uri = "file:{{ python.platstdlib }}" },
 
 # Монтирование кода приложения и зависимостей (например, site-packages виртуального окружения)
 { path = "/app", uri = "file:./app" },
 { path = "{{ python.distlib }}", uri = "file:{{ python.distlib }}" },
]

# Размер анклава должен быть настроен под потребление памяти приложением
sgx.enclave_size = "2G"
# Количество потоков должно соответствовать параллелизму приложения
sgx.max_threads = 16

# Для системы Proof-of-Execution весь код должен быть доверенным
sgx.trusted_files = [
 "file:{{ gramine.runtimedir() }}/",
 "file:{{ arch_libdir }}/",
 "file:/usr/{{ arch_libdir }}/",
 "file:/usr/bin/python3.8",
 "file:{{ python.stdlib }}/",
 "file:{{ python.platstdlib }}/",
 "file:{{ python.distlib }}/",
 "file:./app/",
]



5.2. Стратегии оптимизации производительности


Функция Exitless (Switchless):
* Механизм: Обменивает ядра ЦП на более быстрое выполнение OCALL. Потоки анклава не выходят из него при OCALL, а вместо этого активно ожидают, пока выделенные недоверенные «вспомогательные потоки» выполнят системные вызовы от их имени, избегая накладных расходов EEXIT/EENTER.2
* Конфигурация: Включается через sgx.insecure__rpc_thread_num. Рекомендуется устанавливать это значение равным sgx.max_threads.2
* Влияние: Значительно улучшает производительность для нагрузок с большим количеством системных вызовов. Тест Redis показал улучшение производительности на 58 %.2
* Предостережение: Эта функция помечена как insecure и не рекомендуется для производственного использования из-за потенциальных уязвимостей.2 Это серьезный предупреждающий знак для производственной системы.
Таблица: Ключевые опции манифеста для оптимизации производительности


Опция манифеста
	Назначение
	Рекомендуемая настройка для Python-агентов
