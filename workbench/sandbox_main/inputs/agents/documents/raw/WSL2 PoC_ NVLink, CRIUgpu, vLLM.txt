Отчет о валидации PoC (Этап 13): Оценка поддержки SOTA-технологий (NVLink, CRIUgpu, vLLM Sleep Mode) в WSL2




I. Сводка о состоянии PoC и ключевые выводы




A. Общая оценка


Отчет представляет собой окончательную оценку Proof-of-Concept (PoC) для Этапа 13. Анализ документации, отраслевых отчетов и технических данных за 2024-2025 гг. показывает, что, хотя базовая поддержка NVIDIA CUDA в Windows Subsystem for Linux 2 (WSL2) 1 функциональна для рабочих нагрузок разработки и сценариев с одним GPU, она демонстрирует фундаментальные архитектурные ограничения и критическую нестабильность.
Эти ограничения делают WSL2 непригодной для производственного развертывания запрошенных SOTA-технологий (NVLink, CRIUgpu и vLLM Sleep Mode).


B. Итоги валидации (Трек 1: Local-HA / NVLink)


* Статус: NO-GO (Блокирующий фактор)
* Обоснование: Поддержка NVLink полностью отсутствует в архитектуре паравиртуализации GPU (GPU-PV) в WSL2. Анализ документации NVIDIA и Microsoft не выявил ни одного упоминания поддержки NVLink.1 Коммуникации между GPU принудительно даунгрейдятся до стандартного P2P (Peer-to-Peer) через шину PCIe. Это полностью нивелирует все преимущества высокопроизводительной топологии "Local-HA" и, как сообщается, приводит к сбоям в фреймворках, зависящих от NCCL, при много-GPU обучении в WSL2.5


C. Итоги валидации (Трек 3: CRIUgpu)


* Статус: NO-GO (Блокирующий фактор)
* Обоснование: Валидация выявила двойной отказ на двух разных уровнях стека.
   1. Отказ на уровне ядра: Базовая утилита CRIU (Checkpoint/Restore In Userspace) 6 несовместима со специализированным ядром Linux, поставляемым Microsoft для WSL2.7 Отчеты пользователей подтверждают, что docker checkpoint (который использует CRIU) зависает или терпит неудачу в WSL2.8
   2. Отказ на уровне драйвера: Новая технология CRIUgpu 10 зависит от низкоуровневых API драйвера NVIDIA (таких как cuda-checkpoint) 12 для дампа состояния VRAM. Архитектура WSL2 GPU-PV, основанная на Windows Display Driver Model (WDDM), не предоставляет эти низкоуровневые API. Отчеты о сбоях nvidia-container-runtime во время чекпоинта подтверждают этот вывод.14
Сохранение состояния VRAM CUDA-процесса в WSL2 в настоящее время невозможно.


D. Итоги валидации (Трек 3: vLLM Sleep Mode)


* Статус: NO-GO (Высокий риск / Нестабильность)
* Обоснование: Функция –enable-sleep-mode в vLLM 15 существует и предназначена для достижения цели "теплого рестарта" путем сохранения JIT-скомпилированных ядер и CUDA-графов.16 Однако анализ отчетов об ошибках выявил критическую нестабильность, делающую ее непригодной для production:
   1. Сбои при паралеллизме данных (DP): Вызов "сна" приводит к падению движка vLLM при использовании data parallelism.17
   2. Сбои при доступе: Сервер падает, если получает запрос во время нахождения в "спящем режиме".18
Эта нестабильность усугубляется фундаментальным ограничением WSL2 на использование pinned memory (закрепленной памяти) 19, что снижает общую производительность и надежность асинхронных операций памяти.


E. Ключевые блокирующие факторы и стратегические риски


* Главный вывод: Архитектурная модель WSL2 (GPU-PV поверх WDDM) фундаментально несовместима с требованиями к прямому, низкоуровневому доступу к оборудованию, которые необходимы для SOTA-технологий HPC и MLOps, таких как NVLink и CRIUgpu. WSL2 предоставляет абстракцию CUDA, а не прямой доступ к GPU.
* Стратегический риск: Использование WSL2 в качестве производственной платформы для этих треков создает недопустимый риск. Трек 1 (Local-HA) будет работать со значительно сниженной (PCIe) производительностью. Трек 3 (CRIUgpu) неработоспособен. Трек 3 (vLLM Sleep Mode) подвержен непредсказуемым сбоям.


II. Анализ архитектуры виртуализации GPU в WSL2 (Стек 2024-2025 гг.)




A. Архитектура драйвера: WDDM, GPU-PV и фундаментальный компромисс


Ключ к пониманию всех сбоев PoC лежит в архитектуре того, как WSL2 получает доступ к GPU. WSL2 не использует прямой проброс PCIe (PCIe passthrough), который предоставлял бы гостевой ОС Linux эксклюзивный доступ к оборудованию.
Вместо этого WSL2 использует модель паравиртуализации GPU (GPU-PV).20 Эта система работает следующим образом:
1. Хост (Windows): Драйвер NVIDIA на хост-системе Windows 11 работает в режиме WDDM (Windows Display Driver Model).21 Этот режим является многопользовательским и предназначен для совместного использования GPU несколькими процессами и операционными системами (Windows и всеми ее гостями WSL2).
2. Гость (WSL2): Внутри дистрибутива Linux библиотека libcuda.so представляет собой "заглушку" (stub).4 Она не взаимодействует с оборудованием напрямую.
3. Транспорт: Когда приложение CUDA (например, vLLM) выполняется в WSL2, вызовы API CUDA перехватываются этой заглушкой и транслируются через шину виртуальной машины (VMBUS) к хост-драйверу WDDM, который уже выполняет фактическую работу на GPU.23
Существует фундаментальный конфликт между двумя режимами работы драйверов NVIDIA: WDDM (для графики, виртуализации и совместного использования) и TCC (Tesla Compute Cluster, для эксклюзивных, высокопроизводительных compute-задач).24 Технологии SOTA HPC, такие как NVLink и API cuda-checkpoint, неявно требуют TCC-подобного, низкоуровневого, эксклюзивного доступа к оборудованию.
Архитектура WSL2 GPU-PV по своей конструкции основана на WDDM, что делает ее неспособной предоставлять этот уровень доступа. Прямым доказательством этого архитектурного ограничения являются отчеты пользователей о профессиональных картах (например, NVIDIA L4), которые работают только в режиме TCC.25 Чтобы заставить их работать с WSL2, пользователи вынуждены переключать карту в режим MCDM (WDDM-like), что часто приводит к сбоям драйвера. Это доказывает, что WDDM является жестким требованием для WSL2, а TCC-подобные функции — недоступны.


B. Критическое ограничение 1: Отсутствие поддержки Unified Memory (UVM)


Официальная документация NVIDIA по WSL2 предельно ясна в отношении этого ограничения. В ней говорится: "Full Managed Memory Support is not available on Windows native and therefore WSL 2 will not support it for the foreseeable future. UVM full features will not be available...".4
Это не просто незначительное неудобство. Unified Virtual Memory (UVM) является основой многих современных CUDA-приложений, которые полагаются на автоматическое управление страницами (page faulting) и миграцию данных между CPU и GPU по требованию. Отсутствие этой функции в WSL2 означает, что любое приложение, зависящее от UVM, либо не запустится, либо будет вынуждено вернуться к ручному управлению памятью, что может привести к значительному снижению производительности и высокому использованию системной памяти.4


C. Критическое ограничение 2: Деградация Pinned Memory (Page-Locked Memory)


Анализ отчетов об ошибках vLLM выявил критическое предупреждение, которое vLLM выдает при запуске в WSL2: WARNING... Using 'pin_memory=False' as WSL is detected. This may slow down the performance..19
Это предупреждение является не просто оптимизацией, а обходным путем для фундаментального ограничения WSL2. NVIDIA подтверждает это в своей документации, цитируемой в отчете об ошибке: "Pinned system memory... availability for applications is limited".19
Pinned memory (закрепленная память) является основой для высокопроизводительных асинхронных операций, таких как cudaMemcpyAsync. Когда память "закреплена", она гарантированно не будет выгружена (swapped out) ОС, что позволяет GPU напрямую обращаться к ней через DMA (Direct Memory Access), не вмешивая CPU.
Отключение этой функции (pin_memory=False) в vLLM — это не выбор, а необходимость в WSL2. Это заставляет vLLM возвращаться к более медленным, синхронным или, по крайней мере, кэшируемым передачам данных. Это создает серьезное узкое место на шине PCIe и, вероятно, является первопричиной каскадных сбоев в более сложных асинхронных функциях, таких как "Sleep Mode", особенно в сочетании с паралеллизмом данных. Платформа начинается с нестабильного и низкопроизводительного фундамента для операций памяти.


D. Базовая производительность: Сравнение WSL2 с Bare-Metal (Phoronix 2025)


Даже без учета специфических для GPU ограничений, платформа WSL2 по своей сути имеет накладные расходы. Независимые бенчмарки, проведенные Phoronix в сентябре 2025 года на Windows 11 25H2, показали, что Ubuntu 24.04 в WSL2 обеспечивает в среднем 87% производительности от bare-metal установки Ubuntu 24.04 LTS на том же оборудовании.26
В отчете Phoronix отмечается, что основное снижение производительности связано с рабочими нагрузками, включающими операции ввода-вывода (I/O).26 Это согласуется с архитектурными накладными расходами на трансляцию вызовов файловой системы и системных вызовов через VMBUS. Таким образом, платформа WSL2 начинается с дефицита производительности в ~13% еще до учета специфических для GPU ограничений WDDM, UVM и pinned memory.
________________


Таблица 1: Сводка архитектуры и ограничений GPU в WSL2 (Стек 2024-2025)




Компонент
	Архитектура в WSL2
	Статус поддержки
	Ключевое влияние на PoC
	GPU Driver Model
	WDDM (Хост) + GPU-PV (Гость) 20
	Штатный режим
	Фундаментальный конфликт: Режим WDDM несовместим с низкоуровневыми требованиями TCC для SOTA-технологий.
	Доступ к GPU
	Паравиртуализированный (Трансляция вызовов) 4
	Штатный режим
	Высокие накладные расходы и отсутствие прямого доступа к оборудованию.
	Unified Memory (UVM)
	Не поддерживается 4
	Отказ
	Сбой или деградация производительности для приложений, зависящих от UVM.
	Pinned Memory
	Ограничено / Не поддерживается 19
	Деградация
	Снижение производительности cudaMemcpyAsync. Вероятная причина нестабильности vLLM "Sleep Mode".
	NVLink Fabric
	Не поддерживается
	Отказ
	Провал Трека 1. Коммуникации даунгрейдятся до PCIe.
	CUDA Checkpoint API
	Не предоставляется
	Отказ
	Провал Трека 2. Невозможность дампа состояния VRAM.
	________________


III. Валидация Трека 1: "Local-HA" (NVLink и P2P-коммуникации)




A. Официальный статус: Поддержка NVLink в WSL2 (Анализ документации)


Цель этого трека — валидировать высокоскоростные коммуникации между GPU, в частности, NVLink.
Проведен исчерпывающий анализ официальной документации NVIDIA (включая руководства по CUDA на WSL, заметки о драйверах и документацию NIM) 1 и Microsoft (включая блоги разработчиков и документацию по WSL) 2 за 2024-2025 гг.
Результат однозначен: ни в одном официальном документе не упоминается термин "NVLink" в контексте WSL2.
Учитывая стратегическую важность NVLink для много-GPU HPC и ИИ-нагрузок, которую NVIDIA активно продвигает 29, это молчание является доказательством отсутствия поддержки. Вся документация по GPU в WSL2 явно или неявно ссылается на стандартное взаимодействие через PCIe. Архитектура WDDM/GPU-PV не предназначена для виртуализации или проброса низкоуровневой фабрики, такой как NVLink.
Заключение: NVLink не пробрасывается, не виртуализируется и не поддерживается в WSL2.


B. Анализ P2P-коммуникаций: Функциональность cudaMemcpyPeerAsync


Запрос на валидацию cudaMemcpyPeerAsync является проверкой Peer-to-Peer (P2P) доступа. В отсутствие NVLink, система может вернуться к P2P-доступу через шину PCIe.
Это создает потенциальную "ловушку" для валидации: тесты, такие как p2pBandwidthLatencyTest из CUDA Samples 30, скорее всего, будут выполнены успешно. Однако они будут измерять пропускную способность PCIe, а не NVLink. В то время как NVLink 5-го поколения обеспечивает пропускную способность 1800 ГБ/с 29, PCIe 5.0 x16 ограничен ~64 ГБ/с.
Таким образом, хотя cudaMemcpyPeerAsync может работать (т.е. не возвращать ошибку), он будет работать в режиме, который полностью нивелирует цель "Local-HA" по достижению максимальной пропускной способности.
Более того, реальные отчеты пользователей подтверждают, что даже этот P2P-режим через PCIe нестабилен в WSL2. Пользователь в Reddit-сообществе 5 прямо заявляет о "постоянных проблемах с NCCL" при попытке распределенного обучения на нескольких GPU (с NVLink) в WSL2. NVIDIA NCCL (NVIDIA Collective Communications Library) 31 является основой для "Local-HA" и распределенного обучения. Его сбой является прямым следствием отсутствия NVLink и, возможно, нестабильной реализации P2P через PCIe в виртуализированной среде.


C. Оценка NIXL (NVIDIA Inference Xfer Library) как альтернативы P2P


NIXL (NVIDIA Inference Xfer Library) — это библиотека, предназначенная для ускорения P2P-коммуникаций в инференс-фреймворках, таких как vLLM.33 Она предоставляет абстракцию для перемещения данных и может использовать такие технологии, как GPUDirect RDMA.34
Однако NIXL не решает фундаментальную проблему. Это библиотека, которая использует базовые аппаратные возможности (P2P, GPUDirect). Если базовые возможности (NVLink) отсутствуют или деградировали (PCIe P2P в WSL2), NIXL также будет работать в деградированном режиме или потерпит неудачу. Она не может создать P2P-связь, которой нет на уровне гипервизора.


D. Заключение (Трек 1): Вердикт "NO-GO"


Топология "Local-HA" полностью зависит от высокоскоростной шины NVLink. WSL2 не поддерживает NVLink. Любые много-GPU операции будут вынуждены использовать значительно более медленную шину PCIe, что полностью нивелирует цель "Local-HA" и, как показывают отчеты, приводит к проблемам совместимости с NCCL. Трек 1 не может быть реализован в WSL2.


IV. Валидация Трека 2: CRIUgpu (Чекпоинт и восстановление CUDA)




A. Обзор технологии: CRIU, cuda-checkpoint и CRIUgpu


Цель этого трека — валидировать возможность чекпоинта (сохранения) и восстановления CUDA-процесса, включая его состояние VRAM. Этот процесс требует совместной работы трех ключевых технологий, появившихся в 2024-2025 гг.:
1. CRIU (Checkpoint/Restore In Userspace): Стандартная утилита Linux для заморозки состояния процесса (PID, файловые дескрипторы, память CPU) и сохранения его на диск.6
2. NVIDIA cuda-checkpoint: Новая утилита от NVIDIA (появившаяся, например, в драйвере версии 550+ 12), которая использует недавно добавленные API драйвера 13 для дампа состояния GPU (контексты CUDA, выделения памяти в VRAM и т.д.).
3. CRIUgpu: Новый (2025 г.) плагин для CRIU, который интегрирует и координирует оба процесса. Он "замораживает" CPU-процесс с помощью CRIU и одновременно использует cuda-checkpoint для дампа GPU-состояния, создавая единый согласованный чекпоинт.10


B. Анализ совместимости: Двойной отказ (Kernel и Driver)


Успех CRIUgpu зависит от двух независимых компонентов: CRIU должен работать в ядре Linux, а cuda-checkpoint должен иметь доступ к API драйвера. Анализ показывает, что в WSL2 оба компонента терпят неудачу независимо друг от друга.


1. Отказ на уровне ядра (CRIU vs. WSL2 Kernel)


CRIU не является обычным приложением; это низкоуровневый инструмент, который глубоко интегрирован с ядром Linux и требует наличия специфических функций и конфигураций ядра (например, CONFIG_MEMFD_CREATE=y).6
WSL2 не использует стандартное ядро Linux (mainline). Он использует кастомное, долгосрочно поддерживаемое (LTSC) ядро, собранное и поставляемое Microsoft.7 Это ядро оптимизировано для WSL2, но не обязательно включает все функции, необходимые для HPC-утилит, таких как CRIU.
Прямые отчеты пользователей подтверждают эту несовместимость. Пользователи на Stack Overflow и GitHub сообщают, что docker checkpoint (который является высокоуровневой оберткой для CRIU) зависает или терпит неудачу в среде WSL2.8 В отчете об ошибке CRIU 9 упоминается ошибка Function not implemented при вызове memfd_create, что является явным признаком отсутствия необходимой функции в ядре WSL2.


2. Отказ на уровне драйвера (GPU-PV vs. cuda-checkpoint API)


Даже если бы ядро WSL2 поддерживало CRIU, технология CRIUgpu все равно потерпела бы неудачу.
Утилита cuda-checkpoint 12 и ее API 13 требуют прямого, TCC-подобного (см. Раздел II.A) доступа к драйверу для выполнения низкоуровневых операций по приостановке и дампу GPU-контекста.
Как установлено, архитектура WSL2 GPU-PV 20 — это абстракция высокого уровня. Драйвер-заглушка в WSL2 4 транслирует вызовы CUDA к хост-драйверу WDDM 21, который управляет GPU в режиме совместного использования. Этот WDDM-драйвер не предоставляет низкоуровневые API-перехваты, необходимые для cuda-checkpoint.
"Дымящийся пистолет" этого сбоя найден в отчете об ошибке GitHub.14 При попытке docker checkpoint для GPU-контейнера (в среде, которая, вероятно, включает nvidia-container-runtime), пользователь получает ошибку: criu failed: type NOTIFY errno 0... nvidia-container-runtime did not terminate successfully. Это прямое доказательство того, что среда выполнения NVIDIA (nvidia-container-runtime) не может успешно взаимодействовать с CRIU для чекпоинта GPU-контекста.


C. Заключение (Трек 2): Вердикт "NO-GO"


Технология CRIUgpu в настоящее время (2024-2025 гг.) фундаментально несовместима с WSL2. Отказ происходит как на уровне ядра Linux (CRIU не поддерживается ядром WSL2), так и на уровне драйвера GPU (API cuda-checkpoint не предоставляются через WDDM/GPU-PV). Сохранение и восстановление состояния VRAM CUDA-процесса в WSL2 невозможно.
________________


Таблица 2: Матрица совместимости CRIUgpu и WSL2




Компонент
	Требование
	Статус в WSL2 (2024-2025)
	Доказательство (
