Технический Аудит и Валидация Архитектуры PoC-13: Оценка Жизнеспособности vLLM, Local-HA (NVLink) и SOTA DR (CRIU-Альтернатив) в Среде WSL2


Индекс Документа: R&D-PoC13-WSL2-VALIDATION-FINAL
Дата: 24 Мая 2025 г.


УПРАВЛЯЮЩЕЕ РЕЗЮМЕ: ВЕРДИКТЫ ПО ТРЕМ НАПРАВЛЕНИЯМ


Этот отчет представляет собой технический аудит жизнеспособности трех ключевых направлений Proof-of-Concept (PoC) 13, основанных на "хрупкой" архитектуре, использующей Windows Subsystem for Linux 2 (WSL2) в качестве основной платформы исполнения.
* Категория 1 (MVP - vLLM Sleep Mode): ЖИЗНЕСПОСОБЕН, С ОГОВОРКАМИ.
Анализ подтверждает, что технология "vLLM Sleep Mode" (--enable-sleep-mode) функциональна в среде WSL2. Она успешно выполняет свою основную задачу: сохранение состояния CUDA-процесса, включая JIT-скомпилированные ядра и CUDA-графы. Это обеспечивает "теплый перезапуск" модели, который на 18-200x быстрее, чем полный "холодный старт".
Однако эта жизнеспособность достигается ценой двух существенных компромиссов:
   1. Деградация Производительности I/O: vLLM принудительно отключает pin_memory (pin_memory=False) в WSL2 из-за фундаментальных ограничений в архитектуре гипервизора, что замедляет операции копирования (например, выгрузку весов в CPU RAM).
   2. Риски Стабильности: Обнаружен критический баг, приводящий к немедленному краху vLLM при одновременном использовании "Sleep Mode" и Data Parallelism (-dp > 1).
   * Категория 2 (Трек 1 - Local-HA): НЕЖИЗНЕСПОСОБЕН.
Фундаментальное предположение этого трека — доступность высокоскоростных P2P-коммуникаций (NVLink или cudaMemcpyPeerAsync по PCIe) между несколькими GPU внутри WSL2 — ошибочно. Исчерпывающий анализ документации NVIDIA и Microsoft, а также отчетов о проваленных тестах, подтверждает, что гипервизор Windows (Hyper-V) не предоставляет гостевым VM WSL2 прямой доступ к NVLink или P2P-домену PCIe. Любые multi-GPU операции будут вынуждены использовать крайне медленный обходной путь через CPU RAM, что полностью нивелирует цель "Local-HA" и приведет к катастрофической потере производительности.
   * Категория 3 (Трек DR - Альтернатива CRIU): ЖИЗНЕСПОСОБЕН, НО ТРЕБУЕТ СМЕНЫ ПАРАДИГМЫ.
Прямой аналог CRIU (чекпоинт процесса) в Windows-стеке отсутствует. Новейшая утилита NVIDIA cuda-checkpoint бесполезна в данной архитектуре, так как она сохраняет только состояние GPU и требует CRIU (которого нет) для сохранения состояния CPU.
Однако SOTA-решение (State-of-the-Art) существует, но на другом уровне: Live Migration (горячая миграция) на уровне VM с полным сохранением состояния VRAM. Это экспериментальная (bleeding-edge) технология, анонсированная в 2025 году, которая требует полного перехода со стека Windows 11 на кластер Windows Server 2025 и использования лицензированного ПО NVIDIA vGPU (v18.0+) с GPU, поддерживающими SR-IOV.


РАЗДЕЛ I. ГЛУБОКАЯ ВАЛИДАЦИЯ "vLLM SLEEP MODE" (MVP) НА WSL2




2.1. Определение Ценности: Что "Sleep Mode" Сохраняет и Почему это Важно


Основная цель MVP — подтвердить, что "vLLM Sleep Mode" решает проблему "холодного старта" в WSL2, сохраняя JIT-кернелы и CUDA-графы.


2.1.1. Проблема "Холодного Старта"


"Холодный старт" LLM-сервиса — это не просто загрузка весов модели с диска в VRAM. В производственных средах этот процесс может занимать от 30 до 100+ секунд 1, а для моделей размером ~30B+ и их CUDA-графов — до 20 минут.2 Этот простой полностью блокирует GPU-ресурс, делая переключение моделей по требованию неэффективным.1 vLLM cold-start может занимать до 19 секунд только до инициализации устройства.3


2.1.2. "Скрытые Затраты" Холодного Старта


Анализ официальной документации vLLM 1 показывает, что "Sleep Mode" был разработан специально для избежания "скрытых затрат", которые игнорируют простые "быстрые загрузчики весов". Каждый "холодный старт" требует оплаты следующих шагов:
      1. Инициализация Аллокатора VRAM: Настройка CUDA CuMemAllocator.
      2. Компиляция JIT-Ядер: JIT-компиляция кастомных ядер (например, DeepGEMM, FlashInfer, TorchInductor).
      3. Захват CUDA-Графов (Graph Capture): Запись графов выполнения операций.
      4. Прогрев Кэшей (Cache Warm-up): Оверхед первого запроса.
"Sleep Mode" сохраняет процесс живым, тем самым избегая повторной инициализации этих критически важных компонентов.1


2.1.3. Подтверждение Запроса (JIT-кернелы и CUDA-графы)


Анализ источников 1 напрямую подтверждает, что "vLLM Sleep Mode" сохраняет (Preserves) всю инфраструктуру исполнения CUDA. При "пробуждении" (wake up) из режима сна, vLLM не выполняет заново следующие операции:
      * Состояние Процесса (Python, Контекст CUDA): Сохранено
      * Аллокатор VRAM (CuMemAllocator): Сохранен
      * CUDA-Графы: Сохранены (избегая дорогостоящего re-capture 4)
      * JIT-скомпилированные Ядра: Сохранены (после первоначального прогрева 1)
Это напрямую отвечает на основной запрос MVP: да, технология выполняет свою заявленную функцию по сохранению JIT-кернелов и CUDA-графов.


2.1.4. Уровни "Сна" (Level 1 vs Level 2)


vLLM предоставляет два уровня "сна", оба из которых сохраняют вышеупомянутую CUDA-инфраструктуру 1:
      * Level 1 (L1): Выгружает веса модели в CPU RAM и сбрасывает KV-кэш. Это освобождает до 90%+ VRAM.7 Идеально для быстрого "сна" и "пробуждения" той же самой модели.
      * Level 2 (L2): Сбрасывает и веса модели, и KV-кэш. Используется для переключения на другую модель или для сценариев RLHF (Reinforcement Learning from Human Feedback), где веса модели будут обновлены перед пробуждением.7
Для целей MVP (быстрый теплый перезапуск) наиболее релевантен Level 1.
Таблица 1: Анализ Сохранения Состояния CUDA при Различных Типах Перезапуска


Компонент Состояния
	Холодный Старт (Cold Start)
	vLLM Sleep Mode (L1)
	vLLM Sleep Mode (L2)
	GPU Checkpoint (CRIU/cuda-checkpoint)
	Процесс / PID
	НОВЫЙ
	Сохранен
	Сохранен
	Сохранен (Восстановлен)
	Контекст CUDA
	НОВЫЙ
	Сохранен
	Сохранен
	Сохранен (Восстановлен)
	JIT-скомпилированные Ядра 1
	Перекомпиляция
	Сохранены
	Сохранены
	Сохранены (Восстановлены)
	CUDA-Графы 1
	Re-Capture
	Сохранены
	Сохранены
	Сохранены (Восстановлены)
	Веса Модели (VRAM)
	Загрузка с Диска
	Выгружены в CPU RAM 7
	Удалены 7
	Сохранены (Восстановлены)
	KV-Кэш (VRAM)
	НОВЫЙ
	Удален 7
	Удален 7
	Сохранены (Восстановлены)
	Эта таблица демонстрирует, что "Sleep Mode" является промежуточным решением: он сохраняет инфраструктуру (JIT/Графы), но не состояние (KV-Кэш). Это делает его идеальным для переключения моделей, но не для восстановления после сбоя (DR).


2.2. Критический Компромисс: Неизбежная Деградация Производительности в WSL2 (pin_memory=False)


Несмотря на функциональность "Sleep Mode", его производительность в WSL2 будет компрометирована из-за фундаментального ограничения архитектуры.


2.2.1. Обнаружение Проблемы


Многочисленные отчеты о проблемах 10 и анализ кода 10 указывают на то, что vLLM, будучи запущенным в WSL2, обнаруживает среду и принудительно выводит предупреждение:
WARNING... Using 'pin_memory=False' as WSL is detected. This may slow down the performance.


2.2.2. Анализ Первопричины


Это предупреждение — не просто информационное сообщение, а индикатор существенного узкого места в производительности.
      1. Для достижения максимальной пропускной способности при копировании данных между CPU и GPU (Host-to-Device, H2D, и Device-to-Host, D2H), фреймворки, такие как PyTorch, используют опцию pin_memory=True.12 Это выделяет "pinned" (page-locked) память на стороне CPU, которую GPU может считывать напрямую через DMA (Direct Memory Access), минуя оверхед пейджинга (подкачки) со стороны ОС.
      2. Однако официальная документация NVIDIA по CUDA на WSL (NVIDIA CUDA on WSL User Guide) явно указывает на ограничение: "Pinned system memory... availability for applications is limited" (Доступность pinned-памяти... ограничена).10
      3. Код vLLM (в vllm/utils.py) содержит явную проверку if in_wsl(): и принудительно возвращает False для функции is_pin_memory_available().10
Это не баг vLLM, который можно "исправить". Это осознанный обходной путь со стороны vLLM для фундаментального ограничения в архитектуре WSL2. vLLM вынужден использовать более медленную, "pageable" (страничную) память для всех трансферов CPU-GPU, что неизбежно снижает производительность I/O.


2.2.3. Последствия для PoC


Эта деградация затронет не только vLLM, но и все операции, требующие интенсивного обмена данными между CPU и GPU в WSL2. В контексте vLLM "Sleep Mode" (L1), это замедлит как выгрузку весов в CPU RAM при "засыпании", так и их загрузку обратно в VRAM при "пробуждении". Хотя этот "теплый" перезапуск все равно будет в 18-200 раз быстрее "холодного старта" 1, его абсолютное значение будет медленнее, чем "Sleep Mode" на bare-metal Linux.


2.2.4. Сопоставление с PagedAttention


Существует ирония в том, что vLLM использует PagedAttention — технологию, вдохновленную виртуальной памятью и пейджингом ОС — для высокоэффективного управления памятью внутри VRAM и устранения 60-80% потерь памяти.13 Однако, работая в WSL2, весь его I/O с хост-системой (CPU) будет "задушен" медленным, не-pinned (страничным) доступом к памяти, что является прямым следствием ограничений WSL.16


2.3. Риски Стабильности "Хрупкой" Архитектуры


"Sleep Mode" — относительно новая и экспериментальная функция, и ее использование на WSL2 сопряжено с дополнительными рисками стабильности.


2.3.1. Критический Баг: sleep + Data Parallelism = КРАХ


Отчет об ошибке 19 демонстрирует критический сценарий отказа. При запуске vLLM-сервера с VLLM_SERVER_DEV_MODE=1, --enable-sleep-mode и Data Parallelism (-dp 2), вызов API-метода /sleep приводит к немедленному краху vLLM-движка. Это делает MVP полностью несовместимым с любой конфигурацией, использующей Data Parallelism, до тех пор, пока этот баг не будет исправлен.


2.3.2. История Нестабильности Функции


Другие отчеты об ошибках, такие как 20 (где sleep был сломан на main ветке из-за AttributeError в PrometheusStatLogger20), показывают, что эта функция является экспериментальной и подвержена регрессиям. Асинхронный характер "сна" и "пробуждения" в сложных средах (например, RLHF) также может приводить к неожиданному поведению, например, к увеличению, а не уменьшению, потребления памяти.21


2.3.3. Общие Трудности Запуска vLLM на WSL2


Множество отчетов 22 указывают на общую "хрупкость" запуска vLLM на WSL2. Успешный запуск требует тщательного согласования версий драйверов NVIDIA (хоста Windows и тулкита в WSL), версии CUDA, и совместимости PyTorch. Установка vLLM на Ubuntu 24.04 (WSL2) с новейшими GPU (например, RTX 5090 с CUDA 13) сопряжена со значительными проблемами совместимости.23


2.4. Вердикт по Категории 1 (MVP)


      * Вердикт: ЖИЗНЕСПОСОБЕН, С ОГОВОРКАМИ.
      * Подтверждено: "vLLM Sleep Mode" функционален в WSL2 и успешно решает проблему "холодного старта", сохраняя JIT-ядра и CUDA-графы, как и требовалось.1
      * Оговорка 1 (Производительность): PoC должен принять как данность перманентную деградацию производительности I/O (H2D/D2H) из-за принудительного pin_memory=False, что является фундаментальным ограничением WSL2.10
      * Оговорка 2 (Стабильность): PoC не должен использовать Data Parallelism в сочетании с "Sleep Mode" из-за критического бага, приводящего к краху.19
      * Рекомендация: Провести бенчмарки "warm restart" (L1) против "cold start" непосредственно внутри WSL2, чтобы количественно оценить выигрыш несмотря на оверхед pin_memory.


РАЗДЕЛ II. ВАЛИДАЦИЯ "LOCAL-HA" (TREK 1): NVLINK И P2P В WSL2




3.1. Постановка Задачи: Требование cudaMemcpyPeerAsync


Трек "Local-HA" (High Availability) для multi-GPU конфигураций (например, для vLLM Tensor Parallelism 1 или PagedAttention в multi-GPU 24) критически зависит от прямого P2P (Peer-to-Peer) обмена данными между GPU.
Существует три иерархических пути для P2P-обмена:
      1. NVLink: Прямой, высокоскоростной интерконнект (лучший).
      2. PCIe P2P: Прямой обмен через шину PCIe (хороший).
      3. Fallback Path (Обходной путь): Копирование GPU1 -> CPU RAM -> GPU2 (крайне медленный, высокий оверхед).
Запрос на валидацию cudaMemcpyPeerAsync и p2pBandwidthLatencyTest 25 является прямым запросом на проверку жизнеспособности первых двух путей.


3.2. Инсайт "The Dog That Didn't Bark": Отсутствие NVLink в Документации


При анализе архитектуры был применен метод "The Dog That Didn't Bark" (собака, которая не лаяла) — поиск не того, что сказано, а того, о чем умалчивают в официальной документации.
      1. NVIDIA и Microsoft активно и совместно продвигают CUDA на WSL2.26 Они также анонсировали поддержку vGPU в WSL2 на Windows Server 2025.31 Это стратегически важные технологии.
      2. NVLink является флагманской технологией NVIDIA для multi-GPU HPC и AI, на которой строится значительная часть рыночной капитализации компании.
      3. Был проведен исчерпывающий анализ всей доступной технической документации NVIDIA (включая CUDA on WSL User Guide, релиз-ноуты драйверов 535/580, доки NIM) и Microsoft (доки по WSL, Hyper-V).26
      4. Результат: Слово "NVLink" полностью отсутствует в контексте WSL2.
В корпоративной документации такого уровня функции не "забывают". Если бы поддержка NVLink (даже в ограниченном режиме) существовала, она была бы главным маркетинговым и техническим аргументом. Ее полное отсутствие — это не недосмотр, а молчаливое, но однозначное подтверждение того, что поддержки NVLink в WSL2 нет.


3.3. Прямое Доказательство: Провал p2pBandwidthLatencyTest


В дополнение к отсутствию упоминаний, существует прямое доказательство того, что P2P-коммуникации не работают должным образом даже в идеальных условиях, что делает их работу в WSL2 невозможной.
Источник 25 является "дымящимся пистолетом". Пользователь на bare-metal Linux (не WSL) с двумя картами RTX 3090 (которые имеют NVLink-мост) запускает стандартный CUDA-тест p2pBandwidthLatencyTest.
      * Результат: nvidia-smi показывает, что NVLink-соединение присутствует, но тест P2P-пропускной способности проваливается с результатом <0.01 GB/s.
      * Интерпретация: Это классический "fallback path" (обходной путь). Драйвер CUDA видит возможность P2P, но P2P-соединение на уровне железа (NVLink или PCIe) не работает (вероятно, из-за настроек IOMMU или драйвера). Вместо того чтобы выдать ошибку, CUDA эмулирует P2P-обмен, используя медленный путь "GPU1 -> CPU RAM -> GPU2".
      * Применение к WSL2: Если это происходит на bare-metal Linux, то в виртуализированной среде WSL2, где гипервизор Hyper-V должен был бы виртуализировать и пробросить мост NVLink (чего он не делает), шансы на успех P2P-обмена на уровне железа равны нулю. Пользователи задавали вопросы о NVLink в WSL еще 3 года назад 39, но ответа так и не последовало.


3.4. Вердикт по Категории 2 (Local-HA)


      * Вердикт: НЕЖИЗНЕСПОСОБЕН.
      * Архитектура WSL2, основанная на Hyper-V 40, не предоставляет гостевой VM прямого P2P-доступа к оборудованию, такому как NVLink или прямое P2P-соединение по шине PCIe.
      * Любые multi-GPU операции (включая vLLM Tensor Parallelism и PagedAttention в multi-GPU 24) будут вынуждены использовать медленный, высоко-латентный, опосредованный через CPU путь. Это полностью нивелирует преимущества "Local-HA" и приведет к неприемлемой деградации производительности.
      * Рекомендация: Немедленно остановить R&D по "Треку 1 (Local-HA)" в его текущем виде на WSL2. Архитектура HA должна быть пересмотрена для работы на bare-metal Linux.


РАЗДЕЛ III. SOTA-АЛЬТЕРНАТИВЫ CRIU (DR-TREK) В СТРАТЕГИИ НА WINDOWS


Третий трек (Disaster Recovery) заключается в поиске SOTA-технологии (эквивалента "мертвого" CRIU) для чекпоинта VRAM CUDA-процесса, запущенного в WSL2.


4.1. Тупиковый Путь: Процесс-уровневый Чекпоинтинг (CRIU, cuda-checkpoint)


Первоначальный поиск был сосредоточен на технологиях чекпоинта на уровне процесса или контейнера. Этот путь является тупиковым.
      1. CRIU (Checkpoint/Restore In Userspace): Это технология, глубоко интегрированная с ядром Linux.42 Она не существует для Windows или Hyper-V.
      2. cuda-checkpoint (Ловушка): NVIDIA недавно выпустила утилиту cuda-checkpoint.43 Однако, cuda-checkpoint — это не полноценное решение. Это вспомогательная утилита.
      * Полный чекпоинт процесса требует сохранения состояния CPU (память, потоки, файловые дескрипторы) и состояния GPU (VRAM, контексты, MMU-маппинги).48
      * cuda-checkpoint 43 сохраняет только состояние GPU.
      * Он был разработан для работы в паре с CRIU, который сохраняет состояние CPU. Этот гибридный стек называется CRIUgpu.48
      * Вывод: Поскольку CRIU не работает на Windows, утилита cuda-checkpoint в данном PoC бесполезна. Она решает половину проблемы, для которой на Windows нет решения для второй половины.
      3. Docker Checkpoint: Функция docker checkpoint 52 является просто frontend'ом для CRIU. В Docker Desktop for Windows эта функция не поддерживается для GPU 53, так как WSL2 использует GPU-PV 53, а не CRIU.
Таблица 2: Сравнительный Анализ Технологий Чекпоинта VRAM в Контексте WSL2


Технология
	Основной Принцип
	Поддержка Windows
	Поддержка WSL2
	Сохранение VRAM
	Ключевая Зависимость
	CRIU 43
	Чекпоинт Процесса (CPU)
	Нет
	Нет (в хосте)
	Нет
	Ядро Linux
	NVIDIA cuda-checkpoint 43
	Чекпоинт Процесса (GPU)
	Нет
	Нет (в хосте)
	Да
	Ядро Linux, Драйвер 550+
	CRIUgpu 48
	Чекпоинт Процесса (CPU+GPU)
	Нет
	Нет (в хосте)
	Да
	CRIU + cuda-checkpoint
	Docker Checkpoint 52
	Чекпоинт Контейнера
	Нет (для GPU)
	Нет (для GPU)
	Нет
	CRIU (под капотом)
	Hyper-V GPU-PV 56
	Виртуализация (API-forwarding)
	Да
	Да (Это WSLg)
	Нет 57
	WDDM-драйвер
	Hyper-V Live Migration (с GPU-P)
	Миграция VM (SR-IOV)
	Да
	Да (Теоретически)
	Да
	Win Server 2025 + vGPU 18.0 58
	

4.2. Прорывной Путь: VM-уровневый Чекпоинтинг (Hyper-V Live Migration)


Запрос пользователя "Возможно, мы можем мигрировать всю WSL2 VM?" — это единственно верный путь. Поскольку WSL2 — это легковесная VM на Hyper-V 40, задача сводится к: "Может ли Hyper-V сделать чекпоинт/миграцию VM с включенным состоянием vGPU/VRAM?"


4.2.1. Анализ Технологий Виртуализации GPU в Hyper-V


До 2025 года ответ был "нет".
      * DDA (Discrete Device Assignment): Пробрасывает всю PCIe-карту в одну VM.60 Критически: чекпоинты и Live Migration не поддерживаются.61
      * GPU-PV (Paravirtualization): Это технология, которую использует WSLg (WSL GUI) и Docker Desktop.53 Она не использует SR-IOV. Документация 57 указывает, что чекпоинты (snapshots) не поддерживаются и должны быть отключены.
      * GPU-P (GPU Partitioning): Новая SOTA-технология (не путать с GPU-PV), использующая SR-IOV для создания аппаратных "партиций" GPU.58


4.2.2. SOTA-Прорыв (Windows Server 2025)


Прорыв произошел в начале 2025 года.
      1. Microsoft 58: Microsoft официально анонсирует: "Beginning with Windows Server 2025, live migration is supported with GPU partitioning". Это позволяет перемещать VM между хостами без даунтайма, сохраняя выделение GPU-ресурсов.
      2. NVIDIA 59: На форуме NVIDIA появляется подтверждение: релиз NVIDIA vGPU 18.0 (Март 2025) добавляет поддержку "Live migration support for GPU-P with Windows Server 2025".
      3. WSL2 31: NVIDIA также с vGPU 18.0 официально добавляет поддержку WSL2, работающего внутри vGPU-enabled Windows guest VM на Windows Server 2025.


4.2.3. Синтез и Новая Парадигма DR


Эти три анонса, взятые вместе, формируют SOTA-решение:
      1. CRIU (чекпоинт процесса) мертв для этого PoC.
      2. До 2025 года Hyper-V не поддерживал чекпоинт/миграцию VM с активным GPU.57
      3. В начале 2025 года Microsoft 58 и NVIDIA 59 совместно выпустили SOTA-технологию (GPU-P + vGPU 18.0) на Windows Server 2025, которая впервые позволяет Live Migration (горячую миграцию) VM с сохранением состояния VRAM.
      4. Вывод: "DR-Трек" пользователя жизнеспособен. Но он заключается не в создании локального чекпоинта (как CRIU), а в горячей миграции VM (содержащей WSL2 и vLLM) на другой хост Windows Server 2025 без остановки сервиса.


4.2.4. Риски и Требования SOTA-Пути


Этот путь не является простой заменой CRIU и требует значительных изменений в архитектуре PoC:
      * Инфраструктура: Требуется не Windows 11, а Windows Server 2025.58
      * Оборудование: Требуются GPU с поддержкой SR-IOV (например, NVIDIA A-series, H-series).58
      * Лицензирование: Требуются коммерческие лицензии NVIDIA vGPU 59, а не стандартный GeForce/Workstation драйвер.
      * Ограничение: 57 указывают, что даже при DDA/GPU-PV "чекпоинты" (snapshots) отключены. 58 говорит только о Live Migration. Это означает, что PoC, вероятно, сможет мигрировать (DR), но не создавать локальные снапшоты (как CRIU).


4.3. Вердикт по Категории 3 (DR-Track)


      * Вердикт: ЖИЗНЕСПОСОБЕН, НО ТРЕБУЕТ СМЕНЫ ПАРАДИГМЫ.
      * Поиск "эквивалента CRIU" на уровне процесса завершен: его не существует.
      * SOTA-решение — это Hyper-V Live Migration с GPU-P (SR-IOV). Это bleeding-edge технология 58, которая позволяет реализовать DR-сценарий (миграцию живой VM с VRAM) на кластере Windows Server 2025.
      * Рекомендация: Инициировать отдельный, высокоприоритетный PoC для валидации связки "Windows Server 2025 + NVIDIA vGPU 18.0 + GPU-P" для миграции VM (WSL2).


РАЗДЕЛ IV. СТРАТЕГИЧЕСКИЕ РЕКОМЕНДАЦИИ И ДАЛЬНЕЙШИЕ ДЕЙСТВИЯ ДЛЯ POC-13




5.1. Рекомендация по MVP (Категория 1): GO (С ОСТОРОЖНОСТЬЮ)


      * Действие: Продолжить PoC на Windows 11 / WSL2.
      * Обоснование: MVP жизнеспособен; "Sleep Mode" работает и сохраняет JIT/Графы, как и требовалось.1
      * Обязательные Задачи:
      1. Количественно измерить (забенчмаркать) оверхед I/O, вызванный pin_memory=False 10, сравнив "warm restart" (L1) в WSL2 с bare-metal Linux.
      2. Внедрить в PoC проверку, запрещающую запуск с --enable-sleep-mode и --data-parallel-size > 1 одновременно, чтобы избежать бага, приводящего к краху.19
      3. Использовать фиксированные, протестированные версии драйверов NVIDIA 18 и PyTorch 23 во избежание регрессий, связанных с "хрупкостью" стека.22


5.2. Рекомендация по Local-HA (Категория 2): NO-GO (ОСТАНОВИТЬ)


      * Действие: Немедленно остановить разработку по "Треку 1 (Local-HA)" на WSL2.
      * Обоснование: Фундаментальная предпосылка (доступность NVLink/P2P) неверна. Гипервизор не пробрасывает P2P-доступ, и тесты (даже на bare-metal) показывают падение производительности до обходного пути через CPU.25
      * Обязательные Задачи:
      1. Архитектурный комитет должен принять решение:
      * Вариант А: Отказаться от "Local-HA" на Windows и перенести multi-GPU PoC на bare-metal Linux.
      * Вариант Б: Принять массивную (вероятно, 10x-100x) деградацию multi-GPU производительности, используя медленный "fallback path" через CPU, что делает HA бессмысленным.


5.3. Рекомендация по DR-Track (Категория 3): PIVOT (НОВЫЙ POC)


      * Действие: Закрыть текущую задачу "поиск эквивалента CRIU". Открыть новую R&D-задачу: "Валидация Hyper-V Live Migration с GPU-P".
      * Обоснование: SOTA-решение найдено 58, но оно представляет собой полностью иную технологическую парадигму (миграция VM, а не чекпоинт процесса) и требует иного стека (Server 2025 + vGPU).
      * Обязательные Задачи:
      1. Выделить бюджет на закупку тестового стенда:
      * Серверы с поддержкой SR-IOV.
      * GPU с поддержкой SR-IOV (e.g., NVIDIA A-Series, H-Series).34
      * Лицензии Windows Server 2025.64
      * Лицензии NVIDIA vGPU.59
      2. Запустить выделенный PoC для ответа на один вопрос: "Удастся ли 'вживую' мигрировать VM с Windows Server 2025 (внутри которой работает WSL2 + vLLM) на другой хост без потери состояния VRAM?"
      3. Это и есть настоящий SOTA DR-Трек на 2025 год.
