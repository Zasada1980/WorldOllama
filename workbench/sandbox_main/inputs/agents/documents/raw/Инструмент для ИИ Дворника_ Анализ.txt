Интеллектуальная гигиена репозитория: архитектурный проект для агента-уборщика на базе ИИ




Часть I: Таксономия беспорядка в репозитории и фундаментальные методы очистки


Эта первая часть отчета закладывает всестороннее понимание проблемной области. Мы разберем концепцию «беспорядка в репозитории» на отдельные, поддающиеся анализу категории. Для каждой категории будет проведен углубленный анализ современного состояния детерминированных, не связанных с ИИ инструментов и методов обнаружения и устранения. Этот раздел служит основой, на которой будет построен наш интеллектуальный агент, предоставляя «инструменты», которыми он сможет оперировать.
________________


Глава 1: Обнаружение избыточности — дубликаты файлов и кода


В этой главе рассматривается наиболее очевидная форма беспорядка в репозитории: избыточность. Мы исследуем весь спектр дублирования, от простых файлов, идентичных байт в байт, до более тонкой проблемы структурно схожего, но текстуально различного исходного кода, часто называемой «запахом кода» (code smell).


1.1. Обнаружение бинарных дубликатов: алгоритмы и реализации


Обнаружение файлов, которые являются точными копиями друг друга, является фундаментальной задачей для поддержания гигиены репозитория. Эффективное решение этой задачи требует не простого сравнения, а многоступенчатого, оптимизированного по производительности подхода.
Многоступенчатая воронка фильтрации
Алгоритмический подход, используемый такими инструментами, как fdupes, представляет собой не простое сравнение хэшей, а оптимизированную по производительности воронку.1 Этот метод является образцом эффективности, поскольку он применяет серию проверок, упорядоченных по возрастанию их вычислительной стоимости. Такой архитектурный паттерн гарантирует, что дорогостоящие операции выполняются только для небольшого подмножества кандидатов, прошедших более дешевые начальные фильтры.
1. Сравнение размеров файлов: Это самая дешевая первоначальная проверка. Файлы разных размеров не могут быть дубликатами, что позволяет немедленно отбросить подавляющее большинство пар файлов без доступа к их содержимому.1
2. Сигнатура частичного хэша: На втором этапе вычисляется хэш только первых нескольких килобайт файла (например, MD5). Этот метод быстро отсеивает большинство оставшихся недубликатов, не требуя чтения всего содержимого крупных файлов, что значительно экономит ресурсы ввода-вывода.1
3. Полный хэш файла: Полный криптографический хэш (например, MD5) вычисляется только для тех файлов, которые прошли первые два этапа и имеют одинаковый размер и одинаковый частичный хэш.1
4. Побайтная верификация: В качестве последней, окончательной проверки для предотвращения коллизий хэшей (хотя и крайне редких для криптографических хэшей) выполняется прямое побайтовое сравнение содержимого файлов-кандидатов.1
Эта многоступенчатая, эскалирующая по стоимости фильтрация является фундаментальной концепцией, которую агент-уборщик ИИ должен применять не только к дубликатам, но и ко всем своим задачам анализа, чтобы обеспечить масштабируемость и производительность.
Современные реализации на высокопроизводительных языках
Современные инструменты, такие как czkawka, написанный на Rust, демонстрируют эволюцию в этой области.2 Переход от инструментов на интерпретируемых языках (например, FSlint на Python) к высокопроизводительным компилируемым языкам с безопасным управлением памятью (например, czkawka и fclones на Rust) является явной технологической тенденцией для системных утилит.2 Это говорит о том, что ядро обработки файлов агента-уборщика должно быть создано на языке вроде Rust для достижения максимальной производительности, в то время как компоненты ИИ/МО могут использовать экосистему Python.
Ключевые преимущества czkawka включают:
* Производительность и параллелизм: Использование Rust и активное применение многопоточности позволяют czkawka сканировать большие объемы данных значительно быстрее, чем его предшественники.3
* Безопасность памяти: Rust предотвращает целые классы ошибок, связанных с памятью, что критически важно для надежного системного инструмента.
* Богатый набор функций: Помимо простого поиска дубликатов, czkawka может находить пустые файлы/папки, большие файлы, поврежденные файлы и неверные символические ссылки, что делает его моделью для многофункционального инструмента.2
Поддержка кэширования для повышения эффективности
Критически важной функцией для повторных сканирований, реализованной в czkawka, является кэширование хэшей файлов.2 При последующих сканированиях в активном рабочем пространстве разработки необходимо пересчитывать хэши только для новых или измененных файлов. Это кардинально повышает производительность, так как большая часть файловой системы остается неизменной между сканированиями. Этот механизм должен быть неотъемлемой частью модуля обнаружения дубликатов в агенте-уборщике.


1.2. Дублирование исходного кода: взгляд с точки зрения «запахов кода»


Избыточность в репозиториях программного обеспечения часто выходит за рамки простых дубликатов файлов и проявляется в виде дублирования исходного кода. Это считается серьезным «запахом кода», поскольку усложняет сопровождение: исправление ошибки или изменение логики требует внесения правок во все скопированные экземпляры.
За пределами текстовой идентичности
Необходимо проводить различие между простым скопированным кодом и кодом, который является структурно схожим. Инструменты, основанные на хэшировании, здесь бессильны. Отличным примером более сложного подхода является Copy/Paste Detector (CPD), входящий в состав PMD.5 Его эволюция от алгоритма Greedy String Tiling к алгоритму сопоставления строк Карпа-Рабина подчеркивает сложность и зрелость этой области.5
Семантический анализ против лексического
Настоящая мощь инструментов, подобных CPD, заключается в опциях, позволяющих абстрагироваться от конкретных имен. Например, флаги --ignore-identifiers и --ignore-literals позволяют обнаруживать дублирующуюся логику, в которой были изменены только имена переменных, методов или классов.5 Это делает возможным выявление глубоко укоренившегося архитектурного дублирования, которое невозможно обнаружить методами, основанными на простом сравнении текста или хэшей. Эта возможность является критически важной для агента, который должен анализировать качество кода, а не только находить идентичные файлы.
Стратегии автоматизированного рефакторинга
Обнаружение дублирующегося кода — это лишь первый шаг. Логическим продолжением являются действия по его устранению. Существуют устоявшиеся шаблоны рефакторинга, такие как «Извлечение метода» (Extract Method), «Поднятие поля» (Pull Up Field) и «Извлечение суперкласса» (Extract Superclass), которые служат логическими «действиями», которые интеллектуальный агент мог бы предложить или даже выполнить после обнаружения таких «запахов кода».5 Интеграция этих знаний позволяет агенту не просто сообщать о проблеме, но и предлагать конкретное, обоснованное решение.


Таблица 1: Сравнительный анализ существующих утилит для очистки репозиториев


Чтобы обеспечить четкий, основанный на данных обзор текущего ландшафта инструментов и обосновать выбор конкретных технологий и алгоритмов для модулей агента-уборщика, ниже приведена сравнительная таблица. Эта таблица визуально подчеркивает функциональные пробелы в существующих инструментах. Например, ни один инструмент не преуспевает одновременно в обнаружении бинарных дубликатов (как czkawka) и структурного дублирования кода (как PMD). Этот анализ пробелов напрямую мотивирует необходимость создания нового, интегрированного инструмента, такого как агент-уборщик ИИ, который может объединить сильные стороны этих разрозненных утилит в единую интеллектуальную систему.
Характеристика
	czkawka / Krokiet
	fdupes
	FSlint
	DupeGuru
	Bleachbit
	PMD (CPD)
	Основная функция
	Поиск ненужных файлов
	Поиск дубликатов файлов
	Набор утилит для очистки
	Поиск дубликатов файлов
	Очистка системы
	Статический анализ кода
	Язык/Платформа
	Rust (кроссплатформенный)
	C (Linux/macOS)
	Python (Linux)
	Python/Obj-C (кроссплатформенный)
	Python (кроссплатформенный)
	Java (кроссплатформенный)
	Алгоритм поиска дубликатов
	Размер, хэш, побайтовое сравнение
	Размер, частичный/полный MD5, побайтовое сравнение
	Н/Д
	Н/Д
	Нет
	Нет
	Поиск похожих изображений/видео
	Да
	Нет
	Нет
	Да
	Нет
	Нет
	Очистка временных файлов
	Базовая
	Нет
	Да
	Нет
	Расширенная
	Нет
	Поиск битых ссылок
	Да
	Нет
	Да
	Нет
	Нет
	Нет
	Дублирование кода (структурное)
	Нет
	Нет
	Нет
	Нет
	Нет
	Да (Karp-Rabin)
	Поддержка кэша
	Да
	Да (опционально)
	Нет
	Да
	Нет
	Нет
	GUI/CLI
	GUI и CLI
	Только CLI
	GUI и CLI
	Только GUI
	GUI и CLI
	Только CLI
	Статус разработки
	Активная
	Активная
	Неактивная
	Неактивная*
	Активная
	Активная
	Источники:.1 Примечание: DupeGuru имел коммиты в 2024 году, но последний релиз был в 2023 году.2
________________


Глава 2: Выявление устаревания — заброшенные, неиспользуемые и разлагающиеся артефакты


В этой главе рассматривается более сложная и субъективная категория беспорядка: файлы, которые технически не являются поврежденными или дублированными, но со временем утратили свою актуальность. Обнаружение устаревания требует выхода за рамки простого анализа содержимого файлов и перехода в область исторического анализа репозитория.


2.1. Анализ истории коммитов на предмет неактивности


Базовые эвристики
Самым простым показателем устаревания является возраст. Можно использовать команду git log с настраиваемым форматированием для извлечения временной метки последнего коммита для каждого файла в репозитории.7 Сортировка файлов по дате их последнего изменения предоставляет первоначальный список потенциально устаревших файлов. Этот метод прост в реализации и дает быстрый, хотя и поверхностный, результат.
Навигация по упрощению истории
Критически важной технической деталью является то, что Git по умолчанию использует «упрощение истории», которое может скрывать релевантные коммиты, особенно те, что связаны со слияниями и отменами.8 Например, если изменения были внесены в ветке, которая затем была слита, а позже эти изменения были отменены другим слиянием, стандартный git log для файла может не показать промежуточные коммиты. Для точного и полного анализа необходимо использовать флаг --full-history. Это гарантирует, что инструмент не пропустит важные изменения файлов, произошедшие в сложных сценариях ветвления, и является обязательным требованием для надежного инструмента анализа.


2.2. Предиктивное моделирование распада кода


Устаревание — это не бинарное состояние, а спектр, который можно предсказать. Эволюция методов от git log (простая эвристика) до git-of-theseus (статистический анализ выживаемости) и «Git History Analyzer» (предиктивная модель МО) демонстрирует кривую зрелости для обнаружения устаревания. Агент-уборщик ИИ должен реализовывать всю эту кривую, предлагая различные уровни анализа. Пользователь может сначала спросить: «Какие файлы старые?» (ответ дает git log). Более искушенный пользователь спросит: «Какие части моего кода становятся нерелевантными?» (ответ дает git-of-theseus). Конечный вопрос: «Какие файлы, скорее всего, вызовут проблемы или потребуют рефакторинга в ближайшее время?» (ответ дает анализатор МО). Агент должен уметь отвечать на все три вопроса.
Количественный анализ выживаемости кода
Продвинутая концепция «анализа выживаемости кода», впервые реализованная в инструменте git-of-theseus, выходит за рамки простых дат последнего изменения.10 Эта методология анализирует всю историю, чтобы определить «период полураспада» кода из разных когорт (например, «код, написанный в 2022 году»). Она использует метод Каплана-Мейера для оценки кривой выживаемости. Генерируемый график выживаемости является мощной визуализацией здоровья репозитория и может предсказать, какие части кодовой базы «распадаются» (т. е. удаляются или подвергаются рефакторингу). Это позволяет выявлять не просто старые, а именно устаревающие компоненты.
Выявление горячих точек ошибок с помощью метрик изменчивости
Подход, используемый в GitHub Action «Git History Analyzer», представляет собой следующий шаг — от анализа к прогнозированию.11 Этот инструмент использует такие метрики, как частота коммитов и «изменчивость кода» (code churn) — как часто меняются определенные участки кода — в качестве признаков для модели машинного обучения. Эта модель предсказывает потенциальные «горячие точки» для ошибок и файлы, требующие рефакторинга. Это прямой мост от исторического анализа к действенному прогнозированию качества кода.


2.3. Удаление файлов из истории


Когда большие или конфиденциальные файлы определены как устаревшие, их необходимо удалить не только из текущей рабочей копии, но и из всей истории репозитория.
Современный стандарт: git-filter-repo
Для этой задачи git-filter-repo является современным стандартом.12 Он предназначен для эффективного и безопасного переписывания истории. Его основные сценарии использования включают:
* Удаление больших файлов для уменьшения размера репозитория.
* Вычищение конфиденциальных данных (паролей, ключей API).
* Реструктуризация репозитория, например, перемещение всего проекта в подкаталог.
Устаревание git-filter-branch
Важно отметить, что более старый инструмент git-filter-branch считается устаревшим.14 git-filter-repo является рекомендуемой заменой из-за его значительно более высокой скорости, более простого синтаксиса и улучшенных функций безопасности, таких как требование работы на свежем клоне для предотвращения случайных разрушительных изменений.13 Это критически важная деталь для создания надежного и безопасного инструмента.
Важность сборки мусора
Переписывание истории с помощью git-filter-repo только помечает старые объекты как недостижимые. Заключительным шагом для фактического освобождения дискового пространства является запуск сборки мусора Git с помощью команды git gc.15 Агент-уборщик ИИ должен включать этот шаг в свой рабочий процесс после любой операции по переписыванию истории. Существует критическая связь между аналитическими инструментами (которые безопасны и работают в режиме только для чтения) и исполнительными инструментами (которые могут быть разрушительными). Вывод анализа устаревания из git-of-theseus или модели МО является прямым входом для операции переписывания истории с помощью git-filter-repo. Агент ИИ является идеальным посредником для этого рабочего процесса, поскольку он может применять проверки безопасности, запрашивать подтверждение пользователя и управлять многоэтапным процессом (фильтрация, сборка мусора, принудительная отправка), который подвержен ошибкам при ручном выполнении.


Таблица 2: Методологии обнаружения устаревших файлов


Чтобы систематически сравнить различные подходы к выявлению устаревших и разлагающихся файлов, а также прояснить их компромиссы с точки зрения сложности, вычислительных затрат и глубины получаемых данных, в следующей таблице представлена их структурированная классификация. Эта таблица позволяет архитектору агента-уборщика увидеть, что это не конкурирующие, а взаимодополняющие методы, которые могут быть интегрированы в единую, многоуровневую систему анализа.
Методология
	Основной принцип
	Ключевые инструменты/команды
	Преимущества
	Недостатки
	Идеальный сценарий использования
	Анализ временной метки последнего изменения
	Файлы, которые не изменялись долгое время, вероятно, устарели.
	git log --format="%at %an %s" -- <file>
	Простота реализации, низкие вычислительные затраты.
	Не учитывает контекст; стабильный файл не обязательно устаревший.
	Быстрая первоначальная оценка для выявления "забытых" файлов.
	Анализ выживаемости кода (Каплан-Мейер)
	Статистический анализ того, как долго строки кода "выживают" в репозитории после их добавления.
	git-of-theseus
	Глубокое понимание "распада" кода, не зависит от абсолютного возраста.
	Высокие вычислительные затраты, требует анализа всей истории.
	Оценка общего состояния кодовой базы, выявление устаревающих модулей.
	Анализ изменчивости и частоты коммитов (на основе МО)
	Файлы с высокой исторической изменчивостью (churn) и частыми коммитами, которые затем были заброшены, являются кандидатами на устаревание или рефакторинг.
	Git History Analyzer (GitHub Action), пользовательские скрипты
	Предиктивный характер, может выявлять "горячие точки" ошибок.
	Требует обучающих данных, модель может быть непрозрачной ("черный ящик").
	Проактивное выявление рисков качества кода в CI/CD пайплайнах.
	Источники:.7
________________


Глава 3: Управление временными файлами и артефактами сборки


В этой главе основное внимание уделяется файлам, которые по своей природе являются эфемерными, но часто остаются в рабочем пространстве, создавая беспорядок. К ним относятся скомпилированные двоичные файлы, журналы, файлы пакетов и другие результаты процесса разработки и сборки.


3.1. Таксономия временных артефактов


Результаты систем сборки
Анализ конфигураций CI/CD из Bitbucket и GitLab позволяет выявить общие шаблоны.16 К ним относятся стандартные имена каталогов, такие как dist/, build/, target/, bin/, и шаблоны glob для файлов, такие как *.o, *.class, *.log, *.jar, *.pyc. Эти шаблоны являются сильными индикаторами временных файлов.
Управление артефактами в CI/CD
В контексте CI/CD «артефакты» — это файлы, созданные на одном этапе, которые используются на следующем или сохраняются для выпуска.16 Важно понимать их жизненный цикл. Облачные платформы часто имеют политику хранения (например, 14 дней в Bitbucket), что дает четкое представление о том, что можно считать временным.16 Определение «временного файла» сильно зависит от контекста и специфики проекта. Хотя существуют универсальные шаблоны, по-настоящему интеллектуальный агент должен изучать «сигнатуру артефактов» конкретного репозитория.
Локальный беспорядок при разработке
Помимо артефактов сборки, существует множество других временных файлов:
* Файлы резервных копий/подкачки редакторов (*~, *.swp).
* Файлы метаданных операционной системы (.DS_Store, Thumbs.db).
* Папки окружения, специфичные для языка (.venv/, node_modules/).


3.2. Стратегии обнаружения: от .gitignore до машинного обучения


Обнаружение на основе правил
Наиболее распространенным методом управления этими файлами является файл .gitignore. Файл .gitignore проекта является не просто списком игнорирования; это машиночитаемая спецификация шаблонов временных файлов проекта, созданная и поддерживаемая самими разработчиками. Он должен быть первым и самым надежным источником истины для агента-уборщика. Агент может использовать .gitignore как основной, высоконадежный источник информации о том, что следует считать временным или нерелевантным.
Контекстная классификация
Однако .gitignore часто бывает неполным. Более продвинутый подход заключается в использовании машинного обучения для классификации документов.19 Модель МО может быть обучена распознавать временные файлы на основе таких признаков, как шаблоны имен файлов, пути и, возможно, фрагменты содержимого. Это позволяет выявлять артефакты, которые не указаны явно в .gitignore. Это особенно полезно для репозиториев без хорошо поддерживаемых списков игнорирования. Вместо того чтобы начинать с нуля, модуль восприятия агента должен анализировать файл .gitignore. Это обеспечивает немедленный, высоконадежный набор правил. Роль модели МО тогда заключается в выявлении файлов, которые должны быть в .gitignore, но отсутствуют, превращая агента из простого уборщика в анализатор и помощника по сопровождению репозитория.
________________


Глава 4: Обеспечение целостности — неработающие символические ссылки и поврежденные файлы


В заключительной главе первой части рассматриваются файлы, которые не просто избыточны или устарели, а являются фундаментально поврежденными. Это напрямую влияет на удобство использования и целостность репозитория.


4.1. Обнаружение неработающих и циклических символических ссылок


Надежные системные утилиты
Для этой цели будет предоставлено исчерпывающее руководство по использованию команды find на основе синтеза лучших практик.21 Проверка целостности файлов — это задача чистой детерминированности. Нет никакой двусмысленности в том, указывает ли символическая ссылка на действительное местоположение или поврежден ли заголовок файла. Эти задачи идеально подходят для быстрого, основанного на правилах выполнения и не требуют сложного ИИ-рассуждения. Роль ИИ заключается не в том, чтобы решать, не работает ли ссылка, а в том, чтобы реагировать на отчет модуля целостности и включать этот факт в свой общий план очистки.
Различие между -xtype l и -L
Подчеркивается критическое различие между этими двумя флагами. -xtype l является правильной и безопасной опцией, поскольку она проверяет цель ссылки, не переходя по ней. В отличие от этого, -L заставляет find следовать по ссылкам, что опасно и неэффективно, так как ссылка, указывающая, например, на корневой каталог (/), может заставить инструмент сканировать всю файловую систему.21 Это критически важное соображение по безопасности и производительности для реализации агента. Безопасность в этом контексте означает ограничение области действия. Анализ флага -L в команде find выявляет критический принцип проектирования для любого инструмента, работающего с репозиторием: он ни при каких обстоятельствах не должен следовать по символическим ссылкам, ведущим за пределы корневого каталога репозитория. Это должно быть не подлежащим обсуждению архитектурным ограничением.
Вопросы переносимости
Следует отметить, что -xtype является расширением GNU и может отсутствовать в других системах, таких как macOS. Для таких систем будет предоставлена более переносимая, хотя и менее эффективная альтернатива: find. -type l! -exec test -e {} \;.22


4.2. Идентификация поврежденных и несоответствующих файлов


Анализ характеристик
В качестве отправной точки будет использована функция czkawka «Поврежденные файлы».2 Эта функциональность обычно включает использование библиотек, специфичных для формата файла, для попытки проанализировать файл и проверить, соответствует ли он ожидаемой структуре (например, проверка наличия действительных заголовков в файле JPEG или ZIP).
Несоответствие расширений
Связанная с этим функция, также присутствующая в czkawka, — это обнаружение неверных расширений, когда содержимое файла (определяемое по «магическим числам») не соответствует его расширению.2 Это может помочь найти файлы, которые были неправильно названы или загружены частично.
Предлагаемое расширение
Агент-уборщик ИИ может значительно расширить эту функциональность, интегрировав более широкий спектр библиотек для проверки форматов, превратившись в мощный инструмент для проверки состояния репозитория.


Часть II: Интеллектуальный уровень — архитектура агента-уборщика ИИ


Эта часть знаменует переход от анализа существующих инструментов к проектированию новой, интеллектуальной системы. Мы определим архитектуру агента-уборщика ИИ, опираясь на передовые исследования в области автономных агентов на базе больших языковых моделей (LLM) и предлагая гибридную модель, которая сочетает детерминированную логику с вероятностным машинным обучением.
________________


Глава 5: Агентная парадигма в автоматизированной инженерии программного обеспечения


Здесь мы вводим концептуальную основу для нашего агента, переходя от простой автоматизации к истинной автономии.


5.1. Архитектура современного ИИ-агента


Основные компоненты
Синтезируя результаты многочисленных обзоров по LLM-агентам, можно определить каноническую архитектуру.24 Агент — это не сама LLM, а система, построенная вокруг нее. Ключевые компоненты:
1. Ядро рассуждений (LLM): «Мозг» агента, отвечающий за понимание целей, планирование и принятие решений.
2. Модуль восприятия (Perception): «Органы чувств» агента. Этот модуль собирает контекст, взаимодействуя с окружением (например, читая содержимое файлов, выполняя git log, запуская средства проверки типов файлов).
3. Модуль действий (Action): «Руки» агента. Этот модуль выполняет команды в окружении (например, вызывая rm, git-filter-repo или другие инструменты). Он преобразует решения LLM в конкретные операции.
4. Модуль памяти (Memory): Обеспечивает агенту контекст и способность к обучению. Включает краткосрочную память (история текущей задачи) и долгосрочную память (знания из прошлых запусков, специфичные для репозитория).
5. Модуль планирования (Planner): Разбивает высокоуровневую цель (например, «очистить репозиторий») на последовательность конкретных шагов (например, «1. Просканировать на наличие дубликатов. 2. Проанализировать историю коммитов на предмет файлов старше 2 лет. 3. Предложить план удаления.»).


5.2. Рабочий процесс агента: цикл выполнения


Целеориентированная, многошаговая операция
В отличие от традиционного скрипта, который выполняет фиксированную последовательность действий, агент работает в цикле 24:
1. Наблюдение (Observe): Использовать модуль восприятия для сбора информации о состоянии.
2. Размышление (Think): Передать наблюдение и общую цель в ядро рассуждений LLM для принятия решения о следующем наилучшем действии.
3. Действие (Act): Использовать модуль действий для выполнения выбранного действия.
4. Повторение: Цикл продолжается до тех пор, пока цель не будет достигнута или не будет выполнено условие остановки.
Интеграция инструментов
Ключевой характеристикой современных агентов является их способность использовать внешние инструменты.24 Агент-уборщик ИИ не будет заново реализовывать поиск дубликатов; он будет вызывать инструмент, подобный czkawka. Его интеллект заключается в том, чтобы знать, какой инструмент вызвать, когда его вызвать и как интерпретировать его вывод. Агент-уборщик ИИ должен быть спроектирован не как единое монолитное приложение, а как оркестратор. Его основная роль — интеллектуально управлять и синтезировать выводы специализированных, высокопроизводительных инструментов, проанализированных в Части I. Исследования LLM-агентов постоянно подчеркивают использование инструментов. LLM хорошо справляется с рассуждениями, но не с хэшированием файлов со скоростью 10 ГБ/с. Инструмент, подобный czkawka, отлично хэширует файлы, но не имеет представления об «устаревании». Таким образом, оптимальная архитектура является симбиотической: «Ядро рассуждений», которое управляет набором «Специализированных инструментов». Этот модульный дизайн более эффективен, масштабируем и удобен в сопровождении.
Переход к агентной парадигме переопределяет модель взаимодействия с пользователем с императивной («удали этот файл») на декларативную («убедись, что репозиторий чист в соответствии с политикой X»). Это фундаментальное изменение в пользовательском опыте. Традиционный инструмент требует, чтобы пользователь указывал каждое действие. Агент, как описано в 25 и 31, принимает высокоуровневую цель. Пользователь не говорит уборщику, как найти устаревшие файлы; он сообщает ему определение устаревания для своего проекта (например, «любой файл, не являющийся документацией, не изменявшийся в течение 3 лет с низкой изменчивостью кода»), и агент сам определяет необходимые команды git и анализ для достижения этой цели.
________________


Глава 6: Гибридная интеллектуальная модель для очистки кода


В этой главе предлагается основная интеллектуальная собственность агента-уборщика ИИ: гибридный подход, который сочетает предсказуемость правил с адаптивностью машинного обучения.


6.1. Ограничения чисто-правиловой системы


Хотя правила отлично подходят для детерминированных проблем (например, точные дубликаты, неработающие ссылки), они не справляются с двусмысленностью и контекстной зависимостью (например, «важен ли этот лог-файл?» или «этот старый служебный скрипт устарел или просто стабилен?»).


6.2. Сила нейросимволического подхода


Сочетание сильных сторон
Вводится концепция нейросимволического ИИ, которая объединяет логику на основе правил (символическую) с моделями машинного обучения (нейронными).35 Оптимальная интеллектуальная архитектура для этой проблемы — это система «триажа». Агент сначала применяет дешевые, детерминированные правила для обработки простых случаев, а затем использует дорогостоящие, вероятностные модели МО только для оставшихся, неоднозначных случаев.
Предлагаемая гибридная модель:
1. Первый проход на основе правил: Для задач с четкими, недвусмысленными определениями (точные дубликаты, неработающие символические ссылки, файлы в .gitignore) агент будет использовать быстрые, детерминированные модули, основанные на инструментах из Части I. Это обеспечивает базовый уровень высоконадежных находок.
2. Второй проход с использованием МО: Для неоднозначных задач агент будет вызывать модели МО. Это включает:
   * Классификатор файлов 19, обученный выявлять специфичные для проекта временные файлы и артефакты, не указанные в .gitignore.
   * Предиктор устаревания (вдохновленный 11), который использует исторические метрики (изменчивость, частота коммитов, возраст, кривые выживаемости) для присвоения каждому файлу «оценки устаревания».
   * Детектор «запахов кода» 36 для выявления структурно дублированного кода.
Очистка данных для МО
Критически важным моментом является то, что правила могут использоваться для очистки и подготовки данных для моделей МО, создавая добродетельный цикл.35 Например, агент может использовать правила для исключения бинарных файлов перед подачей исходного кода в детектор «запахов кода». Эффективность агента будет прямо пропорциональна его способности учиться на конкретном контексте репозитория и отзывах пользователя. Когда он предлагает удалить temp.log, а пользователь говорит «нет», агент должен сохранить эту информацию в своей долгосрочной памяти ((repository_X, file_pattern='temp.log', action='keep')) и использовать ее для уточнения своих правил или дообучения локальной модели МО для этого конкретного репозитория. Это превращает инструмент из статического анализатора в постоянно обучающегося партнера.
________________


Глава 7: Предлагаемая многомодульная архитектура для агента-уборщика


В этой главе представлен конкретный архитектурный проект для агента-уборщика ИИ, подробно описывающий его компоненты и их взаимодействие.


7.1. Высокоуровневая диаграмма системы


Будет представлена диаграмма, показывающая центральное ReasoningCore (Ядро рассуждений), взаимодействующее с набором периферийных модулей и внешней средой (файловая система, Git). Модульная, основанная на инструментах архитектура превосходит монолитный дизайн. Она позволяет независимую разработку, тестирование и обновление компонентов. Ядро хэширования файлов может быть оптимизировано на Rust, не затрагивая модель МО на Python.


7.2. Ядро рассуждений (Reasoning Core)


* Оркестратор на базе LLM: Это центральный цикл агента, обсуждавшийся в Главе 5. Он получает цели и политики из конфигурации пользователя.
* Движок политик: Интерпретирует определенные пользователем правила (например, obsolescence_threshold: 2 years, auto_delete_level: recycle_bin_only).
* Планировщик: Разбивает задачи очистки на подзадачи и направляет их в соответствующие модули.


7.3. Специализированные модули («Инструменты»)


Будет определен набор модулей, каждый из которых инкапсулирует определенную функциональность, вероятно, реализованную как отдельные, высокопроизводительные исполняемые файлы или библиотеки. Этот дизайн вдохновлен философией Unix «простые части, которые работают вместе» 39 и шаблоном проектирования «Команда» (Command).40 Связь между ReasoningCore и специализированными модулями должна осуществляться через структурированный, машиночитаемый формат, такой как JSON или Protobuf, а не простой текст. Это обеспечивает надежный парсинг результатов и принятие обоснованных решений.


Таблица 3: Спецификация модулей агента-уборщика ИИ


Эта таблица служит основным архитектурным проектом, определяя обязанности и технологии каждого компонента в системе. Она преобразует высокоуровневые архитектурные концепции из Глав 5 и 6 в конкретную, реализуемую спецификацию и четко определяет границы и интерфейсы между компонентами, что необходимо для параллельной разработки и обеспечения разделения ответственности.
Имя модуля
	Основная функция
	Основная технология
	Ключевые входы
	Ключевые выходы (схема данных)
	Взаимодействие с ядром рассуждений
	PerceptionModule
	Сбор информации о состоянии репозитория.
	Набор системных утилит и парсеров.
	Путь к репозиторию, конфигурация сканирования.
	JSON-объект с состоянием файловой системы, историей Git.
	Предоставляет контекст для принятия решений.
	ActionModule
	Выполнение команд в файловой системе и Git.
	Оболочка для безопасного выполнения команд.
	Команда (например, delete, rewrite_history), параметры.
	Статус выполнения (успех/неудача), журналы.
	Выполняет действия, запланированные ядром.
	MemoryModule
	Хранение краткосрочного и долгосрочного контекста.
	Встроенная БД (например, SQLite), векторная БД.
	Данные для сохранения (например, пользовательские предпочтения).
	Запрошенные данные из памяти.
	Сохраняет и извлекает знания для улучшения будущих решений.
	DuplicateDetectionModule
	Обнаружение бинарных и текстовых дубликатов.
	Правила (многоступенчатая фильтрация).
	Пути для сканирования, параметры кэша.
	JSON: {"duplicate_sets": [...]}.
	Предоставляет отчет о дубликатах для планирования.
	ObsolescenceAnalysisModule
	Анализ устаревания и распада кода.
	Гибрид (правила + МО).
	Глубина истории, пороги устаревания.
	JSON: {"files": [{"path":..., "obsolescence_score":...}]}.
	Предоставляет оценки устаревания для планирования.
	ArtifactClassificationModule
	Классификация временных файлов и артефактов.
	Гибрид (правила из .gitignore + МО).
	Пути для сканирования.
	JSON: {"artifacts": [{"path":..., "reason":...}]}.
	Идентифицирует временные файлы для удаления.
	IntegrityCheckModule
	Проверка на наличие неработающих ссылок и поврежденных файлов.
	Правила (системные утилиты, валидаторы форматов).
	Пути для сканирования.
	JSON: {"broken_links": [...], "corrupted_files": [...]}.
	Сообщает о проблемах целостности для исправления.
	

Часть III: Стратегия реализации и эксплуатационные гарантии


Эта заключительная часть предоставляет действенные рекомендации по созданию и эксплуатации агента-уборщика ИИ с неизменным акцентом на доверие пользователя, безопасность и контроль. Агент, обладающий полномочиями удалять файлы и переписывать историю, должен быть спроектирован с безопасностью в качестве основного, нефункционального требования.
________________


Глава 8: Взаимодействие и контроль — человеко-ориентированный интерфейс командной строки


Мощь агента должна быть доступной и контролируемой. Мы применим устоявшиеся принципы проектирования CLI для создания интерфейса, который будет одновременно мощным для автоматизации и интуитивно понятным для интерактивного использования.


8.1. Применение основных принципов проектирования CLI


* Человеко-ориентированный дизайн: Вывод агента должен быть ясным и информативным, никогда не оставляя пользователя в неведении относительно того, что он делает.39 Подробное журналирование, индикаторы выполнения и четкие сводки являются обязательными.
* Компонуемость: Агент должен быть пригоден для написания скриптов. Он должен принимать структурированный ввод (например, файл политики в формате YAML) и производить структурированный вывод (например, отчет в формате JSON о предлагаемых действиях), что позволяет интегрировать его в более крупные конвейеры CI/CD.39
* Согласованность: Структура команд должна быть предсказуемой, следуя соглашениям, таким как agent <глагол> <существительное> (например, janitor analyze duplicates, janitor execute plan). Критически важны подкоманды с собственными справочными сообщениями.41
Пользовательский интерфейс является механизмом безопасности. Запутанный или непрозрачный CLI приведет к ошибке пользователя и катастрофической потере данных. Принципы хорошего дизайна CLI — это не эстетические предложения; они являются основополагающими для создания надежного автономного инструмента.


8.2. Система конфигурации и политик


Будет предложена иерархическая система конфигурации (например, с использованием файла YAML), которая позволяет пользователям определять поведение агента с высокой степенью детализации.
* Политики: Пользователи будут определять, что представляет собой беспорядок для их проекта (например, шаблоны файлов, пороги возраста, оценки устаревания).
* Уровни автономии: Пользователи будут устанавливать уровень автономии агента, от чисто консультативного («только отчет») до полуавтономного («требовать подтверждения для каждого действия») и полностью автономного («выполнять план автоматически», для использования в доверенных средах CI).
________________


Глава 9: Приоритет безопасности — предварительный просмотр, обратимость и доверие


В этой главе подробно описаны не подлежащие обсуждению функции безопасности, которые должны быть встроены в архитектуру агента с самого первого дня. Доверие пользователя — это самый важный показатель для агента. Оно зарабатывается не хитростью его ИИ, а надежностью его функций безопасности и ясностью его коммуникации.


9.1. «Пробный запуск» как режим по умолчанию


Основным режимом выполнения агента должен быть режим «пробного запуска» или «предварительного просмотра». В этом режиме он будет выполнять полный анализ и генерировать подробный план предлагаемых действий (например, «УДАЛИТЬ: a.txt (дубликат b.txt)», «ПЕРЕМЕСТИТЬ_В_КАРАНТИН: old_script.py (оценка устаревания: 0.92)»). Этот план затем представляется пользователю для утверждения. Никаких изменений в файловой системе не производится.


9.2. Обратимость через карантин


Шаблон «Корзины»
Вдохновленный такими инструментами, как File Juggler, стандартным действием «удалить» должно быть не перманентное rm, а перемещение файлов в специальный, помеченный временной меткой каталог карантина (например, .janitor_quarantine/2024-10-27_15-30-00/).42 Это делает случайные удаления полностью обратимыми. Этот подход смещает цену ошибки агента с «необратимой потери данных» на «незначительное неудобство восстановления файла».
Перманентное удаление с высоким порогом
Перманентное удаление должно быть явным, опциональным действием, требующим специального флага (например, --force-permanent-delete) и, возможно, даже интерактивного подтверждения.


9.3. Безопасное удаление для чувствительных сред


Для конкретных случаев использования, требующих этого, агент может включать возможности безопасного удаления. Будет объяснена разница между простым удалением и безопасной перезаписью 43, со ссылкой на методы, используемые такими инструментами, как SDelete (стандарт DOD 5220.22-M) и Eraser.43 Эта функциональность должна быть четко помечена как необратимая и опасная.
Операционные режимы агента должны напрямую соответствовать уровням доверия пользователя. Новый пользователь начнет с режима «только отчет». По мере того как он видит, что агент делает хорошие предложения, он может перейти в режим «подтверждать каждое действие». Только в полностью доверенной, автоматизированной среде CI/CD пользователь включит полностью автономный режим. Архитектура должна поддерживать эту градуированную модель доверия.


Заключение и рекомендации


Этот отчет представляет собой архитектурный проект для создания интеллектуального агента-уборщика, предназначенного для автоматизации гигиены репозиториев программного обеспечения. Анализ существующего ландшафта инструментов выявил значительные пробелы: ни один существующий инструмент не объединяет в себе возможности по очистке бинарных дубликатов, анализу структурных «запахов кода», предиктивному выявлению устаревания и управлению временными артефактами в рамках единой, интеллектуальной системы.
Предлагаемая архитектура решает эту проблему путем внедрения гибридной интеллектуальной модели и модульной, основанной на инструментах, структуры. Ключевые выводы и рекомендации для разработки таковы:
1. Принять модульный подход «оркестратора»: Агент не должен быть монолитом. Его ядро рассуждений на базе LLM должно выступать в роли оркестратора, вызывая специализированные, высокопроизводительные модули (инструменты) для выполнения конкретных задач. Это повышает производительность, ремонтопригодность и позволяет использовать лучшие в своем классе технологии для каждой задачи (например, Rust для операций ввода-вывода, Python для МО).
2. Реализовать гибридную модель «триажа»: Для обеспечения эффективности и точности агент должен использовать многоуровневый подход к анализу. Быстрые, детерминированные правила должны применяться в первую очередь для решения однозначных задач (неработающие ссылки, точные дубликаты). Более ресурсоемкие, вероятностные модели МО должны использоваться для решения неоднозначных задач (классификация артефактов, прогнозирование устаревания).
3. Сделать безопасность основой дизайна: Доверие пользователя является главным приоритетом. Функции, такие как «пробный запуск» по умолчанию, перемещение в карантин вместо необратимого удаления и градуированные уровни автономии, не являются опциональными дополнениями, а должны быть заложены в ядро архитектуры с самого начала. Пользовательский интерфейс, особенно CLI, должен быть спроектирован как основной механизм обеспечения безопасности, обеспечивая ясность, предсказуемость и контроль.
4. Обеспечить контекстную адаптацию и обучение: Агент должен выйти за рамки статического анализа. Через модуль памяти и механизмы обратной связи он должен учиться на специфике каждого репозитория и предпочтениях пользователя. Использование .gitignore в качестве начального набора правил и последующее его дополнение с помощью МО является ярким примером этого принципа.
Реализация агента-уборщика ИИ на основе этих принципов позволит создать не просто утилиту, а интеллектуального партнера для разработчиков, который проактивно поддерживает чистоту, качество и удобство сопровождения кодовой базы, тем самым снижая технический долг и повышая общую производительность команды.
