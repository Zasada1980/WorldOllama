# üß† AI Knowledge Library

**–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è AI –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LightRAG GraphRAG**

Plug-and-play —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –≥–æ—Ç–æ–≤—ã–º–∏ –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–∞–º–∏ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –ª—é–±–æ–π AI –ø—Ä–æ–µ–∫—Ç –∑–∞ **3 –º–∏–Ω—É—Ç—ã**.

## ‚ú® –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- üìä **377+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤** –ø–æ AI/ML —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ (96.7% –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è)
- üï∏Ô∏è **Graph RAG**: 3.7 MB –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π + 27.7 MB –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î —Å—É—â–Ω–æ—Å—Ç–µ–π
- üîå **–ì–æ—Ç–æ–≤—ã–µ SDK**: Python –∏ TypeScript –∫–ª–∏–µ–Ω—Ç—ã
- üöÄ **REST API**: –ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ HTTP
- ü§ñ **Multi-agent ready**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ AGENTS —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ

## üöÄ Quick Start (3 –º–∏–Ω—É—Ç—ã)

### –í–∞—Ä–∏–∞–Ω—Ç 1: Python SDK (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# 1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª–∏–µ–Ω—Ç –≤ —Å–≤–æ–π –ø—Ä–æ–µ–∫—Ç
curl -O https://raw.githubusercontent.com/Zasada1980/PRICE_PC/main/connector/python/library_client.py

# 2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ –∫–æ–¥–µ
```

```python
from library_client import KnowledgeLibrary

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
library = KnowledgeLibrary("http://localhost:8003")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
if library.health_check():
    print("‚úÖ –°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω")

# –ó–∞–ø—Ä–æ—Å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
result = library.query(
    query="–ß—Ç–æ —Ç–∞–∫–æ–µ –¢–†–ò–ó? –†–∞—Å—Å–∫–∞–∂–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã",
    mode="hybrid"  # naive, local, global, hybrid
)
print(result['response'])

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
status = library.get_status()
print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {status['processed']}/{status['total_docs']}")
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: TypeScript SDK

```bash
# 1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª–∏–µ–Ω—Ç
curl -O https://raw.githubusercontent.com/Zasada1980/PRICE_PC/main/connector/typescript/library-client.ts

# 2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ
```

```typescript
import { KnowledgeLibraryClient } from './library-client';

const library = new KnowledgeLibraryClient("http://localhost:8003");

// –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
await library.healthCheck();

// –ó–∞–ø—Ä–æ—Å
const result = await library.query(
  "–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ LangGraph",
  "hybrid"
);
console.log(result.response);
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: –ü—Ä—è–º–æ–π REST API

```bash
# –ó–∞–ø—Ä–æ—Å –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
curl -X POST http://localhost:8003/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç LightRAG?",
    "mode": "hybrid"
  }'

# –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
curl http://localhost:8003/status

# Health check
curl http://localhost:8003/health
```

## üìö –†–µ–∂–∏–º—ã –ø–æ–∏—Å–∫–∞

| –†–µ–∂–∏–º | –û–ø–∏—Å–∞–Ω–∏–µ | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ |
|-------|----------|----------|----------|---------------|
| **`naive`** | –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ embedding | ‚ö° –ë—ã—Å—Ç—Ä–æ | ‚≠ê‚≠ê‚≠ê | –ü—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã |
| **`local`** | –õ–æ–∫–∞–ª—å–Ω—ã–π –≥—Ä–∞—Ñ (—Å—É—â–Ω–æ—Å—Ç–∏ + –æ–∫—Ä—É–∂–µ–Ω–∏–µ) | üî• –°—Ä–µ–¥–Ω–µ | ‚≠ê‚≠ê‚≠ê‚≠ê | –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã |
| **`global`** | –ì–ª–æ–±–∞–ª—å–Ω—ã–π –≥—Ä–∞—Ñ (—à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç) | üêå –ú–µ–¥–ª–µ–Ω–Ω–æ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –°–ª–æ–∂–Ω—ã–µ —Å–≤—è–∑–∏ |
| **`hybrid`** | –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤ | üî• –°—Ä–µ–¥–Ω–µ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è ‚ú®** |

## üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```
ai-knowledge-library/
‚îú‚îÄ‚îÄ documents/              # 377+ –∏—Å—Ö–æ–¥–Ω—ã—Ö .txt —Ñ–∞–π–ª–æ–≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
‚îú‚îÄ‚îÄ connector/              # SDK –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ python/             # Python –∫–ª–∏–µ–Ω—Ç (library_client.py)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ library_client.py
‚îÇ   ‚îî‚îÄ‚îÄ typescript/         # TypeScript –∫–ª–∏–µ–Ω—Ç (library-client.ts)
‚îÇ       ‚îî‚îÄ‚îÄ library-client.ts
‚îú‚îÄ‚îÄ graph/                  # –≠–∫—Å–ø–æ—Ä—Ç –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π (3.7 MB)
‚îÇ   ‚îî‚îÄ‚îÄ knowledge_graph.graphml
‚îú‚îÄ‚îÄ tools/                  # –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º
‚îÇ   ‚îî‚îÄ‚îÄ sync_documents.ps1  # Auto-sync Documents ‚Üí GitHub
‚îî‚îÄ‚îÄ api/                    # OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è REST API
    ‚îî‚îÄ‚îÄ openapi.yaml
```

## üìñ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

**377 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤** (96.7% –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è, 13 failed) –ø–æ AI/ML —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ:

### –¢–µ–º–∞—Ç–∏–∫–∏:
- ü§ñ **AI Frameworks**: LangGraph, CrewAI, LightRAG, Autogen
- üí¨ **LLM Engineering**: –ü—Ä–æ–º–ø—Ç-–∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥, —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã, RAG –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- üß† **–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏**: –¢–†–ò–ó –¥–ª—è AI —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, Agent Design Patterns
- üåê **Real-time**: WebSocket streaming, SSE, async –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- üê≥ **DevOps**: Docker, DevContainers, CI/CD –¥–ª—è AI –ø—Ä–æ–µ–∫—Ç–æ–≤
- üéÆ **GPU**: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è VRAM, overclocking, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (RTX 5060 Ti 16GB)
- üìä **Data Processing**: Parsing, scoring, database optimization
- üîß **Tools**: Ollama, Open WebUI, LightRAG server setup

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π:
- **graph_chunk_entity_relation.graphml**: 3.7 MB (3792 KB)
- **vdb_entities.json**: 27.7 MB (28364 KB) ‚Äî –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î —Å—É—â–Ω–æ—Å—Ç–µ–π
- **kv_store_full_docs.json**: 5.5 MB ‚Äî –ø–æ–ª–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- **–°—Ä–µ–¥–Ω–µ–µ**: 2.61 sub-chunks –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç (max 3)

## üîå –ü—Ä–∏–º–µ—Ä—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Open WebUI (Tool)

–°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π Tool –≤ Open WebUI ‚Üí Settings ‚Üí Tools:

```python
import requests

def search_knowledge_library(query: str, mode: str = "hybrid") -> str:
    """
    –ü–æ–∏—Å–∫ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∑–Ω–∞–Ω–∏–π AI –∞–≥–µ–Ω—Ç–æ–≤
    
    :param query: –í–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
    :param mode: naive/local/global/hybrid (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é hybrid)
    :return: –û—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    """
    response = requests.post(
        "http://localhost:8003/query",
        json={"query": query, "mode": mode},
        timeout=60
    )
    return response.json()["response"]
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ChatGPT (Custom GPT)

**Instructions:**
```
You have access to AI Knowledge Library ‚Äî knowledge graph with 377 documents about AI/ML development.

Use this API to answer questions:
- POST http://your-public-url:8003/query
- Body: {"query": "...", "mode": "hybrid"}
- Always use "hybrid" mode for best results
```

**Actions schema:**
```json
{
  "openapi": "3.0.0",
  "info": {"title": "AI Knowledge Library", "version": "1.0.0"},
  "servers": [{"url": "http://your-server:8003"}],
  "paths": {
    "/query": {
      "post": {
        "operationId": "queryKnowledge",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "type": "object",
                "properties": {
                  "query": {"type": "string"},
                  "mode": {"type": "string", "enum": ["hybrid"]}
                }
              }
            }
          }
        }
      }
    }
  }
}
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CrewAI Agent

```python
from crewai import Agent, Task, Crew
from library_client import KnowledgeLibrary

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
library = KnowledgeLibrary("http://localhost:8003")

# –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
researcher = Agent(
    role="AI Research Specialist",
    goal="Find answers in centralized knowledge library",
    backstory="Expert in AI/ML with access to 377+ documents",
    tools=[
        lambda query: library.query(query, mode="hybrid")
    ]
)

# –ó–∞–¥–∞—á–∞
task = Task(
    description="–ù–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¢–†–ò–ó –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ AI —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
    agent=researcher
)

crew = Crew(agents=[researcher], tasks=[task])
result = crew.kickoff()
```

## üöß Roadmap

- [x] ‚úÖ –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
- [x] ‚úÖ LightRAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (377/390 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, 96.7%)
- [x] ‚úÖ Python SDK (`library_client.py`)
- [x] ‚úÖ TypeScript SDK (`library-client.ts`)
- [x] ‚úÖ Auto-sync —Å–∫—Ä–∏–ø—Ç (`sync_documents.ps1`)
- [ ] üîÑ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è (`api/openapi.yaml`)
- [ ] üîÑ GitHub Pages –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [ ] üîÑ Open WebUI Tool template
- [ ] üîÑ Export –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π ‚Üí `graph/knowledge_graph.graphml`
- [ ] üîÑ Docker Compose –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–µ–ø–ª–æ—è —Å–µ—Ä–≤–µ—Ä–∞
- [ ] üîÑ –ü—Ä–∏–º–µ—Ä—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–ª—è: Claude Projects, Google Gemini, LangChain
- [ ] üîÑ Smart Reindexing —Å qwen2.5-4k (num_ctx=4096)
- [ ] üîÑ GPU Overclock Profile (+2500 MHz Memory Clock)

## üõ†Ô∏è Deployment

### –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä (—É–∂–µ –∑–∞–ø—É—â–µ–Ω)

```powershell
# –ó–∞–ø—É—Å–∫ LightRAG —Å–µ—Ä–≤–µ—Ä–∞
cd E:\AI_Librarian_Core
python lightrag_server.py

# –°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω: http://localhost:8003
# Health check: curl http://localhost:8003/health
```

### Docker (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)

```bash
docker-compose up -d
# –°–µ—Ä–≤–µ—Ä: http://localhost:8003
```

## ‚öôÔ∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –í–µ—Ä—Å–∏—è/–ú–æ–¥–µ–ª—å |
|-----------|-----------|---------------|
| **GraphRAG** | LightRAG | Latest |
| **LLM** | Ollama + qwen2.5 | 14b-instruct-q4_k_m |
| **Embeddings** | nomic-embed-text | Latest |
| **API Server** | FastAPI | Python 3.11+ |
| **GPU** | RTX 5060 Ti 16GB | MSI Gaming OC |
| **SDK** | Python + TypeScript | Requests + Fetch API |

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

## ü§ù –ö–æ–Ω—Ç–∞–∫—Ç—ã

–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–∑–¥–∞–Ω –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–≤ –≤ multi-agent —Å–∏—Å—Ç–µ–º–∞—Ö.

---

**Powered by:** LightRAG + Ollama + RTX 5060 Ti 16GB
