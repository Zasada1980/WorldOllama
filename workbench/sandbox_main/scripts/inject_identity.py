"""
SESA MEMORY INJECTOR
–û–ø–µ—Ä–∞—Ü–∏—è: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ system_identity.txt –≤ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π Cortex
–ü—Ä–∏–Ω—Ü–∏–ø –¢–†–ò–ó ‚Ññ16: –ß–∞—Å—Ç–∏—á–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (1% –≤—Ä–µ–º–µ–Ω–∏, 100% —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)
"""
import asyncio
import os
from lightrag import LightRAG, QueryParam
from lightrag.utils import EmbeddingFunc
from lightrag.kg.shared_storage import initialize_pipeline_status
from ollama import AsyncClient

# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
WORKING_DIR = r"E:\AI_Librarian_Core\lightrag_cache"
DOC_PATH = r"E:\WORLD_OLLAMA\library\raw_documents\system_identity.txt"
OLLAMA_BASE_URL = "http://localhost:11434"
LLM_MODEL = "qwen2.5:14b"
EMBEDDING_MODEL = "nomic-embed-text"

# Ollama –∫–ª–∏–µ–Ω—Ç
ollama_client = AsyncClient(host=OLLAMA_BASE_URL)

async def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs) -> str:
    """LLM wrapper –¥–ª—è Ollama"""
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.extend(history_messages)
    messages.append({"role": "user", "content": prompt})
    
    response = await ollama_client.chat(model=LLM_MODEL, messages=messages)
    return response['message']['content']

async def embedding_func(texts: list[str]) -> list[list[float]]:
    """Embedding wrapper –¥–ª—è Ollama"""
    results = []
    for text in texts:
        response = await ollama_client.embeddings(model=EMBEDDING_MODEL, prompt=text)
        results.append(response['embedding'])
    return results

async def main():
    print(f"\nüíâ SESA INJECTOR: –ó–∞–≥—Ä—É–∑–∫–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –∏–∑ {DOC_PATH}...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É –≥—Ä–∞—Ñ—É)
    rag = LightRAG(
        working_dir=WORKING_DIR,
        workspace="",
        llm_model_func=llm_model_func,
        llm_model_name=LLM_MODEL,
        llm_model_max_async=1,
        embedding_func=EmbeddingFunc(
            embedding_dim=768,
            max_token_size=8192,
            func=embedding_func
        )
    )
    
    # –ö–†–ò–¢–ò–ß–ù–û: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â...")
    await rag.initialize_storages()
    await initialize_pipeline_status()
    print("‚úÖ –•—Ä–∞–Ω–∏–ª–∏—â–∞ –≥–æ—Ç–æ–≤—ã")

    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞
    if os.path.exists(DOC_PATH):
        with open(DOC_PATH, "r", encoding="utf-8") as f:
            content = f.read()
            print(f"üìÑ –†–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            print("üîÑ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∏–Ω—ä–µ–∫—Ü–∏—è –≤ –≥—Ä–∞—Ñ...")
            await rag.ainsert(content)
        print("‚úÖ SUCCESS: System Identity –≤–Ω–µ–¥—Ä—ë–Ω –≤ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π.")
    else:
        print(f"‚ùå ERROR: –§–∞–π–ª {DOC_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    # Smoke Test –Ω–∞ –º–µ—Å—Ç–µ
    print("\nüîé VERIFYING MEMORY (Smoke Test)...")
    try:
        ans = await rag.aquery(
            "–ß—Ç–æ —Ç–∞–∫–æ–µ CORTEX –∏ –Ω–∞ –∫–∞–∫–æ–º –ø–æ—Ä—Ç—É –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç? –ò–∑ —á–µ–≥–æ —Å–æ—Å—Ç–æ–∏—Ç Neuro-Terminal?", 
            param=QueryParam(mode="local")
        )
        print(f"\n{'='*60}")
        print("üó£Ô∏è CORTEX MEMORY CHECK (–ø–æ—Å–ª–µ –∏–Ω—ä–µ–∫—Ü–∏–∏):")
        print(f"{'='*60}")
        print(ans)
        print(f"{'='*60}\n")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if "8004" in ans or "Cortex" in ans or "LightRAG" in ans:
            print("‚úÖ MIRROR TEST PASSED: –°–∏—Å—Ç–µ–º–∞ –∑–Ω–∞–µ—Ç –æ —Å–µ–±–µ!")
        else:
            print("‚ö†Ô∏è WARNING: –û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–∂–∏–¥–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–∞–º–æ–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Verification failed: {e}")

if __name__ == "__main__":
    asyncio.run(main())
