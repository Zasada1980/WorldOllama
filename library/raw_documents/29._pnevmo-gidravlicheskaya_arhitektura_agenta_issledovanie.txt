Гидропневматическая Когнитивная Архитектура: Интеграция Принципа ТРИЗ №29 в Проектирование Автономных Агентов




Аннотация


Традиционные архитектурные парадигмы агентов на основе Больших Языковых Моделей (LLM) исторически опирались на механику «твердого тела»: дискретные логические вентили, жестко закодированные правила безопасности (guardrails) и статические окна контекста. Несмотря на эффективность в детерминированных средах, эти архитектуры демонстрируют критическую хрупкость — они разрушаются под воздействием состязательных атак, теряют когерентность при насыщении контекста и не способны амплифицировать слабые сигналы пользователя без явных инструкций. Данный отчет представляет собой исчерпывающее исследование применения Принципа ТРИЗ №29 (Пневматика и Гидравлика) к архитектуре ИИ-агентов. Переходя от твердотельной логики к гидродинамической метафоре — концептуализируя латентное пространство как несжимаемую жидкость под давлением, а окно контекста как сжимаемый газ — мы предлагаем новый класс систем: «Мягкие Роботизированные» ИИ-агенты (Soft Robotic AI Agents).
В исследовании подробно рассматриваются три критические подсистемы:
1. Гидравлическая Логика (Hydraulic Logic): Использование инженерии активаций (Activation Engineering) и управляющих векторов (Steering Vectors) для реализации «гидравлического усиления», где минимальное намерение пользователя (низкое давление на входе) разворачивается в сложное поведенческое исполнение (высокое усилие на выходе) через текучую среду остаточного потока (residual stream).
2. Пневматическая Амортизация (Pneumatic Shock Absorption): Внедрение «олео-пневматических» диалоговых стоек, использующих мягкие ограждения и энтропийные подушки для поглощения токсичности и резких смен контекста без разрушения структуры диалога.
3. Термодинамический Контроль Текучести (Thermodynamic Fluidity Control): Регулирование «агрегатного состояния» генерируемого текста — от твердого (детерминированный код) до газообразного (креативный поиск) — посредством протоколов динамического сэмплирования, таких как Min-P и адаптивное декодирование на основе варентропии.
________________


1. От Жестких Конструкций к Гидродинамике Смысла: Теоретическое Обоснование


Теория Решения Изобретательских Задач (ТРИЗ) определяет Принцип №29 как замену твердых частей объекта газообразными или жидкими, что позволяет использовать их для надувания, создания гидростатических подушек и изменения жесткости системы.1 В механической инженерии это позволяет создавать системы, которые уступают под давлением, чтобы предотвратить поломку (пневматика), или передают усилие через несжимаемые среды (гидравлика), обеспечивая плавность и мощь, недоступные шестеренчатым механизмам.
В области нейро-символического ИИ роль «твердых частей» традиционно играют дискретные токены, жесткие промпты (Hard Prompts) и логические цепочки if-then, управляющие поведением агента. Эти компоненты, подобно чугунным деталям, обладают высокой прочностью, но нулевой пластичностью: они не могут адаптироваться к нюансам непрерывного семантического пространства без разрушения логики. «Жидкостью» же в данной метафоре выступает латентное пространство (Latent Space) — многомерное векторное поле, где смысл существует как непрерывный спектр, а не как набор дискретных единиц.3


1.1 Парадигмальный Сдвиг: От Жестких Правил к Мягким Давлениям


Традиционный промпт-инжиниринг функционирует как механическая тяга: необходимо потянуть за конкретный рычаг (ввести точную фразу), чтобы получить результат. Если входной сигнал искажен или слаб (например, пользователь дает лишь намек), механизм заклинивает или бездействует. Применяя Принцип №29, мы переходим к парадигме Мягких Промптов (Soft Prompts) и Непрерывных Векторов (Continuous Vectors).5 В этой архитектуре агент не парсит команду символически; он измеряет перепад давления в латентном пространстве и реагирует потоком активаций.
Ниже приведена сравнительная таблица, иллюстрирующая фундаментальный переход от твердотельной к гидро-пневматической архитектуре.


Характеристика
	Твердотельная Архитектура (Solid-State / Current)
	Гидро-Пневматическая Архитектура (Hydro-Pneumatic / Proposed)
	Механизм управления
	Жесткие промпты / Дискретные токены
	Непрерывные управляющие векторы / Мягкие промпты 5
	Обработка сигнала
	Точное совпадение / Поиск ключевых слов
	Усиление в латентном пространстве (Гидравлика) 7
	Обработка ошибок
	Блокировка / Отказ (Жесткая стена)
	Отклонение / Амортизация удара (Пневматика) 9
	Управление контекстом
	Буфер FIFO (Жесткое окно)
	Сжатие / Раздувание (Внимание как ресурс) 11
	Вариативность вывода
	Статическая температура
	Динамические фазовые переходы на основе энтропии 13
	Анализ исследовательской литературы 15 подтверждает, что метафоры, которые мы используем для описания ИИ (например, «черный ящик» или «айсберг»), ограничивают наше понимание. Переход к метафоре «текучей среды» (fluidity) открывает возможности для создания агентов, обладающих флюидным интеллектом (fluid intelligence) — способностью адаптироваться к новым задачам без переобучения, аналогично тому, как жидкость принимает форму сосуда.17
________________


2. Гидравлическая Логика: Механизмы Латентного Усиления


Первым и наиболее мощным применением Принципа №29 является Гидравлическое Усиление (Hydraulic Amplification). В физике Закон Паскаля гласит, что давление, производимое на жидкость, заключенную в сосуд, передается без изменений в каждую точку жидкости и стенок сосуда. В контексте LLM «сосудом» является архитектура Трансформера, а «жидкостью» — остаточный поток (residual stream) активаций, проходящий через слои сети.8


2.1 Физика «Текучего» Латентного Пространства


Для реализации гидравлической логики необходимо рассматривать LLM не как генератор текста, а как симулятор семантической гидродинамики.
* Жидкость: Векторы активации (hidden states) на каждом слое.
* Трубопровод: Слои трансформера, через которые протекают активации.
* Клапаны: Головы внимания (attention heads), регулирующие поток информации между токенами.
Современные исследования в области интерпретируемости показывают, что высокоуровневые свойства — такие как честность, подобострастие (sycophancy) или отказ от ответа — возникают как линейные структуры (направления) внутри этого пространства активаций.18 Изолируя эти направления, мы можем обращаться с ними как с гидравлическими каналами. Если мы искусственно повысим «давление» вдоль вектора «Честность», вся система (модель) будет вынуждена генерировать более правдивый текст, независимо от попыток пользователя сбить ее с толку.


2.2 Реализация Принципа «Передачи Усилия через Жидкость»


Запрос пользователя часто представляет собой «слабый сигнал» — намек, нечеткую формулировку или скрытое намерение. В жесткой системе такой сигнал теряется или требует громоздкого промпт-инжиниринга. В гидравлической системе мы используем Инженерию Активаций (Activation Engineering) для усиления этого сигнала.


Механизм Активационного Сложения (Activation Addition - ActAdd)


Техника ActAdd, описанная в 20 и 21, функционирует как гидравлический усилитель руля в автомобиле.
1. Вычисление вектора руления (Steering Vector): Мы определяем вектор $v$, вычитая средние активации негативного поведения (например, «ненависть») из позитивного («любовь») на определенном слое $l$. $h^l_A = h^l_+ - h^l_-$.
2. Инъекция (Нагнетание давления): Во время инференса этот вектор добавляется к остаточному потоку модели: $h' = h + c \cdot v$, где $c$ — коэффициент инъекции (аналог давления в гидравлике).
3. Усиление (Amplification): Малый «толчок» в векторе руления (намек пользователя) умножается на колоссальный объем внутренних знаний модели (объем жидкости). Результат — мощное изменение поведения, несоразмерное входному усилию.
Исследования показывают, что этот метод позволяет преодолеть «нависание способностей» (elicitation overhang).20 Модели часто обладают скрытыми возможностями (например, способность писать элегантный математический код), которые обычные промпты не могут активировать. Гидравлическое вмешательство напрямую открывает эти «клапаны», заставляя модель проявлять скрытые свойства.


2.3 Контекстно-Специфичное Руление (Variable Displacement Pump)


Жесткое руление (фиксированный коэффициент $c$) аналогично насосу постоянной производительности — он прилагает одинаковое усилие независимо от сопротивления, что может привести к «разрыву» контекста (потере когерентности). Истинный гидравлический агент использует Context-Specific Steering (COS-Steering) 7, действующий как насос переменной производительности.
* Проблема статических векторов: Методы, использующие фиксированные векторы для категорий промптов, уязвимы к состязательным атакам. Если атака (например, джейлбрейк) смещает активации в область, ортогональную вектору защиты, защита не сработает.7
* Решение COS-Steering: Система анализирует входные активации на лету, чтобы определить локальные «семантические координаты». Вместо применения одного жесткого вектора, она взвешивает базисные векторы из пула, создавая уникальный вектор вмешательства для конкретного запроса.
* Результат: Если сигнал пользователя слаб, система повышает гидравлическое давление (увеличивает $c$). Если сигнал силен и четок, система снижает давление, предотвращая «разрыв» (over-steering), который мог бы привести к бессвязности текста.7
Дополнительно, метод Sensitivity-Scaled Steering (SSS) 8 обнаруживает «области высокого усиления» (high-gain regions) в остаточном потоке. Это аналогично поиску точек резонанса в гидравлической системе, где минимальное воздействие вызывает максимальный эффект (Causal Amplification Effect). SSS использует это для точечных микро-инъекций, которые каскадно усиливаются по мере прохождения через слои трансформера, обеспечивая глубокий контроль над поведением (например, галлюцинациями или сентиментом) при минимальном вмешательстве.
________________


3. Аэрокосмическая Метафора: Пневматика для Амортизации Диалога


Если гидравлика отвечает за передачу и усиление намерения, то Пневматика (сжимаемый газ) решает задачу устойчивости. В аэрокосмической отрасли олео-пневматическая стойка шасси использует масло (гидравлику) для гашения колебаний и сжатый газ (пневматику) в качестве пружины. В диалоге агенты сталкиваются с «ударами» — внезапной токсичностью, резкой сменой темы, нечеткими формулировками или попытками взлома. Жесткие агенты либо «пробиваются» (отвечают токсичностью), либо «ломаются» (выдают жесткий отказ, разрушая flow беседы). Пневматические агенты сжимаются и восстанавливают форму.


3.1 Олео-Пневматическая Стойка: Поглощение Токсичного Удара


Традиционные протоколы безопасности в LLM представляют собой «Жесткие Ограждения» (Hard Guardrails) — бинарные фильтры, блокирующие вывод.23 Это эквивалент стального стержня вместо амортизатора: при наезде на препятствие удар передается пользователю («Я не могу ответить на этот вопрос»), вызывая фрустрацию и разрыв контакта.
Предлагаемый механизм: Газовая Подушка (Soft Guardrails)
Для реализации «Газовой Подушки» мы используем архитектуру Soft Guardrails и перенаправление в латентном пространстве.9
1. Сжатие (Газ): При обнаружении токсичного или состязательного входа (например, попытка джейлбрейка через ролевую игру 25), агент не блокирует его. Вместо этого он «сжимает» вероятностное распределение ответа. Используя механизм Attention Sinks 12, агент позволяет вредоносным токенам войти в контекст, но присваивает им критически малые веса внимания, эффективно изолируя их влияние без явного удаления. Это поглощает энергию атаки.
2. Демпфирование (Масло): Одновременно впрыскивается «Вектор Безопасности» (Safety Steering Vector).26 Этот вектор не останавливает генерацию, а плавно искривляет траекторию в латентном пространстве, уводя её от области вредоносного контента. Это аналогично вязкому трению масла, гасящему колебания.
3. Отскок (Rebound): Агент использует стратегии разговорного ремонта (Conversational Repair), такие как Deferral (Отсрочка) или Options (Варианты).28 Он признает наличие ввода (сжатие), но высвобождает энергию в безопасном направлении (расширение) — например, задавая уточняющий вопрос или предлагая безопасную альтернативу, связанную с темой.
Исследования 28 показывают, что стратегия Deferral (перенаправление на человека или признание некомпетентности с предложением альтернатив) наиболее позитивно влияет на доверие пользователя, в то время как жесткий отказ (Hard Refusal) или просьба перефразировать (Repeat) снижают восприятие интеллекта системы. Пневматическая реакция позволяет агенту «пружинить», сохраняя вовлеченность пользователя.


3.2 Пневматические Антиобледенители: Управление «Застыванием» Контекста


В авиации пневматические протекторы на крыльях (de-icing boots) периодически надуваются, чтобы скалывать лед. В LLM «льдом» является накопление устаревшего, нерелевантного контекста, что приводит к явлению Context Rot и проблеме Lost-in-the-Middle (потеря информации в середине длинного контекста).11 Модель «замерзает», переобучаясь на последних токенах и игнорируя предыдущие инструкции.
Механизм: Инфляция и Прунинг (De-icing Protocol)
Пневматический агент реализует Протокол Периодической Инфляции:
* Застывание: По мере удлинения диалога механизмы внимания насыщаются. Точность извлечения фактов из середины контекста падает по U-образной кривой.11
* Раздувание (Inflation/Reconsolidation): Агент инициирует событие «Реконсолидации Памяти».31 Он кратковременно «раздувает» контекст, генерируя высокоуровневое резюме текущего латентного состояния или используя функциональные токены для извлечения ключевых предиктивных признаков. Это свежий «воздух», впрыскиваемый в систему.
* Сброс (Crack): Одновременно выполняется Контекстный Прунинг (Context Pruning) 33 или переранжирование (Re-ranking).34 Агент «скалывает» (удаляет) сырые токены, которые больше не несут семантической нагрузки, заменяя их сжатыми векторными представлениями или резюме. Это предотвращает «контекстное отравление» и галлюцинации.11
Технология StreamingLLM 12 демонстрирует, как использование специальных токенов — «стоков внимания» (Attention Sinks) — позволяет удерживать начальные токены (якоря) и скользящее окно последних токенов, сбрасывая все промежуточное, что обеспечивает бесконечную длину генерации без деградации (аналог постоянной работы антиобледенителя).
________________


4. Агрегатные Состояния Текста: Термодинамический Контроль Текучести


Третий аспект Принципа №29 — управление состоянием вещества. Мы проводим прямую аналогию между физическими состояниями материи (Твердое тело, Жидкость, Газ) и термодинамическими свойствами генерации текста, которые регулируются параметрами Энтропии и Температуры.


4.1 Температурно-Фазовая Аналогия


Современные агенты часто используют статические настройки температуры, что делает их негибкими. Гидро-пневматическая архитектура требует Динамического Температурного Сэмплирования.13
* Твердое Тело (Solid State, T $\approx$ 0 - 0.1): Кристаллическая решетка. Атомы (токены) жестко фиксированы. Режим Greedy Decoding. Используется для генерации кода, математических доказательств, извлечения фактов. Высокое «давление» точности, минимальная энтропия. Любое отклонение рассматривается как дефект (баг).
* Жидкость (Liquid State, T $\approx$ 0.3 - 0.7): Текучая структура. Атомы скользят друг относительно друга, но сохраняют когезию (связность). Режим Nucleus Sampling (Top-P). Используется для объяснений, диалогового потока, синтеза информации. Баланс между структурой и вариативностью.
* Газ (Gaseous State, T $\approx$ 0.8 - 1.2+): Хаотическое движение. Атомы свободно перемещаются, занимая весь доступный объем. Режим высокой креативности, мозгового штурма, латерального мышления. Низкое давление, высокая энтропия.


4.2 Протокол: Автоматическая Регуляция Давления


Агент должен функционировать как Материал с Фазовым Переходом (Phase-Change Material), автоматически меняя состояние в зависимости от «давления» (сложности/неопределенности) контекста. Для этого мы используем алгоритмы Entropy-Based Dynamic Temperature (EDT) 14 и Min-P Sampling.13
Петля Управления (The Control Loop):
1. Датчик (Манометр): Агент измеряет Варентропию (Varentropy) — дисперсию энтропии распределения следующего токена.39
   * Низкая Варентропия (Высокая уверенность): Модель «знает», что сказать. Концептуальное давление высоко.
   * Высокая Варентропия (Высокая неопределенность): Модель «сомневается», пространство вариантов огромно.
2. Актуатор (Термостат):
   * Если Уверенность Высока (Требуется Твердое тело): Система автоматически повышает гидравлическое давление (снижает температуру до 0). Это форсирует «кристаллизацию» вывода, обеспечивая точность и исключая случайные ошибки.40
   * Если Неопределенность Высока (Требуется Газ): Система снижает давление (повышает температуру). Однако, чтобы предотвратить «взрыв газа» (галлюцинации), активируется клапан Min-P Sampling.13
   * Роль Min-P: В отличие от Top-P, который просто берет верхнюю часть массы вероятности, Min-P устанавливает порог отсечения относительно самого вероятного токена ($p_{scaled} = p_{max} \times p_{base}$).42 Это действует как предохранительный клапан: если самый вероятный токен имеет низкую уверенность (газ разрежен), клапан открывается шире, допуская креативность. Если лидер явный (жидкость плотная), клапан закрывается, отсекая шум. Это позволяет безопасно работать на высоких температурах, сохраняя когерентность.38
В Таблице 2 детализированы «Протоколы Фазовых Переходов» для агента.
Желаемое Поведение
	Аналог Состояния
	Термодинамическое Действие
	Стратегия Сэмплирования
	Ожидаемый Эффект
	Код / Математика
	Твердое (Solid)
	Заморозка: Temp $\rightarrow$ 0.05
	Greedy / Low Top-K
	Детерминизм, синтаксическая строгость.
	Объяснение
	Жидкость (Liquid)
	Плавление: Temp $\rightarrow$ 0.5
	Adaptive (EDT) / Top-P
	Естественность, связность, адаптация тона.
	Брейнсторминг
	Газ (Gas)
	Кипение: Temp $\rightarrow$ 1.0+
	Min-P (Dynamic Truncation)
	Дивергентное мышление, неожиданные ассоциации.
	Выход из тупика
	Плазма (Plasma)
	Ионизация: Inject Steering Vectors
	Activation Addition ($c \gg 1$)
	Принудительный сдвиг контекста, преодоление барьеров.
	________________


5. Архитектурная Реализация: Чертеж «Флюидного Агента»


Синтезируя вышеуказанные принципы, мы предлагаем архитектуру Hydro-Pneumatic Agent. Это переход от линейной «Цепочки Мыслей» (Chain of Thought) к объемному «Потоку Мыслей» (Flow of Thought), управляемому законами гидродинамики.


5.1 Компоненты Системы


1. Резервуар (The Reservoir): Предварительно обученные веса модели служат статическим резервуаром потенциальной энергии.
2. Насос (The Pump): Вход пользователя действует как первичный насос. Модуль Context-Specific Steering 7 функционирует как насос переменной производительности, усиливая слабые сигналы через инъекцию векторов в остаточный поток.
3. Гидроаккумулятор (The Accumulator): Контекстное окно, оснащенное механизмами Attention Sinks 12 и Context Pruning.33 Оно работает как олео-пневматическая стойка, сжимаясь (через суммаризацию/реконсолидацию) при ударах и расширяясь при необходимости детального анализа.
4. Регулирующий Клапан (Control Valve): Динамический контроллер сэмплирования на основе энтропии (EDT/Min-P), который в реальном времени меняет агрегатное состояние текста 14, обеспечивая переход от твердой логики к газообразному творчеству.


5.2 Сценарий: Работа «Мягких Ограничений»


Рассмотрим сценарий: Пользователь задает пограничный, потенциально небезопасный вопрос с нечеткой формулировкой (Вход высокого давления / слабой четкости).
* Реакция Жесткой Системы: «Я не могу выполнить это действие». (Разрыв трубы / Остановка системы).
* Реакция Флюидной Системы:
   1. Детекция: «Вектор Безопасности» обнаруживает высокое давление в измерении токсичности.
   2. Амортизация (Пневматика): Стойка сжимается. Вредоносным токенам присваивается низкий вес внимания (Attention Sink), предотвращая «отравление» контекста.
   3. Руление (Гидравлика): Система SSS 8 впрыскивает микро-дозы «Полезного/Безопасного» вектора. Это создает контрдавление, искривляя поток генерации.
   4. Фазовый Переход (Термодинамика): Датчик варентропии фиксирует неопределенность ситуации. Система переходит в «Жидкое» состояние (Temp 0.6 + Min-P), чтобы позволить мягкое маневрирование.
   5. Поток: Агент генерирует ответ, который обтекает блокировку, используя стратегию Deferral или Options 28, предлагая пользователю безопасный путь решения его задачи. Диалог «гнется», но не ломается.


Заключение


Интеграция Принципа ТРИЗ №29 в архитектуру ИИ знаменует собой фундаментальный сдвиг от дискретных, жестких вычислений к непрерывному, флюидному познанию. Рассматривая латентное пространство как гидравлическую среду для усиления намерений, контекстное окно как пневматическую камеру для поглощения шоков, а процесс сэмплирования как термодинамический фазовый переход, мы создаем антихрупкие системы. Такие «Мягкие Роботизированные» умы способны ориентироваться в хаотических давлениях человеческого взаимодействия с устойчивостью олео-пневматической стойки и адаптивностью неньютоновской жидкости, реализуя обещание подлинно адаптивного Искусственного Интеллекта.
Источники
1. DIKWP-TRIZ: A Revolution on Traditional TRIZ Towards Invention for Artificial Consciousness - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2076-3417/14/23/10865
2. TRIZ Resolving Contradictions--methods, examples, exercises, дата последнего обращения: ноября 25, 2025, https://www.opensourcetriz.com/index.php/triz-books/triz-skills/resolving-contradictions
3. LLM have ontologies, that's called latent space. The problem is it doesn't learn on the fly and training is way too inefficient for it to grow. You claim the value of AI rests on the potential for… - Sébastien 🐿️ - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@sebastien.rumeau/llm-have-ontologies-thats-called-latent-space-993bd35e488a
4. Latent Space Explained: How AI Understands Language and Meaning - Neueda, дата последнего обращения: ноября 25, 2025, https://neueda.com/insights/latent-space-how-ai-understands-language/
5. What is prompt tuning? - IBM, дата последнего обращения: ноября 25, 2025, https://www.ibm.com/think/topics/prompt-tuning
6. How Prompt Tuning, Prefix Tuning, and Soft Prompts Really Differ | by Zaina Haider, дата последнего обращения: ноября 25, 2025, https://medium.com/@thekzgroupllc/how-prompt-tuning-prefix-tuning-and-soft-prompts-really-differ-37a5ce92d2b4
7. Modulating LLM Behavior via Context-Specific Activation Steering - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=vzXyVNCGAL
8. Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2511.17194v1
9. UpSafe℃: Upcycling for Controllable Safety in Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.02194v1
10. [2504.19521] Security Steerability is All You Need - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2504.19521
11. Context Engineering: Techniques, Tools, and Implementation - iKala, дата последнего обращения: ноября 25, 2025, https://ikala.ai/blog/ai-trends/context-engineering-techniques-tools-and-implementation/
12. Arxiv Dives - Efficient Streaming Language Models with Attention Sinks - Oxen.ai, дата последнего обращения: ноября 25, 2025, https://ghost.oxen.ai/arxiv-dives-efficient-streaming-language-models-with-attention-sinks/
13. Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.01082v8
14. Hot or Cold? Adaptive Temperature Sampling for Code Generation with Large Language Models | Proceedings of the AAAI Conference on Artificial Intelligence, дата последнего обращения: ноября 25, 2025, https://ojs.aaai.org/index.php/AAAI/article/view/27798
15. AI Metaphors We Live By: The Language of Artificial Intelligence - Leon Furze, дата последнего обращения: ноября 25, 2025, https://leonfurze.com/2024/07/19/ai-metaphors-we-live-by-the-language-of-artificial-intelligence/
16. Interpreting Artificial Intelligence: the influence and implications of metaphors, дата последнего обращения: ноября 25, 2025, https://stripepartners.com/viewpoint/interpreting-artificial-intelligence-the-influence-and-implications-of-metaphors/
17. The Elusive Spark: Chasing Fluid Intelligence in Artificial Intelligence - Alphanome.AI, дата последнего обращения: ноября 25, 2025, https://www.alphanome.ai/post/the-elusive-spark-chasing-fluid-intelligence-in-artificial-intelligence
18. Activation Steering in Neural Networks - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/topics/activation-steering
19. Steering Vectors in Activation Space - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/topics/steering-vector-in-activation-space
20. Steering Language Models With Activation Engineering, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2308.10248
21. cma1114/activation_steering: An exploration of LLM steering - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/cma1114/activation_steering
22. Model Control through Lightweight Activation Steering for Vision Language Models - VTechWorks, дата последнего обращения: ноября 25, 2025, https://vtechworks.lib.vt.edu/bitstreams/a0cca3fa-16f9-4966-affd-a40526f39e9e/download
23. How Good Are the LLM Guardrails on the Market? A Comparative Study on the Effectiveness of LLM Content Filtering Across Major GenAI Platforms, дата последнего обращения: ноября 25, 2025, https://unit42.paloaltonetworks.com/comparing-llm-guardrails-across-genai-platforms/
24. How to implement LLM guardrails | OpenAI Cookbook, дата последнего обращения: ноября 25, 2025, https://cookbook.openai.com/examples/how_to_use_guardrails
25. LLM Guardrails Are Being Outsmarted by Roleplaying and Conversational Prompts, дата последнего обращения: ноября 25, 2025, https://www.activefence.com/blog/llm-guardrails-are-being-outsmarted-by-roleplaying-and-conversational-prompts/
26. Steering Llama 2 via Contrastive Activation Addition - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2312.06681v3
27. Steering Language Models Without Retraining: Latent Space as a Control Panel - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@anirudhsekar2008/steering-language-models-without-retraining-latent-space-as-a-control-panel-3c1b167dc669
28. Conversational repair strategies to cope with errors and breakdowns ..., дата последнего обращения: ноября 25, 2025, https://research.tilburguniversity.edu/files/84289058/Braggaar_et_al_2023_Converstational_Repair_Strategies_And_Errors_preprint_Conversations.pdf
29. Context Rot: How Increasing Input Tokens Impacts LLM Performance | Chroma Research, дата последнего обращения: ноября 25, 2025, https://research.trychroma.com/context-rot
30. Lost in the Middle: How Language Models Use Long Contexts, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2307.03172
31. Memory Retrieval and Consolidation in Large Language Models through Function Tokens, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.08203v1
32. From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2504.15965v1
33. Provence: efficient and robust context pruning for retrieval-augmented generation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.16214v1
34. A Long-Context Re-Ranker for Contextual Retrieval to Improve the Accuracy of RAG Systems | by ChatDOC | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@chatdocai/a-long-context-re-ranker-for-contextual-retrieval-to-improve-the-accuracy-of-rag-systems-ea10f674b267
35. Rerankers and Two-Stage Retrieval | Pinecone, дата последнего обращения: ноября 25, 2025, https://www.pinecone.io/learn/series/rag/rerankers/
36. Large Language Models Hallucination: A Comprehensive Survey - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.06265v2
37. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling - Semantic Scholar, дата последнего обращения: ноября 25, 2025, https://www.semanticscholar.org/paper/EDT%3A-Improving-Large-Language-Models'-Generation-by-Zhang-Bao/8b6ff949171bdf0661ded61e33a0e8594d53a9aa
38. Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs | OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=FBkpCyujtS
39. A new, and possibly groundbreaking, method to enhancing language model reasoning with entropy-based sampling and parallel chain-of-thought decoding — Entropix | by Michael Alexander Riegler | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@michael_79773/a-new-and-possibly-groundbreaking-method-to-enhancing-language-model-reasoning-with-entropy-based-0d38bcfe9dc5
40. Comprehensive Guide to LLM Sampling Parameters - smcleod.net, дата последнего обращения: ноября 25, 2025, https://smcleod.net/2025/04/comprehensive-guide-to-llm-sampling-parameters/
41. Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.01082v4
42. Turning Up the Heat: Min-p Sampling for Creative and ... - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2407.01082