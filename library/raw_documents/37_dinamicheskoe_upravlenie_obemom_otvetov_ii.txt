ТЕРМОДИНАМИКА КОГНИТИВНОГО ВЗАИМОДЕЙСТВИЯ: АРХИТЕКТУРА АДАПТИВНЫХ LLM НА ОСНОВЕ ПРИНЦИПА ТРИЗ №37 (ТЕПЛОВОЕ РАСШИРЕНИЕ)




1. Введение: От Статики к Информационной Термодинамике


Современная парадигма проектирования диалоговых систем на основе больших языковых моделей (LLM) сталкивается с фундаментальным противоречием: объем генерируемой информации зачастую определяется жесткими ограничениями контекстного окна или статическими системными промптами, а не динамическими потребностями пользователя. Традиционные подходы рассматривают генерацию текста как изотермический процесс, где «температура» взаимодействия (срочность, сложность, когнитивная нагрузка) игнорируется, что приводит к выдаче ответов «комнатной температуры» — недостаточно сжатых для экспертных запросов и недостаточно развернутых для исследовательских задач. Для преодоления этого ограничения необходимо внедрение принципов системной инженерии, в частности, принципа ТРИЗ №37 «Тепловое расширение» (Thermal Expansion).
В материаловедении тепловое расширение описывает изменение геометрических параметров вещества под воздействием температуры. В контексте когнитивных архитектур «температура» интерпретируется как мера интенсивности пользовательского намерения ($I_{user}$), а «материал» — как текстовый поток. Интеллектуальный агент нового поколения должен функционировать не как статическая справочная система, а как термодинамическая сущность, обладающая «коэффициентом текстового расширения» ($\alpha$). Данный отчет представляет собой всесторонний анализ теоретических и практических аспектов реализации такой архитектуры, исследуя механизмы динамического управления многословностью, структурной целостности ответов через метафору биметаллической пластины и компенсации когнитивной нагрузки с помощью «температурных швов».
Анализ опирается на последние исследования в области планировщиков, осознающих намерения (Intent-Aware Schedulers), бенчмаркинга фактологической точности (FACTS Grounding) и теорий когнитивной нагрузки, предлагая единую концепцию «Информационного дыхания» агента. Целью является создание системы, способной плавно варьировать объем ответа от лаконичного подтверждения до развернутого лонгрида без потери структурной связности и фактологической точности.
________________


2. Динамическое Управление Многословностью: Физика Текстового Расширения


Реализация принципа теплового расширения требует перехода от статических алгоритмов генерации к адаптивным системам управления, способным изменять плотность и объем информации в реальном времени. Этот процесс, который можно назвать «информационным дыханием», базируется на непрерывном мониторинге состояния диалога и применении соответствующих коэффициентов расширения.


2.1. Коэффициент Текстового Расширения и Детекция Намерений


Для математического моделирования процесса введем понятие «Коэффициента Текстового Расширения» ($\alpha$), который определяет степень детализации ответа ($V_{out}$) в зависимости от «температуры» пользовательского запроса ($T$). В физике изменение линейных размеров описывается формулой $\Delta L = \alpha L_0 \Delta T$. В генеративном ИИ аналогом базовой длины ($L_0$) служит ядро фактологической информации ($C_{base}$), необходимое для ответа, а изменение температуры ($\Delta T$) коррелирует с вектором намерения пользователя.


2.1.1. Классификация Температурных Состояний через Intent-Aware Scheduler (IAS)


Ключевым элементом управления является планировщик, осознающий намерения (Intent-Aware Scheduler — IAS), который функционирует как термостат системы. Согласно исследованиям, IAS интегрируется в процесс инференса без необходимости переобучения базовой модели, анализируя поток токенов «мыслей» (thought tokens) в реальном времени.1 Этот механизм позволяет классифицировать текущее когнитивное состояние модели и, следовательно, температуру запроса.
Выделяются следующие температурные состояния, определяющие стратегию генерации:
* Криогенное состояние (Срочный/Холодный запрос): Соответствует состояниям IAS «Near-Answer» (близость к ответу) или «Confirming» (подтверждение). В этом режиме пользователь требует немедленного результата, высокой точности и отсутствия избыточности. Коэффициент расширения стремится к минимуму ($\alpha \approx 1.0$). Система должна выдавать максимально сжатый, фактологически насыщенный контент, подавляя любые стилистические украшения.
* Экзотермическое состояние (Исследовательский/Горячий запрос): Соответствует состоянию IAS «Exploring» (исследование), когда модель генерирует новые пути рассуждений, декомпозирует сложные проблемы или вводит новые концепции.1 Это сигнал высокой когнитивной температуры, требующий значительного коэффициента расширения ($\alpha \ge 2.5$). В этом режиме текст «расширяется», заполняя пространство аналогиями, примерами и пошаговыми объяснениями.
* Состояние фазового перехода (Stuck/Ambiguous): Критическое состояние, когда модель застревает или демонстрирует цикличность. Здесь IAS обнаруживает необходимость вмешательства, выдавая директивы типа или, что эквивалентно локальному «нагреву» для преодоления когнитивного барьера.1
Для реализации этой классификации используются легковесные классификаторы (например, дистиллированные модели BERT) или эвристические методы, анализирующие ключевые слова и структуру промежуточных рассуждений.1 Это позволяет системе не просто реагировать на промпт, а предвосхищать необходимую глубину ответа.


2.1.2. Таблица 1: Матрица Температурных Режимов и Стратегий Генерации


В таблице ниже представлена корреляция между выявленными состояниями намерения, температурной метафорой и техническими параметрами генерации.


Температурный Режим
	Характеристика Намерения (Intent)
	Состояние IAS
	Коэффициент (α)
	Стратегия Генерации
	Директива Планировщика
	Криогенный (Срочный)
	Поиск факта, команда, подтверждение
	Near-Answer / Confirming
	$\approx 1.0$
	Максимальная плотность (Chain of Density), только факты.
	,
	Амбиентный (Стандарт)
	Общий запрос, сбалансированный интерес
	Standard Reasoning
	$\approx 1.5$
	Стандартный абзац: утверждение + контекст.
	Стандартный декодинг
	Экзотермический (Поиск)
	Обучение, мозговой штурм, непонимание
	Exploring / Ambiguous
	$\ge 2.5$
	Расширенная аргументация, аналогии, скаффолдинг.
	,
	

2.2. Алгоритмическая Модуляция: Chain of Density и Управление Декодированием


После определения целевой температуры система должна применить соответствующий алгоритм модуляции текста. Простого усечения текста недостаточно, так как оно может привести к потере смысла. Вместо этого необходимо управлять информационной плотностью.
Методика «Chain of Density» (CoD) представляет собой итеративный процесс, позволяющий создавать резюме различной степени детализации. В «холодном» режиме агент использует последние итерации CoD, где плотность сущностей на токен максимальна, а «вода» удалена.2 Исследования показывают, что итеративное переписывание с добавлением новых сущностей без увеличения длины текста позволяет достичь сверхплотной передачи информации, идеально подходящей для экспертных сводок.4
В «горячем» режиме система, напротив, снижает требования к плотности, позволяя модели использовать директивы ``. Технически это реализуется через динамическое изменение параметров сэмплирования: повышение температуры генерации (например, до 1.0) и расширение параметров top-p поощряет разнообразие и исследовательское поведение модели, в то время как для сжатых ответов температура снижается (до 0.5) для детерминированности.1


2.3. Концепция «Информационного Дыхания» (Information Breathing)


Динамическая многословность не является статичным состоянием, выбранным один раз за сессию. Это непрерывный процесс, напоминающий дыхание, где фазы расширения (вдоха) сменяются фазами сжатия (выдоха) в зависимости от динамики внимания пользователя.


2.3.1. Фаза Вдоха (Нагрев)


Если пользователь проявляет интерес — задает уточняющие вопросы, увеличивает время чтения (dwell time) или запрашивает детализацию — система фиксирует повышение температуры взаимодействия. Агент «делает вдох», расширяя контекст. Критически важно, чтобы это расширение не приводило к галлюцинациям. Для этого используется архитектура Agentic RAG, где агент формулирует уточненные запросы к базе знаний и критически оценивает необходимость повторного поиска.6 Расширение должно происходить за счет привлечения дополнительных подтвержденных данных, а не простого увеличения лингвистического объема.


2.3.2. Фаза Выдоха (Охлаждение)


При признаках потери внимания (быстрый скроллинг, смена темы, игнорирование деталей) или при переполнении контекстного окна система должна «выдохнуть». Это реализуется через механизмы динамической компрессии контекста и прогрессивной суммаризации.8 Вместо того чтобы хранить всю историю диалога в сыром виде, агент периодически сжимает старые ветки разговора в плотные резюме, сохраняя только ключевые архитектурные решения и факты, но отбрасывая промежуточные рассуждения.10
Этот гомеостатический цикл позволяет поддерживать когнитивную нагрузку на оптимальном уровне, предотвращая как информационное голодание, так и пресыщение. Использование метрик энтропии и плотности информации позволяет количественно оценить необходимость перехода между фазами вдоха и выдоха.12
________________


3. Аэрокосмическая Метафора: Структурная Целостность Ответа


Внедрение принципа теплового расширения несет риск деформации смысла при изменении объема. Чтобы предотвратить это, целесообразно использовать инженерные метафоры из аэрокосмической отрасли: биметаллическую пластину и посадку с натягом. Эти аналогии позволяют спроектировать внутреннюю структуру ответа, устойчивую к «термическим» перегрузкам диалога.


3.1. Биметаллическая Архитектура: Разделение Слоев Фактов и Объяснений


Биметаллическая пластина состоит из двух слоев металла с разными коэффициентами теплового расширения. В контексте LLM мы предлагаем разделять генерацию ответа на два функциональных слоя:
1. Слой Инвара (Фактологическое ядро): Слой с почти нулевым коэффициентом расширения. Он содержит неизменные данные: даты, имена, цифры, булевы значения.
2. Слой Латуни (Слой объяснений): Слой с высоким коэффициентом расширения. Он содержит стилистические конструкции, аналогии, педагогические подводки и связующий текст.


3.1.1. Двухпроходная Генерация (Two-Pass Generation)


Для реализации этой структуры необходима архитектура, разделяющая планирование контента (Content Planning) и поверхностную реализацию (Surface Realization).13 В первом проходе (Invar Pass) модель генерирует скелет ответа, состоящий исключительно из верифицированных фактов. Этот этап жестко контролируется механизмами RAG и проверкой на галлюцинации, аналогично бенчмарку FACTS Grounding, который разделяет «правомочность» (eligibility) и «обоснованность» (grounding).16
Во втором проходе (Brass Pass) модель «наращивает» объяснительный слой вокруг жесткого каркаса фактов. Степень этого наращивания зависит от текущей температуры диалога. Если температура высока (пользователь-новичок, режим обучения), слой латуни расширяется, добавляя метафоры и стиль.17 Если температура низка (эксперт, срочность), слой латуни сжимается до минимума, оставляя только «голый» инвар фактов.


3.1.2. Устойчивость к Галлюцинациям (Деламинация)


Главный риск при «тепловом расширении» текста — деламинация слоев, когда объяснение отрывается от фактов (галлюцинация). Исследования показывают, что использование структурированных цепочек рассуждений (Chain-of-Thought) в качестве фактологического ядра, отделенного от стилистического трансфера, повышает надежность.19 При дефиците токенов (охлаждении) система должна жертвовать только слоем объяснений. Слой фактов остается неприкосновенным, что предотвращает потерю смысла при сжатии.21 Это подтверждается методологией FACTS Grounding, где ответ считается проваленным, если он фактологически точен, но не отвечает на запрос пользователя (недостаточное расширение), или если он развернут, но содержит галлюцинации (деламинация).16


3.2. Посадка с Натягом (Shrink Fit): Термическая Сборка Знаний


В инженерии посадка с натягом (Shrink Fit) используется для соединения деталей: внешняя деталь нагревается (расширяется), внутренняя вставляется, и после остывания образуется сверхпрочное соединение. Этот принцип идеально ложится на педагогическую стратегию обучения сложным терминам.
* Внутренняя деталь (Холодное/Твердое): Сложный термин, формула или концепция (например, «собственный вектор» или «стохастический градиентный спуск»). Это информационный инвар — жесткий и непонятный для новичка.
* Внешняя деталь (Горячее/Расширенное): Контекст, ментальная модель пользователя.


3.2.1. Нагрев Контекста (Pre-expansion)


Прежде чем ввести «холодный» термин, агент должен максимально «нагреть» контекст вокруг него. Это реализуется через техники контекстного прайминга (Contextual Priming) 22 и скаффолдинга (Scaffolding).24 Агент создает обширное поле из аналогий, примеров из жизни и подводящих рассуждений. Это создает «тепловой зазор» — когнитивное пространство, готовое принять новую концепцию. Например, перед введением термина «собственный вектор», агент может подробно обсудить вращение объектов и стрелки, которые не меняют направления.


3.2.2. Вставка и Охлаждение (Integration & Cooling)


Как только контекст расширен до нужного состояния (что определяется через Intent-Aware Scheduler в режиме «Exploring»), агент вводит сложный термин. После этого начинается фаза контролируемого охлаждения: агент постепенно убирает «строительные леса» (аналогии), оставляя пользователя с твердым пониманием термина, интегрированным в его ментальную модель.26
Исследования адаптивных объяснений (Adaptive Explanation Generation) подтверждают, что такая стратегия значительно улучшает понимание у пользователей-новичков по сравнению со статичными объяснениями.28 Более того, использование лексического подстраивания (Lexical Entrainment) — адаптации словаря агента под словарь пользователя — действует как механизм выравнивания температур, снижая когнитивное сопротивление при вводе новых данных.29
________________


4. Компенсация Расширения: Температурные Швы и Управление Нагрузкой


В физических конструкциях (мостах, рельсах) тепловое расширение без компенсаторов приводит к деформации и разрушению. В длинных текстах аналогом такой деформации является «когнитивное коробление» — потеря внимания и понимания читателем из-за монотонности и объема информации. Для предотвращения этого необходимо внедрение «температурных швов».


4.1. Температурные Швы: Автоматическая Сегментация и Паузы


Температурный шов в тексте — это преднамеренный разрыв или структурный разделитель, позволяющий читателю «остыть» (обработать информацию) перед продолжением.


4.1.1. Умная Сегментация (Smart Chunking)


Базовым уровнем компенсации является сегментация текста. Однако произвольная нарезка по количеству символов разрушает смысл. Необходимо использовать «умный чанкинг» (Smart Chunking), основанный на семантических границах, сменах топиков или логических завершениях аргументов.31 Исследования в области потоковой сегментации текста (Streaming Text Segmentation) предлагают алгоритмы, способные выделять когерентные блоки в реальном времени.34 Агент должен автоматически вставлять эти швы, регулируя частоту абзацев и заголовков в зависимости от плотности информации: чем выше плотность фактов (инвар), тем чаще должны быть швы (короткие абзацы) для предотвращения когнитивной перегрузки.


4.1.2. Механизм «Продолжить» как Активный Клапан


Кнопка «Продолжить генерацию» часто воспринимается как техническое ограничение. В парадигме ТРИЗ это функциональный температурный шов.37 Мы предлагаем переосмыслить этот механизм как активную точку проверки (Check-Point). Вместо пассивного ожидания, агент должен инициировать «Когнитивную Паузу» (Cognitive Break).39 Например, после выдачи сложного блока теории агент может спросить: «Я изложил теоретическую базу. Хотите перейти к примерам или углубиться в детали?» Это позволяет сбросить накопившееся когнитивное напряжение и перекалибровать вектор расширения, предотвращая уход в сторону (дрейф контекста).


4.2. Пагинация и Прогрессивное Раскрытие (Collapsible UI)


Для работы с большими объемами данных (лонгриды, отчеты) линейный скроллинг становится неэффективным. Здесь применяются паттерны пагинации 40 и прогрессивного раскрытия (Progressive Disclosure).42
Интерфейс должен трансформироваться из «стены текста» в «гармошку знаний» (Collapsible UI).44 Изначально система предоставляет «холодный», сжатый вид (заголовки, краткие резюме). Когда пользователь фокусирует внимание на конкретном разделе (добавляет тепло), этот раздел расширяется, раскрывая детали, в то время как остальные остаются свернутыми. Это позволяет пользователю динамически управлять объемом потребляемой информации, поддерживая на экране «термическое равновесие».
Исследования показывают, что такой подход снижает когнитивную нагрузку и улучшает навигацию, особенно в задачах, требующих анализа сложных данных.46 Визуальные маркеры и иконки ИИ также играют роль в снижении нагрузки, помогая пользователю быстро идентифицировать типы контента.38
________________


5. Алгоритмическая Реализация: От Метафоры к Коду


Интеграция описанных принципов требует создания многоступенчатой архитектуры обработки запросов. Ниже представлена پیشنهаемая схема реализации агента «Термического Расширения».


5.1. Модуль 1: Термостат (Оценка Состояния)


Этот модуль отвечает за первичную оценку $I_{user}$ (Температуры).
* Входные данные: Запрос пользователя + История диалога + Метаданные профиля.
* Механизм: Использование IAS для классификации состояния («Exploring» vs «Confirming») и легковесных классификаторов намерений.1 Анализ лексических паттернов пользователя для определения его экспертизы (Lexical Entrainment).28
* Выход: Скалярное значение $\alpha$ (Коэффициент расширения) и категориальное состояние намерения.


5.2. Модуль 2: Биметаллический Планировщик (Архитектура)


Разделяет контент на потоки фактов и объяснений.
* Фактологическое ядро (RAG): Если намерение требует точности, запускается агентный RAG для извлечения сущностей. Используется двухэтапная проверка: поиск документов (Retrieval Agent) и синтез ответа (Response Synthesis Agent) с валидацией по бенчмаркам типа FACTS.49
* Планирование контента: Организация фактов в логическую последовательность (Content Planner). Это жесткая структура, устойчивая к деформации.14
* Выбор стиля: На основе $\alpha$ выбирается промпт-персона. Высокий $\alpha$ активирует режим «Сократический тьютор» (Socratic Tutor) с использованием скаффолдинга. Низкий $\alpha$ активирует режим «Исполнительное резюме».17


5.3. Модуль 3: Двигатель Расширения (Генерация)


Финальная генерация текста с применением техник посадки с натягом и температурных швов.
* Динамический Промптинг: Конструирование системного промпта на лету. Для высокого $\alpha$: «Используй аналогии, объясни контекст перед терминами». Для низкого $\alpha$: «Будь краток, используй буллиты, Chain of Density итерация 5».
* Петля Chain of Density: Для задач суммаризации запускается итеративный цикл уплотнения до достижения нужной плотности, соответствующей температуре пользователя.3
* Вставка Швов: Мониторинг буфера токенов. Если длина параграфа превышает порог когнитивной нагрузки, вставляется разрыв или проверочный вопрос.53


5.4. Таблица 2: Матрица Реализации Принципов ТРИЗ #37 в ИИ-Агентах




Компонент Метафоры
	Применение ТРИЗ
	Техническая Реализация (AI)
	Ожидаемый Эффект
	Источники
	Температура
	Уровень срочности / сложности
	Intent-Aware Scheduler (IAS), Intent Classifiers
	Синхронизация выхода с состоянием пользователя
	1
	Расширение
	Увеличение многословности
	High-Temperature Sampling, Chain-of-Thought
	Глубокое понимание, обучение
	1
	Сжатие
	Суммаризация
	Chain of Density, Progressive Summarization
	Снижение затрат токенов и нагрузки
	2
	Биметалл
	Двухслойный ответ
	Разделение Facts (RAG) и Style (LLM)
	Предотвращение галлюцинаций при сохранении стиля
	14
	Посадка с натягом
	Контекстная подгонка
	Contextual Priming, Scaffolding, ZPD
	Усвоение сложных терминов без отторжения
	24
	Термо-швы
	Управление нагрузкой
	Smart Chunking, Pagination, Break-points
	Предотвращение когнитивного утомления
	31
	________________


6. Вызовы и Стратегии Смягчения Рисков


Несмотря на надежность теоретической модели, практическая реализация сталкивается с рядом вызовов.


6.1. Термический Разгон (Галлюцинации)


В физике неконтролируемое расширение ведет к разрушению. В LLM установка слишком высокого $\alpha$ (чрезмерная креативность) без достаточного количества фактов («инвара») ведет к «разжижению» смысла и галлюцинациям.
* Стратегия: Внедрение ограничений по плотности фактов. Использование метрик FACTS Grounding в качестве регулятора. Если соотношение сгенерированных токенов к найденным доказательствам превышает безопасный порог, система автоматически запускает протокол «охлаждения», принуждая модель к верификации или сжатию.16


6.2. Гистерезис (Контекстная Инерция)


Физические материалы обладают гистерезисом — они не возвращаются в исходное состояние мгновенно после охлаждения. Агент также может «застрять» в многословном режиме, даже если пользователь переключился на короткие команды.
* Стратегия: Триггеры сброса состояния. IAS должен переоценивать $\alpha$ на каждом шаге, а не только в начале сессии.1 Резкое изменение длины реплик пользователя (например, переход от абзацев к односложным ответам) должно действовать как «термический шок», мгновенно сбрасывающий коэффициент расширения.


6.3. Когнитивная Усталость (Перегрев Пользователя)


Даже при идеальной калибровке способность пользователя воспринимать информацию снижается со временем.
* Стратегия: Мониторинг «температуры сессии». Если сессия затягивается, система должна постепенно снижать $\alpha$ независимо от намерений пользователя, переходя к более поддерживающим и суммаризирующим форматам взаимодействия, чтобы снизить нагрузку на рабочую память.56 Использование внешней памяти (Long-Term Memory) позволяет разгрузить текущий контекст.11
________________


7. Заключение: Дышащий Агент


Применение принципа ТРИЗ №37 «Тепловое расширение» к архитектуре ИИ позволяет совершить качественный скачок от статических вопросно-ответных машин к динамическим, «дышащим» агентам. Рассматривая объем информации не как константу, а как функцию от «температуры взаимодействия», мы создаем системы, уважающие физику человеческого познания.
Агент с «термическим расширением» понимает, что новичку требуется «тепло» объяснений и «посадка с натягом» для усвоения новых понятий. Он осознает, что эксперту в критической ситуации необходим «холодный», плотный ответ, подобный инвару. Он использует дисциплину «биметаллической пластины», чтобы удерживать факты неизменными даже при стилистическом расширении, и грамотно вставляет «температурные швы», чтобы диалог сохранял структурную прочность на протяжении длительного времени.
Данный термодинамический подход разрешает фундаментальное противоречие между краткостью и детализацией, предлагая единую теорию управления вербозностью LLM. Будущее интерфейсов ИИ лежит не в увеличении размеров контекстных окон, а в способности динамически расширять и сжимать этот контекст, подстраиваясь под контуры человеческого разума. Конечная цель — агент, который не просто генерирует текст, а респерирует смыслом: расширяясь, чтобы научить, сжимаясь, чтобы подтвердить, и всегда сохраняя структурную целостность истины.
Источники
1. Dynamic Adaptive Reasoning: Optimizing LLM Inference-Time ..., дата последнего обращения: ноября 25, 2025, https://www.preprints.org/manuscript/202511.0291/v1
2. Chain of Density (CoD) - Learn Prompting, дата последнего обращения: ноября 25, 2025, https://learnprompting.org/docs/advanced/self_criticism/chain-of-density
3. What is the Chain of Density in Prompt Engineering? - Analytics Vidhya, дата последнего обращения: ноября 25, 2025, https://www.analyticsvidhya.com/blog/2024/07/chain-of-density-in-prompt-engineering/
4. Better Summarization with Chain of Density Prompting - PromptHub, дата последнего обращения: ноября 25, 2025, https://www.prompthub.us/blog/better-summarization-with-chain-of-density-prompting
5. Unlocking GPT-4 Summarization with Chain of Density Prompting - KDnuggets, дата последнего обращения: ноября 25, 2025, https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting
6. Traditional RAG vs. Agentic RAG—Why AI Agents Need Dynamic Knowledge to Get Smarter, дата последнего обращения: ноября 25, 2025, https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/
7. Agentic RAG: turbocharge your RAG with query reformulation and self-query! - Hugging Face Open-Source AI Cookbook, дата последнего обращения: ноября 25, 2025, https://huggingface.co/learn/cookbook/en/agent_rag
8. Context Management Strategies - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/topics/context-management-strategies
9. Characterizing Prompt Compression Methods for Long Context Inference - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.08892v1
10. Effective context engineering for AI agents - Anthropic, дата последнего обращения: ноября 25, 2025, https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents
11. LLM Chat History Summarization Guide October 2025 - Mem0, дата последнего обращения: ноября 25, 2025, https://mem0.ai/blog/llm-chat-history-summarization-guide-2025
12. Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/396330662_Revisiting_the_Uniform_Information_Density_Hypothesis_in_LLM_Reasoning_Traces
13. Hua Wu (吴华) - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/people/hua-wu/
14. Natural Language Generation (NLG) - ijrpr, дата последнего обращения: ноября 25, 2025, https://ijrpr.com/uploads/V5ISSUE4/IJRPR25050.pdf
15. Natural Language Generation in the context of the Semantic Web - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/282723703_Natural_Language_Generation_in_the_context_of_the_Semantic_Web
16. FACTS Grounding: A new benchmark for evaluating the factuality of ..., дата последнего обращения: ноября 25, 2025, https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/
17. Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2025.findings-emnlp.1094.pdf
18. Dr Genré: Reinforcement Learning from Decoupled LLM Feedback for Generic Text Rewriting - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2503.06781v1
19. Structuring Reasoning for Complex Rules Beyond Flat Representations - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.05134v1
20. Learning to Plan for Language Modeling from Unlabeled Data - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/pdf?id=nT6fQIidrQ
21. A Hierarchical Model for Data-to-Text Generation - PMC - NIH, дата последнего обращения: ноября 25, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC7148215/
22. Advanced Prompt Engineering Techniques for Optimal Output - Phaedra Solutions, дата последнего обращения: ноября 25, 2025, https://www.phaedrasolutions.com/blog/advanced-prompt-engineering-techniques
23. Advanced Prompt Engineering Techniques: Examples & Best Practices - Patronus AI, дата последнего обращения: ноября 25, 2025, https://www.patronus.ai/llm-testing/advanced-prompt-engineering-techniques
24. 7 Scaffolding Learning Strategies for the Classroom - University of San Diego Professional & Continuing Ed, дата последнего обращения: ноября 25, 2025, https://pce.sandiego.edu/scaffolding-in-education-examples/
25. A Theory of Adaptive Scaffolding for LLM-Based Pedagogical Agents - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2508.01503v1
26. AI-Integrated Scaffolding to Enhance Agency and Creativity in K-12 English Language Learners: A Systematic Review - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2078-2489/16/7/519
27. Scaffolding Middle-School Mathematics Curricula With Large Language Models - EdWorkingPapers.com, дата последнего обращения: ноября 25, 2025, https://edworkingpapers.com/sites/default/files/ai24-1028_v2.pdf
28. Personalized Explainable AI: Dynamic Adjustment of Explanations for Novice and Expert Users | Jurnal Penelitian Pendidikan IPA, дата последнего обращения: ноября 25, 2025, https://jppipa.unram.ac.id/index.php/jppipa/article/download/12586/8360
29. [2310.09651] Lexical Entrainment for Conversational Systems - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2310.09651
30. Lexical Entrainment for Conversational Systems - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2023.findings-emnlp.22.pdf
31. Smart Chunking & Embeddings for RAG - DEV Community, дата последнего обращения: ноября 25, 2025, https://dev.to/ashokan/smart-chunking-embeddings-for-rag-4ok
32. Understanding What Matters for LLM Ingestion and Preprocessing - Unstructured, дата последнего обращения: ноября 25, 2025, https://unstructured.io/blog/understanding-what-matters-for-llm-ingestion-and-preprocessing
33. RAG Chunking Strategies That Actually Work (and Why Most Don't) - DEV Community, дата последнего обращения: ноября 25, 2025, https://dev.to/rajinh24/rag-chunking-strategies-that-actually-work-and-why-most-dont-49n2
34. Findings of the Association for Computational Linguistics: ACL 2025, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/volumes/2025.findings-acl/
35. One-Dimensional Object Detection for Streaming Text Segmentation of Meeting Dialogue | Request PDF - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/394271056_One-Dimensional_Object_Detection_for_Streaming_Text_Segmentation_of_Meeting_Dialogue
36. Accepted Findings Papers - ACL 2025, дата последнего обращения: ноября 25, 2025, https://2025.aclweb.org/program/find_papers/
37. Argumentative Experience: Reducing Confirmation Bias on Controversial Issues through LLM-Generated Multi-Persona Debates - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2412.04629v5
38. What is AI icon - Querio, дата последнего обращения: ноября 25, 2025, https://querio.ai/articles/what-is-ai-icon
39. The Cognitive Echo: Exploring the Neurological and Psychological Mechanisms Linking AI-Assisted Writing to Vivid Dreaming - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/387949547_The_Cognitive_Echo_Exploring_the_Neurological_and_Psychological_Mechanisms_Linking_AI-Assisted_Writing_to_Vivid_Dreaming
40. Pagination Design Tips and Examples to Improve Your Website Navigation - Halo Lab, дата последнего обращения: ноября 25, 2025, https://www.halo-lab.com/blog/pagination-design-tips-and-examples
41. Efficient Data Pagination in Angular: Implementing Smooth and Performant Pagination for Large Data Sets | by Hassaan Ali | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@hassaanali.dev/efficient-data-pagination-in-angular-implementing-smooth-and-performant-pagination-for-large-data-637fe994bbbf
42. Designing for Progressive Disclosure | by G. L. - Prototypr, дата последнего обращения: ноября 25, 2025, https://blog.prototypr.io/designing-for-progressive-disclosure-aabb5ddfbab4
43. Progressive Disclosure UI Patterns (PDP) - Agentic Design, дата последнего обращения: ноября 25, 2025, https://agentic-design.ai/patterns/ui-ux-patterns/progressive-disclosure-patterns
44. Essential UI Design Patterns Every AI Engineer Should Know | by inGrade - Medium, дата последнего обращения: ноября 25, 2025, https://ingrade.medium.com/essential-ui-design-patterns-every-ai-engineer-should-know-82bed36e1f84
45. Expanding Conversational User Interfaces - LukeW Ideation + Design, дата последнего обращения: ноября 25, 2025, https://www.lukew.com/ff/entry.asp?2018
46. UI Design Patterns: Innovative Ways to Highlight Elements in Your App - Chameleon.io, дата последнего обращения: ноября 25, 2025, https://www.chameleon.io/blog/new-design-patterns-highlighting-elements
47. Where should AI sit in your UI?. Mapping emerging AI UI patterns and how… | by Sharang Sharma | UX Collective, дата последнего обращения: ноября 25, 2025, https://uxdesign.cc/where-should-ai-sit-in-your-ui-1710a258390e
48. Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2411.12307v1
49. Building a Memory-Powered AI Agent: A Journey with Amazon Bedrock, Strands, and Mem0, дата последнего обращения: ноября 25, 2025, https://builder.aws.com/content/35INnEyn81OR4bDwujsvfkSUDzt/building-a-memory-powered-ai-agent-a-journey-with-amazon-bedrock-strands-and-mem0
50. Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.09136v1
51. Comparing Behavioral Patterns of LLM and Human Tutors: A Population-level Analysis with the CIMA Dataset - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2025.bea-1.64.pdf
52. Prompt Engineering Patterns Guide - GroqDocs, дата последнего обращения: ноября 25, 2025, https://console.groq.com/docs/prompting/patterns
53. GenAI — Managing Context History Best Practices | by VerticalServe Blogs - Medium, дата последнего обращения: ноября 25, 2025, https://verticalserve.medium.com/genai-managing-context-history-best-practices-a350e57cc25f
54. Extending Chat History through Dynamic Summarization Workflow · heshengtao comfyui_LLM_party · Discussion #93 - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/heshengtao/comfyui_LLM_party/discussions/93
55. Distilling from Dialogues: Finding Meaning in LLM Interactions - Hugging Face, дата последнего обращения: ноября 25, 2025, https://huggingface.co/blog/chansung/adaptive-summarization
56. Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2509.19517v1
57. Cognitive Overload Attack: Prompt Injection for Long Context - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=L5fZHoaUCF
58. Challenging Cognitive Load Theory: The Role of Educational Neuroscience and Artificial Intelligence in Redefining Learning Efficacy - PMC - PubMed Central, дата последнего обращения: ноября 25, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11852728/