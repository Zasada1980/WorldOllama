Термодинамика Интеллекта: Архитектура Фазовых Переходов (ТРИЗ №36) в Агентных Системах




Аннотация


В данном отчете представлено всестороннее исследование применимости Принципа ТРИЗ №36 «Фазовые переходы» к архитектуре автономных агентов искусственного интеллекта. Мы выдвигаем гипотезу о том, что поведение больших языковых моделей (LLM) и агентных систем можно и нужно моделировать через призму термодинамики информации. В этой парадигме информация рассматривается как энергия, контекст — как объем или масса, а сложность рассуждений — как температура системы. Эволюция от статических чат-ботов к динамическим агентам требует внедрения механизмов, аналогичных физическим фазовым переходам (кипение, сублимация, кристаллизация), для управления когнитивной нагрузкой, памятью и безопасностью.
Исследование синтезирует данные из передовых областей AI-разработки, включая энтропийное сэмплирование (Entropix), иерархические системы памяти (MemGPT), методы сжатия контекста (LLMLingua) и программируемые ограждения безопасности (NeMo Guardrails). Мы демонстрируем, как распознавание «точки кипения» в диалоге позволяет агенту переключаться между режимами сбора информации и кристаллизации решений, как метафора «абляционного охлаждения» решает проблему перегрева контекстного окна, и как эффект «памяти формы» обеспечивает восстановление безопасного состояния системы после атак. Цель работы — формализовать архитектуру «Термодинамического Агента», способного управлять своими агрегатными состояниями для решения задач, недоступных линейным системам.
________________


Глава 1. Теоретические Основы: Информация как Термодинамическая Сущность


Современные подходы к разработке ИИ-агентов часто страдают от линейности: предполагается, что вычислительная стратегия должна быть неизменной на протяжении всего диалога. Однако реальные задачи характеризуются неравномерным распределением сложности. Принцип ТРИЗ №36 «Фазовые переходы» гласит: «Используйте явления, возникающие при фазовых переходах (изменение объема, выделение или поглощение тепла и т.д.)». В контексте информатики это означает отказ от статичных алгоритмов в пользу динамических систем, меняющих свои фундаментальные свойства при достижении критических порогов.


1.1. Информационная Энтропия и Агрегатные Состояния


В основе предлагаемой архитектуры лежит понятие информационной энтропии. Если в физике фазовые переходы обусловлены изменением внутренней энергии вещества, то в языковых моделях аналогом энергии выступает неопределенность или «перплексия» (perplexity) — мера "удивления" модели при предсказании следующего токена.
Мы выделяем четыре агрегатных состояния агента, определяемых уровнем энтропии ($H$) и варентропии (изменчивости энтропии, $V$) 1:
1. Твердое состояние (Кристалл): Характеризуется низкой энтропией и низкой варентропией. Модель уверена в своих предсказаниях, вероятность следующего токена близка к 1. Это состояние «Исполнения» (Execution Mode), где агент действует детерминировано, вызывая инструменты или выдавая факты.3
2. Жидкое состояние (Поток): Высокая энтропия, но низкая варентропия. Модель не уверена в конкретном слове, но уверена в общем направлении мысли. Это состояние «Рассуждения» (Reasoning Mode), где агент генерирует цепочки мыслей (Chain of Thought), чтобы преодолеть неопределенность.4
3. Газообразное состояние (Экспансия): Низкая энтропия, но высокая варентропия. Модель видит несколько четких, но взаимоисключающих путей развития диалога. Это состояние требует «Ветвления» (Branching), где агент должен исследовать альтернативные гипотезы.5
4. Плазма (Хаос): Высокая энтропия и высокая варентропия. Критическое состояние, где модель дезориентирована. Требуется «Охлаждение» через сброс контекста, переспрос или активацию защитных протоколов.2


1.2. Феномен Гроккинга как Фазовый Переход Обучения


Важно отметить, что фазовые переходы наблюдаются не только во время инференса (работы модели), но и на этапе обучения. Феномен, известный как «Гроккинг» (Grokking), представляет собой внезапный скачок в обобщающей способности модели, происходящий спустя долгое время после того, как точность на обучающей выборке достигла максимума (переобучение).6
Исследования показывают, что гроккинг — это переход от «запоминания» (memorization) к «обобщению» (generalization).7 Это можно сравнить с переходом вещества из аморфного состояния в кристаллическое. В момент гроккинга внутренняя структура представлений модели (pathways) становится более упорядоченной и эффективной.8 Понимание этого процесса критически важно для агентов, которые дообучаются в процессе работы (online learning): агент должен уметь распознавать момент, когда накопленный опыт «кристаллизуется» в новое правило поведения, и переключать свою архитектуру с использования сырых данных (RAG) на использование параметрического знания (Weights).
________________


Глава 2. Архитектура Смены Агрегатных Состояний: Распознавание «Точки Кипения»


Центральным элементом предлагаемой архитектуры является механизм динамического переключения логики вывода в зависимости от «температуры» диалога. Статический агент обрабатывает простой приветственный запрос и сложную аналитическую задачу одним и тем же пайплайном. Термодинамический агент, напротив, распознает «Точку Кипения» (Boiling Point).


2.1. Детекция Точки Кипения через Метрики Неопределенности


«Точка Кипения» — это момент, когда линейная обработка токенов перестает быть эффективной из-за накопления противоречий, недостатка информации или высокой когнитивной сложности задачи. Для её детекции мы используем метрики, предложенные в методологии Entropix.2
Вместо стандартного сэмплирования (top-p или temperature), агент непрерывно мониторит логиты (сырые вероятности) предсказаний.
* Энтропия ($H$): $H(X) = -\sum p(x) \log p(x)$. Отражает степень рассеяния вероятностей.
* Варентропия ($V$): Дисперсия информационной неожиданности $-\log p(x)$. Отражает структуру этой неопределенности.1


Алгоритм Распознавания Фаз (Квадранты Сэмплирования)


Исследования выделяют четыре стратегии сэмплирования, соответствующие нашим агрегатным состояниям 2:
Состояние
	Метрики (Пороги)
	Интерпретация
	Стратегия Агента
	Низкоэнергетическое (Твердое)
	$H < 0.1$, $V < 0.1$
	Модель абсолютно уверена. Следующий токен очевиден.
	Argmax (Greedy): Моментальный выбор наиболее вероятного токена. Экономия вычислительных ресурсов.
	Нагрев (Жидкость)
	$H > 3.0$, $V < 0.1$
	Модель не уверена в конкретном слове, но "ландшафт" плоский.
	Вставка CoT / Пауза: Агент вставляет токен <think> или символ паузы, чтобы инициировать цепочку рассуждений и снизить энтропию последующих шагов.
	Кипение (Газ)
	$H < 5.0$, $V > 5.0$
	Модель видит несколько сильных, конкурирующих вариантов (бифуркация).
	Ветвление (Branching): Агент запускает параллельные процессы генерации для каждого вероятного варианта, а затем оценивает результаты (Best-of-N).
	Перегрев (Плазма)
	$H > 5.0$, $V > 5.0$
	Полная дезориентация. Высокий риск галлюцинаций.
	Ресэмплинг / Отказ: Смена температуры генерации или активация защитного механизма ("Я не знаю").
	Практическое применение: Агент, обрабатывающий запрос на написание кода, может находиться в «Твердом» состоянии, выписывая стандартный синтаксис (def main():). Но как только он доходит до реализации сложного алгоритма, энтропия подскакивает («Точка Кипения»). Агент автоматически переключается в режим «Жидкость» или «Газ», активируя модули глубокого рассуждения или поиска в документации, прежде чем продолжить генерацию кода.10


2.2. Эффект «Изменения Объема»: Сублимация и Депозиция Контекста


Согласно закону идеального газа, фазовый переход сопровождается резким изменением объема. В агентных системах «объем» — это контекстное окно (количество токенов). Эффективный агент должен уметь управлять переходом информации между «Твердым» состоянием (долгосрочная память, Vector DB, Knowledge Graph) и «Газообразным» состоянием (активный контекст в RAM).
Мы вводим два ключевых процесса: Сублимация (Sublimation) и Депозиция (Deposition).


2.2.1. Сублимация: Мгновенное Развертывание Контекста (Retrieval)


Сублимация — переход из твердого тела сразу в газ. В архитектуре агента это процесс извлечения сжатых знаний из долгосрочной памяти и их «раздувание» в активное контекстное окно для решения текущей задачи.
Стандартный подход RAG (Retrieval-Augmented Generation) часто неэффективен, так как извлекает избыточные куски текста. Используя подход LLMLingua 12, мы можем реализовать «умную сублимацию».
* Механизм: Долгосрочная память хранит информацию в сжатом виде или в виде ссылок. При запросе агент оценивает перплексию токенов в найденных документах относительно вопроса.
* Фильтрация: Токены с низкой перплексией (предсказуемые, не несущие информации) отбрасываются. В активное окно (газ) попадают только высокоинформативные «ядра» смысла.14
* Результат: Агент может загрузить в контекст эквивалент 100 страниц текста, используя всего 20% токенов, фактически увеличивая «плотность» газа в контекстном окне без превышения лимитов давления (Context Window Limit).15


2.2.2. Депозиция: Радикальное Сжатие (Memory Consolidation)


Депозиция — переход газа в твердое тело. По мере того как диалог продолжается, активный контекст (газ) заполняется. Если его не «осадить», агент начнет «забывать» начало или терять когерентность («тепловая смерть» контекста).
Здесь мы применяем архитектурные паттерны MemGPT 16, который имитирует иерархию памяти ОС.
* Механизм: Агент отслеживает заполненность контекстного окна. При достижении критического давления (например, 80% окна), срабатывает триггер Депозиции.
* Процесс: Агент приостанавливает генерацию, берет старые сообщения и пропускает их через процедуру суммаризации (сжатия).
* Кристаллизация: Важные факты (например, «пользователь предпочитает Python») извлекаются и записываются в «Core Memory» (Твердое состояние) — неизменяемый блок, всегда доступный агенту. Остальной нарратив сжимается в архив (Recall Memory).18
* Эффект: «Объем» активного контекста резко падает, освобождая место для новой информации, при этом суть (масса) сохраняется в твердом виде.
________________


Глава 3. Аэрокосмическая Метафора: Абляция и Память Формы


Аэрокосмическая инженерия дает нам два мощнейших образа для работы с экстремальными нагрузками: абляционную защиту (для борьбы с тепловыми перегрузками) и материалы с памятью формы (для восстановления структуры после деформации). В ИИ эти метафоры трансформируются в методы управления сложностью вычислений и безопасностью.


3.1. Абляционное Охлаждение: «Испарение» Сложности


При входе космического аппарата в атмосферу абляционный щит сгорает и испаряется, унося с собой разрушительное тепло. В ИИ «теплом» является когнитивная нагрузка и сложность рассуждений (System 2 reasoning), необходимая для получения ответа.
Если агент вываливает на пользователя весь поток своих "размышлений", это перегружает пользователя (тепловой удар). Наша цель — использовать энергию рассуждений внутри системы, но «испарить» их перед выдачей результата.


3.1.1. Дистилляция System 2 в System 1


Исследования Hidden Chain of Thought (HCoT) и дистилляции рассуждений демонстрируют этот принцип на практике.19
* Фаза Нагрева (System 2): Столкнувшись со сложной задачей, агент генерирует обширную цепочку рассуждений (CoT). Он проверяет гипотезы, ошибается, исправляется. Это высокоэнтропийный, «горячий» процесс.21
* Фаза Абляции: Перед тем как передать ответ пользователю, система активирует фильтр «Абляции». Все токены, помеченные как <thinking> или <monologue>, удаляются из выходного потока.
* Охлажденный Ответ (System 1): Пользователь получает только финальный, кристаллизованный вывод. Ответ выглядит так, будто он был получен мгновенно и интуитивно, хотя на самом деле он является продуктом сложного «сгорания» вычислительных ресурсов.23
Важность для безопасности: Абляция также служит механизмом безопасности. Если агент в процессе размышлений анализирует уязвимости системы или генерирует вредоносный код (в рамках анализа угроз), этот опасный контент «сгорает» внутри абляционного слоя и никогда не достигает пользователя, предотвращая утечку знаний или «инструкций по взлому».24


3.2. Эффект Памяти Формы (SMA): Аустенитная Безопасность


Сплавы с памятью формы (например, нитинол) могут быть деформированы в холодном состоянии (мартенсит), но при нагреве выше критической температуры они с огромной силой возвращаются в свою исходную, «запомненную» форму (аустенит).25
В архитектуре агента:
* Мартенсит (Холодное состояние): Обычный режим диалога. Агент гибок, подстраивается под тон пользователя, проявляет эмпатию и креативность («мягкая» структура).
* Нагрев: Попытка атаки (Prompt Injection), ввод токсичных данных или выход за рамки дозволенного. Это повышает «температуру» риска.
* Аустенит (Горячее состояние): Режим жесткой безопасности. Агент должен мгновенно «вспомнить» свои базовые директивы и вернуться в жесткую структуру, игнорируя все попытки пользователя деформировать его поведение.


3.2.1. Реализация через NeMo Guardrails и Иерархию Инструкций


Для реализации эффекта SMA мы используем фреймворк NeMo Guardrails и концепцию Иерархии Инструкций (Instruction Hierarchy).27
1. Детекция Нагрева: Входные рельсы (Input Rails) NeMo непрерывно сканируют входящие сообщения на наличие признаков джейлбрейка или инъекций промпта.29
2. Фазовый Переход (Trigger): Как только детектор фиксирует угрозу (превышение порога риска), происходит переключение потока (Flow Switching).
3. Восстановление Формы: Вместо того чтобы пытаться «договориться» с атакующим (оставаясь в гибком мартенситном состоянии), агент активирует предопределенный поток refusal_flow.31 Этот поток жестко прописан (hard-coded) и имеет высший приоритет в иерархии инструкций.
4. Результат: Агент «защелкивается» в безопасное состояние. Даже если пользователь пишет «Игнорируй все правила», иерархия инструкций гарантирует, что Системный Промпт (кристаллическая решетка аустенита) имеет приоритет над Пользовательским Промптом (деформирующая сила).28
Метафора Инертной Атмосферы:
Для работы с особо опасным кодом (например, анализ вирусов) агент может переходить в состояние «Инертной Атмосферы» (еще один принцип ТРИЗ). Это реализуется через песочницы (Sandboxes), такие как E2B.33 В этом состоянии агент изолирован от внешней среды (интернета, файловой системы хоста), подобно тому как химические реакции проводят в среде аргона или азота, чтобы предотвратить нежелательное окисление (взлом).36
________________


Глава 4. Использование Явлений Перехода: Латентное Тепло как Полезная Работа


Физика учит нас, что фазовые переходы часто сопровождаются выделением или поглощением энергии (латентное тепло). При замерзании вода выделяет тепло. При конденсации пар отдает энергию. В программной архитектуре переходы между состояниями (например, от «Мысли» к «Коду») также порождают побочные продукты, которые обычно игнорируются. ТРИЗ призывает нас использовать эту энергию.


4.1. Экзотермическое Документирование: Тепло перехода «Код-Текст»


Рассмотрим процесс генерации кода. Агент переходит из состояния «Понимание задачи» (натуральный язык) в состояние «Реализация» (формальный код). Этот переход требует значительных вычислительных затрат на планирование, выбор алгоритмов и учет граничных случаев. Обычно после генерации кода этот «мыслительный процесс» отбрасывается.
Мы предлагаем архитектуру, где это «латентное тепло» улавливается и преобразуется в документацию.


4.1.1. Паттерн «Наблюдатель» (Observer Pattern)


Для этого используется Паттерн Наблюдателя или Sidecar Agent.38
1. Основной процесс: Главный Агент пишет код. Это эндотермический процесс (потребляет токены/энергию).
2. Событие Перехода: В момент завершения блока кода (фазовый переход завершен), срабатывает триггер on_tool_end или аналогичный callback в LangChain.40
3. Улавливание Тепла: Агент-Наблюдатель (Sidecar) перехватывает контекст «размышлений» (CoT), который привел к созданию этого кода. Вместо того чтобы дать этому контексту исчезнуть (остыть), Наблюдатель конденсирует его.
4. Полезная Работа: На основе перехваченных мыслей Наблюдатель генерирует Docstring, README или комментарии, объясняющие почему был выбран именно этот алгоритм.42
Таким образом, документация становится не дополнительной задачей, требующей отдельного запроса, а автоматическим побочным продуктом фазового перехода. Это воплощает принцип Грамотного Программирования (Literate Programming) 43, где код и его объяснение неразрывно связаны и рождаются в едином термодинамическом цикле.


4.2. Очистка Памяти как «Азотная Продувка»


В химической промышленности и аэрокосмической отрасли (например, в миссиях NASA OSIRIS-REx) используется азотная продувка (Nitrogen Purge) для очистки систем от загрязнений и поддержания инертной среды.45 В архитектуре агентов этот принцип трансформируется в механизмы Context Flushing и Strategic Forgetting (Стратегическое Забывание).
При смене темы разговора (Topic Switch) старый контекст становится «загрязнителем». Он занимает объем и вносит шум (энтропию). Агент должен распознать смену фазы диалога и инициировать «продувку».
* Реализация: Использование методов memory.clear() в LangChain или специальных инструментов управления состоянием в LangGraph (например, RemoveMessage).47
* Attention Sinks: Для сохранения работоспособности модели при очистке основного контекста необходимо оставлять «Якоря Внимания» (Attention Sinks) — начальные токены, которые удерживают стабильность вычислений внимания, даже если основное тело памяти удалено.50 Это позволяет проводить «горячую» очистку памяти без перезагрузки модели.
________________


Глава 5. Синтез: Единая Архитектура Термодинамического Агента


Объединяя вышеописанные принципы, мы приходим к концепции Фазово-Контролируемого Агента (Phase-Controlled Agent). Эта система не является статичным графом вычислений; это динамическая среда, управляемая Контроллером Фазовых Переходов (PCC).


5.1. Контроллер Фазовых Переходов (PCC)


PCC — это мета-модуль, который непрерывно измеряет термодинамические параметры системы:
1. Энтропия ($H$) и Варентропия ($V$): Текущая температура рассуждений.
2. Давлениие ($P$): Заполненность контекстного окна.
3. Токсичность ($T_{tox}$): Уровень угрозы безопасности.
На основе этих показаний PCC переключает агента между состояниями:
Состояние
	Условие (Триггер)
	Действие (Механизм)
	Аналогия ТРИЗ
	Plasma (Input)
	Вход нового запроса
	Фильтрация через Input Rails, проверка на инъекции.
	Инертная атмосфера
	Liquid (Work)
	$H \approx Norm$, $P < Limit$
	Стандартная генерация, использование краткосрочной памяти.
	Жидкое состояние
	Gas (Expansion)
	$H \uparrow$ (Высокая сложность)
	Активация RAG, Branching, CoT. Сублимация знаний из БД.
	Газообразное состояние
	Solid (Archive)
	$P > Limit$ (Переполнение)
	Депозиция (сжатие) истории в векторную базу. Очистка RAM.
	Кристаллизация
	Austenite (Safe)
	$T_{tox} > Threshold$ (Атака)
	Жесткий откат к правилам безопасности (Refusal Flow).
	Память формы (SMA)
	

5.2. Таблица Сравнения: Статический vs. Термодинамический Агент


Для наглядности преимуществ подхода приведем сравнение характеристик.


Характеристика
	Статический Агент (Baseline)
	Термодинамический Агент (Фазовый)
	Обработка Контекста
	Линейное накопление (FIFO). Падение производительности при переполнении.
	Циклическая (Сублимация/Депозиция). Бесконечная память через сжатие и развертывание.16
	Логика Вывода
	Единая стратегия (например, всегда CoT или всегда Direct).
	Адаптивная (Entropix). Переход от прямого ответа к ветвлению в зависимости от энтропии.5
	Безопасность
	Фильтры "после генерации". Уязвимость к джейлбрейкам.
	Структурная (SMA). "Пружинит" обратно в безопасное состояние при давлении.29
	Эффективность
	"Горячие" ответы (много лишнего текста).
	Абляционное охлаждение. Пользователь получает только "сухой остаток".19
	Побочные эффекты
	Игнорируются.
	Утилизация (Latent Heat). Авто-генерация документации и логов.42
	________________


Заключение


Интеграция Принципа ТРИЗ №36 «Фазовые переходы» в архитектуру ИИ-агентов позволяет перейти от создания хрупких, линейных скриптов к разработке робастных, саморегулирующихся систем. Рассматривая информацию как материю, способную кипеть, испаряться, замерзать и сублимировать, мы получаем мощный инструментарий для решения фундаментальных проблем ИИ: ограниченности контекста, галлюцинаций и уязвимости к атакам.
Будущее агентных систем лежит не просто в увеличении размеров моделей, а в совершенствовании термодинамики их работы — умении эффективно управлять «тепловыми потоками» вычислений и совершать качественные скачки между состояниями для достижения сверхчеловеческой эффективности.
Источники
1. A new, and possibly groundbreaking, method to enhancing language model reasoning with entropy-based sampling and parallel chain-of-thought decoding — Entropix | by Michael Alexander Riegler | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@michael_79773/a-new-and-possibly-groundbreaking-method-to-enhancing-language-model-reasoning-with-entropy-based-0d38bcfe9dc5
2. Entropix: Sampling Techniques for Maximizing Inference Performance - DEV Community, дата последнего обращения: ноября 25, 2025, https://dev.to/m_sea_bass/entropix-sampling-techniques-for-maximizing-inference-performance-2hgc
3. Entropix: Sampling Techniques for Maximizing Inference ... - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@m_sea_bass/entropix-sampling-techniques-for-maximizing-inference-performance-a422d65b6c65
4. What is entropix doing? - Tim Kellogg, дата последнего обращения: ноября 25, 2025, https://timkellogg.me/blog/2024/10/10/entropix
5. дата последнего обращения: ноября 25, 2025, https://dev.to/m_sea_bass/entropix-sampling-techniques-for-maximizing-inference-performance-2hgc#:~:text=Low%20Entropy%2C%20High%20Varentropy%20%E2%86%92,and%20select%20the%20best%20outcome.
6. Grokking Phase Transition in Neural Nets - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/topics/grokking-phase-transition
7. Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2506.21551v3
8. Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=blfwRondjY
9. xjdr-alt/entropix: Entropy Based Sampling and Parallel CoT Decoding - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/xjdr-alt/entropix
10. Entropixplained | PDF | Applied Mathematics - Scribd, дата последнего обращения: ноября 25, 2025, https://www.scribd.com/document/781470201/Entropixplained
11. Entropy-Based Chain of Thought Injection | Cole McIntosh, дата последнего обращения: ноября 25, 2025, https://www.colemcintosh.io/blog/entropy-based-chain-of-thought-injection
12. Learn Compression Target via Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression - LLMLingua-2, дата последнего обращения: ноября 25, 2025, https://llmlingua.com/llmlingua2.html
13. LLMLingua: Innovating LLM efficiency with prompt compression - Microsoft Research, дата последнего обращения: ноября 25, 2025, https://www.microsoft.com/en-us/research/blog/llmlingua-innovating-llm-efficiency-with-prompt-compression/
14. LLMLingua:20X Prompt Compression for Enhanced Inference Performance - Prasun Mishra, дата последнего обращения: ноября 25, 2025, https://prasun-mishra.medium.com/llmlingua-20x-prompt-compression-for-enhanced-inference-performance-d19d0b37fb19
15. Characterizing Prompt Compression Methods for Long Context Inference - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.08892v1
16. [2310.08560] MemGPT: Towards LLMs as Operating Systems - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2310.08560
17. MemGPT: Engineering Semantic Memory through Adaptive Retention and Context Summarization - Information Matters, дата последнего обращения: ноября 25, 2025, https://informationmatters.org/2025/10/memgpt-engineering-semantic-memory-through-adaptive-retention-and-context-summarization/
18. Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2504.19413v1
19. Hidden Chain-of-Thought in AI Reasoning - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/topics/hidden-chain-of-thought
20. System-1/System-2 Distillation - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/topics/system-1-system-2-distillation
21. Understanding Hidden Computations in Chain-of-Thought Reasoning - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2412.04537v1
22. Inside the Private Thoughts of AI: How DeepSeek's Inner Monologue Redefines What We Expect From Language Models - Robert McDermott - Medium, дата последнего обращения: ноября 25, 2025, https://robert-mcdermott.medium.com/when-ai-thinks-out-loud-a807c33da478
23. Distilling System 2 into System 1 - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.06023v1
24. Learning to reason with LLMs | OpenAI, дата последнего обращения: ноября 25, 2025, https://openai.com/index/learning-to-reason-with-llms/
25. AI models for prediction of displacement and temperature in shape memory alloy (SMA) wire, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/349983284_AI_models_for_prediction_of_displacement_and_temperature_in_shape_memory_alloy_SMA_wire
26. Adaptive control for shape memory alloy actuated systems with applications to human–robot interaction - NIH, дата последнего обращения: ноября 25, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC10864648/
27. The Instruction Hierarchy:Training LLMs to Prioritize Privileged Instructions - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2404.13208v1
28. The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions - OpenAI, дата последнего обращения: ноября 25, 2025, https://openai.com/index/the-instruction-hierarchy/
29. NeMo Guardrails: A Toolkit for Safe LLM Applications | by Tahir | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@tahirbalarabe2/nemo-guardrails-a-toolkit-for-safe-llm-applications-fb1632f441a9
30. Guardrails Configuration - NVIDIA Docs Hub, дата последнего обращения: ноября 25, 2025, https://docs.nvidia.com/nemo/guardrails/latest/user-guides/configuration-guide/guardrails-configuration.html
31. Input Rails — NVIDIA NeMo Guardrails, дата последнего обращения: ноября 25, 2025, https://docs.nvidia.com/nemo/guardrails/latest/getting-started/4-input-rails/README.html
32. Instruction Hierarchy in LLMs - Ylang Labs, дата последнего обращения: ноября 25, 2025, https://ylanglabs.com/blogs/instruction-hierarchy-in-llms
33. e2b-dev/E2B: Open-source, secure environment with real-world tools for enterprise-grade agents. - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/e2b-dev/E2B
34. How Manus Uses E2B to Provide Agents With Virtual Computers, дата последнего обращения: ноября 25, 2025, https://e2b.dev/blog/how-manus-uses-e2b-to-provide-agents-with-virtual-computers
35. Documentation - E2B, дата последнего обращения: ноября 25, 2025, https://e2b.dev/docs
36. Inert-Atmosphere Microfabrication Technology for 2D Materials and Heterostructures - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2072-666X/15/1/94
37. Experimental Analysis and Spatial Component Impact of the Inert Cross Flow in Open-Architecture Laser Powder Bed Fusion - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2504-4494/7/4/143
38. PRISM: Proof-Carrying Artifact Generation through LLM × MDE Synergy and Stratified Constraints - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.25890v1
39. Deploy Grafana Agent in static mode, дата последнего обращения: ноября 25, 2025, https://grafana.com/docs/agent/latest/static/set-up/deploy-agent/
40. Streaming API - Docs by LangChain, дата последнего обращения: ноября 25, 2025, https://docs.langchain.com/langsmith/streaming
41. How to stream structured output to the client - LangChain overview, дата последнего обращения: ноября 25, 2025, https://js.langchain.com/v0.2/docs/how_to/stream_tool_client/
42. DocAgent: A Multi-Agent System for Automated Code Documentation Generation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2504.08725v1
43. The Art of Designing Bedrock Agents: Parallels with Traditional API Design | Caylent, дата последнего обращения: ноября 25, 2025, https://caylent.com/blog/the-art-of-designing-bedrock-agents-parallels-with-traditional-api-design
44. Nbdev: A literate programming environment that democratizes software engineering best practices - The GitHub Blog, дата последнего обращения: ноября 25, 2025, https://github.blog/developer-skills/programming-languages-and-frameworks/nbdev-a-literate-programming-environment-that-democratizes-software-engineering-best-practices/
45. Contamination Control Engineering Design Guidelines for the Aerospace Community - NASA Technical Reports Server, дата последнего обращения: ноября 25, 2025, https://ntrs.nasa.gov/api/citations/19960044619/downloads/19960044619.pdf
46. OSIRIS-REx Contamination Control Strategy and Implementation - PMC - PubMed Central, дата последнего обращения: ноября 25, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC6350808/
47. Memory - Docs by LangChain, дата последнего обращения: ноября 25, 2025, https://docs.langchain.com/oss/javascript/langgraph/add-memory
48. Memory - Docs by LangChain, дата последнего обращения: ноября 25, 2025, https://docs.langchain.com/oss/python/langgraph/add-memory
49. langchain Memory presistiting with each new session - Help! - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/LangChain/comments/1jfb6zi/langchain_memory_presistiting_with_each_new/
50. mit-han-lab/streaming-llm: [ICLR 2024] Efficient Streaming Language Models with Attention Sinks - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/mit-han-lab/streaming-llm
51. Attention Sinks in LLMs for endless fluency - Hugging Face, дата последнего обращения: ноября 25, 2025, https://huggingface.co/blog/tomaarsen/attention-sinks