ИНТЕГРАЦИЯ ПРИНЦИПА №23 (ОБРАТНАЯ СВЯЗЬ) В АРХИТЕКТУРУ САМОКОРРЕКТИРУЮЩИХСЯ АГЕНТОВ: ОТ ТЕОРИИ TRIZ К КИБЕРНЕТИКЕ LLM




1. Введение: Эволюция от Баллистических Систем к Кибернетическим Организмам


Современный ландшафт генеративного искусственного интеллекта (GenAI) переживает фундаментальный фазовый переход. Доминирующая парадигма последних лет, характеризующаяся архитектурами "разомкнутого цикла" (open-loop), достигла своего технологического плато. В таких системах процесс генерации текста подобен баллистическому выстрелу: пользователь задает начальные условия (промпт), и модель, подобно снаряду, летит по траектории вероятностного распределения токенов. После начала генерации ("выстрела") система слепа к отклонениям, неспособна к рефлексии в реальном времени и лишена механизмов активной коррекции курса до момента завершения ответа.
Данный отчет представляет собой всестороннее исследование, направленное на преодоление ограничений "разомкнутых" архитектур через призму Теории решения изобретательских задач (ТРИЗ), в частности, Принципа №23 "Обратная связь". Мы постулируем, что трансформация агентов из "вероятностных попугаев" в надежные инженерные системы требует внедрения рекурсивных контуров управления, аналогичных тем, что используются в аэрокосмической отрасли и биологических системах.


1.1 Кризис Стохастичности и Потребность в Управлении


Фундаментальная проблема больших языковых моделей (LLM) заключается в их стохастической природе. Без внешнего управления вероятность ошибки (галлюцинации, логического сбоя, потери контекста) накапливается с каждым сгенерированным токеном. Исследования показывают, что традиционные методы "prompt engineering" достигают предела эффективности, так как они пытаются "запрограммировать" траекторию снаряда до выстрела, не учитывая турбулентность семантического пространства во время полета.1
Применение Принципа №23 (Введение обратной связи) позволяет перейти от статической оптимизации промпта к динамической оптимизации процесса. Это сближает архитектуру агентов с кибернетикой второго порядка, где система становится наблюдателем собственных состояний. Как отмечают исследователи искусственного сознания (Artificial Consciousness, AC), эволюция ИИ в сторону большей автономности и креативности невозможна без сложных петель обратной связи и саморегуляции, свойственных биологическим организмам.1 Модель DIKWP (Data, Information, Knowledge, Wisdom, Purpose), применяемая в исследованиях AC, подчеркивает, что обратная связь является критическим механизмом для трансформации данных в мудрость и целеполагание, позволяя системе корректировать свои действия в соответствии с Идеальным Конечным Результатом (ИКР).


1.2 Три Контура Управления


Для всесторонней реализации Принципа №23 мы предлагаем трехуровневую архитектуру, охватывающую все аспекты функционирования агента:
1. Внутренний Контур (Internal Loop - Self-Correction): Когнитивный уровень. Агент "думает", критикует и исправляет себя до того, как выдать ответ пользователю. Это аналог "Системы 2" в человеческом мышлении (медленное, аналитическое мышление).
2. Системный Контур (Systemic Loop - Aerospace Metaphor): Уровень автоматического регулирования. Использование метафор Fly-By-Wire и FADEC для стабилизации диалога (гашение "рыскания" темы) и управления "температурой" генерации.
3. Внешний Контур (External Loop - User-in-the-Loop): Уровень валидации. Интеграция пользователя не как пассивного получателя, а как активного элемента системы управления, замыкающего цепь принятия решений.
Эта архитектура направлена на создание антихрупкой системы, которая использует ошибки и отклонения (сигналы обратной связи) не как сбои, а как информацию для уточнения траектории движения к решению задачи.
________________


2. Внутренний Контур (Internal Loop): Механизмы Моментальной Самокоррекции


Внутренний контур — это "автопилот" когнитивного процесса агента. Его задача — перехватить сырую генерацию модели, подвергнуть её критическому анализу и исправить ошибки до того, как они станут видимы пользователю. Это прямая реализация Принципа №23: "Если обратная связь есть, измените её величину или влияние". В контексте LLM это означает переход от линейной генерации к итеративной рефлексии.


2.1 Архитектура "Моментальной Критики" (Actor-Critic и Reflexion)


Традиционные LLM работают в режиме "Системы 1" по Канеману — быстрое, интуитивное, но подверженное ошибкам мышление. Для сложных задач требуется "Система 2" — медленная, логическая проверка. Реализация этого механизма в агентах опирается на паттерн Actor-Critic и архитектуру Reflexion.3


2.1.1 Механизм Reflexion: Лингвистический Градиент


В отличие от обучения с подкреплением (RL), где обратная связь представляет собой скалярное вознаграждение, в архитектуре Reflexion "градиентом" выступает текст — собственная самокритика агента. Этот процесс происходит целиком в контекстном окне.4
Алгоритм работы Внутреннего Контура:
1. Генерация Черновика (Drafting): Агент (Actor) генерирует первичный ответ $R_0$.
2. Оценка (Evaluation): Модуль "Критик" (Critic) анализирует $R_0$. Критик не генерирует решение, а проверяет его на соответствие фактам, логике и ограничениям. Исследования показывают, что LLM (особенно GPT-4) обладают эмерджентной способностью находить ошибки в собственных рассуждениях, даже если не могут сразу сгенерировать правильный ответ.6
3. Генерация Отражения (Reflection Generation): Критик формирует вербальную обратную связь $F$, перечисляя конкретные недостатки (например, "Цитата вымышленная", "Отсутствует шаг 3").
4. Исправление (Refinement): Агент получает $R_0$ и $F$ и генерирует исправленную версию $R_1$.
Компонент
	Роль
	Температура (T)
	Инструкция (System Prompt)
	Actor
	Генератор идей
	$0.7 - 0.9$
	"Предложи креативное решение задачи..."
	Critic
	Верификатор
	$0.0 - 0.2$
	"Ты — строгий аудитор. Найди логические ошибки и галлюцинации. Не исправляй, только критикуй."
	Revisor
	Редактор
	$0.2 - 0.5$
	"Перепиши текст, устранив указанные ошибки. Сохрани стиль."
	Этот цикл позволяет агенту вырваться из "галлюцинаторных спиралей". Важно отметить, что критика должна быть "конституционной" (Constitutional AI), то есть опираться на жестко заданные правила, а не на абстрактные ощущения "качества".6


2.1.2 Спекулятивное Декодирование как Форма Самокоррекции


Для снижения латентности внутреннего контура (основная проблема рекурсивных вызовов) можно использовать методы Спекулятивного Декодирования (Speculative Decoding).8 В этой схеме малая, быстрая модель (Draft Model) генерирует цепочку токенов ("спекуляцию"), а большая, мощная модель (Verifier Model) параллельно проверяет их вероятность.
Это техническая реализация Принципа №23 на уровне токенов:
* Малая модель предлагает гипотезу (Draft).
* Большая модель дает мгновенную обратную связь (Accept/Reject).
* Если токен отвергнут, большая модель корректирует траекторию.
Такой подход позволяет сохранить качество "сильной" модели при скорости "слабой", реализуя принцип самокоррекции на микро-уровне без необходимости полных циклов перезапроса.10


2.2 Принцип №23б ("Изменить Величину"): Адаптивная Глубина Верификации


ТРИЗ явно указывает: "Если обратная связь уже используется, измените её величину". Применение "сильной" верификации (полный цикл Reflexion) к каждой реплике (например, "Привет, как дела?") избыточно и дорого. Необходима архитектура Адаптивного Вычисления (Adaptive Computation Time).11


2.2.1 От "Слабой" к "Сильной" Обратной Связи


Мы предлагаем динамическую систему переключения режимов верификации в зависимости от типа задачи и уровня неуверенности модели.
Уровень 1: Слабая Обратная Связь (Spell-Check)
   * Механизм: Быстрая проверка на соответствие формату (JSON, Markdown) и отсутствие запрещенных слов.
   * Применение: Chit-chat, творческое письмо, простые запросы.
   * Реализация: Линейные пробы (Linear Probes) или легковесные классификаторы, работающие над скрытыми состояниями модели в реальном времени.13 Они сигнализируют о потенциальной проблеме без остановки генерации.
Уровень 2: Средняя Обратная Связь (Self-Correction)
   * Механизм: Внутренний диалог (Monologue) перед ответом. Модель генерирует "мысли" (...), оценивает их и только потом выдает ответ.
   * Применение: Логические рассуждения, саммаризация текстов, написание кода средней сложности.
   * Реализация: Использование паттернов "Chain-of-Thought" (CoT) с обязательным шагом самопроверки перед выводом.15
Уровень 3: Сильная Обратная Связь (Chain of Verification - CoVe)
   * Механизм: Разбиение ответа на атомарные факты, генерация независимых проверочных вопросов для каждого факта, поиск ответов (через RAG или инструменты) и синтез итогового ответа.16
   * Применение: Медицинские советы, финансовая аналитика, сложные инженерные расчеты.
   * Реализация: Агентная оркестрация (Captain Agent), где "Критик" имеет доступ к внешним инструментам (калькулятор, поисковик) для валидации фактов.17


2.2.2 Маршрутизация на Основе Уверенности (Confidence-Based Routing)


Как агент выбирает уровень? Используется метрика Энтропии Предикции. Если модель "сомневается" (распределение вероятностей токенов "размазано", высокая энтропия), система автоматически повышает уровень обратной связи.
Исследования показывают, что "слабые" генераторы часто производят ошибки, которые легче обнаружить, чем ошибки "сильных" генераторов. Однако парадоксально, но для сложных задач верификатор должен быть сопоставим по мощности с генератором.18
Использование Метакогнитивного Промптинга (Metacognitive Prompting) позволяет модели самой оценить сложность задачи: "Оцени вероятность ошибки в ответе. Если риск высок, перейди в режим глубокой верификации".19
________________


3. Аэрокосмическая Метафора: Системный Контур (Fly-By-Wire и FADEC)


Второй уровень интеграции Принципа №23 выходит за рамки проверки фактов и касается динамики диалога. Здесь уместна аналогия с современными самолетами, управляемыми через Электродистанционную систему (ЭДСУ / Fly-By-Wire). Пилот (пользователь) не управляет рулями напрямую; он выражает намерение, а компьютер интерпретирует его и исполняет, соблюдая эксплуатационные ограничения.


3.1 Демпфер Рыскания (Yaw Damper): Гашение Колебаний Темы


В авиации "рыскание" (Yaw) — это угловое движение носа самолета влево или вправо. Без демпфера самолет может войти в режим "голландского шага" (раскачка). В диалоге аналогом является Дрейф Темы (Topic Drift) или потеря контекста.20


3.1.1 Природа Диалоговых Осцилляций


LLM подвержены эффекту "Recency Bias" (смещение к недавнему). Если пользователь сделает небольшое отступление (оффтоп), модель может "зацепиться" за него и увести диалог далеко от изначальной цели (ИКР). Это похоже на неустойчивость по рысканию.


3.1.2 Реализация "Демпфера Рыскания" в Агенте


Для стабилизации используется механизм постоянного мониторинга вектора диалога относительно вектора цели.
   1. Гироскоп (Semantic Vector Anchor): В начале сессии формулируется "Вектор Цели" ($V_{goal}$) — эмбеддинг основной задачи (например, "Техническая поддержка принтера").
   2. Датчик Отклонения: Каждый новый промпт пользователя ($V_{turn}$) сравнивается с $V_{goal}$ через косинусное сходство (Cosine Similarity).
   3. Исполнительный Механизм (Actuator):
   * Если $Sim(V_{turn}, V_{goal}) > Threshold$: Диалог продолжается в штатном режиме.
   * Если $Sim(V_{turn}, V_{goal}) < Threshold$ (обнаружен дрейф): Активируется "Демпфер".
Стратегии Демпфирования (Repair Strategies):
Вместо грубого отказа ("Я не буду говорить об этом"), агент использует мягкие техники восстановления 22:
   * Soft Pivot (Мягкий разворот): "Это интересное наблюдение касательно [Оффтоп], но давайте вернемся к [Цель], чтобы решить вашу проблему."
   * Grounding (Заземление): "Чтобы мы не потеряли нить, напомню: мы сейчас на шаге 3 диагностики."
   * Clarification Loop (Петля уточнения): Если пользователь уходит в абстракцию, агент задает закрытый вопрос, возвращающий к конкретике.
Этот механизм работает как "Neural Barrier Function" (NBF), создавая невидимые границы безопасности вокруг диалога, не позволяя ему свалиться в нежелательные области (токсичность, галлюцинации).24


3.2 FADEC: Автоматическое Управление "Двигателем" Генерации


В авиации FADEC (Full Authority Digital Engine Control) управляет подачей топлива в двигатель, анализируя сотни параметров (температура, давление), чтобы обеспечить оптимальную тягу и предотвратить срыв потока. В ИИ "двигателем" является LLM, а "топливом" — параметры генерации (Tokens, Compute).


3.2.1 Датчики "Температуры" Диалога


Для реализации FADEC необходима система Аффективных Вычислений (Affective Computing), встроенная в контур агента.25 Мы анализируем не просто тональность (позитив/негатив), а более сложные метрики:
   * Confusion Index (Индекс Замешательства): Повторяющиеся вопросы, синтаксическая несвязность.
   * Frustration Level (Уровень Фрустрации): Капслок, обсценная лексика, короткие резкие фразы.
   * Engagement (Вовлеченность): Длина ответов, использование специфической терминологии.


3.2.2 Регулировка "Подачи Топлива" (Dynamic Parameter Adjustment)


На основе показаний датчиков FADEC динамически меняет гиперпараметры генерации для следующего ответа 27:
Сценарий А: "Перегрев" (Высокая Фрустрация)
   * Датчик: Frustration > 0.8.
   * Регулировка:
   * Temperature $\downarrow$ (0.1 - 0.3): Снижение случайности. Ответы должны быть максимально предсказуемыми и четкими.
   * Max Tokens $\downarrow$: Краткость. Раздраженный пользователь не хочет читать лекции.
   * Tone Injection: "Будь эмпатичным, кратким, извинись за неудобства."
Сценарий Б: "Срыв Потока" (Замешательство/Непонимание)
   * Датчик: Confusion High, пользователь просит перефразировать.
   * Регулировка:
   * Temperature $\uparrow$ (0.6 - 0.7): Увеличение креативности для поиска новых аналогий.
   * Max Tokens $\uparrow$: Развернутые объяснения.
   * Prompt Strategy: Включение "Chain-of-Thought" в вывод, чтобы пользователь видел логику решения.
Сценарий В: "Крейсерский Режим" (Исследование/Брейншторм)
   * Датчик: Sentiment Positive, Keywords: "Idea", "Draft", "Suggest".
   * Регулировка:
   * Top_P $\uparrow$: Расширение словарного запаса (Nucleus Sampling).30
   * Temperature $\approx$ 0.8 - 1.0: Максимальная вариативность.
Такой подход превращает агента из статичного бота в адаптивную систему, которая "чувствует" собеседника и подстраивает свой когнитивный стиль под ситуацию, подобно тому как FADEC обогащает смесь при форсаже.
________________


4. Внешний Контур (User-in-the-Loop): Человек как Часть Двигателя


Третий уровень интеграции Принципа №23 — это включение пользователя в контур управления. В традиционных системах человек — это внешний заказчик. В замкнутой системе человек — это валидатор и источник энтропии (информации), необходимой для схлопывания волновой функции неопределенности.


4.1 От Опции к Обязательству: Принудительные Контрольные Точки


Частая ошибка при проектировании агентов — попытка решить задачу end-to-end без промежуточных сверок. Это нарушает принцип обратной связи. Агент должен быть спроектирован как Конечный Автомат (Finite State Machine), где переход между состояниями невозможен без явного сигнала от пользователя.31
Архитектурный паттерн: Stepwise Chain of Thought
Вместо генерации полного отчета, агент разбивает задачу на этапы и использует паттерн "Stop-and-Confirm".33
   * Промпт-структура:"Твоя задача: Создать стратегию маркетинга.
ЭТАП 1: Сформулируй 3 гипотезы ЦА.
СТОП-КРИТЕРИЙ: Не переходи к Этапу 2, пока пользователь явно не выберет одну из гипотез. Если пользователь молчит или дает неясный ответ, задай уточняющий вопрос."
Этот подход превращает обратную связь из "опции" (пользователь может поправить) в "часть двигателя" (без пользователя двигатель глохнет). Это критически важно для задач с высокой ценой ошибки (юриспруденция, финансы).


4.2 Интерфейсы Взаимодействия (UI/UX)


Текстовый ввод ("Да", "Нет") часто неэффективен. Для реализации плотной обратной связи интерфейс агента должен поддерживать Структурированный Ввод.34
      * Кнопки Подтверждения: Вместо парсинга текста "Вроде норм", агент выводит UI-элементы [Approve] /.
      * Слайдеры Настройки: Пользователь может регулировать параметры FADEC вручную (например, слайдер "Кратко <-> Подробно" или "Официально <-> Креативно").
      * Edit-in-Place: Агент генерирует черновик, пользователь правит его прямо в окне чата, и исправленный текст становится контекстом для следующего шага (Few-Shot Learning на лету).


4.3 Метакогнитивные Промпты для Извлечения Знаний


Часто пользователь сам не знает, что ему нужно (проблема "Unknown Unknowns"). Агент должен использовать обратную связь для выявления скрытых требований.
Здесь работает техника Active Learning via Feedback:
      * Агент не просто спрашивает "Все верно?", а генерирует Дискриминативные Вопросы.
      * Пример: Вместо "Написать код на Python?", агент спрашивает: "Для этой задачи можно использовать Pandas (быстрее писать) или чистый Python (меньше зависимостей). Что важнее: скорость разработки или легковесность скрипта?"
Ответ пользователя служит мощнейшим сигналом обратной связи, отсекающим половину пространства поиска решений.35
________________


5. Архитектурный Синтез и Заключение: Сходимость к ИКР


Интеграция Принципа №23 на трех уровнях трансформирует саму суть работы AI Агента. Мы уходим от парадигмы "Вопрос-Ответ" к парадигме "Проблема-Решение через Итерацию".
Уровень
	Принцип TRIZ №23
	Механизм Реализации
	Результат
	Внутренний
	Самокоррекция
	Actor-Critic, Reflexion, CoVe
	Устранение фактических ошибок и логических сбоев до вывода.
	Системный
	Автоматическое регулирование
	Yaw Damper, FADEC, Sentiment Analysis
	Удержание контекста, адаптация тона, предотвращение дрейфа.
	Внешний
	Валидация
	Human-in-the-Loop, Stop-and-Confirm
	Сходимость к истинным потребностям пользователя, безопасность.
	

5.1 Синергия Контуров


Эти контуры не работают изолированно. Они образуют единую кибернетическую систему:
      * Внутренний контур снижает нагрузку на Внешний, исправляя очевидные ляпы, чтобы не тратить внимание пользователя.
      * Системный контур обеспечивает комфортную среду для работы Внутреннего, предотвращая эмоциональную дестабилизацию диалога.
      * Внешний контур поставляет "ground truth" (истину), которая калибрует Внутренний и Системный контуры (если пользователь постоянно поправляет тон, FADEC запоминает это смещение).


5.2 Будущее: Антихрупкость


Реализация такой архитектуры позволяет создать агентов, стремящихся к Идеальному Конечному Результату (ИКР) даже при неточных входных данных. В системе без обратной связи шум во входе приводит к хаосу на выходе. В системе с тройным контуром обратной связи шум фильтруется, а ошибки используются как обучающий сигнал. Агент становится антихрупким: чем сложнее и дольше диалог, тем точнее и эффективнее становится агент, накапливая контекст и обратную связь.
Таким образом, Принцип №23 перестает быть абстрактной эвристикой ТРИЗ и становится конкретным инженерным чертежом для создания надежных, автономных и полезных интеллектуальных систем нового поколения. Мы переходим от эры "Генеративного ИИ" к эре "Рефлексивного ИИ".
Источники
      1. DIKWP-TRIZ: A Revolution on Traditional TRIZ Towards Invention for Artificial Consciousness - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2076-3417/14/23/10865
      2. Deep Learning Meets TRIZ: A Systematic Review of Innovation Patterns in Neural Network Development - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/393654352_Deep_Learning_Meets_TRIZ_A_Systematic_Review_of_Innovation_Patterns_in_Neural_Network_Development
      3. Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.16062v1
      4. Building a Self-Correcting AI: A Deep Dive into the Reflexion Agent with LangChain and LangGraph | by Vi Q. Ha | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@vi.ha.engr/building-a-self-correcting-ai-a-deep-dive-into-the-reflexion-agent-with-langchain-and-langgraph-ae2b1ddb8c3b
      5. Reflection Agents - LangChain Blog, дата последнего обращения: ноября 25, 2025, https://blog.langchain.com/reflection-agents/
      6. Can LLMs Critique and Iterate on Their Own Outputs? | Eric Jang, дата последнего обращения: ноября 25, 2025, https://evjang.com/2023/03/26/self-reflection.html
      7. Self-Reflection in LLM Agents: Effects on Problem-Solving Performance - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2405.06682v1
      8. Speculative Decoding: Types and Optimizations - Aussie AI, дата последнего обращения: ноября 25, 2025, https://www.aussieai.com/research/speculative-decoding
      9. SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.02329v1
      10. Draft Model Knows When to Stop: Self-Verification Speculative Decoding for Long-Form Generation - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2025.emnlp-main.844/
      11. Think Just Enough: Sequence-Level Entropy as a Confidence Signal for LLM Reasoning, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.08146v1
      12. Confident Adaptive Language Modeling, дата последнего обращения: ноября 25, 2025, https://proceedings.neurips.cc/paper_files/paper/2022/file/6fac9e316a4ae75ea244ddcef1982c71-Paper-Conference.pdf
      13. Real-Time Detection of Hallucinated Entities in Long-Form Generation, дата последнего обращения: ноября 25, 2025, https://www.hallucination-probes.com/
      14. [2509.03531] Real-Time Detection of Hallucinated Entities in Long-Form Generation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2509.03531
      15. Zero-Shot Verification-guided Chain of Thoughts - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.13122v1
      16. PAIRS: Parametric–Verified Adaptive Information Retrieval and Selection for Efficient RAG, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2508.04057v1
      17. Adaptive In-conversation Team Building for Language Model Agents - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=uPwe2w78Wx
      18. [2509.17995] Variation in Verification: Understanding Verification Dynamics in Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2509.17995
      19. Metacognitive Prompting Improves Understanding in Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2308.05342v4
      20. Drift Detection in Large Language Models: A Practical Guide | by Tony Siciliani | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@tsiciliani/drift-detection-in-large-language-models-a-practical-guide-3f54d783792c
      21. Steering Conversational Large Language Models for Long Emotional Support Conversations - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2402.10453v2
      22. Using LLMs to Investigate Correlations of Conversational Follow-up Queries with User Satisfaction - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.13166v1
      23. Conversational repair strategies to cope with errors and breakdowns in customer service chatbot conversations - Tilburg University Research Portal, дата последнего обращения: ноября 25, 2025, https://research.tilburguniversity.edu/files/84289058/Braggaar_et_al_2023_Converstational_Repair_Strategies_And_Errors_preprint_Conversations.pdf
      24. Steering Dialogue Dynamics for Robustness against Multi-turn Jailbreaking Attacks - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2503.00187v1
      25. Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2408.04638v1
      26. Emotion Analysis AI Model for Sensing Architecture Using EEG - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2076-3417/15/5/2742
      27. What is LLM Temperature? - IBM, дата последнего обращения: ноября 25, 2025, https://www.ibm.com/think/topics/llm-temperature
      28. LLM Parameters Explained: A Practical, Research-Oriented Guide with Examples, дата последнего обращения: ноября 25, 2025, https://promptrevolution.poltextlab.com/llm-parameters-explained-a-practical-research-oriented-guide-with-examples/
      29. Understanding Temperature, Top P, and Maximum Length in LLMs - Learn Prompting, дата последнего обращения: ноября 25, 2025, https://learnprompting.org/docs/intermediate/configuration_hyperparameters
      30. My Guide to Fine-Tuning Top_p and Temperature in LLMs | by Adel Basli | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@adelbasli/taming-the-wild-imagination-fine-tuning-top-p-and-temperature-in-llms-2e7dac30658d
      31. Human-in-the-loop in AI workflows: Meaning and patterns - Zapier, дата последнего обращения: ноября 25, 2025, https://zapier.com/blog/human-in-the-loop/
      32. Implement human-in-the-loop confirmation with Amazon Bedrock Agents - AWS, дата последнего обращения: ноября 25, 2025, https://aws.amazon.com/blogs/machine-learning/implement-human-in-the-loop-confirmation-with-amazon-bedrock-agents/
      33. Must Known 4 Essential AI Prompts Strategies for Developers | by Reynald - Medium, дата последнего обращения: ноября 25, 2025, https://reykario.medium.com/4-must-know-ai-prompt-strategies-for-developers-0572e85a0730
      34. Human in the Loop · Cloudflare Agents docs, дата последнего обращения: ноября 25, 2025, https://developers.cloudflare.com/agents/concepts/human-in-the-loop/
      35. Human-in-the-Loop in Agentic Workflows: From Definition to Walkthrough Demo and Use Cases - Orkes, дата последнего обращения: ноября 25, 2025, https://orkes.io/blog/human-in-the-loop/