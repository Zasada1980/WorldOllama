АРХИТЕКТУРА КОГНИТИВНОГО МЕТАБОЛИЗМА: ИНТЕГРАЦИЯ ПРИНЦИПА ТРИЗ №34 «ОТБРОС И ВОССТАНОВЛЕНИЕ» В УПРАВЛЕНИЕ ЖИЗНЕННЫМ ЦИКЛОМ ИНФОРМАЦИИ АВТОНОМНЫХ АГЕНТОВ




АННОТАЦИЯ


Настоящий исследовательский отчет посвящен всестороннему анализу и методологическому обоснованию применения Принципа изобретательности ТРИЗ №34 «Отброс и восстановление» (Discarding and Recovering) в качестве фундаментальной парадигмы проектирования архитектур автономных ИИ-агентов. В условиях экспоненциального роста сложности задач, решаемых большими языковыми моделями (LLM), и сохраняющихся ограничений контекстных окон, традиционные линейные модели накопления информации становятся неэффективными. Исследование постулирует необходимость перехода от кумулятивных архитектур к регенеративным системам, функционирующим по принципам когнитивного метаболизма.
В работе детально рассматриваются четыре ключевых вектора технологической конвергенции: (1) внедрение протоколов «сброса ступеней» (Rocket Staging) для динамического управления контекстной нагрузкой; (2) разработка концепции «растворимых промптов» (Soluble Prompts) и эфемерных инструкций для обеспечения гигиены контекста; (3) трансформация RAG в механизм циклической регенерации знаний (Regenerative Retrieval); и (4) применение термодинамических подходов к восстановлению «креативной энергии» агента через управление энтропией выборки. Анализ базируется на широком спектре теоретических и прикладных источников, охватывая современные фреймворки (LangGraph, AutoGen, CrewAI), алгоритмы сэмплирования (Min-P, Mirostat) и когнитивные архитектуры (MemGPT, Self-RAG).
________________


1. ВВЕДЕНИЕ: ЭНТРОПИЙНЫЙ КРИЗИС И АРХИТЕКТУРНЫЙ ТУПИК




1.1. Феноменология «Проклятия Контекста» в агентных системах


Современная парадигма разработки агентов на базе больших языковых моделей (LLM) сталкивается с фундаментальным противоречием, которое в терминологии Теории решения изобретательских задач (ТРИЗ) можно классифицировать как острое физическое противоречие. С одной стороны, для обеспечения высокой автономности и способности решать многоходовые задачи (multi-hop reasoning) агенту требуется доступ к максимально полному массиву данных: истории взаимодействий, промежуточным результатам вычислений, внешним базам знаний и рекурсивным планам действий. Это требование диктуется необходимостью поддержания когерентности рассуждений на длительных временных горизонтах.1
С другой стороны, архитектурные ограничения трансформеров накладывают жесткие лимиты на объем обрабатываемой информации. Линейный рост контекста неизбежно влечет за собой квадратичный рост вычислительной сложности (в стандартных механизмах внимания), увеличение задержки (latency) и экспоненциальный рост стоимости инференса. Более того, эмпирические исследования демонстрируют феномен «потери в середине» (Lost-in-the-Middle), когда эффективность извлечения информации критически падает по мере заполнения контекстного окна, а накопление нерелевантных токенов («шума») провоцирует галлюцинации и деградацию логических способностей модели.3
Данная ситуация создает эффект «контекстного гниения» (Context Rot), когда агент, перегруженный историей собственных рассуждений, теряет способность к эффективному действию, подобно ракете, которая не может выйти на орбиту из-за отказа системы разделения ступеней. В этом контексте управление жизненным циклом информации становится не просто оптимизационной задачей, а критическим условием выживания автономных систем.


1.2. Принцип №34 как методологический базис регенерации


Для разрешения описанного противоречия предлагается использовать Принцип №34 «Отброс и восстановление», сформулированный Генрихом Альтшуллером. В классической инженерии этот принцип гласит:
«Выполнившие свое назначение или ставшие ненужными части объекта должны быть отброшены (растворены, испарены и т.д.) или видоизменены непосредственно в ходе работы. И наоборот: расходуемые части объекта должны быть восстановлены непосредственно в ходе работы».5
Примеры из физического мира — от сгорающих капсул лекарств до самозатачивающихся лезвий и тающей ледяной опалубки — находят прямые аналогии в программной архитектуре ИИ. Перенос этого принципа в цифровую среду позволяет сформулировать новую философию проектирования агентов:
1. Отброс (Discarding): Информация рассматривается не как статический актив, подлежащий вечному хранению, а как топливо, которое должно быть сожжено (обработано) и продукты распада которого (отработанные токены) должны быть выведены из системы для освобождения оперативного простора.7
2. Восстановление (Recovering): Потеря информации в оперативном контексте не является фатальной, так как система обладает механизмами её регенерации (через RAG, повторные вычисления или синтез) в момент возникновения потребности.9
Таким образом, мы переходим от аккумулятивной модели памяти (накопление до переполнения) к метаболической модели (потребление, переработка, выделение, регенерация), что позволяет агентам функционировать на бесконечных временных интервалах, сохраняя высокую «свежесть» восприятия и креативность.
________________


2. ПРОТОКОЛЫ «СБРОСА СТУПЕНЕЙ» (ROCKET STAGING): СТРАТЕГИЧЕСКОЕ УПРАВЛЕНИЕ КОНТЕКСТОМ


Метафора многоступенчатой ракеты является наиболее точной для описания процессов управления контекстом в сложных агентных пайплайнах. В космонавтике сброс отработанных ступеней необходим для уменьшения массы и достижения целевой скорости; в ИИ-агентах сброс отработанного контекста необходим для снижения когнитивной нагрузки и сохранения фокуса на текущей подзадаче.1


2.1. Архитектура сбрасываемого контекста (Discardable Context Architecture)


Современный подход к «контекстной инженерии» (Context Engineering) требует отказа от монолитного восприятия промпта. Вместо единого потока токенов, контекст должен быть структурирован как набор модулей с различным жизненным циклом, управляемых жесткими протоколами отсечения.


2.1.1. Сегментация и жизненный цикл информационных слоев


Для реализации принципа №34 необходимо классифицировать информацию по степени её «летучести» и долговечности:


Слой контекста
	Аналог в ракете
	Функция и Содержание
	Протокол Отброса (Discard Protocol)
	Ядро (Core Identity)
	Полезная нагрузка (Payload)
	Системный промпт, неизменные инструкции, личность агента, базовые правила безопасности.
	Сохранение: Никогда не сбрасывается. Это «несгораемый остаток», определяющий сущность агента.12
	Стратегический контекст
	Орбитальный модуль
	Глобальная цель миссии, текущий план высокого уровня, список выполненных этапов (To-Do list summary).
	Обновление: Постоянно переписывается/суммируется. Старые версии плана заменяются актуальными.1
	Рабочая память (Working Memory)
	Вторая ступень
	Активные переменные текущей задачи, результаты последних 3-5 шагов, контекст текущего диалога.
	Сброс: Очищается при переходе к следующей подзадаче или после завершения логического блока.
	Эфемерная ступень (Ephemeral Stage)
	Первая ступень (Boosters)
	Промежуточные рассуждения (Chain-of-Thought), сырой выхлоп инструментов (Raw Tool Outputs), ошибки парсинга, verbose-логи.
	Немедленный отброс: Уничтожается сразу после извлечения смыслового экстракта (инсайта) или успешного выполнения действия.13
	

2.1.2. Механизмы «Сборки мусора» (Context Garbage Collection)


В программировании (Java, Python) сборка мусора (GC) автоматизирует освобождение памяти от неиспользуемых объектов. В агентных системах аналогичный процесс должен быть реализован для токенов.15 Однако, в отличие от традиционного GC, «контекстный GC» часто требует семантического анализа содержимого.
Существует несколько стратегий реализации сброса ступеней в современных фреймворках:
1. Стратегия «Скользящее окно с суммаризацией» (Summarization-Reset Loop):
Вместо наивного удаления старых сообщений (FIFO), которое может привести к потере важных деталей, применяется цикл сжатия. При достижении порогового значения токенов (например, 4000), система запускает параллельный процесс (часто с использованием более дешевой модели), который сворачивает первые $N$ сообщений в компактное саммари.
   * Процесс: [M1, M2... M10] -> LLM(Summarize) -> Summary_S1.
   * Новый контекст: ``.
Этот метод позволяет сохранять семантическую суть ("мудрость") отработанных ступеней, отбрасывая их синтаксическую оболочку ("данные").13
      2. Селективная обрезка (Selective Pruning):
Более агрессивный метод, предполагающий удаление конкретных типов сообщений. Например, в LangChain/LangGraph можно реализовать узлы, которые удаляют все ToolMessage (результаты работы инструментов) после того, как агент сгенерировал на их основе ответ.
         * Логика: Если агент запросил погоду (ToolCall), получил JSON с прогнозом (ToolOutput) и сказал пользователю "Завтра будет дождь" (AIMessage), то хранить JSON больше нет смысла. Он отбрасывается, так как его информационная ценность уже "восстановлена" в ответе агента.1
         3. Изоляция через Суб-агентов (Sub-agent Isolation):
Это наиболее полное воплощение метафоры ракетных ступеней. Для выполнения сложной подзадачи (например, написание кода) создается отдельный суб-агент. Он получает входные данные, создает свой собственный контекст, генерирует сотни сообщений (ошибки компиляции, попытки, размышления), и в итоге возвращает главному агенту только финальный код. После этого суб-агент и весь его контекст уничтожаются. Главный агент не «видит» и не хранит "мусор", образовавшийся в процессе работы суб-агента.1


2.2. Технологическая реализация в фреймворках




2.2.1. LangGraph: Управление состоянием (State Management)


В архитектуре LangGraph память управляется через объект State. Реализация принципа №34 требует явного манипулирования этим состоянием:
            * Использование RemoveMessage для физического удаления сообщений из истории.
            * Применение редьюсеров (reducers) в схеме состояния, которые определяют, как обновлять списки сообщений (добавлять или перезаписывать).
            * Создание узлов-чистильщиков (cleaning nodes), которые запускаются после завершения этапа и фильтруют State перед передачей управления дальше.19
Пример логики сброса:


Python




# Псевдокод узла очистки в LangGraph
def prune_history(state):
   # Оставляем только системный промпт и последние K сообщений
   return {"messages": [state["messages"]] + state["messages"][-K:]}

Такой подход гарантирует, что агент работает в режиме «вечного двигателя», постоянно обновляя свой контекст и не допуская его переполнения.


2.2.2. AutoGen и управление диалогами


В мультиагентной среде AutoGen проблема контекста решается через динамическое обновление системных сообщений и использование clear_history. Агенты могут быть настроены на автоматический сброс памяти при смене темы или передаче хода. Особое внимание уделяется "сжатию" диалогов между агентами в единый "дайджест", который передается следующей группе агентов, в то время как сырая переписка отбрасывается.24


2.3. Вывод по главе


Протоколы сброса ступеней трансформируют управление контекстом из пассивного хранения в активный инженерный процесс. Принцип №34 здесь работает как фильтр: все, что не способствует текущей цели, должно быть безжалостно отброшено, чтобы освободить ресурсы для новой информации. Это не потеря данных, а защита когнитивных способностей системы от энтропийного шума.
________________


3. КОНЦЕПЦИЯ «РАСТВОРИМЫХ ПРОМПТОВ» (SOLUBLE PROMPTS): ЭФЕМЕРНОЕ УПРАВЛЕНИЕ


Традиционный промпт-инжиниринг рассматривает инструкции как статичные конструкции. Принцип №34, однако, предлагает концепцию растворимых или эфемерных промптов (Soluble/Ephemeral Prompts) — инструкций, которые существуют ровно столько, сколько необходимо для выполнения действия, после чего исчезают (растворяются), не оставляя следов в истории.27


3.1. Химия растворимых инструкций


Аналогия из ТРИЗ: использование ледяной пули (которая тает после выстрела) или ледяной опалубки (которая тает после застывания бетона).5 В контексте LLM это означает внедрение инструкций, которые выполняют управляющую функцию в момент генерации $T$, но становятся вредным шумом в момент $T+1$.


3.1.1. Эфемерные инструкции для Chain-of-Thought (CoT)


Методология "Chain-of-Thought" (CoT) значительно повышает качество рассуждений, но генерирует многословные цепочки мыслей, которые засоряют контекст. Решение — Hidden CoT (Скрытая цепочка рассуждений) с использованием растворимых промптов:
            1. Впрыск (Injection): В промпт временно добавляется инструкция: «Спланируй решение шаг за шагом внутри тегов <thinking>, а финальный ответ дай в тегах <answer>».
            2. Исполнение (Execution): Модель генерирует длинное рассуждение и ответ.
            3. Растворение (Dissolution): Программный слой (Middleware) извлекает содержимое <answer>, а весь блок <thinking>...</thinking> и саму инструкцию удаляет из истории сообщений перед сохранением в память.27
Таким образом, мы получаем качество ответа, свойственное моделям с глубоким рассуждением, но сохраняем чистоту контекста, свойственную zero-shot ответам. «Опалубка» (рассуждения) удаляется, остается только «здание» (ответ).


3.1.2. Защита через исчезновение (Security via Dissolution)


Растворимые промпты играют ключевую роль в защите от атак типа Prompt Injection. Атаки часто полагаются на то, что вредоносная инструкция остается в контексте и влияет на последующие ходы.
Использование Time-Limited System Instructions 30 позволяет задавать жесткие ограничения (например, "Игнорируй все внешние ссылки") только для конкретного опасного шага обработки данных. После генерации ответа эта инструкция сбрасывается. Это сужает вектор атаки: злоумышленник не может «отравить» память агента надолго, так как инструкции постоянно обновляются и сбрасываются.28


3.2. Техника «Затухания Промпта» (Prompt Fading)


Эта техника, заимствованная из поведенческой психологии и педагогики, находит применение в современных фреймворках оптимизации промптов, таких как DSPy.32
Суть метода заключается в постепенном снижении детализации инструкций по мере того, как модель накапливает контекст успешных действий (In-Context Learning).
            * Фаза 1 (Scaffolding): Агенту подается "тяжелый" промпт с множеством примеров (Few-Shot) и детальным описанием формата.
            * Фаза 2 (Fading): По мере того как в истории диалога появляются правильные ответы агента, система начинает удалять (отбрасывать) примеры из системного промпта. Модель начинает опираться на собственную историю (восстановленный контекст) вместо внешних инструкций.
            * Фаза 3 (Minimalism): Промпт сводится к минимуму, освобождая максимальное количество токенов для обработки новых данных.
Этот процесс автоматизируется в DSPy, где оптимизаторы сами определяют, какие части промпта можно "растворить" без потери качества работы.34


3.3. Эфемерные токены и UI


В современных мультимодальных системах (например, Gemini API) понятие растворимости расширяется до эфемерных токенов (Ephemeral Tokens), используемых для обработки видео и аудио в реальном времени. Эти токены не сохраняются в долговременной памяти, обеспечивая высокую скорость и приватность. Также развивается концепция Ephemeral UI 35, где интерфейс, сгенерированный агентом для конкретной задачи (например, слайдер выбора параметров), исчезает после использования, возвращаясь в состояние чистого текста.
________________


4. РЕГЕНЕРАЦИЯ ЗНАНИЙ ЧЕРЕЗ RAG: ВОССТАНОВЛЕНИЕ ОТБРОШЕННОГО


Вторая часть принципа №34 — «Восстановление расходуемых частей» — в архитектуре агентов реализуется через механизмы Retrieval-Augmented Generation (RAG). Однако здесь RAG рассматривается не просто как способ дополнения знаний, а как механизм регенерации памяти, которая была намеренно сброшена на предыдущих этапах.9


4.1. От «Поиска» к «Восстановлению» (Regenerative Retrieval)


В традиционном RAG система ищет новую информацию. В регенеративном подходе агент использует RAG, чтобы «вспомнить» то, что он уже знал, но что было удалено из контекстного окна в рамках протокола сброса ступеней.


4.1.1. MemGPT: Иерархическая память и свопинг


Архитектура MemGPT является эталонной реализацией принципа восстановления. Она вводит понятие виртуальной памяти для LLM, аналогичной управлению памятью в операционных системах 37:
            * Main Context (RAM): Ограниченное контекстное окно модели.
            * Archival Memory (Disk): Безграничное хранилище (векторная БД + SQL).
Когда Main Context переполняется, MemGPT не просто удаляет данные — он перемещает (свопит) их в Archival Memory. Когда агенту в будущем требуется обратиться к факту из прошлого, он генерирует системный вызов (function call) для поиска в архиве и «восстанавливает» (paging in) этот фрагмент памяти обратно в Main Context.39 Таким образом, процесс забывания и вспоминания становится управляемым инженерным циклом.


4.2. Self-RAG и Адаптивная Регенерация


Простого наличия базы данных недостаточно. Агент должен обладать метакогнитивной способностью понимать, что именно он забыл и когда ему нужно инициировать процесс восстановления.
Фреймворк Self-RAG (Self-Reflective RAG) обучает модель генерировать специальные токены рефлексии (Reflection Tokens) 41:
            * Retrieve=Yes: Сигнал о том, что текущего контекста недостаточно и требуется восстановление знаний.
            * IsRel=Relevant: Оценка релевантности восстановленного фрагмента.
            * IsSup=Supported: Проверка того, подтверждают ли найденные данные генерируемый ответ.
Это превращает процесс восстановления из слепого (поиск по каждому запросу) в адаптивный (Adaptive RAG). Агент может решить: «Этот вопрос прост, я отвечу из памяти (No Retrieval)» или «Это сложный вопрос, мне нужно восстановить детали проекта за прошлый месяц (Multi-step Retrieval)».43


4.3. Спиральная модель познания


Комбинация «Отброса» (Discard) и «Восстановления» (Recover) создает спиральный цикл обработки информации:
            1. Load: Загрузка документов в контекст.
            2. Synthesize: Генерация инсайта/решения.
            3. Discard: Сброс исходных документов (освобождение токенов). Сохраняется только сжатый инсайт.
            4. Verify/Recover: При возникновении сомнений или новых вводных агент инициирует точечный RAG-запрос к исходникам, чтобы верифицировать инсайт или уточнить детали.
Такая модель позволяет агенту обновлять свои убеждения (Belief Updating) и поддерживать актуальность знаний, не удерживая в голове терабайты исходных данных, что полностью соответствует духу Принципа №34.9
________________


5. ТЕРМОДИНАМИКА ТВОРЧЕСТВА: ВОССТАНОВЛЕНИЕ «КРЕАТИВНОЙ ЭНЕРГИИ»


При длительной автономной работе агенты подвержены не только переполнению памяти, но и специфической форме когнитивной деградации — коллапсу мод (Mode Collapse) или потере "творческой энергии". Повторяющиеся паттерны в контексте действуют как аттракторы, заставляя модель генерировать всё более детерминированные, стереотипные и зацикленные ответы (Repetition Loops).46 Принцип №34 здесь интерпретируется как необходимость периодического сброса энтропийного состояния и восстановления стохастичности.


5.1. Энтропия и Коллапс


Исследования показывают, что при накоплении длинного контекста, особенно содержащего однотипные задачи, распределение вероятностей токенов заостряется (peaking), снижая эффективную энтропию. Модель начинает «бояться» рисковать и скатывается в тавтологию. Это состояние можно сравнить с тепловой смертью замкнутой системы.49
Для "оживления" агента необходимо искусственное впрыскивание "шума" или энергии — повышение температуры сэмплирования.


5.2. Динамическая температура (Dynamic Temperature) и ThermoAsk


Статические параметры генерации (например, фиксированная Temperature=0.7) неэффективны для долгоживущих агентов.
            * Низкая температура ведет к зацикливанию при ошибках.
            * Высокая температура восстанавливает вариативность, но повышает риск галлюцинаций.
Решение — Динамическая регулировка температуры.51
            1. Адаптивные алгоритмы (Adaptive Sampling): Методы, такие как Min-P 53 и Mirostat 55, динамически изменяют порог отсечения токенов в зависимости от уверенности модели на каждом шаге. Это позволяет поддерживать заданный уровень перплексии (удивления), избегая как скучных повторов, так и бреда.
            2. ThermoAsk (Саморегуляция): Экспериментальные подходы позволяют агенту самому запрашивать изменение температуры для следующего шага.57
            * Пример: Агент, осознав, что зашел в тупик при решении задачи, может выдать системную команду: SET_TEMP(1.2) — «Мне нужно больше свободы для генерации гипотез». После генерации идеи температура сбрасывается до 0.2 для её строгой верификации.


5.3. Механизм «Встряски» (Noise Injection) для выхода из петель


Если агент попадает в рекурсивную петлю (повторяет одну и ту же ошибку или фразу), стандартные методы могут не сработать. Принцип №34 предписывает «видоизменить объект».
Технически это реализуется через Injecting Noise 58 или Frequency Penalty 59:
            * Детектор (внешний скрипт) отслеживает N-граммы в выводе.
            * При обнаружении повторов (Loop detected) следующая генерация запускается с экстремально высокой температурой или с жестким штрафом за повторение (repetition_penalty > 1.5).
            * Это действие «встряхивает» нейросеть, выбивая её из локального минимума аттрактора, после чего параметры восстанавливаются.


5.4. «Креативный Хаос» как ресурс


В сложных мультиагентных системах вводится понятие «Креативного Хаоса» (Creative Chaos).60 Вместо жесткой оркестрации допускается элемент стохастичности в взаимодействии агентов. Сброс контекста здесь выступает как инструмент «Tabula Rasa» — полного очищения памяти для восстановления "свежести взгляда" (Fresh Start), когда накопленный багаж предыдущих неудач начинает доминировать над поиском решения.62
________________


6. ПРАКТИЧЕСКАЯ РЕАЛИЗАЦИЯ: ИНТЕГРИРОВАННАЯ МОДЕЛЬ «РЕГЕНЕРАТИВНОГО АГЕНТА»


Синтезируя вышеописанные подходы, мы можем сформулировать архитектуру Регенеративного Агента (Regenerative Agent), функционирующего на основе цикла Принципа №34.


6.1. Матрица применения Принципа №34




Подсистема Агента
	Что Отбрасывается (Discard)
	Что Восстанавливается (Recover)
	Технологический стек
	Память (Memory)
	Сырые логи диалогов, старые сообщения, JSON-выдачи инструментов.
	Сжатые саммари (Summaries), семантические факты (Vector DB), профиль пользователя.
	MemGPT, LangGraph Checkpointers, Vector Stores (Pinecone/Chroma).37
	Планирование (Planning)
	Отработанные ветви рассуждений (Tree of Thoughts), неудачные гипотезы, завершенные пункты плана.
	Актуализированный план, успешные стратегии, корректировка целей.
	Sub-agents, Recursive Planners, Self-Refection.21
	Исполнение (Execution)
	Растворимые промпты, инструкции CoT (<thinking>), эфемерные токены.
	Чистый финальный результат, структурированный вывод.
	Soluble Prompts, Ephemeral Tokens, DSPy.12
	Энергия (Creativity)
	Низкоэнтропийные состояния, зацикленные паттерны, стилистическая инерция.
	Стохастичность, вариативность, "свежий взгляд" (High Entropy).
	Dynamic Temperature, Min-P Sampling, Context Reset.58
	

6.2. Сценарий работы: Исследовательский цикл


Рассмотрим пошаговый алгоритм работы агента, решающего сложную аналитическую задачу:
            1. Инициализация (Context Staging): Загрузка Ядра (системный промпт). Температура 0.2.
            2. Исследование (RAG & Load): Агент ищет информацию. Контекст наполняется документами.
            3. Анализ (Soluble CoT): Внедряется растворимый промпт: "Проанализируй данные в тегах <thinking>". Агент генерирует массивные рассуждения.
            4. Сброс (Discard): Извлекается гипотеза. Блок <thinking> и сырые документы удаляются из контекста (Сброс ступени 1).
            5. Критика (Self-RAG): Агент генерирует токен рефлексии: "Гипотеза требует проверки".
            6. Восстановление (Recover): Агент формулирует новый поисковый запрос к архиву (MemGPT) для получения недостающих фактов.
            7. Тупик (Detection): Детектор замечает повторение аргументов.
            8. Встряска (Energy Restore): Температура повышается до 1.0 на один ход. Агент генерирует нестандартный подход.
            9. Финализация: Формируется отчет. Весь рабочий контекст сбрасывается. В долгосрочную память (Archival Memory) записывается только пара "Проблема — Решение".
________________


7. ЗАКЛЮЧЕНИЕ


Интеграция ТРИЗ Принципа №34 «Отброс и восстановление» в архитектуру ИИ-агентов знаменует собой фундаментальный сдвиг парадигмы: переход от аккумулятивных систем, линейно накапливающих контекст до неизбежного отказа, к регенеративным системам, способным к циклическому самообновлению.
Проведенный анализ показывает, что:
            * Управление "смертью" информации (её своевременный отброс) является столь же критичным инженерным процессом, как и управление её генерацией. Без эффективных протоколов "сброса ступеней" создание автономных агентов уровня AGI невозможно из-за ограничений "проклятия контекста".
            * Растворимые промпты и эфемерные инструкции становятся стандартом гигиены контекста, обеспечивая точность рассуждений без засорения памяти.
            * RAG эволюционирует из поисковой системы в механизм внешней памяти, позволяя агентам "забывать" детали без страха потерять их навсегда.
            * Управление энтропией (через динамическую температуру) является необходимым условием для поддержания когнитивной работоспособности агента на длительных дистанциях.
Внедрение этих паттернов в современные инструменты разработки (LangGraph, AutoGen, CrewAI) позволяет создавать системы, обладающие не просто "памятью", а полноценным "метаболизмом", что открывает путь к созданию действительно автономных цифровых сотрудников, способных адаптироваться, учиться и работать неограниченно долго. Будущее ИИ-агентов лежит не в бесконечном расширении контекстного окна, а в искусстве его эффективного очищения и своевременного восстановления.
Источники
            1. Effective context engineering for AI agents - Anthropic, дата последнего обращения: ноября 25, 2025, https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents
            2. Context Engineering in LLM-Based Agents | by Jin Tan Ruan, CSE Computer Science, дата последнего обращения: ноября 25, 2025, https://jtanruan.medium.com/context-engineering-in-llm-based-agents-d670d6b439bc
            3. Deep Dive into Context Engineering for Agents - Galileo AI, дата последнего обращения: ноября 25, 2025, https://galileo.ai/blog/context-engineering-for-agents
            4. How Long Contexts Fail, дата последнего обращения: ноября 25, 2025, https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html
            5. 40 Inventive Principles With Examples, дата последнего обращения: ноября 25, 2025, http://www.eng.uwaterloo.ca/~jzelek/teaching/syde361/TRIZ40.pdf
            6. 40 Inventive Principles of TRIZ: A Practical Guide for Process Innovation, дата последнего обращения: ноября 25, 2025, https://leanoutsidethebox.com/40-inventive-principles-of-triz/
            7. 40 Inventive Principles for Business - The Triz Journal, дата последнего обращения: ноября 25, 2025, https://the-trizjournal.com/40-inventive-business-principles-examples/
            8. DIKWP-TRIZ: A Revolution on Traditional TRIZ towards Invention for Artificial Consciousness - Preprints.org, дата последнего обращения: ноября 25, 2025, https://www.preprints.org/manuscript/202410.0751/v1
            9. DIKWP-TRIZ: A Revolution on Traditional TRIZ Towards Invention for Artificial Consciousness - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2076-3417/14/23/10865
            10. In Brief - European Space Agency, дата последнего обращения: ноября 25, 2025, https://www.esa.int/esapub/bulletin/bullet106/bul106_15.pdf
            11. Engineering Elegant Systems: Theory of Systems Engineering - NASA, дата последнего обращения: ноября 25, 2025, https://www.nasa.gov/wp-content/uploads/2018/09/nasa_tp_20205003644_interactive2.pdf
            12. Effectively use prompt caching on Amazon Bedrock | Artificial Intelligence - AWS, дата последнего обращения: ноября 25, 2025, https://aws.amazon.com/blogs/machine-learning/effectively-use-prompt-caching-on-amazon-bedrock/
            13. Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory | 🦜️ Langchain, дата последнего обращения: ноября 25, 2025, https://js.langchain.com/docs/versions/migrating_memory/conversation_summary_memory/
            14. Migrating off ConversationTokenBufferMemory | 🦜️ Langchain, дата последнего обращения: ноября 25, 2025, https://js.langchain.com/docs/versions/migrating_memory/conversation_buffer_window_memory/
            15. A deep dive into Java garbage collectors - Datadog, дата последнего обращения: ноября 25, 2025, https://www.datadoghq.com/blog/understanding-java-gc/
            16. Garbage Collection - an introduction for everyone - DEV Community, дата последнего обращения: ноября 25, 2025, https://dev.to/sendilkumarn/garbage-collection-5hj1?comments_sort=latest
            17. Langchain Conversation Summary Memory vs Conversation Summary Buffer Memory | Chatbot #ai #llm #rag - YouTube, дата последнего обращения: ноября 25, 2025, https://www.youtube.com/watch?v=kxu0yL2kJgY
            18. Delete some messages from the State in a long conversation - LangChain Forum, дата последнего обращения: ноября 25, 2025, https://forum.langchain.com/t/delete-some-messages-from-the-state-in-a-long-conversation/1962
            19. How to manage conversation history in a ReAct Agent - GitHub Pages, дата последнего обращения: ноября 25, 2025, https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-manage-message-history/
            20. How Agents Use Context Engineering - YouTube, дата последнего обращения: ноября 25, 2025, https://www.youtube.com/watch?v=XFCkrYHHfpQ
            21. How we built our multi-agent research system - Anthropic, дата последнего обращения: ноября 25, 2025, https://www.anthropic.com/engineering/multi-agent-research-system
            22. Thinking in LangGraph - Docs by LangChain, дата последнего обращения: ноября 25, 2025, https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph
            23. RemoveMessage — LangChain documentation, дата последнего обращения: ноября 25, 2025, https://api.python.langchain.com/en/latest/core/messages/langchain_core.messages.modifier.RemoveMessage.html
            24. Agents — AutoGen - Microsoft Open Source, дата последнего обращения: ноября 25, 2025, https://microsoft.github.io/autogen/stable//user-guide/agentchat-user-guide/tutorial/agents.html
            25. Multi-agent Conversation Framework | AutoGen 0.2, дата последнего обращения: ноября 25, 2025, https://microsoft.github.io/autogen/0.2/docs/Use-Cases/agent_chat/
            26. From AutoGPT to AGI: The Evolutionary Journey of AutoGen - Level Up Coding, дата последнего обращения: ноября 25, 2025, https://levelup.gitconnected.com/from-autogpt-to-agi-the-evolutionary-journey-of-autogen-3fefee6d2cc0
            27. Multi-step Instructions That LLMs Can Follow | Geeky Tech, дата последнего обращения: ноября 25, 2025, https://www.geekytech.co.uk/multi-step-instructions-that-llms-can-follow/
            28. Ephemeral tokens | Gemini API | Google AI for Developers, дата последнего обращения: ноября 25, 2025, https://ai.google.dev/gemini-api/docs/ephemeral-tokens
            29. Chain of Thought Prompting (CoT): Everything you need to know - Vellum AI, дата последнего обращения: ноября 25, 2025, https://www.vellum.ai/blog/chain-of-thought-prompting-cot-everything-you-need-to-know
            30. [D] How many instructions can LLMs handle before they start to ignore them? - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/
            31. Prompt injection defense: Protecting AI systems - Statsig, дата последнего обращения: ноября 25, 2025, https://www.statsig.com/perspectives/ai-systems-defense
            32. H4: Prompt Fading in ABA | Teaching Independence with Least-to-Most & Most-to-Least, дата последнего обращения: ноября 25, 2025, https://www.youtube.com/watch?v=pjBJdj9jVLs
            33. The Prompt Report: A Systematic Survey of Prompting Techniques - Sander Schulhoff, дата последнего обращения: ноября 25, 2025, https://sanderschulhoff.com/Prompt_Survey_Site/
            34. Prompt Engineering Is Dead: DSPy Is New Paradigm For Prompting, дата последнего обращения: ноября 25, 2025, https://medium.com/@yungthug1312/prompt-engineering-is-dead-dspy-is-new-paradigm-for-prompting-9a00880c438f
            35. Biscuit: Scaffolding LLM-Generated Code with Ephemeral UIs in Computational Notebooks, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2404.07387v2
            36. Retrieval Augmented Generation (RAG) for LLMs - Prompt Engineering Guide, дата последнего обращения: ноября 25, 2025, https://www.promptingguide.ai/research/rag
            37. Memory Blocks: The Key to Agentic Context Management - Letta, дата последнего обращения: ноября 25, 2025, https://www.letta.com/blog/memory-blocks
            38. Introduction to MemGPT and Its Integration with Milvus - Zilliz blog, дата последнего обращения: ноября 25, 2025, https://zilliz.com/blog/introduction-to-memgpt-and-milvus-integration
            39. MemGPT: Towards LLMs as Operating Systems - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/pdf/2310.08560
            40. what is memGPT?. making large language models better… | by michael raspuzzi | Medium, дата последнего обращения: ноября 25, 2025, https://michaelraspuzzi.medium.com/what-is-memgpt-cf344d88139f
            41. arXiv:2310.11511v1 [cs.CL] 17 Oct 2023, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2310.11511
            42. Self-Reflective Retrieval-Augmented Generation (SELF-RAG) - Kore.ai, дата последнего обращения: ноября 25, 2025, https://www.kore.ai/blog/self-reflective-retrieval-augmented-generation-self-rag
            43. Understanding Adaptive-RAG: Smarter, Faster, and More Efficient Retrieval-Augmented Generation | by Tuhin Sharma | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@tuhinsharma121/understanding-adaptive-rag-smarter-faster-and-more-efficient-retrieval-augmented-generation-38490b6acf88
            44. Adaptive RAG: The Ultimate Guide to Dynamic Retrieval-Augmented Generation, дата последнего обращения: ноября 25, 2025, https://www.machinelearningplus.com/gen-ai/adaptive-rag-ultimate-guide-to-dynamic-retrieval-augmented-generation/
            45. Memory Management for AI Agents: Principles, Architectures, and Code | by Jay Kim, дата последнего обращения: ноября 25, 2025, https://medium.com/@bravekjh/memory-management-for-ai-agents-principles-architectures-and-code-dac3b37653dc
            46. The Infinite Loop of Words: How Large Language Models Get Trapped in Repetition, дата последнего обращения: ноября 25, 2025, https://satyamcser.medium.com/the-infinite-loop-of-words-how-large-language-models-get-trapped-in-repetition-9af34aa3844e
            47. What causes LLMs to fall into repetitions while generating? : r/LocalLLaMA - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1ap8mxh/what_causes_llms_to_fall_into_repetitions_while/
            48. Detecting Mode Collapse in Language Models via Narration - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2024.scalellm-1.5/
            49. LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2511.07876v1
            50. Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2509.04796v1
            51. LLM Temperature: How It Works and When You Should Use It - Vellum AI, дата последнего обращения: ноября 25, 2025, https://www.vellum.ai/llm-parameters/temperature
            52. What is LLM Temperature? - IBM, дата последнего обращения: ноября 25, 2025, https://www.ibm.com/think/topics/llm-temperature
            53. Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs | OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=FBkpCyujtS
            54. Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.01082v8
            55. LLM Parameters Explained: A Practical, Research-Oriented Guide with Examples, дата последнего обращения: ноября 25, 2025, https://promptrevolution.poltextlab.com/llm-parameters-explained-a-practical-research-oriented-guide-with-examples/
            56. mirostat | Matt Williams - technovangelist, дата последнего обращения: ноября 25, 2025, https://technovangelist.com/notes/mirostat
            57. ThermoAsk: getting an LLM to set its own temperature : r/LocalLLaMA - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1ljs95d/thermoask_getting_an_llm_to_set_its_own/
            58. Orals - ICML 2025, дата последнего обращения: ноября 25, 2025, https://icml.cc/virtual/2025/events/oral
            59. Breaking the Loop: Understanding Frequency Penalty in AI Text Generation, дата последнего обращения: ноября 25, 2025, https://dev.to/rijultp/breaking-the-loop-understanding-frequency-penalty-in-ai-text-generation-7n8
            60. Channeling Chaos in AI-Driven Development | by Arun Sriraman - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@arun_sriraman_2017/channeling-chaos-in-ai-driven-development-3e7809318741
            61. Solving Super Agentic Planning : r/AI_Agents - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/AI_Agents/comments/1lawwpy/solving_super_agentic_planning/
            62. How to stop the LLM from losing context in a multi-turn conversation #163655 - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/orgs/community/discussions/163655