Архитектуры избыточности и частичности: Интеграция принципа ТРИЗ №16 в проектирование автономных агентов




Аннотация


В современной разработке интеллектуальных агентов на базе больших языковых моделей (LLM) доминирует парадигма «zero-shot» перфекционизма — ожидание, что агент способен принять сложную инструкцию и выдать идеальный, завершенный результат за один проход инференса. Однако эмпирические данные и практика внедрения показывают, что такой подход часто ведет к «параличу перфекционизма»: модели либо галлюцинируют, пытаясь заполнить пробелы в знаниях, либо выдают усредненные, безопасные ответы, игнорируя специфику запроса. Данный отчет представляет собой исчерпывающее исследование методов интеграции принципа ТРИЗ №16 «Частичное или Избыточное действие» в архитектуру ИИ-агентов. Принцип постулирует, что если достижение 100% заданного результата ресурсоемко или невозможно напрямую, следует либо выполнить действие с избытком, а затем удалить лишнее, либо выполнить его частично, оставив финализацию внешней системе или пользователю.
В отчете детально рассматриваются две стратегические ветви реализации этого принципа. Первая — стратегия избыточности, включающая методы Best-of-N Sampling, Parallel Decoding и Speculative Decoding для генерации множества гипотез, а также Parent Document Retrieval и Knowledge Buffering для создания контекстных буферов в RAG-системах. Вторая — стратегия частичности, охватывающая архитектуры Skeleton-of-Thought и Plan-and-Solve для создания MVP-ответов, а также методы Uncertainty Quantification для честного отказа от генерации ненадежного контента. Особое внимание уделяется аэрокосмической метафоре «технологических припусков» и «покрытий», которые операционализируются через шаблоны Human-in-the-Loop (HITL), Placeholders и Iterative Pruning. Исследование демонстрирует, как переход от линейной генерации к итеративным циклам расширения и сжатия информации позволяет создавать робастные, экономически эффективные и доверенные агентные системы.
________________


1. Стратегия Избыточности: Архитектуры «Over-Generate & Filter»


Фундаментальная проблема детерминированного инференса в LLM заключается в том, что наиболее вероятная последовательность токенов (greedy decoding) не всегда соответствует наиболее качественному решению задачи. Принцип №16 предлагает решать эту проблему через Избыточное действие: замену неопределенности вычислениями. Генерируя избыточное количество вариантов решения, путей рассуждения или контекстных данных, агент создает статистический буфер, внутри которого с высокой вероятностью содержится оптимальный ответ. Главным техническим вызовом здесь становится не генерация, а эффективная фильтрация и управление ресурсами.


1.1 Техническая реализация выборки Best-of-N и параллельной генерации


Стратегия «Over-Generate & Filter», известная в технической литературе как Best-of-N (BoN) или Rejection Sampling, трансформирует процесс инференса из линейного пути в ветвящееся дерево решений. Вместо того чтобы полагаться на одну попытку генерации, система инициирует $N$ независимых процессов, создавая пространство решений, которое затем сужается до единственного оптимального выхода.1


1.1.1 Параллелизм на этапе генерации и спекулятивное декодирование


Для реализации стратегии избыточности без критического увеличения задержки (latency) архитекторы должны использовать возможности параллельного декодирования. Современные движки инференса, такие как vLLM или TGI, позволяют обрабатывать пакеты (batching), где $N$ последовательностей генерируются одновременно на одном GPU. Это возможно благодаря тому, что префикс (промпт) обрабатывается единожды, а ветвление происходит только на этапе генерации новых токенов. Хотя это увеличивает нагрузку на память (KV-кэш), рост времени выполнения часто сублинеен, что делает генерацию 5-10 вариантов экономически оправданной для задач высокой ценности.3
Критической оптимизацией в этом процессе является Спекулятивное Декодирование (Speculative Decoding). В этой архитектуре используется принцип иерархической генерации: меньшая и более быстрая «черновая модель» (Draft Model) генерирует последовательность токенов (избыточный черновик), который затем верифицируется параллельно более крупной «целевой моделью» (Target Model).
* Механизм действия: Черновая модель предлагает $K$ токенов вперед. Целевая модель за один проход проверяет вероятность этих токенов. Если черновик совпадает с распределением целевой модели, токены принимаются. Если нет — отвергаются и корректируются.
* Связь с Принципом №16: Черновая модель выполняет «избыточное» предсказание, рискуя ошибиться, чтобы ускорить общий процесс. Это классический пример того, как создание избыточного материала (черновых токенов) позволяет быстрее достичь финального результата.1
* PARD (Parallel Draft Decoding): Новейшие методы, такие как PARD, позволяют адаптировать черновые модели для параллельной генерации, достигая ускорения до 4x на моделях семейства LLaMA3, что делает стратегию избыточности доступной даже для resource-constrained сред.7


1.1.2 Фильтрация: Верификаторы и Модели Вознаграждения (Reward Models)


После того как агент «перегенерировал» варианты (например, 5 вариантов кода или 3 саммари), система должна отфильтровать лишнее без участия пользователя. Этот этап «сжатия» критичен для UX. Для этого используются Верификаторы и Модели Вознаграждения (Reward Models — RM).
* Детерминированные Верификаторы: В задачах с четкими критериями успеха (например, генерация кода или математика) фильтрация может быть жесткой. Агент генерирует 10 вариантов решения задачи, и каждый прогоняется через интерпретатор кода или тестовый кейс. Варианты, вызвавшие ошибку выполнения (Runtime Error), отбрасываются. Среди оставшихся выбирается наиболее эффективный по времени исполнения или использованию памяти.2
* Process-Based Reward Models (PRM): Для субъективных задач (креативное письмо, саммаризация) используется модель, обученная на человеческих предпочтениях (RLHF). Она присваивает каждому из $N$ вариантов скалярную оценку качества. Система выдает пользователю только вариант с наивысшим скором ($y_{best} = \arg\max(Score(y_i))$).9
* Self-Truncation Best-of-N: Продвинутые реализации используют методы ранней остановки. Модель оценивает перспективность ветки генерации на промежуточных этапах. Если кумулятивная вероятность или промежуточная оценка качества падает ниже порога, генерация этой ветки прерывается. Это создает «воронку», где избыточность максимальна на старте, но быстро отсекается, экономя вычислительные ресурсы.1


1.1.3 Self-Consistency: Избыточность в рассуждениях


Особым подтипом стратегии избыточности является Self-Consistency Prompting, применяемая для задач, требующих сложной логики (Chain-of-Thought). Здесь избыточность применяется не к финальному ответу, а к пути рассуждения.
Агент генерирует множество (например, 10 или 40) независимых цепочек рассуждений для одного и того же вопроса. Поскольку ошибки в LLM часто стохастичны (галлюцинации случайны), ошибочные цепочки рассуждений, скорее всего, приведут к разным неправильным ответам. В то же время корректные логические пути будут конвергировать к одному и тому же ответу. Алгоритм «голосования большинства» (Majority Voting) выбирает ответ, который встречается чаще всего, отсекая шум одиночных ошибок.10
Таблица 1: Сравнительный анализ архитектур избыточной генерации
Архитектура
	Механизм Избыточности
	Логика Фильтрации (Сжатия)
	Ресурсный компромисс
	Оптимальный сценарий применения
	Best-of-N (BoN)
	Генерация $N$ полных ответов
	Reward Model / Verifier Score
	Высокие затраты вычислений / Высокое качество текста
	Креативное письмо, Саммаризация, Рерайтинг
	Self-Consistency
	Генерация $N$ цепочек рассуждений (CoT)
	Majority Voting / Консенсус ответов
	Высокие затраты / Высокая точность
	Математика, Логика, QA со сложным выводом
	Speculative Decoding
	Генерация $K$ черновых токенов вперед
	Принятие/Отвержение целевой моделью
	Низкая задержка / Высокая пропускная способность
	Real-time чат-боты, Автодополнение кода
	Tree of Thoughts
	Генерация $N$ ветвей на каждом шаге мысли
	Look-ahead оценка / Бэктрекинг
	Очень высокие затраты / Глубокое планирование
	Стратегическое планирование, Сложное решение проблем
	

1.2 Принцип «Запаса знаний»: Избыточное извлечение контекста (RAG)


В системах Retrieval Augmented Generation (RAG) принцип «Частичности» часто реализуется наивно: извлекается только тот фрагмент текста, который имеет максимальное векторное сходство с запросом. Это часто приводит к потере контекста («context amputation»), когда факт вырван из окружения и интерпретируется неверно. Принцип №16 предлагает решать это через Knowledge Buffering — стратегическое извлечение избыточного контекста.


1.2.1 Parent Document Retrieval (Поиск родительского документа)


В этой архитектуре процесс индексации и поиска разделен. Для поиска используются мелкие фрагменты (chunks), обеспечивающие высокую точность семантического совпадения. Однако для генерации используется не найденный фрагмент, а его «Родительский документ» или значительно более крупное окно.12
* Механизм: Документы разбиваются на мелкие «дочерние» чанки (child chunks) и связываются с более крупными «родительскими» чанками (parent chunks). Векторный поиск идет по дочерним элементам. При нахождении совпадения (hit) извлекается весь родительский блок.
* Преимущество избыточности: Это создает «буфер знаний». Если пользователь задает уточняющий вопрос, касающийся деталей, соседствующих с исходным фактом, агент уже имеет эту информацию в контекстном окне. Это устраняет необходимость повторного обращения к базе данных (round-trip latency) и позволяет LLM видеть причинно-следственные связи, которые могли быть потеряны при нарезке на мелкие чанки.14
* Техническая реализация: Библиотеки, такие как LangChain и LlamaIndex, реализуют это через хранилища InMemoryStore для родительских документов и векторные индексы для дочерних, связывая их через doc_id.15


1.2.2 Sentence Window Retrieval и временная буферизация


Аналогично работает метод Sentence Window Retrieval. Система находит конкретное предложение, наиболее релевантное запросу, но передает в LLM окно из $k$ предложений до и после него.17 В агентах, работающих с потоковыми данными (real-time data), применяется Temporal Knowledge Buffering. Агент поддерживает в памяти буфер последних событий, превышающий текущую потребность запроса. Это гарантирует, что при необходимости анализа «недавней истории» данные уже предзагружены и выровнены, предотвращая задержки на подгрузку («state lag») и обеспечивая консистентность восприятия динамической среды.20
Эта стратегия избыточности контекста напрямую адресует проблему «паралича отсутствующей информации». Предоставляя агенту чуть больше фона, чем строго необходимо, мы даем ему возможность отвечать с нюансами и обрабатывать имплицитные запросы, которые строгая точечная выборка пропустила бы.
________________


2. Стратегия Частичности: Архитектуры «MVP Response»


Если стратегия избыточности меняет вычисления на качество, то стратегия «Частичного действия» меняет полноту на скорость, безопасность и управляемость. Этот подход признает, что несовершенный, но быстрый прототип (MVP) часто ценнее для пользователя, чем задержанный или сгаллюцинированный «финальный» продукт. В этом разделе анализируются архитектуры, позволяющие агентам выдавать структурные скелеты, планы и честные частичные ответы.


2.1 «Skeleton-of-Thought» (SoT): Скелет как MVP


Методология Skeleton-of-Thought (SoT) является квинтэссенцией применения принципа частичности для снижения задержки и структурирования сложных ответов. Вместо последовательной генерации полного ответа (что медленно и чревато потерей логической нити), агент сначала создает структурный каркас.22


2.1.1 Этап Скелета (Partial Draft)


Агент явно инструктируется не генерировать полный текст, а создать сжатый план или аутлайн ответа. Этот скелет выступает в роли «частичного решения» — он фиксирует логику и структуру без наполнения деталями. Генерация такого скелета занимает доли времени, необходимого для полного ответа.24
* Ценность для пользователя (Fail Fast): Пользователь мгновенно видит структуру будущего ответа. Если агент неверно понял намерение и предлагает нерелевантную структуру, пользователь может прервать генерацию и скорректировать запрос до того, как ресурсы будут потрачены на написание полного текста.
* Параллельное Расширение (Point-Expanding): Как только скелет утвержден (автоматически или пользователем), агент (или рой субагентов) может расширять каждый пункт скелета параллельно. Это трансформирует процесс генерации из линейного $O(N)$ в квази-параллельный $O(N/K)$, где $K$ — количество пунктов, что радикально снижает общую задержку (end-to-end latency).25


2.1.2 Plan-and-Solve Prompting


Родственной техникой является Plan-and-Solve Prompting. Здесь агент сначала генерирует «План» (Partial Action), состоящий из подзадач, и только затем приступает к их выполнению. Это отделяет рассуждение (reasoning) от исполнения (execution).27
* Логика MVP: План служит MVP решения. Он позволяет агенту верифицировать логическую связность до начала ресурсоемких вычислений или генерации кода.29 Если на этапе планирования обнаруживается нехватка данных, агент может остановиться и запросить их у пользователя, вместо того чтобы галлюцинировать решение на ошибочных предпосылках. Эксперименты показывают, что такой подход (особенно в вариации PS+) снижает количество ошибок вычисления и пропущенных шагов по сравнению с классическим Chain-of-Thought.30


2.2 Управление неопределенностью: Честный частичный ответ


Одной из самых опасных проблем современных LLM является «уверенная галлюцинация». Принцип №16 диктует агенту выполнять «Частичное действие»: предоставлять только то, что известно достоверно, и отсекать неизвестное.


2.2.1 Квантификация Неопределенности (Uncertainty Quantification - UQ)


Для реализации этой стратегии агент должен обладать способностью к самодиагностике уверенности.
* White-Box UQ: Агент анализирует логиты (распределения вероятностей) собственных сгенерированных токенов. Если энтропия (мера хаоса/неопределенности) токенов превышает заданный порог, ответ помечается как ненадежный. Библиотеки, такие как UQLM, позволяют стандартизировать эти сигналы в скор уверенности от 0 до 1.32
* Black-Box UQ: Агент генерирует несколько вариантов ответа (Избыточное действие) и проверяет их на семантическое расхождение. Высокая степень несогласия между вариантами служит индикатором высокой неопределенности.34
* Вербализованная неопределенность: Вместо бинарного отказа агент обучается выражать свою неуверенность лингвистически, используя хеджирование (hedging) — вводные конструкции типа «Вероятно», «Судя по имеющимся данным», «Я не уверен полностью, но...».36 Исследования показывают, что LLM часто неспособны выражать неопределенность «из коробки», но могут быть дообучены или спромптированы для этого.38


2.2.2 Селективная генерация и Частичный отказ


На основе скоров UQ агент применяет тактику Селективной Генерации.
* Partial Refusal (Частичный отказ): В сценариях RAG агент часто сталкивается с запросами, на которые найденные документы дают лишь частичный ответ. Стратегия «Gap Strategy» предписывает агенту ответить на ту часть, которая подтверждена документами, и явно отказаться от остального: «Документы подтверждают дату запуска проекта (1 июня), однако информация о бюджете в них отсутствует». Это значительно повышает доверие пользователя по сравнению с полным отказом или попыткой выдумать бюджет.40
* Визуализация уверенности: В интерфейсах агентов можно использовать цветовую подсветку (heatmaps) на уровне токенов, чтобы показать пользователю, какие части ответа надежны, а какие — являются результатом обобщения или имеют низкую вероятность.42
Таблица 2: Стратегии управления неопределенностью (Частичное действие)


Стратегия
	Механизм
	Характеристика вывода
	Цель применения
	Хеджирование (Hedging)
	Лингвистическая модификация
	Использование фраз-маркеров («Вероятно...»)
	Коммуникация границ надежности без отказа от ответа 37
	Частичный отказ (Partial Refusal)
	Селективный ответ
	Ответ на часть X, отказ от Y
	Предотвращение галлюцинаций по неизвестным аспектам 40
	Подсветка токенов
	UI Визуализация
	Цветовое кодирование уверенности
	Визуальная верификация пользователем 42
	Fallback to Search/Tools
	Динамический роутинг
	«Не знаю, проверяю инструменты...»
	Закрытие пробелов знаний в реальном времени 19
	________________


3. Аэрокосмическая Метафора: Припуски и Покрытия


Запрос предлагает провести параллель с инженерными концепциями Технологических припусков (allowances) — материала, намеренно оставляемого на детали для финальной обработки, и Покрытий — нанесения материала на всю поверхность с последующим удалением лишнего. Эти метафоры предоставляют мощный концептуальный каркас для проектирования взаимодействия «Человек-ИИ» (HITL), сдвигая роль агента с «Оракула» (дающего финальный ответ) на «Фабрикатора» (создающего заготовку для доработки).


3.1 Технологические припуски: Агент «Черновой обработки»


В производстве «черновой проход» (roughing pass) быстро удаляет основной объем материала, оставляя небольшой припуск для «чистового прохода» (finishing pass), который выполняет человек или высокоточный станок. Это эффективно, так как черновая обработка дешева и быстра, а чистовая — дорога и медленна.


3.1.1 Шаблоны с заполнителями (Placeholder Pattern)


Цифровым эквивалентом припуска является Паттерн Заполнителя (Placeholder Pattern). Агент генерирует 90% контента (структуру, стандартную логику, бойлерплейт), но явно оставляет «припуски» в местах, требующих специфических знаний или ответственности.
* Реализация: Агент использует специальные токены (например, {{INSERT_CLIENT_NAME}}, ``, TODO: Verify API Key) для маркировки зон, где у него не хватает контекста или прав принятия решений.47
* Дизайн Co-Pilot: Это меняет рабочий процесс. Пользователь получает не «финальный черновик», в котором могут быть скрытые ошибки (сложные для обнаружения), а «шаблон», требующий его активного участия. Агент фактически говорит: «Я сделал тяжелую работу по структурированию; вы должны выполнить точную доводку». Это снижает риск пассивного принятия галлюцинаций, так как наличие плейсхолдеров форсирует проверку.49
* Применение в кодогенерации: При генерации кода агент может создавать скелет функции и комментарии // TODO: Implement specific business logic here, предоставляя работающую архитектуру, но оставляя критическую бизнес-логику разработчику.52


3.1.2 Human-in-the-Loop (HITL) и Персистентность Состояния


Для поддержки процесса «доработки припусков» архитектура агента должна поддерживать Прерывания (Interrupts) и Персистентность (Persistence).
* Прерывания: Фреймворки, такие как LangGraph и AutoGen, позволяют останавливать граф выполнения агента в определенных узлах. Агент генерирует черновик с плейсхолдерами, приостанавливается и ждет ввода пользователя.53
* Возобновляемость (Resumability): Система сохраняет состояние (чекпоинт) графа. Когда пользователь заполняет плейсхолдеры или утверждает план, агент возобновляет выполнение, подгружая обновленное состояние. Это позволяет реализовать сложные, долгоживущие процессы, где агент и человек передают управление друг другу, как эстафетную палочку. Технологии чекпоинтинга гарантируют, что контекст не теряется между сессиями.56
* Agent Continuations: Механизм, позволяющий «заморозить» полное состояние агента (включая стек вызовов инструментов) и передать его во внешнюю систему для утверждения, а затем «разморозить» и продолжить. Это критично для процессов, требующих авторизации или экспертной оценки высоких рисков.58


3.2 Метод «Покраски»: Широкий охват и отсечение лишнего


Метафора «покраски» подразумевает нанесение покрытия на всю поверхность (Избыточное действие) с последующим удалением лишнего (маскирование/шлифовка). В ИИ это соответствует Broad-First Generation с последующим User-Guided Pruning.


3.2.1 Broad-to-Narrow Information Retrieval (Широкий поиск)


Когда намерение пользователя неоднозначно (например, запрос «Расскажи про ИИ»), попытка угадать точный интент рискует промахом. Агент выполняет Broad-First Search, извлекая широкий спектр тем: История, Технологии, Этика, Бизнес.59
* Фасетное представление: Агент не вываливает весь текст сразу. Он использует Фасетный поиск (Faceted Search) для структурирования избыточности. Пользователю предлагаются направления: «Я нашел информацию по ценам, техническим спецификациям и конкурентам. Какое направление детализировать?».61
* Когнитивная эргономика: Человеку проще выбрать из предложенного (recognition), чем формулировать запрос с нуля (recall). Широкий охват на старте обеспечивает полноту, а фасеты — навигацию.63


3.2.2 Interactive RAG и Петли обратной связи


В системах Interactive RAG агент может представить широкий ответ или список чанков. Пользователь дает Отрицательную обратную связь (Negative Feedback), например: «Убери технические детали» или «Этот источник неактуален». Агент использует этот сигнал для «отсечения» (pruning) ненужных ветвей контекста и регенерации ответа.65
* Relevance Feedback: Этот цикл позволяет итеративно уточнять «покрытие» информации. Начальная избыточность необходима, чтобы пользователь увидел карту возможностей, а последующее отсечение позволяет сфокусироваться. Это реализует принцип №16 через удаление избыточного.67
* Pruning в мультиагентных системах: В системах типа "Debate" или "Critique and Refine" один агент генерирует избыточный черновик, а другой (или человек) выступает в роли критика, отсекая галлюцинации и лишнюю воду. Это автоматизирует процесс «шлифовки».69
________________


4. Синтез: Преодоление паралича перфекционизма


Интеграция принципа №16 предлагает выход из ловушки «все или ничего», характерной для современной разработки ИИ. Проектируя агентов, которые осциллируют между Избыточностью (для гарантии покрытия и качества) и Частичностью (для гарантии скорости, безопасности и контроля), мы создаем системы, устойчивые к неопределенности.


4.1 Диалектика Избыточности и Частичности в пайплайне


Эти стратегии не являются взаимоисключающими, они формируют этапы единого робастного пайплайна:
1. Фаза 1: Избыточность (Черновая обработка). Агент использует Speculative Decoding 5 и Parent Document Retrieval 12 для сбора избыточного контекста. Применяется Best-of-N 1 для генерации множества вариантов решения или путей рассуждения.
2. Фаза 2: Фильтрация и Квантификация. Применяются Reward Models 9 для выбора лучших кандидатов и Uncertainty Quantification 34 для оценки уверенности в результате.
3. Фаза 3: Частичная доставка (Припуск). Если уверенность высока, результат доставляется полностью. Если есть сомнения или требуется персонализация, агент выдает Skeleton 22 или Template with Placeholders 47, явно инициируя HITL Interrupt 53 для финальной доработки человеком.


4.2 Экономические и операционные выводы


* Стоимость Избыточности: Over-generation (например, n=5) линейно увеличивает затраты на токены. Однако для задач высокой стоимости (юриспруденция, кодинг) цена ошибки (галлюцинации) на порядки превышает стоимость лишних токенов. Концепция Inference-Time Scaling (масштабирование вычислений во время инференса) становится новым стандартом качества, позволяя меньшим моделям превосходить гигантов за счет более тщательного (избыточного) поиска решения.2
* Ценность Частичности: MVP-ответы снижают задержку (Time-to-First-Token) и повышают доверие. Пользователи предпочитают быстрый, структурированный аутлайн, который они могут скорректировать, медленному и потенциально ошибочному «финальному» тексту. «Технологический припуск» превращает ИИ из конкурента (замена человека) в инструмент (усилитель человека), повышая субъектность пользователя.72


4.3 Будущее архитектур: «Дышащий» Агент


Архитектуры будущего будут «дышащими» — расширяющимися (вдох) для захвата избыточного контекста и генерации множества гипотез, и сжимающимися (выдох) для выдачи лаконичных, верифицированных или частичных результатов. Эта динамика расширения и сжатия, управляемая принципом №16, станет основой для создания антихрупких ИИ-систем, которые не замирают перед лицом неопределенности, а навигируют через нее с помощью стратегического избытка и расчетливой частичности.
________________


Часть I: Стратегия Избыточности («Over-Generate & Filter»)




1.1 Логика изобилия в инференсе


Основным ограничением традиционных LLM является ошибка «одной попытки» (single-shot fallacy): предположение, что наиболее вероятный следующий токен (greedy decoding) всегда ведет к наиболее интеллектуальному ответу. В реальности, оптимальный ответ часто находится в «хвосте» распределения вероятностей или требует планирования, выходящего за рамки одного токена. Принцип №16 «Избыточное действие» решает эту проблему, заменяя неопределенность на вычисления.
Генерируя избыток вариантов — больше, чем просил пользователь — агент создает «пространство поиска», в котором статистически вероятнее найти правильное решение. Задача смещается с генерации (которая становится дешевой commodity) на верификацию (фильтрацию), требующую надежных механизмов оценки.


1.2 Техническая архитектура: Best-of-N (BoN) Sampling


Best-of-N, также известная как Rejection Sampling, является доминирующей архитектурой для реализации Избыточного действия.


1.2.1 Фаза «Сверх-генерации»


Вместо одного прохода инференса агент настраивается на $N$ параллельных проходов.
* Масштабирование температуры (Temperature Scaling): Чтобы $N$ вариантов были достаточно различимы (избыточное разнообразие), параметр temperature повышается (обычно до 0.7–1.0). Это сглаживает распределение вероятностей, позволяя модели исследовать «креативные» или «рискованные» пути, которые при жадном декодировании были бы отсечены.2
* Параллельное исполнение: Современные сервера инференса (vLLM, TGI) поддерживают параметр n в запросе API. Это позволяет GPU обрабатывать общий префикс (промпт) один раз, а затем ветвить генерацию на $N$ завершений. Хотя это увеличивает потребление памяти (KV-кэш), задержка растет сублинейно: генерация 5 ответов может занять лишь в 1.5 раза больше времени, чем одного, а не в 5 раз.1


1.2.2 Фаза «Фильтрации»: Модели Вознаграждения (RM)


Фильтр — это компонент, скрывающий «избыток» от пользователя. Он действует как дискриминатор.
* Эвристические фильтры: Для структурированных задач (например, генерация заголовков) фильтры могут быть простым кодом: «Отбросить заголовки длиннее 10 слов» или «Отбросить заголовки без ключевого слова».
* Обученные Reward Models: Для качественных задач используется отдельная, часто меньшая модель (Reward Model), которая оценивает каждое из $N$ завершений. Эта RM обычно обучается на данных человеческих предпочтений (RLHF). Система вычисляет $Score(y_i)$ для каждого черновика $y_i$ и возвращает пользователю $y_{best} = \arg\max(Score(y_i))$.2
* Self-Correction: Продвинутые реализации позволяют агенту критиковать собственные черновики. Агент генерирует 5 черновиков, затем получает промпт: «Просмотри эти 5 вариантов и выбери лучший на основе критериев X, Y, Z». Это «избыточно», так как расходует токены на чтение своего же вывода, но дает более высокое качество.1


1.3 Self-Consistency: Избыточность в рассуждениях


Для задач логики и математики «качество» объективно. Self-Consistency использует «избыточные» пути рассуждения для нахождения истины.10
* Механизм: Агент получает промпт с инструкцией Chain-of-Thought (CoT) («Давай подумаем шаг за шагом»). Он генерирует $N$ различных цепочек рассуждений.
* Консенсус-фильтр: Система игнорирует сами шаги рассуждения и смотрит только на финальный ответ. Применяется алгоритм «Голосования большинства». Если 7 из 10 путей приводят к ответу «42», а 3 — к «40», система выдает «42».11
* Почему это работает: Ошибки в рассуждениях часто стохастичны (случайные галлюцинации). Правильные пути рассуждения имеют тенденцию конвергировать к одному ответу. «Перегенерируя», агент заглушает шум одиночных галлюцинаций сигналом консенсуса.74


1.4 Speculative Decoding: Избыточность для скорости


Принцип №16 также применяется для оптимизации задержки. Speculative Decoding использует «избыточную» генерацию черновиков для ускорения медленной «целевой» модели.5
* Черновик (Избыток): Маленькая, быстрая модель (Draft Model) угадывает следующие $K$ токенов (например, 5 токенов вперед). Это «избыточно», так как мы еще не знаем, верны ли они.
* Верификация (Фильтр): Большая Target Model обрабатывает эти 5 токенов за один параллельный проход (проверяя их вероятности).
* Результат: Если черновые токены совпадают с тем, что сгенерировала бы целевая модель, они принимаются мгновенно. Система «перепрыгивает» вперед. «Избыточное» действие черновой модели окупается сокращением количества последовательных проходов тяжелой модели.6


1.5 «Буфер Знаний»: Избыточность в RAG


В Retrieval Augmented Generation (RAG) «Частичное действие» (извлечение только точного совпадения) часто терпит неудачу из-за «ампутации контекста» — факт теряет смысл без окружающего абзаца.


1.5.1 Parent Document Retrieval


Эта стратегия реализует «Избыточное действие», разделяя единицу поиска и единицу извлечения.
* Индексация (Мелкая): Система разбивает документы на мелкие «дочерние» чанки (например, 200 токенов) для точного векторного поиска.
* Извлечение (Крупное): Когда дочерний чанк найден, система извлекает его «Родительский документ» (например, полную секцию в 2000 токенов).12
* Эффект Буфера: Передавая «избыточный» родительский документ в контекст LLM, агент получает «Буфер Знаний». Он может ответить на конкретный вопрос и обработать немедленные уточняющие вопросы или неявный контекст (например, «Что предшествовало этому этапу?»), не требуя нового запроса к базе данных. Это размен токенов контекстного окна (ресурс) на плавность диалога и точность (качество).14
________________


Часть II: Стратегия Частичности («MVP Response»)




2.1 Логика MVP


Когда задача слишком сложна для идеального решения с одной попытки, или цена ошибки высока, принцип №16 предлагает «Частичное действие». В ИИ это означает ставку на Minimum Viable Product (MVP) — ответ, который структурно полон, но сжат по содержанию, или фактологически консервативен вместо полной, но выдуманной картины. Эта стратегия борется с проблемой «галлюцинаций», переопределяя «успех» с «полного ответа» на «надежный шаг».


2.2 Skeleton-of-Thought (SoT): Структурный MVP


Стандартная генерация LLM последовательна; если модель «заблудится» в середине абзаца, весь ответ деградирует. Skeleton-of-Thought принуждает к «Частичному действию» в первую очередь: генерации аутлайна.22


2.2.1 Фаза 1: Запрос Скелета


Система инструктирует модель: «Не отвечай на вопрос сразу. Сначала предоставь скелетный план основных пунктов, которые ты осветишь».
* Вывод: Маркированный список или JSON-структура, представляющая «кости» ответа.
* Чекпоинт: Этот «частичный» ответ может быть показан пользователю (или внутреннему оценщику). Если скелет нерелевантен, процесс останавливается (экономия ресурсов).


2.2.2 Фаза 2: Параллельное Расширение


Как только скелет валидирован, агент выполняет «Избыточное действие», расширяя все пункты одновременно.
* Параллелизм: Каждый пункт списка становится промптом для отдельного API-вызова.
* Снижение Задержки: Вместо ожидания завершения пункта 1 перед началом пункта 2, система генерирует пункты 1-5 параллельно. Общее время равно Time(Skeleton) + max(Time(Point_i)), а не sum(Time(Point_i)).25
* Фокус: Поскольку каждый подвызов фокусируется только на одном пункте, контекст чище, снижается «дрейф контекста» и улучшается следование теме.24


2.3 Plan-and-Solve: Разделение обязанностей


Plan-and-Solve применяет «Частичное действие» к задачам рассуждения.
* План: Агент просят «Разработать план решения проблемы». Это текстовый вывод, описывающий шаги (например, «1. Конвертировать единицы в метры. 2. Рассчитать площадь. 3. Умножить на стоимость.»).
* Исполнение: Затем агент выполняет план.
* Польза Частичности: «План» — это «Частичный ответ». Он заставляет модель рассуждать о стратегии до вычислений. Это имитирует когнитивные процессы человека («Думай медленно...») и значительно снижает ошибки «пропущенных шагов», когда модель перепрыгивает к выводам.27


2.4 Управление неопределенностью: Честный Частичный Ответ


Самый опасный режим отказа агента — «Уверенная Галлюцинация». Принцип №16 (Частичное действие) является антидотом: если не можешь быть на 100% прав, будь частично прав и явно не уверен.


2.4.1 Квантификация Неопределенности (UQ)


Агенту нужен «спидометр» собственной уверенности.
* Энтропия на уровне токенов: Изучая распределение вероятностей следующего токена, агент может обнаружить «замешательство». Если топ-5 токенов имеют схожие низкие вероятности (плоское распределение), модель «угадывает».45
* Вербализация: Агент дообучается или промптируется использовать «Хеджирование» (Hedges). Вместо утверждения «CEO — Джон Доу», он говорит «Согласно данным 2021 года, CEO был Джон Доу, но у меня нет свежего подтверждения». Это «Частичное» утверждение защищает пользователя от устаревших фактов.37


2.4.2 Протоколы Частичного Отказа


В RAG-системах агенты часто сталкиваются с запросами, на которые можно ответить лишь частично на основе найденных документов.
* Стратегия «Разрыва» (Gap Strategy): Агент идентифицирует «Разрыв» между запросом и доказательствами.
* Вывод: Он отвечает на подтвержденную часть и явно отказывается от остального. «Документы подтверждают дату запуска проекта 1 июня. Однако они не упоминают распределение бюджета».
* Преимущества: Такой «Частичный Отказ» превосходит «Полный Отказ» (который фрустрирует пользователя) и «Полную Галлюцинацию» (которая вводит в заблуждение).40
________________


Часть III: Аэрокосмическая Метафора (Припуски и Покрытия)




3.1 Технологические припуски: Проектирование для человеческой доводки


В аэрокосмическом производстве «припуск на механообработку» (machining allowance) — это лишний металл, оставленный на отливке. Литейный цех делает 95% работы (грубая форма), но оставляет последние 0.05 дюйма для высокоточного станка. Эта метафора мощно работает для дизайна ИИ-агентов: Агент должен создавать «Грубую отливку», а Пользователь — выполнять «Точную доводку».


3.1.1 Паттерн Заполнителя (Placeholder Pattern)


Вместо того чтобы угадывать конкретные детали (имена, даты, цены), которые могут быть ошибочны, агент использует Заполнители.
* Паттерн: Агент генерирует письмо, отчет или код, но вставляет явные токены типа ``, {{VERIFY_DATE}} или TODO: Add API Key.47
* Черновой проход: Агент берет на себя «тяжелую атлетику» структуры, тона и шаблонной логики. Это «Частичное действие» выполнения всего, кроме специфических деталей.
* Чистовой проход: Пользователь (или вторичный специализированный инструмент) сканирует текст на наличие этих заполнителей и заполняет их. Это снижает когнитивную нагрузку на пользователя (ему не нужно писать письмо с нуля), обеспечивая при этом точность (он верифицирует критические переменные).49


3.1.2 Прерывания HITL (Human-in-the-Loop)


Для операционализации «Припусков» рабочий процесс агента должен поддерживать паузы.
* LangGraph Interrupts: Во фреймворке LangGraph узел может быть обозначен как interrupt. Когда агент достигает этого узла (например, после генерации черновика с заполнителями), он останавливает выполнение и сохраняет свое состояние (чекпоинт).53
* Интерфейс: Пользователю представляется черновик. Пользователь заполняет плейсхолдеры или модифицирует «припуск».
* Возобновление: Пользователь нажимает «Продолжить». Агент возобновляет работу, загружая модифицированное состояние. Он фактически обрабатывает ввод человека как ответ функции.56 Эта архитектура превращает агента в настоящего «Ко-пилота», где управление передается туда и обратно, а не в «Автопилот», который молча падает.


3.2 Метод «Покраски»: Широкий охват и отсечение


Аэрокосмическая покраска часто включает покрытие всей детали с последующим удалением краски с контактных поверхностей (маскирование). В ИИ это эквивалентно Широкой Генерации с последующим Отсечением.


3.2.1 Broad-First Search (Покрытие)


Когда намерение пользователя неоднозначно (например, «Расскажи про ИИ»), конкретный ответ, скорее всего, будет промахом.
* Избыточное действие: Агент выполняет «Широкий поиск» (Broad-First Search). Он извлекает информацию по Истории, Технологиям, Этике и Бизнесу. Он генерирует ответ, который слегка касается всех этих граней.59
* Фасетный интерфейс: Агент представляет эти опции как «Фасеты» или «Пути» пользователю.61


3.2.2 Пользовательское отсечение (Маскирование)


* Частичный выбор: Пользователь кликает «Этика».
* Уточнение: Агент «отсекает» (prunes) остальные темы и использует «Избыточный» контекст, который он уже извлек (если он был буферизован), чтобы углубиться в Этику.
* Петля Отрицательной Обратной Связи: В Interactive RAG пользователь может сказать «Меньше технических деталей». Агент трактует это как инструкцию по отсечению, удаляя этот «слой» информационного покрытия.67 Этот подход — сгенерировать широко, позволить пользователю уточнить — позволяет избежать ловушки «Zero-Shot», когда агент пытается идеально прочитать мысли пользователя с первого хода.
________________


Часть IV: Архитектурный Синтез и Перспективы




4.1 Интегрированная Архитектура


Наиболее надежные агентные системы не будут выбирать между Избыточностью и Частичностью; они интегрируют их в динамический пайплайн.
Схема 1: Пайплайн Принципа №16
1. Вход: Запрос пользователя.
2. Избыточность (Контекст): Parent Document Retrieval извлекает широкий контекст.12
3. Частичность (План): Skeleton-of-Thought генерирует аутлайн.22
4. Избыточность (Драфтинг): Speculative Decoding и Best-of-N генерируют множественные черновые секции для скелета.1
5. Фильтр (Качество): Reward Models выбирают лучшие черновики.9
6. Частичность (Безопасность): Uncertainty Quantification хеджирует утверждения с низкой уверенностью.34
7. Частичность (Доставка): Система выдает черновик с Технологическими Припусками (Плейсхолдерами).47
8. Коллаборативный Финиш: HITL Interrupt позволяет пользователю финализировать вывод.53


4.2 Экономические компромиссы


Внедрение Принципа №16 требует смены парадигмы оценки стоимости вычислений.
* Стоимость Избыточности: "Best-of-N" увеличивает стоимость инференса в $N$ раз.
* Экономия Частичности: "Skeleton-of-Thought" и "Speculative Decoding" снижают задержку, компенсируя стоимость Избыточности.
* Премия за Качество: Для корпоративных приложений стоимость ошибки (галлюцинации) часто на порядки выше стоимости токенов. Следовательно, трата токенов на «Избыточную» верификацию и «Частичные» проверки безопасности имеет положительный ROI.


4.3 Заключение


Применение Принципа №16 — Частичное или Избыточное действие — решает проблему «Паралича Перфекционизма» в ИИ-агентах. Наделяя агентов способностью «делать больше» (генерировать избыточный контекст и черновики) и «делать меньше» (выдавать скелеты и плейсхолдеры), мы уходим от хрупкости zero-shot генерации. Мы движемся к системам, которым «Технологически Разрешено» быть несовершенными в запланированных, управляемых рамках, приглашая человека обратно в контур не как исправителя поломок, а как мастера, завершающего обработку грубой заготовки. Это будущее робастной, коллаборативной архитектуры ИИ.
Список цитируемых источников:


22
Источники
1. Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2503.01422v3
2. Complete Technical Guide: LLM Training Concepts and Implementation Details - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@dvirla84/complete-technical-guide-llm-training-concepts-and-implementation-details-187001975f1f
3. Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding - enlsp 2023, дата последнего обращения: ноября 25, 2025, https://neurips2023-enlsp.github.io/papers/paper_33.pdf
4. dParallel: Learnable Parallel Decoding for dLLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2509.26488v1
5. Speculative decoding | LLM Inference Handbook - BentoML, дата последнего обращения: ноября 25, 2025, https://bentoml.com/llm/inference-optimization/speculative-decoding
6. An Introduction to Speculative Decoding for Reducing Latency in AI Inference, дата последнего обращения: ноября 25, 2025, https://developer.nvidia.com/blog/an-introduction-to-speculative-decoding-for-reducing-latency-in-ai-inference/
7. Accelerating Generative LLMs Inference with Parallel Draft Models (PARD) - AMD, дата последнего обращения: ноября 25, 2025, https://www.amd.com/en/developer/resources/technical-articles/accelerating-generative-llms-interface-with-parallel-draft-model-pard.html
8. PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2504.18583v3
9. Let AI Entertain You: Increasing User Engagement with Generative AI and Rejection Sampling - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2312.12457v1
10. Self-Consistency Prompting - GeeksforGeeks, дата последнего обращения: ноября 25, 2025, https://www.geeksforgeeks.org/artificial-intelligence/self-consistency-prompting/
11. Master Prompting Techniques: Self-Consistency Prompting, дата последнего обращения: ноября 25, 2025, https://promptengineering.org/self-consistency-prompting/
12. Perform Parent Document Retrieval with MongoDB and LangChain - Atlas, дата последнего обращения: ноября 25, 2025, https://www.mongodb.com/docs/atlas/ai-integrations/langchain/parent-document-retrieval/
13. Retrieval-Augmented Generation (RAG) using LangChain, LlamaIndex, and OpenAI, дата последнего обращения: ноября 25, 2025, https://pub.towardsai.net/introduction-to-retrieval-augmented-generation-rag-using-langchain-and-lamaindex-bd0047628e2a
14. RAG IX — Parent Document Retriever | by DhanushKumar - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@danushidk507/rag-ix-parent-document-retriever-a49450a482ab
15. Parent Document Retrieval (PDR): Useful Technique in RAG - DZone, дата последнего обращения: ноября 25, 2025, https://dzone.com/articles/parent-document-retrieval-useful-technique-in-rag
16. LangChain's Parent Document Retriever — Revisited | by Omri Eliyahu Levy | TDS Archive, дата последнего обращения: ноября 25, 2025, https://medium.com/data-science/langchains-parent-document-retriever-revisited-1fca8791f5a0
17. RAG Strategies - Context Enrichment | PIXION Blog, дата последнего обращения: ноября 25, 2025, https://pixion.co/blog/rag-strategies-context-enrichment
18. Optimizing RAG Pipelines: Sentence Window Retrieval or Auto Merging Retrieval? | by Pratik Saha | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@p.saha/optimizing-rag-pipelines-sentence-window-retrieval-or-auto-merging-retrieval-950b50a4eb76
19. How to Enhance the Performance of Your RAG Pipeline | Milvus Documentation, дата последнего обращения: ноября 25, 2025, https://milvus.io/docs/how_to_enhance_your_rag.md
20. (PDF) Memory Architectures in Long-Term AI Agents: Beyond Simple State Representation, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/388144017_Memory_Architectures_in_Long-Term_AI_Agents_Beyond_Simple_State_Representation
21. Identifying Contemplative Intensity in Cognitive Architectures for Virtual-Agent Minds - SFU Summit, дата последнего обращения: ноября 25, 2025, https://summit.sfu.ca/_flysystem/fedora/sfu_migrate/18673/etd19950.pdf
22. Accelerating LLMs with Skeleton-of-Thought Prompting - Portkey, дата последнего обращения: ноября 25, 2025, https://portkey.ai/blog/skeleton-of-thought-prompting/
23. Skeleton of Thought: LLMs Can Do Parallel Decoding Paper Reading - Arize AI, дата последнего обращения: ноября 25, 2025, https://arize.com/blog/skeleton-of-thought-llms-can-do-parallel-decoding-paper-reading/
24. Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2307.15337v3
25. Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation | OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=mqVgBbNCm9
26. Skeleton-of-Thought: Parallel decoding speeds up and improves LLM output - Microsoft, дата последнего обращения: ноября 25, 2025, https://www.microsoft.com/en-us/research/blog/skeleton-of-thought-parallel-decoding-speeds-up-and-improves-llm-output/
27. What Is Plan-and-Solve Prompting? | by Deepak kumar sahoo | The Synaptic Stack, дата последнего обращения: ноября 25, 2025, https://medium.com/the-synaptic-stack/what-is-plan-and-solve-prompting-59293b8b41b1
28. Plan-and-Solve Prompting: Improving Reasoning and Reducing Errors, дата последнего обращения: ноября 25, 2025, https://learnprompting.org/docs/advanced/decomposition/plan_and_solve
29. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models, дата последнего обращения: ноября 25, 2025, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=9057&context=sis_research
30. Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2023.acl-long.147/
31. [2305.04091] Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2305.04091
32. Detecting LLM Hallucinations at Generation Time with UQLM | by Dylan Bouchard | CVS Health Tech Blog | Oct, 2025 | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/cvs-health-tech-blog/detecting-llm-hallucinations-at-generation-time-with-uqlm-cd749d2338ec
33. [Literature Review] Token-level Accept or Reject: A Micro Alignment Approach for Large Language Models - Moonlight, дата последнего обращения: ноября 25, 2025, https://www.themoonlight.io/en/review/token-level-accept-or-reject-a-micro-alignment-approach-for-large-language-models
34. Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.12040v1
35. [2509.13813] Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2509.13813
36. Calibrating Verbal Uncertainty as a Linear Feature to Reduce Hallucinations - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2025.emnlp-main.187.pdf
37. Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2024.emnlp-main.443/
38. SelfReflect: Can LLMs Communicate Their Internal Answer Distribution? | OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=hOErnDsehG
39. Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words? (2405.16908v2) - Emergent Mind, дата последнего обращения: ноября 25, 2025, https://www.emergentmind.com/articles/2405.16908
40. Command A: An Enterprise-Ready Large Language Model - Cohere, дата последнего обращения: ноября 25, 2025, https://cohere.com/research/papers/command-a-technical-report.pdf
41. On the Trustworthiness of Generative Foundation Models - Yue Huang, дата последнего обращения: ноября 25, 2025, https://howiehwong.github.io/TrustGen.pdf
42. (Token-Level) InfoRMIA: Stronger Membership Inference and Memorization Assessment for LLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.05582v1
43. Circuit Tracing: Revealing Computational Graphs in Language Models, дата последнего обращения: ноября 25, 2025, https://transformer-circuits.pub/2025/attribution-graphs/methods.html
44. Training LLMs to Recognize Hedges in Spontaneous Narratives - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2408.03319v1
45. ReTrace: Interactive Visualizations for Reasoning Traces of Large Reasoning Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2511.11187v1
46. Building a Rule-Guided LLM That Actually Follows Instructions : r/LLMDevs - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/LLMDevs/comments/1l3hm0e/building_a_ruleguided_llm_that_actually_follows/
47. How to Create Your First Sequence - Unify, дата последнего обращения: ноября 25, 2025, https://www.unifygtm.com/university/how-to-create-your-first-sequence
48. AI Prompt Engineering: What It Is and 15 Techniques for 2025 - Hostinger, дата последнего обращения: ноября 25, 2025, https://www.hostinger.com/ph/tutorials/ai-prompt-engineering
49. 20+ GenAI UX patterns, examples and implementation tactics | by Sharang Sharma, дата последнего обращения: ноября 25, 2025, https://uxdesign.cc/20-genai-ux-patterns-examples-and-implementation-tactics-5b1868b7d4a1
50. A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT - Distributed Object Computing (DOC) Group for DRE Systems, дата последнего обращения: ноября 25, 2025, https://www.dre.vanderbilt.edu/~schmidt/PDF/prompt-patterns.pdf
51. Is it possible to have a Co-Pilot Agent create a document based on a template, and have the output look exactly like the tempate? : r/microsoft_365_copilot - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/microsoft_365_copilot/comments/1nvk8o1/is_it_possible_to_have_a_copilot_agent_create_a/
52. Enabling AI Copilots for Engineering Design With Parametric, Graph, And Component Inputs - DSpace@MIT, дата последнего обращения: ноября 25, 2025, https://dspace.mit.edu/bitstream/handle/1721.1/158805/zhou-zhourui-smme-meche-2025-thesis.pdf?sequence=1&isAllowed=y
53. How to wait for user input using interrupt - GitHub Pages, дата последнего обращения: ноября 25, 2025, https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/
54. Human in the Loop (HITL) - CopilotKit Docs, дата последнего обращения: ноября 25, 2025, https://docs.copilotkit.ai/langgraph/human-in-the-loop
55. How to make an Agent like Autogen's UserProxyAgent in LangGraph? #18914 - GitHub, дата последнего обращения: ноября 25, 2025, https://github.com/langchain-ai/langchain/discussions/18914
56. Here's how to build durable AI agents with Pydantic and Temporal, дата последнего обращения: ноября 25, 2025, https://temporal.io/blog/build-durable-ai-agents-pydantic-ai-and-temporal
57. How to preserve state and resume workflows in langchain with human intervention, дата последнего обращения: ноября 25, 2025, https://community.latenode.com/t/how-to-preserve-state-and-resume-workflows-in-langchain-with-human-intervention/39108
58. Breaking the Chain: Agent Continuations for Resumable AI Workflows - SnapLogic, дата последнего обращения: ноября 25, 2025, https://www.snaplogic.com/blog/agent-continuations-for-resumable-ai-workflows
59. City, University of London Institutional Repository, дата последнего обращения: ноября 25, 2025, https://openaccess.city.ac.uk/id/eprint/7946/1/Subject_searching_behaviour_at_the_library_catalogue_and_at_the_shelves-_evaluating_the_impact_of_an_online_public_access_catalogue.pdf
60. Discovering and Reasoning of Causality in the Hidden World with Large Language Models, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2402.03941v3
61. Faceted Search for Enhanced Knowledge Discovery - SearchUnify, дата последнего обращения: ноября 25, 2025, https://www.searchunify.com/su/platform/faceted-search/
62. Faceted search: Use AI to improve search scope and results - Elasticsearch Labs, дата последнего обращения: ноября 25, 2025, https://www.elastic.co/search-labs/blog/faceted-search-examples-ai
63. Facets: Constraints or Preferences? | by Daniel Tunkelang - Medium, дата последнего обращения: ноября 25, 2025, https://dtunkelang.medium.com/facets-constraints-or-preferences-8b8689903652
64. Faceted Search: An Overview - Algolia, дата последнего обращения: ноября 25, 2025, https://www.algolia.com/blog/ux/faceted-search-an-overview
65. DMA: Online RAG Alignment with Human Feedback - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2511.04880v1
66. Mastering RAG Implementation: Covering all the Basics - Signity Software Solutions, дата последнего обращения: ноября 25, 2025, https://www.signitysolutions.com/blog/mastering-rag-implementation
67. Retrieval-Augmented Feedback Loops: How They Work - Newline.co, дата последнего обращения: ноября 25, 2025, https://www.newline.co/@zaoyang/retrieval-augmented-feedback-loops-how-they-work--2fcbb047
68. Closed Loop Retrieval-Augmented Generation (RAG) for Content-based Recommendations in E-commerce - Lund University Publications, дата последнего обращения: ноября 25, 2025, https://lup.lub.lu.se/student-papers/record/9208151/file/9208153.pdf
69. LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2508.17692v1
70. Orchestrator: Active Inference for Multi-Agent Systems in Long-Horizon Tasks - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2509.05651v1
71. The Agentic Transformation of Software Engineering | by Daniel Bentes | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@danielbentes/the-agentic-transformation-of-software-engineering-81d1d5dbd51e
72. AI and You: Learn to Be the Human in the Loop - Wharton Global Youth Program, дата последнего обращения: ноября 25, 2025, https://globalyouth.wharton.upenn.edu/articles/science-technology/ai-and-you-learn-to-be-the-human-in-the-loop/
73. ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2508.08895v2
74. Self-Consistency - Prompt Engineering Guide, дата последнего обращения: ноября 25, 2025, https://www.promptingguide.ai/techniques/consistency
75. Looking back at speculative decoding - Google Research, дата последнего обращения: ноября 25, 2025, https://research.google/blog/looking-back-at-speculative-decoding/
76. Calibration of Pre-trained Transformers - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/347234369_Calibration_of_Pre-trained_Transformers
77. Hedging Our Bets on LLMs Challenges in Calibrating the Language of Uncertainty Nikola Datkova A THESIS in Linguistics Presented - Nowe Moore, дата последнего обращения: ноября 25, 2025, https://nowemoore.com/static/media/mathesis.27f7068c44d505d094c3.pdf
78. Self-Consistency Improves Chain of Thought Reasoning in Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2203.11171
79. The Art of Refusal: A Survey of Abstention in Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2407.18418v1
80. Choose a design pattern for your agentic AI system | Cloud Architecture Center, дата последнего обращения: ноября 25, 2025, https://docs.cloud.google.com/architecture/choose-design-pattern-agentic-ai-system
81. Evaluator reflect-refine loop patterns - AWS Prescriptive Guidance, дата последнего обращения: ноября 25, 2025, https://docs.aws.amazon.com/prescriptive-guidance/latest/agentic-ai-patterns/evaluator-reflect-refine-loop-patterns.html
82. 1 Introduction - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.04173v4
83. Semantic Kernel Agent Architecture | Microsoft Learn, дата последнего обращения: ноября 25, 2025, https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/agent-architecture
84. Human-in-the-Loop Agent Using ToolNode in LangGraph | by, дата последнего обращения: ноября 25, 2025, https://medium.com/fundamentals-of-artificial-intelligence/human-in-the-loop-agent-using-toolnode-in-langgraph-785283b1f1b2
85. AWS Prescriptive Guidance - Agentic AI patterns and workflows on AWS - AWS Documentation, дата последнего обращения: ноября 25, 2025, https://docs.aws.amazon.com/pdfs/prescriptive-guidance/latest/agentic-ai-patterns/agentic-ai-patterns.pdf
86. Building Boba AI - Martin Fowler, дата последнего обращения: ноября 25, 2025, https://martinfowler.com/articles/building-boba.html
87. Teaching Language Models to Faithfully Express their Uncertainty - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.12587v1
88. What is Human-in-the-loop? | TELUS Digital, дата последнего обращения: ноября 25, 2025, https://www.telusdigital.com/glossary/human-in-the-loop
89. Human-in-the-Loop Systems for Adaptive Learning Using Generative AI - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2508.11062v1
90. Human-in-the-loop in AI workflows: HITL meaning, benefits, and practical patterns - Zapier, дата последнего обращения: ноября 25, 2025, https://zapier.com/blog/human-in-the-loop/
91. Prompt engineering concepts - Amazon Bedrock, дата последнего обращения: ноября 25, 2025, https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-engineering-guidelines.html
92. How to Build a Generative AI Tool for Information Extraction from Receipts - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/data-science/how-to-build-a-generative-ai-tool-for-information-extraction-from-receipts-516424327f66
93. 10 Ways To Use Microsoft Co-Pilot Effectively For Strategic Advantage, дата последнего обращения: ноября 25, 2025, https://www.aspiretech.com/blog/10-ways-to-use-microsoft-co-pilot-effectively-for-strategic-advantage/