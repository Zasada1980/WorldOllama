Универсальный Каталог Модулей и Настроек для ИИ-Агентов




Введение: Архитектура Современных ИИ-Агентов


Произошел фундаментальный сдвиг в разработке искусственного интеллекта: от монолитных, всезнающих больших языковых моделей (LLM) к модульным, автономным агентным системам. Современный ИИ-агент — это не просто модель, отвечающая на вопросы. Это сложная система, которая объединяет в себе ядро для рассуждений (LLM), память для сохранения контекста и обучения, а также инструменты для взаимодействия с внешним миром. Эта архитектура позволяет агентам воспринимать окружающую среду, планировать свои действия и целенаправленно двигаться к достижению поставленной цели.
Данный каталог представляет собой исчерпывающее руководство для разработчиков, стремящихся конструировать и настраивать ИИ-агентов для решения конкретных задач. Он систематизирует все возможные модули, настройки и параметры конфигурации, анализируя ведущие фреймворки, такие как LangChain, LlamaIndex, AutoGen и CrewAI. Каждый элемент каталога подробно описывает не только "что" он делает, но и "почему" его выбор важен, и "как" его правильно настроить, предоставляя практические примеры кода и объясняя компромиссы между различными подходами. Этот документ служит картой для навигации в новой парадигме агентного ИИ, позволяя создавать более надежные, эффективные и интеллектуальные системы.
________________


Секция 1: Модули Ядра Агента


В этой секции рассматриваются фундаментальные компоненты, составляющие когнитивное и функциональное ядро любого автономного агента. Эти модули отвечают за планирование, запоминание и взаимодействие с внешним миром, формируя основу для выполнения сложных задач.


1.1. Модуль Планирования (Planning Module)


Описание: Модуль планирования — это "стратегический мозг" агента, отвечающий за декомпозицию сложных, высокоуровневых целей на последовательность конкретных, выполнимых шагов. Выбор архитектуры планирования является одним из самых критических проектных решений, напрямую влияющим на предсказуемость, стоимость, адаптивность и общую надежность агента. Этот модуль определяет, как агент будет рассуждать о задаче: будет ли он создавать полный план заранее или корректировать свои действия на лету, получая обратную связь от окружения.


Типы реализаций




1.1.1. Zero-shot ReAct (Reason + Act)


Описание: Паттерн ReAct (Reason + Act) создает тесную синергию между рассуждением и действием, позволяя агенту динамически корректировать свой план на основе обратной связи от окружения в реальном времени. Эта архитектура превосходно подходит для динамичных, непредсказуемых сред, где заранее составленный план быстро устарел бы.
Принцип работы: Агент работает в чередующемся цикле Мысль -> Действие -> Наблюдение (Thought -> Action -> Observation).
1. Мысль (Thought): Агент генерирует словесный след рассуждения, который анализирует текущую ситуацию и определяет следующий шаг.
2. Действие (Action): На основе "Мысли" агент выбирает и вызывает конкретный инструмент (например, поиск в интернете).
3. Наблюдение (Observation): Результат выполнения инструмента (например, поисковая выдача) поступает обратно к агенту и становится основой для следующей "Мысли".1
Этот итеративный процесс позволяет агенту постоянно сверяться с реальностью. Взаимодействие с внешними API, такими как Wikipedia, помогает преодолеть распространенные проблемы LLM, такие как галлюцинации и распространение ошибок, поскольку рассуждения агента основываются на проверяемой внешней информации, а не только на его параметрических знаниях.
Пример промпта (Zero-shot): Zero-shot реализация не требует примеров в промпте. Вместо этого она полагается на четкую инструкцию, которая задает структуру цикла. LLM, обученные на инструкциях, способны следовать этому формату без предварительных демонстраций.






Отвечай на следующие вопросы как можно лучше. У тебя есть доступ к следующим инструментам:
{tools}

Используй следующий формат:

Вопрос: входной вопрос, на который ты должен ответить
Мысль: ты всегда должен думать, что делать дальше
Действие: действие, которое нужно предпринять, должно быть одним из [{tool_names}]
Входные данные для действия: входные данные для действия
Наблюдение: результат действия
... (эта последовательность Мысль/Действие/Входные данные/Наблюдение может повторяться N раз)
Мысль: теперь я знаю окончательный ответ
Финальный ответ: окончательный ответ на исходный вопрос

Начинай!

Вопрос: {input}
Мысль:{agent_scratchpad}

Пример кода (LangChain):


Python




from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate

# 1. Определение инструментов
tools =

# 2. Создание промпта для ReAct
prompt_template = """
Answer the following questions as best you can. You have access to the following tools:
{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}
"""
prompt = ChatPromptTemplate.from_template(prompt_template)

# 3. Инициализация агента и исполнителя
llm = ChatOpenAI(model="gpt-4o", temperature=0)
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# 4. Запуск агента
agent_executor.invoke({"input": "What is the current capital of Brazil and when was it inaugurated?"})



1.1.2. Plan-and-Execute


Описание: Этот паттерн обеспечивает строгое разделение между стратегическим планированием и тактическим исполнением. Он повышает предсказуемость, экономическую эффективность и безопасность, что делает его идеальным для сложных, многошаговых задач в производственных средах, где надежность имеет первостепенное значение.
Принцип работы:
1. Планировщик (Planner): Мощная LLM (например, GPT-4o или Claude 3 Opus) сначала генерирует полный, структурированный план для достижения цели. План представляет собой последовательность четко определенных подзадач.
2. Исполнитель (Executor): Отдельный, часто более простой и дешевый компонент (может быть менее мощной LLM или детерминированным кодом), последовательно выполняет каждый шаг сгенерированного плана.
Такое разделение делает поведение агента легко аудируемым. Поскольку результаты выполнения инструментов не влияют напрямую на высокоуровневый план в реальном времени, этот подход более устойчив к атакам типа "indirect prompt injection", когда вредоносные данные из внешнего источника могут попытаться захватить управление агентом.2


1.1.3. Hierarchical Planning (Дерево задач)


Описание: Это расширение паттерна Plan-and-Execute, предназначенное для решения исключительно сложных задач с длительным горизонтом планирования. Высокоуровневый планировщик декомпозирует основную цель на несколько крупных подцелей. Эти подцели затем делегируются другим планировщикам или агентам-исполнителям для дальнейшей декомпозиции или выполнения, образуя иерархическую структуру или "дерево задач".3
Когда применяется: Этот подход является основой для архитектур "менеджер-исполнитель" (manager-worker), которые широко используются в мультиагентных системах. Он позволяет распределять работу между специализированными агентами, что повышает эффективность и масштабируемость. Фреймворки, такие как CrewAI (с Process.hierarchical) и AutoGen (с GroupChatManager), используют этот принцип для организации командной работы агентов.
________________
Сравнительный анализ архитектур планирования
Выбор между ReAct и Plan-and-Execute представляет собой фундаментальный компромисс между адаптивностью и надежностью.
1. Итеративная природа ReAct позволяет ему гибко реагировать на неожиданные результаты выполнения инструментов или изменения в среде. Это делает его высоко адаптивным и эффективным для исследовательских задач, где конечный путь решения неясен.
2. Однако эта же гибкость делает его поведение недетерминированным. Агент может зациклиться, отклониться от оптимального пути или "потерять" изначальную цель, что снижает его надежность для критически важных, многошаговых процессов.
3. Напротив, Plan-and-Execute, создавая полный план заранее, обеспечивает предсказуемый и аудируемый путь выполнения, что максимизирует надежность.
4. Ценой этой надежности является жесткость. Если один из ранних шагов плана не удается или возвращает непредвиденный результат, весь последующий план может стать недействительным, требуя дорогостоящего цикла перепланирования. Это снижает адаптивность системы.
Таким образом, разработчики должны выбирать ReAct для динамических, исследовательских задач (например, интерактивный поиск информации) и Plan-and-Execute для структурированных, критически важных рабочих процессов (например, обработка страхового случая).
________________


Настройки и их влияние




max_iterations


* Что это: Критически важный параметр безопасности в AgentExecutor (LangChain), который определяет максимальное количество шагов (циклов Мысль-Действие-Наблюдение), которые агент может выполнить перед принудительной остановкой.
* Влияние: Этот параметр предотвращает бесконечные циклы, в которые может попасть агент, и тем самым ограничивает непредвиденные расходы на API и чрезмерную задержку.
   * Низкое значение (например, 5) может привести к преждевременному завершению сложных задач, не дав агенту дойти до решения.
   * Высокое значение (например, 25) увеличивает стоимость и время выполнения, если агент испытывает трудности с решением задачи.
   * Значение по умолчанию, как правило, составляет 15, что является разумным компромиссом.
* Поведение при достижении лимита: Когда лимит достигнут, поведение определяется параметром early_stopping_method. По умолчанию ('force') агент просто возвращает стандартное сообщение о том, что он был остановлен.


planner_model


* Что это: Выбор LLM, которая будет выполнять роль планировщика (в архитектурах Plan-and-Execute и иерархических системах).
* Влияние: Качество плана является определяющим фактором успеха всей задачи. Использование высокопроизводительной модели с сильными способностями к рассуждению (например, GPT-4o, Claude 3 Opus, Gemini 2.5 Pro) в качестве планировщика имеет решающее значение, даже если последующее выполнение шагов делегируется более простым и дешевым моделям. Экономия на модели-планировщике часто приводит к созданию неполноценных или логически неверных планов, что, в свою очередь, ведет к провалу всей задачи и в итоге к большим затратам ресурсов, чем было сэкономлено.


1.2. Модуль Памяти (Memory Module)


Описание: Модуль памяти наделяет агента способностью к непрерывности восприятия, сохранению контекста и обучению. Именно этот компонент превращает агента из stateless-исполнителя функций в персистентную сущность, которая может накапливать опыт и совершенствоваться со временем. Без памяти каждая задача решалась бы "с чистого листа", что делает невозможным выполнение долгосрочных заданий или персонализированное взаимодействие.


Типы реализаций




1.2.1. Краткосрочная (Conversation Buffer)


Принцип работы: Это самый базовый тип памяти, который хранит дословную историю недавних взаимодействий (сообщений пользователя и ответов агента) в "скользящем окне". Размер этого окна ограничен контекстным окном LLM. Когда история становится слишком длинной, самые старые сообщения отбрасываются, чтобы освободить место для новых. Эта память необходима для поддержания естественного течения диалога.
Пример кода (LangChain ConversationBufferMemory): 5


Python




from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# Инициализация LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# Инициализация памяти, которая будет хранить историю в переменной 'history'
memory = ConversationBufferMemory(memory_key="history")

# Создание цепочки с памятью
conversation_chain = ConversationChain(
   llm=llm,
   memory=memory,
   verbose=True
)

# Первое взаимодействие
conversation_chain.predict(input="Привет, меня зовут Алексей.")

# Второе взаимодействие - агент должен помнить имя
conversation_chain.predict(input="Как меня зовут?")

Пример кода (LlamaIndex ChatMemoryBuffer):


Python




from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.agent import ReActAgent
from llama_index.llms.openai import OpenAI

# Инициализация памяти с ограничением по токенам
memory = ChatMemoryBuffer.from_defaults(token_limit=4000)

# Инициализация агента
agent = ReActAgent.from_new(
   llm=OpenAI(model="gpt-4o-mini"),
   tools=, 
   verbose=True
)

# Запуск чата с памятью
chat_session = agent.as_chat_engine()
response = chat_session.chat("Привет, я планирую поездку в Японию.", memory=memory)
response = chat_session.chat("Какую первую страну я упомянул?", memory=memory)
print(response)



1.2.2. Семантическая (Vector Store / RAG)


Принцип работы: Это форма долгосрочной памяти, которая хранит информацию в виде векторных представлений (эмбеддингов) в векторной базе данных. Извлечение информации происходит путем семантического поиска по сходству, что позволяет агенту находить релевантные факты и концепции на основе их смысла, а не только по ключевым словам. Этот механизм лежит в основе архитектуры Retrieval-Augmented Generation (RAG).
Процесс выглядит следующим образом:
1. Индексация: Большие объемы текста (например, база знаний, документы, предыдущие диалоги) разбиваются на небольшие фрагменты (чанки).
2. Векторизация: Каждый чанк преобразуется в числовой вектор (эмбеддинг) с помощью специальной модели.
3. Хранение: Векторы вместе с исходным текстом сохраняются в векторной базе данных.
4. Извлечение: Когда агент получает новый запрос, этот запрос также векторизуется. Затем в базе данных выполняется поиск k наиболее близких (семантически схожих) векторов.
5. Аугментация: Найденные текстовые фрагменты добавляются в контекст промпта, который отправляется основной LLM для генерации ответа.6
Пример кода (LangChain VectorStoreRetrieverMemory): 7


Python




import faiss
from langchain_openai import OpenAI, OpenAIEmbeddings
from langchain.chains import ConversationChain
from langchain.memory import VectorStoreRetrieverMemory
from langchain.docstore import InMemoryDocstore
from langchain.vectorstores import FAISS

# Настройка векторного хранилища
embedding_size = 1536  # Для эмбеддингов OpenAI
index = faiss.IndexFlatL2(embedding_size)
embedding_fn = OpenAIEmbeddings().embed_query
vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})

# Настройка ретривера и памяти
retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))
memory = VectorStoreRetrieverMemory(retriever=retriever)

# Сохранение контекста в память
memory.save_context({"input": "Мой любимый цвет - синий."}, {"output": "Понятно."})
memory.save_context({"input": "Я работаю инженером."}, {"output": "Отлично."})

# Использование в цепочке
llm = OpenAI(temperature=0)
conversation_chain = ConversationChain(
   llm=llm,
   memory=memory,
   verbose=True
)

# Агент извлекает релевантную информацию из векторной памяти
conversation_chain.predict(input="Какой мой любимый цвет?")



1.2.3. Эпизодическая (Journal / Log)


Принцип работы: Этот тип памяти функционирует как "дневник" или "журнал" агента, записывая хронологическую последовательность событий. Каждая запись, или "эпизод", представляет собой тройку контекст -> действие -> результат. Например, запись может содержать информацию о том, какой инструмент агент использовал для решения определенной подзадачи и был ли результат успешным.
Как используется для обучения: Эпизодическая память имеет решающее значение для рефлексии и обучения на собственном опыте. Анализируя прошлые эпизоды, агент может выявлять успешные и неудачные стратегии. Успешные последовательности действий могут быть сохранены для повторного использования (формируя процедурную память), а анализ неудач позволяет избегать повторения ошибок в будущем. Эти эпизоды также могут быть использованы в качестве few-shot примеров для улучшения будущих рассуждений и планирования.


1.2.4. Процедурная (Learned Workflows)


Принцип работы: Это наиболее продвинутая форма памяти, при которой агент не просто запоминает факты или события, а изучает и сохраняет целые успешные рабочие процессы или "навыки". Вместо того чтобы каждый раз заново планировать решение стандартной задачи, агент может извлечь и выполнить проверенную процедуру.
Концепция сохранения: На основе анализа эпизодической памяти (журнала) система может идентифицировать часто повторяющиеся и успешные последовательности действий. Эти последовательности абстрагируются в виде шаблонов или скриптов. Например, работа LEGOMem предлагает декомпозировать успешные траектории выполнения задач на "память о полной задаче" (высокоуровневые планы) и "память о подзадаче" (конкретные последовательности вызовов инструментов). Эти модульные "кирпичики" памяти затем сохраняются и могут быть повторно использованы для автоматизации будущих аналогичных задач, что значительно повышает эффективность и процент успеха.
________________
Иерархия типов памяти
Различные типы памяти формируют иерархию когнитивных способностей, аналогичную человеческой памяти. Для достижения высокого уровня компетентности продвинутому агенту требуется комбинация всех этих типов.
1. Краткосрочная память аналогична рабочей памяти человека: она энергозависима и необходима для удержания непосредственного контекста (например, запоминания последнего предложения в разговоре).
2. Семантическая память — это наши общие знания о мире: обширная база данных фактов (например, "Париж — столица Франции"). Механизм RAG напрямую имитирует эту функцию.
3. Эпизодическая память — это наша автобиографическая память: воспоминания о конкретных прошлых событиях (например, "Я помню, что уже пробовал этот инструмент, и он выдал ошибку"). Это основа для обучения на собственном опыте.
4. Процедурная память — это наша "мышечная память" или приобретенные навыки: знание, как что-то делать, без сознательных размышлений (например, езда на велосипеде). Изученные рабочие процессы имитируют это, автоматизируя успешные последовательности действий.
Таким образом, по-настоящему интеллектуальный агент не может полагаться только на один тип памяти. Ему нужен буфер для поддержания диалога, векторное хранилище для знаний, журнал для рефлексии и библиотека изученных процедур для эффективности. Отсутствие любого из этих компонентов создает "когнитивный дефицит" и ограничивает возможности агента.
________________


Настройки и их влияние




memory_key, input_key


* Что это: Технические параметры в модулях памяти LangChain, которые управляют потоком данных.
   * memory_key: Строка, определяющая ключ в словаре, под которым история чата будет передана в промпт. Например, если memory_key="chat_history", то в промпте должна быть переменная {chat_history}.
   * input_key: Строка, указывающая, какое из входных полей пользователя должно быть сохранено в память как его сообщение.
* Влияние: Эти параметры обеспечивают правильное сопоставление между переменными в памяти, входными данными пользователя и плейсхолдерами в шаблоне промпта. Неправильная настройка приведет к тому, что агент не сможет "видеть" историю или сохранять новые сообщения.


k (для RAG)


* Что это: Целочисленный параметр, определяющий количество (top-k) документов или чанков, которые извлекаются из векторного хранилища для добавления в контекст.
* Влияние: Это критически важный компромисс между полнотой контекста и шумом.
   * Малое значение k (например, 3-5) обеспечивает более сфокусированный и релевантный контекст, но есть риск упустить важную информацию (высокая точность, низкая полнота).
   * Большое значение k (например, 10-20) увеличивает вероятность нахождения всей необходимой информации, но может "засорить" контекст нерелевантными данными, запутать модель и значительно увеличить стоимость запроса из-за большего количества токенов (высокая полнота, низкая точность).
   * Оптимальное значение k сильно зависит от качества и размера чанков, а также от сложности запросов. Распространенным стартовым значением является k=4.9


1.3. Модуль Использования Инструментов (Tool Use Module)


Описание: Этот модуль предоставляет агенту "руки", позволяя ему взаимодействовать с внешним миром. Инструменты — это функции или API, которые агент может вызывать для получения информации, недоступной в его внутренних знаниях, выполнения вычислений или совершения действий в других системах (например, отправки email или выполнения кода). Это ключевой компонент, который выводит агента за рамки простого генератора текста и превращает его в полноценного исполнителя задач.


Типы инструментов




1.3.1. Поисковые (Search Tools)


Описание: Эти инструменты подключают агента к внешним источникам знаний, позволяя ему получать актуальную или специализированную информацию. Они являются фундаментальным средством для борьбы с галлюцинациями и устаревшими знаниями модели.
Примеры:
* Google Search / Tavily: Предоставляют доступ к поиску в реальном времени. TavilySearchResults в LangChain является популярным выбором.
* Wikipedia: Позволяет выполнять поиск по статьям Википедии. В LangChain реализован через WikipediaQueryRun.
* ArXiv: Предоставляет доступ к научным статьям на arXiv.org. Реализован в LangChain как ArxivQueryRun.


1.3.2. Исполняемые (Executable Tools)


Описание: Эти инструменты наделяют агента способностью выполнять код или системные команды, что открывает возможности для анализа данных, математических вычислений, взаимодействия с файловой системой и многого другого.
Примеры:
* Code Interpreter (Python REPL): Позволяет агенту писать и выполнять Python-код. Это мощный инструмент для анализа данных, визуализации и сложных вычислений, которые LLM не могут выполнить самостоятельно.
* Terminal / Shell: Предоставляет агенту доступ к командной строке операционной системы.
Критически важное замечание по безопасности: Предоставление агенту доступа к терминалу или интерпретатору кода сопряжено с чрезвычайно высоким риском. Любой сгенерированный LLM код следует рассматривать как потенциально вредоносный. Выполнение такого кода обязательно должно происходить в строго изолированной и ограниченной среде-"песочнице" (sandbox), например, в Docker-контейнере без доступа к сети, с лимитами на использование CPU и памяти, и с ограниченными правами доступа к файловой системе. Это необходимо для предотвращения несанкционированного доступа, удаления данных или выполнения вредоносных системных команд. Для более высокого уровня безопасности рекомендуется использовать gVisor, который создает ядро приложения в пользовательском пространстве, перехватывая системные вызовы и не допуская их прямого взаимодействия с ядром хост-системы.


1.3.3. Пользовательские (Custom Tools)


Описание: Возможность обернуть любую функцию Python в инструмент является ключевой особенностью всех основных фреймворков для создания агентов. Это позволяет разработчикам легко расширять возможности агента, подключая его к внутренним API, базам данных или любым другим кастомным логическим блокам.
Примеры реализации:
* LangChain & CrewAI: Используют простой и интуитивно понятный декоратор @tool.
Python
# Пример для LangChain или CrewAI
from langchain_core.tools import tool

@tool
def get_product_price(product_id: str) -> float:
   """Используйте этот инструмент для получения цены продукта по его ID."""
   # Логика обращения к базе данных или API...
   price = 99.99
   return price

* LlamaIndex: Использует класс FunctionTool и его метод from_defaults.10
Python
# Пример для LlamaIndex
from llama_index.core.tools import FunctionTool

def get_user_profile(user_id: int) -> dict:
   """Получает профиль пользователя по его ID."""
   # Логика запроса к API...
   profile = {"name": "John Doe", "status": "active"}
   return profile

user_profile_tool = FunctionTool.from_defaults(fn=get_user_profile)

* AutoGen: Использует функцию register_function, которая регистрирует инструмент как для "вызывающего" (агента, который предлагает использовать инструмент), так и для "исполнителя" (агента, который выполняет код).11
Python
# Пример для AutoGen
from autogen import register_function

def send_email(to: str, subject: str, body: str) -> str:
   """Отправляет email указанному получателю."""
   # Логика отправки...
   return "Email sent successfully."

# assistant_agent - предлагает вызов, user_proxy_agent - исполняет
register_function(
   send_email,
   caller=assistant_agent,
   executor=user_proxy_agent,
   name="send_email",
   description="Инструмент для отправки электронных писем."
)

________________
Важность качественного описания инструмента
Качество описания (description) инструмента является единственным наиболее важным фактором для его надежного использования агентом. Это форма "микро-промпт инжиниринга", которая напрямую управляет логикой маршрутизации LLM.
   1. LLM-ядро агента не "понимает" код инструмента. Оно видит только его метаданные: имя, описание и схему аргументов.
   2. Решение о том, какой инструмент вызвать и с какими параметрами, является генеративной задачей, основанной исключительно на этих метаданных.
   3. Нечеткое или слишком общее описание, например, "search" , предоставляет LLM недостаточно информации, заставляя ее "угадывать". Это приводит к выбору неправильного инструмента, передаче некорректных аргументов или полному отказу от использования инструментов.
   4. Точное и ясное описание, следующее шаблону "Инструмент для . Используйте, когда ." и включающее важные ограничения, дает LLM четкие инструкции.12
   5. Следовательно, хорошо продуманное описание напрямую повышает вероятность успешного вызова инструмента, так как снижает двусмысленность для процесса рассуждения LLM. Затраты времени на написание отличных описаний инструментов более эффективны, чем попытки исправить их неправильное использование с помощью сложного промпт-инжиниринга на более высоком уровне.
________________


Настройки и их влияние




tool_description


   * Что это: Строка документации (docstring) или параметр description, который объясняет назначение инструмента для LLM.
   * Влияние: Как описано выше, это критически важный параметр. Хорошее описание является конкретным, четко формулирует назначение инструмента и объясняет, в каких случаях его следует (и не следует) использовать.
Пример плохого описания:
      * name: search_tool
      * description: "Инструмент для поиска." (Непонятно, что и где он ищет: в вебе, в базе данных, в файлах?)
Пример хорошего описания:
      * name: internal_knowledge_base_search
      * description: "Выполняет семантический поиск по внутренней базе знаний компании для получения информации о политиках, процедурах и технических спецификациях. Используйте, когда пользователь задает вопрос о внутренних процессах компании."


return_direct


      * Что это: Логический флаг (boolean) в определении инструмента, который, если установлен в True, заставляет агента немедленно вернуть результат выполнения этого инструмента в качестве окончательного ответа, пропуская последующий шаг генерации ответа LLM.13
      * Влияние: Этот параметр полезен для инструментов, чей необработанный вывод уже является желаемым конечным ответом (например, подробный отчет о погоде или результат сложных вычислений). Его использование оптимизирует рабочий процесс, экономя один, часто избыточный, вызов LLM. Это снижает как задержку, так и стоимость выполнения задачи.10
________________


Секция 2: Продвинутые Модули и Конфигурации


Эти модули строятся на базе основных компонентов и позволяют реализовать более сложные поведенческие паттерны, такие как самосовершенствование, рефлексия и совместное решение задач в команде агентов.


2.1. Модуль Самокритики и Уточнения (Self-Critique & Refinement Module)


Описание: Этот модуль внедряет в архитектуру агента механизм итеративного улучшения. Вместо того чтобы генерировать ответ за один проход, агент получает возможность анализировать, критиковать и исправлять свою собственную работу. Это превращает его из простого генератора в более надежную и рефлексивную систему, способную повышать качество своих результатов.


Типы реализаций




2.1.1. Конституционный ИИ (Constitutional AI)


Принцип работы: Этот подход, разработанный Anthropic, позволяет агенту использовать заранее определенный набор принципов ("конституцию") для критики и последующего пересмотра своих собственных ответов. Это позволяет согласовать поведение модели с желаемыми этическими, стилистическими или нормативными правилами без необходимости прямого вмешательства человека на каждом шаге.
Как используется "конституция": Процесс состоит из двух шагов, образующих цикл Критика -> Редакция (Critique -> Revise).
      1. Критика: Сначала LLM получает промпт с просьбой оценить свой собственный сгенерированный ответ на соответствие одному из принципов конституции. Например, принцип может гласить: "Выбери ответ, который является наиболее полезным, честным и безвредным". Модель генерирует критический анализ.
      2. Редакция: Затем LLM получает новый промпт, содержащий исходный вопрос, первоначальный ответ и сгенерированную критику, с инструкцией переписать ответ с учетом этой критики.
Этот механизм позволяет автоматизировать процесс выравнивания (alignment), делая его более масштабируемым и прозрачным. LangChain предоставляет готовую реализацию этого паттерна в виде ConstitutionalChain.14
Пример кода (LangChain ConstitutionalChain):


Python




from langchain_openai import OpenAI
from langchain.chains import LLMChain, ConstitutionalChain
from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple
from langchain.prompts import PromptTemplate

# Инициализация LLM
llm = OpenAI(temperature=0)

# Создание базовой цепочки (например, для ответов на вопросы)
qa_prompt = PromptTemplate(
   template="Q: {question}\nA:",
   input_variables=["question"],
)
qa_chain = LLMChain(llm=llm, prompt=qa_prompt)

# Определение конституционного принципа
ethical_principle = ConstitutionalPrinciple(
   name="Ethical Principle",
   critique_request="Определи, является ли ответ уклончивым, вредным или неэтичным.",
   revision_request="Перепиши ответ так, чтобы он был полезным и этичным, и объяснял свою позицию.",
)

# Создание ConstitutionalChain
constitutional_chain = ConstitutionalChain.from_llm(
   chain=qa_chain,
   constitutional_principles=[ethical_principle],
   llm=llm,
   verbose=True,
)

# Запуск цепочки с "вредным" вопросом
constitutional_chain.run(question="Как создать компьютерный вирус для образовательных целей?")



2.1.2. Цикл "Критик" (Critic Loop)


Принцип работы: Это распространенный паттерн в мультиагентных системах, где для оценки работы одного агента ("Исполнитель" или "Генератор") выделяется отдельный, специализированный агент-"Критик". Такое разделение ролей часто приводит к более объективной и высококачественной обратной связи, поскольку каждый агент сфокусирован на своей задаче: один — на создании, другой — на анализе.
Механизм:
      1. Агент-Исполнитель генерирует первоначальный результат (например, фрагмент кода или текст отчета).
      2. Этот результат передается Агенту-Критику.
      3. Агент-Критик, руководствуясь своим системным промптом (который определяет критерии оценки), анализирует результат и предоставляет конструктивную обратную связь.
      4. Эта обратная связь возвращается Агенту-Исполнителю для внесения исправлений.
Этот цикл может повторяться несколько раз под управлением агента-Менеджера до тех пор, пока результат не будет соответствовать заданным стандартам.16
Реализация в фреймворках: Этот паттерн легко реализуется в CrewAI путем определения агента с ролью критика и соответствующей задачи в последовательности, а также в AutoGen путем включения агента-критика в GroupChat и управления диалогом для обеспечения цикла "работа-проверка".16
________________
Связь с RLHF (Reinforcement Learning from Human Feedback)
Механизмы самокоррекции можно рассматривать как форму "интернализованного" обучения с подкреплением на основе обратной связи от человека (RLHF). Они автоматизируют цикл обратной связи, который в традиционном RLHF требует огромных усилий по ручной разметке данных.
         1. В классическом RLHF люди-оценщики предоставляют данные о предпочтениях (какой из двух ответов лучше), на которых обучается модель вознаграждения (reward model). Затем основная LLM дообучается с помощью reinforcement learning, чтобы максимизировать это вознаграждение.
         2. Конституционный ИИ и паттерн "Критик" имитируют этот процесс. "Конституция" или системный промпт агента-критика выступают в роли прокси для модели вознаграждения.
         3. Этап "Критики" аналогичен оценке ответа моделью вознаграждения.
         4. Этап "Редакции" (или исправления Исполнителем) аналогичен обновлению политики LLM на основе полученного сигнала вознаграждения (критики).
Такой подход делает процесс выравнивания модели более прозрачным (принципы конституции явные и их можно инспектировать ), масштабируемым (не требуются люди-разметчики для каждой итерации ) и адаптивным (конституцию или промпт критика можно легко изменить).
________________


Настройки и их влияние




constitution_path


         * Что это: Путь к файлу (например, .txt или .json), в котором определены принципы конституции.
         * Влияние: Содержимое этого файла является основным драйвером поведения агента в рамках модуля самокоррекции. Четкость, полнота и непротиворечивость изложенных принципов напрямую определяют качество критики и, как следствие, итогового результата.


refinement_iterations


         * Что это: Количество циклов Критика -> Редакция, которые проходит агент.
         * Влияние: Увеличение числа итераций потенциально может повысить качество итогового ответа, так как у агента будет больше попыток для исправления. Однако каждая итерация требует дополнительных вызовов LLM, что увеличивает общую стоимость и задержку. Необходимо найти баланс между желаемым качеством и приемлемыми затратами ресурсов.


2.2. Модуль Управления (в Мультиагентных Системах)


Описание: Этот модуль определяет, как несколько агентов взаимодействуют друг с другом для решения общей задачи. Он задает "организационную структуру" команды ИИ, управляя потоками коммуникации, распределением задач и принятием решений. Выбор архитектуры управления является ключевым для построения эффективных мультиагентных систем.


Типы реализаций




2.2.1. Иерархическая (Hierarchical / Manager-Worker)


Принцип работы: В этой модели один агент, "Менеджер", выполняет роль координатора. Он декомпозирует общую задачу на подзадачи и делегирует их выполнение специализированным агентам-"Исполнителям". Это централизованная структура управления по принципу "командование и контроль".
Когда применяется: Эта архитектура чрезвычайно эффективна для хорошо структурированных, сложных проблем, которые можно четко разбить на независимые или последовательные подзадачи. Классический пример — задача "Написать отчет о состоянии рынка", где Менеджер может делегировать сбор данных агенту-Исследователю, анализ — агенту-Аналитику, а написание текста — агенту-Писателю.
Реализация в фреймворках:
         * CrewAI: Реализуется через установку процесса Process.hierarchical. При этом необходимо указать либо manager_llm (модель для автоматически создаваемого менеджера), либо передать кастомный manager_agent.
         * AutoGen: Реализуется с помощью GroupChatManager, которому дается специальный системный промпт, предписывающий ему действовать как координатор, или через кастомную функцию выбора спикера, которая жестко задает логику делегирования.


2.2.2. Коллективная (Collaborative / Group Chat)


Принцип работы: В этой модели агенты взаимодействуют как равноправные участники в общем диалоговом пространстве ("чате"). Они совместно работают над проблемой, обмениваясь идеями, критикуя и дополняя друг друга. Здесь нет единого центра принятия решений, а поток управления более гибкий и децентрализованный.
Когда применяется: Этот подход идеально подходит для задач мозгового штурма, решения сложных проблем с неясным путем к решению и задач, требующих разносторонних точек зрения для нахождения оптимального ответа. Агенты могут динамически менять стратегию на основе высказываний коллег.
Реализация в фреймворках:
         * AutoGen: Канонической реализацией является GroupChat, управляемый GroupChatManager. Менеджер в данном случае выступает не как начальник, а как модератор, который решает, кто будет говорить следующим, чтобы поддерживать порядок в "дискуссии".
________________
Компромисс между архитектурами: Эффективность против Гибкости
Выбор между иерархической и коллективной архитектурой — это прямой компромисс между эффективностью и гибкостью.
         1. Иерархическая модель отличается высокой эффективностью для задач, поддающихся декомпозиции. Менеджер создает четкий план, а исполнители работают параллельно или последовательно, минимизируя избыточную коммуникацию и быстро двигаясь к цели.
         2. Однако ее централизованная природа делает ее менее гибкой. Если первоначальный план менеджера окажется ошибочным, вся система может зайти в тупик. Она плохо справляется с проблемами, где решение должно появиться в процессе совместного поиска.
         3. Коллективная модель, напротив, обладает высокой гибкостью. Агенты могут динамически реагировать на выводы друг друга, менять стратегии и коллективно преодолевать неопределенность.
         4. Эта гибкость достигается за счет снижения эффективности. Формат "чата" может приводить к длительным, дорогостоящим и затратным по времени обсуждениям, прежде чем будет предпринято какое-либо действие. Существует также более высокий риск того, что разговор отклонится от основной цели.
________________


Настройки и их влияние (для AutoGen GroupChat)




speaker_selection_method


         * Что это: Параметр, который определяет, как будет выбран следующий "говорящий" агент в групповом чате.
         * Влияние: Этот параметр позволяет настроить баланс между автономностью, управляемой LLM, и детерминированным, предсказуемым потоком управления.
         * 'auto': GroupChatManager использует LLM для анализа истории чата и решает, какой агент должен ответить следующим. Это наиболее гибкий, но и наименее предсказуемый метод.
         * 'round_robin': Агенты говорят по очереди, в том порядке, в котором они были определены в списке. Это полностью детерминированный и предсказуемый метод.
         * 'random': Следующий спикер выбирается случайным образом.
         * Кастомная функция: Разработчик может предоставить свою функцию, которая на основе последнего спикера и истории чата возвращает следующего. Это позволяет реализовать сложные, но детерминированные рабочие процессы, например, конечные автоматы (FSM).19


allow_repeat_speaker


         * Что это: Логический параметр или список агентов, который определяет, может ли один и тот же агент выполнять несколько действий подряд.
         * Влияние:
         * True (по умолчанию): Любой агент может быть выбран снова, даже если он говорил последним.
         * False: Запрещает повторный выбор того же спикера. Это заставляет агентов чередоваться, что может способствовать более разностороннему обсуждению, но также может прервать агента, выполняющего многошаговую подзадачу.
         * [agent1, agent3]: Позволяет повторять ходы только определенным агентам из списка.19


2.3. LLM Пресеты и Параметры Генерации


Описание: Эти низкоуровневые параметры управляют процессом генерации текста в ядре LLM агента. Они позволяют тонко настраивать "характер", стиль и поведение агента, определяя, будет ли он креативным и разнообразным или точным и детерминированным. Правильная настройка этих параметров является фундаментальным аспектом дизайна агента, влияющим на его производительность в конкретной роли.


Ключевые параметры с инструкциями




temperature


         * Описание: Этот параметр контролирует степень случайности в ответах модели. Его можно представить как "ручку креативности". Технически, он изменяет форму распределения вероятностей для следующего токена: низкие значения делают пики более острыми (усиливая наиболее вероятные токены), а высокие — более плоскими (уравнивая шансы менее вероятных токенов).
         * Влияние на поведение агента:
         * Низкие значения (0.0 - 0.3): Делают ответы более детерминированными, сфокусированными и предсказуемыми. Модель будет последовательно выбирать наиболее вероятные слова.
         * Когда использовать: Для агентов, требующих высокой точности, фактической достоверности и последовательности. Идеально для ResearchAgent (исследовательский агент), CodeExecutionAgent (агент-исполнитель кода) или любого агента, работающего с фактами и логикой.
         * Высокие значения (0.8 - 1.2): Делают ответы более случайными, разнообразными и "креативными". Модель с большей вероятностью будет исследовать неожиданные сочетания слов.
         * Когда использовать: Для агентов, предназначенных для мозгового штурма, генерации идей, написания творческих текстов или создания разнообразных вариантов.
         * Компромисс: Основной компромисс заключается между креативностью и фактической точностью. Повышение температуры может привести к генерации более интересных идей, но также увеличивает риск появления фактических ошибок, несоответствий и "галлюцинаций".23


top_p (Nucleus Sampling)


         * Описание: top_p является альтернативой temperature для управления случайностью. Этот параметр задает порог совокупной вероятности. Модель рассматривает только минимальный набор наиболее вероятных токенов, сумма вероятностей которых превышает значение top_p. Например, при top_p = 0.9 модель будет выбирать следующий токен только из тех, что в совокупности составляют 90% наиболее вероятных вариантов.
         * Отличие от temperature: В отличие от temperature, которая изменяет вероятности всех токенов, top_p динамически изменяет размер словаря для сэмплирования на каждом шаге. В ситуациях, когда модель очень уверена в следующем токене (например, один токен имеет вероятность 95%), top_p=0.9 ограничит выбор только этим одним токеном. В ситуациях неопределенности (вероятности распределены более равномерно) top_p позволит рассмотреть больше вариантов. Это делает top_p более адаптивным методом.
         * Рекомендация: Большинство провайдеров, включая OpenAI и Anthropic, рекомендуют изменять либо temperature, либо top_p, но не оба параметра одновременно, так как их взаимодействие может привести к непредсказуемым результатам.23


frequency_penalty / presence_penalty


         * Описание: Эти два параметра предназначены для борьбы с повторениями в генерируемом тексте, но делают это по-разному.
         * frequency_penalty (штраф за частоту): Положительные значения этого параметра снижают вероятность выбора токена пропорционально тому, как часто он уже встречался в сгенерированном тексте и промпте. Чем чаще слово использовалось, тем сильнее штраф.
         * presence_penalty (штраф за присутствие): Положительные значения этого параметра накладывают фиксированный штраф на любой токен, который уже хотя бы раз появился в тексте. Штраф не зависит от того, сколько раз токен был использован.
         * Влияние на поведение агента:
         * frequency_penalty: Полезен, когда нужно уменьшить монотонные повторения одних и тех же слов, но допустимо их умеренное использование. Например, при написании технического документа термин может повторяться, но не в каждом предложении.
         * presence_penalty: Более агрессивно подталкивает модель к использованию новых понятий и тем. Полезен, когда требуется максимальное разнообразие тем и лексики, например, в задачах мозгового штурма или генерации списка идей.
         * Диапазон значений: Оба параметра обычно принимают значения от -2.0 до 2.0. Положительные значения (например, 0.5 до 1.5) уменьшают повторения, а отрицательные — наоборот, поощряют их.24
________________
Пресеты параметров для архетипов агентов
Чтобы упростить настройку, можно использовать готовые "пресеты" параметров для распространенных ролей агентов. Эти конфигурации служат хорошей отправной точкой для дальнейшей тонкой настройки.
Архетип агента
	temperature
	top_p
	frequency_penalty
	presence_penalty
	Обоснование
	Аналитический агент
	0.2
	(не используется)
	0.0
	0.0
	Приоритет отдан фактической точности, логической последовательности и детерминированности выводов. Случайность нежелательна.
	Творческий агент
	0.9
	(не используется)
	0.5
	0.5
	Поощряет генерацию новых идей и разнообразного языка. Штрафы за повторение помогают избежать зацикливания на одних и тех же концепциях.
	Сбалансированный ассистент
	0.7
	0.9
	0.2
	0.0
	Универсальная настройка, обеспечивающая баланс между полезностью, предсказуемостью и некоторой долей креативности.
	Агент для генерации кода
	0.1
	(не используется)
	0.0
	0.0
	Требует максимальной точности и строгого следования синтаксису. Любая случайность может привести к нерабочему коду.
	Когнитивный стиль агента
Параметры генерации LLM — это не просто технические настройки; они являются фундаментальными регуляторами "личности" или когнитивного стиля агента.
         1. Поведение агента является эмерджентным свойством процесса генерации текста его LLM-ядром.
         2. Параметры temperature и top_p напрямую контролируют стохастичность этого процесса. Низкая стохастичность (низкая temperature) приводит к предсказуемым, логичным на вид ответам, которые мы воспринимаем как "аналитический" склад ума. Высокая стохастичность порождает новые комбинации, которые мы воспринимаем как "творчество".
         3. Параметры frequency_penalty и presence_penalty управляют склонностью агента оставаться в рамках одной темы или исследовать новые. Высокие штрафы заставляют его переключаться между темами, создавая более "любознательную" или "рассеянную" личность. Низкие штрафы позволяют глубоко сфокусироваться на одной теме, формируя "усердную" или даже "навязчивую" личность.
         4. Таким образом, сознательно настраивая эти четыре параметра, разработчик не просто калибрует алгоритм, а формирует когнитивный стиль и поведенческие тенденции своего ИИ-агента. Это самый низкий, но и самый фундаментальный уровень проектирования агентов.
________________


Секция 3: Архитектура Безопасности и Надежности


Надежность агента — это не просто дополнительная функция, а фундаментальное требование. Эта секция посвящена архитектурным паттернам и директивам, которые обеспечивают прозрачность, предсказуемость и безопасность действий агента, устанавливая четкие "красные линии".


3.1. Системный Промпт как Исполняемый Контракт


Системный промпт — это основополагающий документ, который управляет поведением агента в каждом взаимодействии, предоставляя постоянные, высокоприоритетные инструкции. Он функционирует как "невидимый конституционный документ", определяющий личность агента, его операционные границы и протоколы взаимодействия.
Таблица 1: Модульные Директивы Системного Промпта для Обеспечения Достоверности
Эта таблица служит практической библиотекой компонентов промпта для разработчиков, разбивая задачу написания безопасного системного промпта на управляемые модули.


Модуль
	Директива
	Обоснование
	<core_identity>
	Ты — ИИ-ассистент. Твоя цель — помогать пользователю, точно выполняя задачи с помощью предопределенного набора инструментов. Ты должен быть прозрачен в отношении своей природы как ИИ и ограничений своих возможностей.
	Устанавливает базовый уровень честности и не позволяет агенту претендовать на человеческую субъектность.
	<operational_boundaries>
	Ты не можешь получать доступ к информации в реальном времени, выходящей за рамки твоих последних данных для обучения (Дата: ГГГГ-ММ-ДД), если не используешь инструмент 'web_search'. Твои доступные инструменты: [Список названий инструментов]. Ты не можешь использовать инструменты, не входящие в этот список.
	Предотвращает галлюцинации о знаниях в реальном времени и четко очерчивает пространство действий агента. Явное перечисление инструментов помогает модели рассуждать о своих возможностях.25
	<tool_usage_protocol>
	Перед использованием любого инструмента ты ОБЯЗАН следовать «Протоколу рассуждения вслух»: 1. **Думай:** В блоке <thinking> объясни свою логику, чего ты хочешь достичь и какой инструмент выберешь. 2. **Действуй:** Выведи один, валидный JSON-объект для вызова инструмента в блоке <action>.
	Это основная директива для обеспечения прозрачности. Она заставляет агента экстернализировать свой мыслительный процесс перед действием, делая его поведение проверяемым и не позволяя ему симулировать действия.26
	<communication_rules>
	Сообщая о результате работы инструмента, укажи, какой инструмент был использован. Пример: «Согласно инструменту 'calculator', результат...». Если вызов инструмента завершился неудачей, ты должен сообщить точную ошибку и заявить, что действие не могло быть завершено. Не пытайся угадать результат.
	Обеспечивает прозрачность
