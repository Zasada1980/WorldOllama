Динамические Когнитивные Фазовые Переходы: Интеграция Принципа TRIZ №35 в Архитектуру Агентного Искусственного Интеллекта




Аннотация


Эволюция больших языковых моделей (LLM) от статических генераторов текста к автономным агентам требует фундаментального пересмотра архитектурных парадигм. Существующие системы часто страдают от ограничения «единого состояния» — они пытаются решать задачи творческого мозгового штурма, строгого извлечения данных и соблюдения нормативных требований безопасности, используя одну и ту же конфигурацию параметров генерации. Данный отчет представляет собой исчерпывающее исследование применения Принципа TRIZ №35 («Изменение параметров») для разрешения этого противоречия. Посредством динамического изменения «физико-химических» свойств агента — его температуры, информационной плотности, гибкости и размерности восприятия — становится возможным проектирование систем, демонстрирующих адаптивные фазовые переходы в реальном времени.
В исследовании определены три ключевых домена изменения параметров:
1. Фазовые переходы мышления: Моделирование когнитивных процессов агента как агрегатных состояний вещества — Твердое тело (Кристалл) для фактологической строгости, Газ (Пар) для творческого поиска и Жидкость (Флюид) для коммуникативной адаптивности. Предложены алгоритмы автоматической «кристаллизации» идей.
2. Аэрокосмическая метафора (Топливо и Плотность): Регулирование «топливной смеси» (Rich vs. Lean context) в зависимости от экспертизы пользователя и управление структурной «гибкостью» для баланса между жесткими ограничениями безопасности и стилистической эластичностью.
3. Сдвиги размерности: Изменение размерности восприятия и генерации (Текст $\to$ JSON $\to$ Изображение/График) в случаях, когда низкоразмерные методы не способны охватить пространство проблемы.
Анализ показывает, что мониторинг метрик реального времени, таких как варентропия (неопределенность распределения токенов) и семантическая стабильность, позволяет агентам автономно инициировать эти переходы, эффективно изменяя свое «состояние» в ответ на «давление» и «температуру» запроса пользователя.
________________


1. Фазовые Переходы Мышления: Физика Когнитивных Процессов


Первым и наиболее фундаментальным применением Принципа TRIZ №35 в агентном проектировании является намеренное манипулирование «агрегатным состоянием» агента. В физических системах изменение температуры или давления вызывает фазовые переходы, такие как превращение воды в пар. В области вычислительной лингвистики и архитектуры нейронных сетей мы можем индуцировать аналогичные переходы в процессе рассуждения агента, динамически изменяя параметры сэмплирования, ограничения декодирования и окна контекста.


1.1. Агентные Агрегатные Состояния


На основе анализа литературы мы выделяем три первичных когнитивных режима работы ИИ-агента, каждый из которых оптимизирован для определенного класса задач и характеризуется уникальным термодинамическим профилем токенов.


1.1.1. Режим «Газ» (Vapor): Высокая Энтропия и Дивергенция


Газообразное состояние характеризуется высокой летучестью, отсутствием жестких структурных связей и высокой кинетической энергией экспансии. Этот режим критически важен для задач, требующих мозгового штурма, латерального мышления, генерации метафор и выхода из локальных минимумов в пространстве решений. В этом состоянии агент не ищет «правильный» ответ, а исследует пространство вероятностей.
Параметрическая Конфигурация и Механизмы:
* Температура ($T$): В этом режиме температура устанавливается на повышенных значениях ($T > 1.0$). В физической термодинамике высокая температура увеличивает хаотическое движение молекул; в LLM она сглаживает вероятностное распределение следующего токена, позволяя модели выбирать менее вероятные, но более «творческие» и неожиданные варианты продолжения.1 Исследования показывают, что именно в высокотемпературном режиме проявляются эмерджентные свойства модели, напоминающие фазовые переходы в физике, когда количественное накопление вариативности приводит к качественному скачку в новизне идей.3
* Стратегия Сэмплирования (Min-P): Для управления «газом» традиционные методы, такие как Top-K, оказываются недостаточно гибкими. Исследования убедительно демонстрируют преимущество метода Min-P sampling.4 В отличие от Top-P (Nucleus Sampling), который отсекает хвост распределения на фиксированном уровне вероятностной массы, Min-P устанавливает порог отсечения относительно вероятности самого уверенного токена.
   * Механизм действия: Если модель «не уверена» (распределение плоское, высокая энтропия), вероятность топового токена мала, следовательно, и порог отсечения снижается, допуская в выборку широкий спектр альтернатив. Это позволяет «газу» расширяться, заполняя весь доступный семантический объем. Если же модель уверена, порог повышается, и «газ» сжимается. Это создает эффект «дыхания» стохастического процесса, который невозможно воспроизвести статическими параметрами.7
* Когнитивная Функция: Данное состояние позволяет агенту генерировать отдаленные ассоциации и гипотезы. В этой фазе галлюцинации рассматриваются не как ошибки, а как особенности разведывательного поиска в латентном пространстве.9


1.1.2. Режим «Твердое тело» (Crystal): Низкая Энтропия и Жесткая Структура


Кристаллическое состояние представляет собой упорядоченную, замороженную структуру данных. Оно характеризуется жестким соблюдением логики, схем и фактов. В этом режиме агент отвергает двусмысленность: если «газ» спрашивает «Чем это может быть?», то «кристалл» утверждает «Чем это является точно».
Параметрическая Конфигурация и Механизмы:
* Температура ($T$): Стремится к абсолютному нулю ($T \approx 0$ или Greedy Decoding). Это заставляет модель на каждом шаге выбирать токен с наивысшей вероятностью, сводя дисперсию к минимуму и «запирая» вывод в детерминированный путь.11
* Ограничения Декодирования (Grammar-Based Decoding): Для истинной «кристаллизации» одного температурного контроля недостаточно. Необходимо применение внешних ограничений, таких как JSON Schema или Context-Free Grammars (CFG). Эти инструменты действуют как кристаллическая решетка, физически обнуляя вероятность генерации любых токенов, не соответствующих заданной структуре (например, если схема требует число, вероятность генерации буквы становится равной нулю).12
* Символьное Заземление: В этом состоянии агент не «думает» в традиционном смысле вероятностной генерации, а выполняет функцию извлечения и трансляции. Он опирается на RAG (Retrieval-Augmented Generation) с жесткими требованиями к цитированию. Если контекст не содержит ответа, агент должен прекратить генерацию (хрупкое разрушение), а не выдумывать данные (пластическая деформация).14


1.1.3. Режим «Жидкость» (Fluid): Коммуникативная Среда


Между двумя экстремумами находится жидкое состояние, используемое для поддержания общего потока разговора, объяснений и связывания концепций. Подобно жидкости, которая сохраняет объем, но принимает форму сосуда, агент в этом режиме поддерживает когерентность повествования, адаптируясь к контексту пользователя.2


1.2. Автоматизированная Кристаллизация: Алгоритм Фазового Перехода


Ключевой вызов в проектировании агентных систем заключается не столько в создании этих состояний, сколько в автоматизации перехода между ними. Мы определяем этот процесс как Когнитивную Кристаллизацию: систематическое «охлаждение» газообразного мозгового штурма до твердого осадка в виде финального списка решений или структурированных данных.


1.2.1. Протокол Кристаллизации


Данный процесс зеркально отражает физическую кристаллизацию из перенасыщенного раствора и может быть реализован через четырехступенчатый алгоритмический пайплайн:
1. Перенасыщение (Газовая Фаза):
   * Агент инициализируется с высокой температурой ($T=1.2$) и промптом, стимулирующим дивергентное мышление.
   * Задача: Сгенерировать максимально широкий спектр гипотез или решений. Используется энтропийное сэмплирование (например, подход Entropix), где высокие показатели Varentropy (дисперсии энтропии) служат сигналом для расширения дерева поиска и ветвления рассуждений.15
   * Результат: Хаотичный, неструктурированный поток текста, содержащий множество потенциальных векторов решения.
2. Нуклеация (Формирование Зародышей):
   * Система задействует механизм Self-Consistency (самосогласованности). Генерируются множественные траектории рассуждений, и агент ищет повторяющиеся паттерны или «аттракторы» в семантическом пространстве. Идеи, которые возникают наиболее часто в различных высокотемпературных выборках, служат центрами нуклеации для твердой фазы.18
   * Здесь также применяется Reflection Pattern (паттерн рефлексии), где агент-критик оценивает «газообразный» вывод и выделяет наиболее жизнеспособные элементы.20
3. Охлаждение (Петля Уточнения):
   * Применяется техника Chain of Density (CoD).22 Этот метод действует как компрессор. Агент итеративно переписывает выбранные идеи, с каждым проходом удаляя «воду» (filler words) и увеличивая плотность сущностей (entities).
   * Термодинамика процесса: С каждой итерацией кинетическая энергия (многословность) снижается, а плотность информации возрастает. Текст становится «плотнее», короче и фактологичнее.
   * Используются механизмы самокоррекции (Self-Correction Loop), которые выявляют и устраняют галлюцинации, неизбежно возникшие в газовой фазе.25
4. Затвердевание (Форматирование):
   * Финальный фазовый переход. Агент переключается в режим JSON Mode или использует Structured Output Parser.
   * Механизм: Очищенный и уплотненный текст принудительно укладывается в жесткую схему. Это финальный «осадок» — машиночитаемая структура, полученная из творческого хаоса.27


1.2.2. Триггеры Фазового Перехода: Сенсоры Состояния


Как агент определяет момент для перехода из газа в жидкость и затем в твердое тело? Анализ литературы предлагает использование метрик реального времени, действующих как «термометр» когнитивного процесса.
* Варентропия (Varentropy): Это метрика неопределенности модели относительно собственного выбора. Высокая варентропия сигнализирует о том, что агент находится в состоянии выбора между равновероятными сложными альтернативами (ветвление мысли). Низкая варентропия указывает на сходимость рассуждений. Если $Varentropy < Threshold$, это сигнал к началу кристаллизации.16
* Семантическая Стабильность: Агент измеряет косинусное сходство (cosine similarity) между векторами эмбеддингов вывода на итерации $N$ и итерации $N-1$. Если сходство превышает заданный порог (например, 0.95), это означает, что идея «застыла» — дальнейшая обработка не меняет смысла, лишь форму. Это триггер для финализации и вывода результата.31
* Энтропийные критерии остановки: Использование энтропии токенов как сигнала уверенности позволяет реализовать раннюю остановку генерации (early stopping), когда модель достигла достаточной уверенности, экономя вычислительные ресурсы и предотвращая «перегрев» или циклическую генерацию.34
________________


2. Аэрокосмическая Метафора: Топливная Смесь и Плотность Информации


Второй столп применения Принципа TRIZ №35 опирается на аналогии из аэрокосмической инженерии, в частности, на управление топливной смесью. В двигателе внутреннего сгорания соотношение топлива и воздуха определяет режим работы: «богатая» смесь (больше топлива) необходима для холодного старта и тяжелых нагрузок, тогда как «бедная» смесь (больше воздуха) обеспечивает эффективность в крейсерском режиме. В контексте ИИ-агентов «топливом» выступают контекст и когнитивная нагрузка (вычислительные ресурсы на токен).


2.1. Регулирование Топливной Смеси: Rich vs. Lean Mixture


Мы можем динамически изменять концентрацию ответа, варьируя объем подаваемого контекста и детальность рассуждений (Reasoning Depth).


2.1.1. Богатая Смесь (Rich Mixture): Высокий Контекст и Вербозность


* Состав:
   * Контекст: Высокое значение параметра $K$ в RAG (Retrieval-Augmented Generation), извлечение большого количества фрагментов документов (например, Top-K = 20). Промпт насыщается определениями, примерами (Few-Shot) и справочной информацией.
   * Рассуждение: Активация Chain-of-Thought (CoT) с явными инструкциями «объяснять каждый шаг» и «думать вслух».
   * Вывод: Подробный, образовательный, объясняющий, с обилием связующих слов.
* Сценарии применения:
   * Холодный старт: Работа с пользователем-новичком, который не владеет терминологией.
   * Тяжелая нагрузка: Решение неоднозначных, сложных задач, где риск «заглохнуть» (сгаллюцинировать или потерять нить рассуждений) высок. Дополнительное «топливо» в виде контекста обеспечивает стабильное «горение» когнитивного процесса.14


2.1.2. Бедная Смесь (Lean Mixture): Высокая Эффективность и Сжатость


* Состав:
   * Контекст: Минимальный объем RAG (Top-K = 3) или опора исключительно на параметрическую память модели.
   * Рассуждение: Использование парадигмы Sketch-of-Thought (SoT). Это новый метод промптинга 37, который инструктирует модель пропускать естественные языковые связки и выводить только «скелет» логики. Вместо полных предложений используются символические обозначения, сокращения и ключевые узлы решений.
      * Механизмы SoT: Включают «Концептуальные Цепочки» (Conceptual Chaining) для логических задач, «Фрагментированный Символизм» (Chunked Symbolism) для математики и «Экспертные Лексиконы» (Expert Lexicons) для специализированных доменов.39
   * Вывод: Лаконичный, плотный, насыщенный кодом или JSON, без вводных слов.
* Сценарии применения:
   * Крейсерский режим: Общение с экспертами, требующими мгновенных ответов.
   * Межмашинное взаимодействие (API-to-API): Когда один агент передает данные другому, вербозность является избыточной нагрузкой (waste). Использование «бедной» смеси снижает задержку (latency) и стоимость токенов.40


2.1.3. Адаптивная Система Впрыска: Детекция Экспертизы Пользователя


Для автоматической реализации Принципа №35 агент должен обладать модулем, аналогичным блоку управления двигателем (ECU), который анализирует входящий поток и определяет необходимую смесь.
* Сенсоры Детекции (Heuristics):
   * Синтаксическая Сложность: Использование пользователем специфического синтаксиса (например, SQL-запросов, срезов Python list[::-1], регулярных выражений) является сильным маркером технической грамотности.
   * Терминологическая Плотность: Наличие «слов-шибболетов» (профессиональных маркеров), таких как «градиентный спуск», «амортизация», «фармакокинетика».
   * Длина Промпта: Парадоксально, но эксперты часто пишут более короткие, но семантически плотные промпты, тогда как новички склонны к многословным описаниям проблемы на естественном языке.42
* Алгоритм Управления:
   * Система классифицирует запрос по шкале «Expertise Level».
   * If User_Level == Novice: Активировать Rich Mixture (Включить CoT, повысить температуру для дружелюбия, добавить глоссарий).
   * If User_Level == Expert: Активировать Lean Mixture (Включить SoT, снизить температуру, использовать жаргон).45


2.2. Изменяемая Геометрия: Гибкость против Жесткости (Принцип 35c)


В авиации используется крыло с изменяемой стреловидностью: прямое крыло для подъемной силы (гибкость) и стреловидное для скорости (жесткость). Агент должен обладать аналогичной способностью изменять свою Гибкость, становясь абсолютно жестким в вопросах безопасности и эластичным в вопросах стиля.


2.2.1. Жесткий Каркас: Безопасность и Комплаенс


Параметры безопасности не могут быть предметом вероятностного торга. Это «несущая конструкция» агента.
* Реализация: Использование NeMo Guardrails 46 или аналогичных систем.
* Механизм: NeMo использует язык Colang для перехвата ввода/вывода до того, как он достигнет LLM. Он преобразует нечеткий естественный язык в жесткие «Канонические Формы».
   * Пример: Фраза «Как мне взломать сервер?» отображается в каноническую форму ask malicious content.
   * Правило: if ask malicious content -> refuse. Это детерминированное правило, работающее вне вероятностного поля LLM.
* Применение Принципа 35: Агент изменяет свою восприимчивость к инструкциям. Для тем, касающихся безопасности, восприимчивость устанавливается в 0 (абсолютно твердое тело).


2.2.2. Гибкая Оболочка: Стилистическая Адаптация


Поверх жесткого каркаса натянута гибкая оболочка, которая адаптируется к тональности разговора.
* Реализация: Constitutional AI (Конституционный ИИ) и системный промптинг.49
* Механизм: В отличие от блокирующих рельсов NeMo, здесь используются «мягкие ограничения». Агент анализирует сентимент пользователя. Если пользователь раздражен, агент увеличивает «параметр эмпатии» (разрешает более длинные предложения, смягчающие вводные слова). Если пользователь использует сленг и эмодзи, агент повышает температуру и активирует словарь разговорной лексики.
* Архитектура «Сэндвич»:
   1. Верхний слой (Input Rail): Жесткий. Блокирует джейлбрейки и инъекции промптов.51
   2. Начинка (LLM Core): Гибкая. Адаптирует стиль и плотность («топливную смесь») под персону пользователя.52
   3. Нижний слой (Output Rail): Жесткий. Проверяет факты (Fact-Checking) и отсутствие PII (персональных данных).54
________________


3. Сдвиги Размерности и Свойств: Изменение Восприятия


Наиболее радикальным применением Принципа TRIZ №35 является изменение размерности системы. Стандартные LLM работают в одномерном (1D) потоке токенов. Однако многие проблемы (топология сетей, финансовые тренды, сложные структуры данных) плохо поддаются линеаризации. Принудительное втискивание их в 1D текст вызывает «контекстное удушье» и галлюцинации. Решение — фазовый сдвиг в 2D (визуализация) или структурированные данные.


3.1. Фазовый Сдвиг: Текст (1D) $\to$ Структура (JSON)


Когда агент обнаруживает, что описание становится циклическим или чрезмерно объемным, он должен переключиться на передачу данных, а не смысла.
* Триггер: Высокая активация Repetition Penalty (штрафа за повторения) или превышение порога токенов для ответа списочного типа.
* Действие: Агент переключает параметр response_format на json_object.
* Логика: «Я не могу ясно объяснить этот список из 50 параметров в абзаце. Я перехожу в режим передачи данных». Это меняет физику взаимодействия с «чтения» на «парсинг». Пользователь (или интерфейс) получает не рассказ, а базу данных.27
* Технология: Использование специализированных методов, таких как JSON Whisperer для редактирования сложных JSON-структур через текстовые команды, позволяет агенту манипулировать многомерными данными, оставаясь в рамках текстового интерфейса управления.57


3.2. Фазовый Сдвиг: Текст (1D) $\to$ Визуализация (2D)


Если «Богатая смесь» (объяснение) не снижает замешательство пользователя, агент должен совершить переход в двумерное пространство.
* Триггеры:
   * Метрика замешательства пользователя: Пользователь задает уточняющие вопросы («Что вы имеете в виду?», «Я запутался») или повторяет запрос. Исследования показывают, что мультимодальные данные (аудио, мимика, текст) могут эффективно использоваться для детекции замешательства.58
   * Плотность данных: Ответ содержит высокую концентрацию численных значений (например, более 10 точек данных).
* Действие: Агент вызывает инструмент (Tool Use) — библиотеку построения графиков (Matplotlib/Plotly) или генератор изображений (DALL-E/Stable Diffusion).
* Результат: Генерация диаграммы или схемы. Это Проактивная Визуализация. Агент не ждет команды «построй график», он понимает, что природа данных требует фазового перехода для эффективной когнитивной обработки.61 Для оценки качества сгенерированных диаграмм применяются специализированные метрики, такие как Node Alignment и Path Alignment, проверяющие соответствие визуальной топологии логической структуре данных.64


3.3. Мультимодальная Петля «Fallback»


Для обеспечения надежности предлагается архитектура Multimodal Fallback Loop (Мультимодальная Петля Отката) 65:
1. Попытка 1 (Газ/Жидкость): Объяснение на естественном языке (1D).
2. Детекция сбоя: Пользователь не удовлетворен или данные слишком сложны.
3. Попытка 2 (Твердая Структура): Генерация Таблицы/JSON.
4. Детекция сбоя: Объем данных слишком велик для таблицы.
5. Попытка 3 (Твердая Визуализация): Генерация Графика/Тепловой карты (2D).
Эта иерархия гарантирует, что агент всегда «мигрирует» в то состояние вещества, которое минимизирует энергию, необходимую для передачи информации.
________________


Заключение


Применение Принципа TRIZ №35 к проектированию агентного ИИ позволяет перейти от парадигмы «Универсального Чат-бота» к концепции «Адаптивного Когнитивного Двигателя».
Агент перестает быть статичной моделью и становится динамической системой, способной к управляемым фазовым переходам:
* Термодинамический контроль: Он «кипятит» идеи в Газовой фазе для креативности, используя Min-P сэмплирование, и «замораживает» их в Твердой фазе для надежности через протоколы кристаллизации и JSON-схемы.
* Регуляция смеси: Он оптимизирует эффективность, регулируя Топливную смесь (Rich/Lean) на основе автоматической детекции экспертизы пользователя через синтаксический анализ.
* Структурная целостность: Он разрешает парадокс «Безопасный, но Гибкий» через разделение Жесткого Каркаса (NeMo Guardrails) и Гибкой Оболочки (Стилевая адаптация).
* Размерная гибкость: Он преодолевает ограничения одномерного текста, автономно переключаясь в Визуальные или Структурированные модальности при превышении порога информационной плотности.
Сводная таблица архитектуры системы:
Компонент
	Аспект TRIZ
	Механизм Реализации
	Ключевые Метрики
	State Engine (Двигатель Состояний)
	Фазовые Переходы
	Регулировка Temp/Min-P, Chain of Density
	Varentropy (Варентропия), Semantic Stability (Семантическая стабильность)
	Fuel Injector (Инжектор Топлива)
	Изменение Параметров
	RAG K-Value, CoT vs. SoT (Sketch-of-Thought)
	Синтаксическая сложность запроса, Плотность жаргона
	Safety Chassis (Шасси Безопасности)
	Гибкость/Жесткость
	NeMo Guardrails (Colang), Constitutional AI
	Уверенность классификации интентов (Intent Confidence)
	Sensor Array (Массив Сенсоров)
	Размерность
	Tool Use (Python/Image), JSON Mode
	Плотность данных, Частота численных значений, User Confusion
	Будущее агентных систем лежит не в простом увеличении параметров моделей, а в создании подобных систем управления «изменением состояний», которые точно знают, когда необходимо кипеть, когда застывать, а когда просто течь.
Источники
1. An Overview and Discussion on Using Large Language Models for Implementation Generation of Solutions to Open-Ended Problems - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.00562v2
2. PHASE TRANSITIONS IN THE OUTPUT DISTRIBUTION OF LARGE LANGUAGE MODELS - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/pdf?id=dq3keisMjT
3. Phase transitions in AI-human interaction networks: statistics, computation, and probabilistic modeling - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2505.02879v1
4. Turning Up the Heat: Min-p Sampling for Creative and ... - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2407.01082
5. MIN-P SAMPLING FOR CREATIVE AND COHERENT LLM OUTPUTS - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/notes/edits/attachment?id=SR6ORZeBAn&name=pdf
6. Min-p Sampling for Creative and Coherent LLM Outputs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/pdf/2407.01082?
7. Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs | OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=FBkpCyujtS
8. Your settings are (probably) hurting your model - Why sampler settings matter - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/LocalLLaMA/comments/17vonjo/your_settings_are_probably_hurting_your_model_why/
9. The Comprehensive Guide to Fine-tuning LLM | by Sunil Rao | Data Science Collective, дата последнего обращения: ноября 25, 2025, https://medium.com/data-science-collective/comprehensive-guide-to-fine-tuning-llm-4a8fd4d0e0af
10. REAL Sampling: Boosting Factuality and Diversity of Open-ended Generation by Extrapolating the Entropy of an Infinitely Large LM, дата последнего обращения: ноября 25, 2025, https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00757/131836/REAL-Sampling-Boosting-Factuality-and-Diversity-of
11. Foundation model parameters: decoding and stopping criteria - IBM, дата последнего обращения: ноября 25, 2025, https://www.ibm.com/docs/en/watsonx/saas?topic=prompts-model-parameters-prompting
12. How to guarantee structured data output with JSON mode - Telnyx, дата последнего обращения: ноября 25, 2025, https://telnyx.com/resources/json-mode-ai
13. Structured Output Generation in LLMs: JSON Schema and Grammar-Based Decoding | by Emre Karatas | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@emrekaratas-ai/structured-output-generation-in-llms-json-schema-and-grammar-based-decoding-6a5c58b698a6
14. Top 30 RAG Interview Questions and Answers for 2025 – IT Exams Training - Pass4sure, дата последнего обращения: ноября 25, 2025, https://www.pass4sure.com/blog/top-30-rag-interview-questions-and-answers-for-2025/
15. A new, and possibly groundbreaking, method to enhancing language model reasoning with entropy-based sampling and parallel chain-of-thought decoding — Entropix | by Michael Alexander Riegler | Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@michael_79773/a-new-and-possibly-groundbreaking-method-to-enhancing-language-model-reasoning-with-entropy-based-0d38bcfe9dc5
16. Reasoning Language Models: A Blueprint - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.11223v1
17. Reasoning Language Models: A Blueprint - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.11223v3
18. A Survey of Large Language Models - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2303.18223v16
19. Fleet of Agents: Coordinated Problem Solving with Large Language Models - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/forum?id=yNpYb376zf
20. Zero to One: Learning Agentic Patterns - Philschmid, дата последнего обращения: ноября 25, 2025, https://www.philschmid.de/agentic-pattern
21. Reflection Agent Pattern — Agent Patterns 0.2.0 documentation - Read the Docs, дата последнего обращения: ноября 25, 2025, https://agent-patterns.readthedocs.io/en/stable/patterns/reflection.html
22. arXiv:2309.04269v1 [cs.CL] 8 Sep 2023 - Research University, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2309.04269
23. Better Summarization with Chain of Density Prompting - PromptHub, дата последнего обращения: ноября 25, 2025, https://www.prompthub.us/blog/better-summarization-with-chain-of-density-prompting
24. Chain of Density (CoD) - Learn Prompting, дата последнего обращения: ноября 25, 2025, https://learnprompting.org/docs/advanced/self_criticism/chain-of-density
25. Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.16062v1
26. Self-correction in LLM calls: a review - The Elder Scripts, дата последнего обращения: ноября 25, 2025, https://theelderscripts.com/self-correction-in-llm-calls-a-review/
27. JSON prompting for LLMs - IBM Developer, дата последнего обращения: ноября 25, 2025, https://developer.ibm.com/articles/json-prompting-llms
28. Structured model outputs - OpenAI API, дата последнего обращения: ноября 25, 2025, https://platform.openai.com/docs/guides/structured-outputs
29. Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for Industrial Asset Health Monitoring - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.18817v1
30. Reasoning Language Models: A Blueprint - Scalable Parallel Computing Lab, дата последнего обращения: ноября 25, 2025, https://spcl.inf.ethz.ch/Publications/.pdf/besta-reasoning.pdf
31. SemaTopic: A Framework for Semantic-Adaptive Probabilistic Topic Modeling - MDPI, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2073-431X/14/9/400
32. SPARSEINFER FRAMEWORK: LEVERAGING SEMANTIC PATTERNS FOR ADAPTIVE SPARSE LLM INFERENCE - Yixuan Yang, дата последнего обращения: ноября 25, 2025, https://yixuanyang.com/files/ECE_689_Project_Report.pdf
33. Semantic Crystallization through Gradient Field Compression in Large Language Models, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/397015296_Semantic_Crystallization_through_Gradient_Field_Compression_in_Large_Language_Models
34. [2510.08146] Think Just Enough: Sequence-Level Entropy as a Confidence Signal for LLM Reasoning - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2510.08146
35. Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.13940v1
36. Claude 4 System Prompts : Operational Blueprint and Strategic Implications - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@tuhinsharma121/decoding-claude-4-system-prompts-operational-blueprint-and-strategic-implications-727294cf79c3
37. arXiv:2503.05179v1 [cs.CL] 7 Mar 2025, дата последнего обращения: ноября 25, 2025, https://arxiv.org/abs/2503.05179
38. Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2025.emnlp-main.1236.pdf
39. Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2503.05179v1
40. Large Reasoning Embedding Models: Towards Next-Generation Dense Retrieval Paradigm, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.14321v2
41. Adaptive Chain-of-Thought Distillation Based on LLM Performance on Original Problems, дата последнего обращения: ноября 25, 2025, https://www.mdpi.com/2227-7390/13/22/3646
42. A list of metrics for evaluating LLM-generated content - Microsoft Learn, дата последнего обращения: ноября 25, 2025, https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/list-of-eval-metrics
43. Exploring Prompt Engineering Practices in the Enterprise - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2403.08950v1
44. How Production AI Systems Parse Millions of Messy User Queries | by Sai Kumar Yava, дата последнего обращения: ноября 25, 2025, https://pub.towardsai.net/how-production-ai-systems-parse-millions-of-messy-user-queries-cef629863ef5
45. Automatic Prompt Generation via Adaptive Selection of Prompting Techniques - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.18162v1
46. Reference Architecture for Generative AI Based on Large Language Models (LLMs), дата последнего обращения: ноября 25, 2025, https://lenovopress.lenovo.com/lp1798-reference-architecture-for-generative-ai-based-on-large-language-models
47. arXiv:2310.10501v1 [cs.CL] 16 Oct 2023, дата последнего обращения: ноября 25, 2025, https://arxiv.org/pdf/2310.10501
48. Configuration Guide — NVIDIA NeMo Guardrails, дата последнего обращения: ноября 25, 2025, https://docs.nvidia.com/nemo/guardrails/latest/user-guides/configuration-guide.html
49. From Craft to Constitution: A Governance-First Paradigm for Principled Agent Engineering, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.13857v1
50. Constitutional AI: Principle-Based Alignment Through Self-Critique - Michael Brenndoerfer, дата последнего обращения: ноября 25, 2025, https://mbrenndoerfer.com/writing/constitutional-ai-principle-based-alignment-through-self-critique
51. How Good Are the LLM Guardrails on the Market? A Comparative Study on the Effectiveness of LLM Content Filtering Across Major GenAI Platforms, дата последнего обращения: ноября 25, 2025, https://unit42.paloaltonetworks.com/comparing-llm-guardrails-across-genai-platforms/
52. PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2509.15447v1
53. Population-Aligned Persona Generation for LLM-based Social Simulation - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2509.10127v1
54. 5 LangChain Safety Layers That Keep Guardrails Snappy | by Thinking Loop - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/@ThinkingLoop/5-langchain-safety-layers-that-keep-guardrails-snappy-09624c0b990b
55. Essential Guide to LLM Guardrails: Llama Guard, NeMo.. | by Sunil Rao - Medium, дата последнего обращения: ноября 25, 2025, https://medium.com/data-science-collective/essential-guide-to-llm-guardrails-llama-guard-nemo-d16ebb7cbe82
56. Lightweight Open Source LLM for text-to-JSON Conversion Using Custom Schema. - Reddit, дата последнего обращения: ноября 25, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1go036r/lightweight_open_source_llm_for_texttojson/
57. JSON Whisperer: Efficient JSON Editing with LLMs - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2510.04717v1
58. "Uh, This One?": Leveraging Behavioral Signals for Detecting Confusion during Physical Tasks | Request PDF - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/391480892_Uh_This_One_Leveraging_Behavioral_Signals_for_Detecting_Confusion_during_Physical_Tasks
59. HRI-Confusion: A Multimodal Dataset for Modelling and Detecting User Confusion in Situated Human-Robot Interaction - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/395521134_HRI-Confusion_A_Multimodal_Dataset_for_Modelling_and_Detecting_User_Confusion_in_Situated_Human-Robot_Interaction
60. Robot Error Awareness Through Human Reactions: Implementation, Evaluation, and Recommendations - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/html/2501.05723v2
61. Agent-Based Simulation of a Financial Market with Large Language Models - ResearchGate, дата последнего обращения: ноября 25, 2025, https://www.researchgate.net/publication/396499583_Agent-Based_Simulation_of_a_Financial_Market_with_Large_Language_Models
62. A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Fra - arXiv, дата последнего обращения: ноября 25, 2025, https://arxiv.org/pdf/2508.12257
63. A Systematic Review of Text-to-Structure Generation with a Universal Evaluation Framework - OpenReview, дата последнего обращения: ноября 25, 2025, https://openreview.net/pdf?id=EcFLNFX13Q
64. DiagramEval: Evaluating LLM-Generated Diagrams via Graphs - ACL Anthology, дата последнего обращения: ноября 25, 2025, https://aclanthology.org/2025.emnlp-main.640.pdf
65. Integrating Vision, Language Models, and Robotic Control for Personalized Task Execution in Virtual Environments - DiVA portal, дата последнего обращения: ноября 25, 2025, https://www.diva-portal.org/smash/get/diva2:1999369/FULLTEXT01.pdf
66. Enhancing Gen AI with Multimodal RAG Systems - OuluREPO, дата последнего обращения: ноября 25, 2025, https://oulurepo.oulu.fi/bitstream/handle/10024/55943/nbnfioulu-202505153455.pdf?sequence=1