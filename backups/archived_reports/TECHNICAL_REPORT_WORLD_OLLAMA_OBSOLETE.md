# üìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô –û–¢–ß–Å–¢: WORLD_OLLAMA PROJECT

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** 26 –Ω–æ—è–±—Ä—è 2025 –≥.  
**–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:** E:\WORLD_OLLAMA  
**–í–µ—Ä—Å–∏—è –æ—Ç—á—ë—Ç–∞:** 1.0  
**–°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞:** –í –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ (Fine-tuning phase)

---

## 1. –û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è –æ solution –∏ –ø—Ä–æ–µ–∫—Ç–∞—Ö

### 1.1. Solution

**–ò–º—è solution:** –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç `.sln` —Ñ–∞–π–ª ‚Äî –ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π **–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É** –Ω–∞ –±–∞–∑–µ Python —Å PowerShell-—Å–∫—Ä–∏–ø—Ç–∞–º–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è.

**–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤:**

| –ü—Ä–æ–µ–∫—Ç | –ü—É—Ç—å | –¢–∏–ø | –Ø–∑—ã–∫ | –°—Ç–∞—Ç—É—Å |
|--------|------|-----|------|--------|
| **CORTEX (LightRAG)** | `services/lightrag` | Knowledge Graph Server | Python 3.12 | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| **Neuro-Terminal** | `services/neuro_terminal` | Web UI (Chainlit) | Python 3.12 | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| **LLaMA Factory** | `services/llama_factory` | Model Fine-tuning Platform | Python 3.12 | üü° Training |
| **SYNAPSE Connector** | `services/connectors/synapse` | API Client Library | Python 3.12 | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| **FastAPI Gateways** | `services/fastapi-gateways` | API Gateway Layer | Python 3.12 | üìù Planned |
| **Agent qwen2-main** | `agents/qwen2-main` | Primary Agent Framework | Python/Config | üìÅ Structure |
| **Agent helper-lite** | `agents/helper-lite` | Helper Agent Framework | Python/Config | üìÅ Structure |
| **Management Scripts** | `USER`, `scripts` | Automation & Orchestration | PowerShell 7+ | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |

### 1.2. –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

**–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è:**
- **Python 3.12** (–æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤)
- **PowerShell 7+** (—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è)
- **Markdown** (–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
- **YAML/JSON** (–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)

**–ü–ª–∞—Ç—Ñ–æ—Ä–º—ã/—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –í–µ—Ä—Å–∏—è | –†–æ–ª—å |
|-----------|-----------|--------|------|
| Knowledge Base | LightRAG | 0.0.0.7+ | GraphRAG framework |
| Web UI | Chainlit | 1.1.402 | Chat interface |
| API Framework | FastAPI | 0.115.0+ | REST API server |
| LLM Server | Ollama | Compatible | Model serving |
| Model (LLM) | qwen2.5:14b-instruct-q4_k_m | 4-bit quantized | Primary LLM |
| Model (Embed) | nomic-embed-text | Standard | Embeddings |
| Fine-tuning | LLaMA-Factory | Latest (editable) | LoRA training |
| HTTP Client | requests | 2.32.0+ | API communication |
| Async Runtime | asyncio + nest_asyncio | Python stdlib + 1.6.0 | Event loop patching |
| Training | PyTorch | 2.1.0+ (CUDA) | Deep learning |
| Transformers | HuggingFace | 4.49.0+ | Model library |

**–¢–∏–ø—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π:**
1. **Web Applications:**
   - Neuro-Terminal (Chainlit) ‚Äî http://localhost:8501
   - LLaMA Board (Gradio WebUI) ‚Äî http://localhost:7860
   
2. **Background Services:**
   - CORTEX (FastAPI) ‚Äî http://localhost:8004
   - Ollama Server ‚Äî http://localhost:11434

3. **CLI Tools:**
   - PowerShell management scripts (`USER/*.ps1`)
   - LLaMA-Factory CLI (`llamafactory-cli`)

### 1.3. –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞

**–û—Å–Ω–æ–≤–Ω—ã–µ entry points:**

| Entry Point | –ü—É—Ç—å | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ–º–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è |
|-------------|------|-----|-------------------------------|
| **lightrag_server.py** | `services/lightrag` | FastAPI App | **CORTEX** ‚Äî –∑–∞–ø—É—Å–∫–∞–µ—Ç GraphRAG —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π (488+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LightRAG –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è knowledge graph —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (naive/local/global/hybrid). –í–∫–ª—é—á–∞–µ—Ç API Key middleware –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. |
| **app.py** | `services/neuro_terminal` | Chainlit App | **Neuro-Terminal** ‚Äî –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç chain-of-thought –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —á–µ—Ä–µ–∑ Steps, –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å CORTEX —á–µ—Ä–µ–∑ SYNAPSE connector. –†–µ–∞–ª–∏–∑—É–µ—Ç –¥–≤—É—Ö—Ñ–∞–∑–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É: Planner ‚Üí Knowledge Lookup ‚Üí Response. |
| **src/train.py** | `services/llama_factory` | Training Script | **LLaMA Factory** ‚Äî –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å fine-tuning –º–æ–¥–µ–ª–µ–π (LoRA/QLoRA). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –¢–†–ò–ó-–¥–∞—Ç–∞—Å–µ—Ç–µ (triz_synthesis_v1.jsonl, 300 –ø–∞—Ä instruction-response). |
| **llamafactory-cli webui** | `services/llama_factory` | Gradio WebUI | **LLaMA Board** ‚Äî –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Gradio UI. |
| **START_ALL.ps1** | `USER` | PowerShell Script | **System Orchestrator** ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (Ollama health check ‚Üí CORTEX ‚Üí LLaMA Board ‚Üí Neuro-Terminal). –ü—Ä–∏–º–µ–Ω—è–µ—Ç –¢–†–ò–ó –ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ10 "–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ" —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è Python –ø—Ä–æ—Ü–µ—Å—Å–æ–≤. |

---

## 2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞(–æ–≤)

### 2.1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ solution –ø–æ —É—Ä–æ–≤–Ω—è–º

```
E:\WORLD_OLLAMA\
‚îú‚îÄ‚îÄ USER/                          # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è (PowerShell)
‚îÇ   ‚îú‚îÄ‚îÄ START_ALL.ps1              # –ó–∞–ø—É—Å–∫ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤)
‚îÇ   ‚îú‚îÄ‚îÄ STOP_ALL.ps1               # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π MSI Afterburner)
‚îÇ   ‚îú‚îÄ‚îÄ CHECK_STATUS.ps1           # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ (Python processes + GPU VRAM)
‚îÇ   ‚îú‚îÄ‚îÄ TEST_E2E.ps1               # End-to-end —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (25 –ø—Ä–æ–≤–µ—Ä–æ–∫, 88% success rate)
‚îÇ   ‚îú‚îÄ‚îÄ START_ALL_TEST.ps1         # –ó–∞–ø—É—Å–∫ –¥–ª—è E2E —Ç–µ—Å—Ç–æ–≤ (background jobs)
‚îÇ   ‚îî‚îÄ‚îÄ README.md                  # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (—Å —ç–º–æ–¥–∑–∏, user-friendly)
‚îÇ
‚îú‚îÄ‚îÄ services/                      # –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã (–∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ venv)
‚îÇ   ‚îú‚îÄ‚îÄ lightrag/                  # CORTEX ‚Äî Knowledge Graph Server
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lightrag_server.py     # FastAPI entry point (697 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ init_index.py          # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ (–ø–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/                  # –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (0.33 MB)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kv_store_llm_response_cache.json  # LLM cache (340.47 KB)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ graph_chunk_entity_relation.graphml  # Knowledge graph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ venv/                  # –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (Python 3.12)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # 8 –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (lightrag-hku, fastapi, uvicorn, etc.)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ neuro_terminal/            # Web UI (Chainlit)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                 # Chainlit entry point (210 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .chainlit/             # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Chainlit
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .venv/                 # –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (NOTE: .venv –Ω–µ venv)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # 3 –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (chainlit, ollama, requests)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ llama_factory/             # Fine-tuning Platform
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/train.py           # Training entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/                  # –î–∞—Ç–∞—Å–µ—Ç—ã
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ triz_synthesis_v1.jsonl  # Self-distilled dataset (480.19 KB, 300 pairs)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_info.json  # Dataset registry (747 lines, 100+ datasets)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ saves/                 # –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Qwen2-7B-Instruct/lora/triz_safe/  # Current training outputs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ venv/                  # –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (editable install)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ triz_safe_config.yaml  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è (LoRA rank 8, batch 1)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # 30+ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (transformers, torch, peft, etc.)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ connectors/                # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ synapse/               # SYNAPSE ‚Äî CORTEX API Client
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ knowledge_client.py  # HTTP –∫–ª–∏–µ–Ω—Ç —Å API Key auth (290 lines)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test_synapse.py    # Unit tests
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test_agent_query.py # Integration tests
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt   # 1 –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å (requests)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ fastapi-gateways/          # API Gateway Layer (planned)
‚îÇ
‚îú‚îÄ‚îÄ library/                       # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ raw_documents/             # 181 .txt —Ñ–∞–π–ª–æ–≤ (7.67 MB)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.triz_droblenie_v_inzhenerii_i_ii.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2._printsip_vyneseniya_v_arhitekture_ii.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...                    # –ü—Ä–∏–Ω—Ü–∏–ø—ã –¢–†–ò–ó 1-40
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_qwen_response.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PyTorch, CUDA –∏ RTX 5060 Ti.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                    # AI methodologies, research
‚îÇ   ‚îú‚îÄ‚îÄ cleaned_documents/         # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ lightrag_cache/            # Legacy (–ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ services/lightrag/data)
‚îÇ
‚îú‚îÄ‚îÄ agents/                        # Multi-Agent Framework
‚îÇ   ‚îú‚îÄ‚îÄ qwen2-main/                # –û—Å–Ω–æ–≤–Ω–æ–π –∞–≥–µ–Ω—Ç (Qwen2.5)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ configs/               # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/                  # Runtime –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logs/                  # Execution logs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scripts/               # Agent automation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ world/                 # Knowledge context
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ helper-lite/               # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç
‚îÇ       ‚îî‚îÄ‚îÄ [–∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞]
‚îÇ
‚îú‚îÄ‚îÄ scripts/                       # Automation & Maintenance
‚îÇ   ‚îú‚îÄ‚îÄ start_lightrag.ps1         # –ó–∞–ø—É—Å–∫ CORTEX –≤ –Ω–æ–≤–æ–º –æ–∫–Ω–µ
‚îÇ   ‚îú‚îÄ‚îÄ start_neuro_terminal.ps1   # –ó–∞–ø—É—Å–∫ Neuro-Terminal
‚îÇ   ‚îú‚îÄ‚îÄ start_training_ui.ps1      # –ó–∞–ø—É—Å–∫ LLaMA Board
‚îÇ   ‚îú‚îÄ‚îÄ start_training.ps1         # CLI training launcher
‚îÇ   ‚îú‚îÄ‚îÄ ingest_watcher.ps1         # File watcher –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ generate_map.ps1           # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PROJECT_MAP.md
‚îÇ   ‚îú‚îÄ‚îÄ maintenance/               # Maintenance scripts
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/                # Monitoring tools
‚îÇ   ‚îî‚îÄ‚îÄ setup/                     # Setup/installation scripts
‚îÇ
‚îú‚îÄ‚îÄ workbench/                     # Experimental & Testing
‚îÇ   ‚îî‚îÄ‚îÄ sandbox_main/              # –ü–µ—Å–æ—á–Ω–∏—Ü–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ       ‚îú‚îÄ‚îÄ scripts/               # Test scripts
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ mirror_test.py     # Cognitive validation (TD-005, 4/4 passed)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ force_inference_test.py  # GPU diagnostics (11.4 GB VRAM confirmed)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_forge.py      # Self-distillation dataset generator (251 lines)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ test_security_perimeter.py  # API Key security tests (3/3 passed)
‚îÇ       ‚îî‚îÄ‚îÄ outputs/               # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
‚îÇ           ‚îî‚îÄ‚îÄ triz_synthesis_v1.jsonl  # Generated dataset (480.19 KB)
‚îÇ
‚îú‚îÄ‚îÄ models/                        # Fine-tuned Models Storage
‚îÇ   ‚îî‚îÄ‚îÄ qwen2-triz-merged/         # LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã (–µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ)
‚îÇ       ‚îú‚îÄ‚îÄ added_tokens.json
‚îÇ       ‚îî‚îÄ‚îÄ ...                    # Adapter weights
‚îÇ
‚îú‚îÄ‚îÄ logs/                          # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ agents/                    # –õ–æ–≥–∏ –∞–≥–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                 # –õ–æ–≥–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
‚îÇ   ‚îî‚îÄ‚îÄ services/                  # –õ–æ–≥–∏ —Å–µ—Ä–≤–∏—Å–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ backups/                       # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ daily/                     # –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –±—ç–∫–∞–ø—ã
‚îÇ   ‚îú‚îÄ‚îÄ weekly/                    # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–µ –±—ç–∫–∞–ø—ã
‚îÇ   ‚îî‚îÄ‚îÄ manual/                    # –†—É—á–Ω—ã–µ –±—ç–∫–∞–ø—ã
‚îÇ
‚îî‚îÄ‚îÄ llamaboard_cache/              # LLaMA Board cache
    ‚îú‚îÄ‚îÄ ds_z2_config.json          # DeepSpeed Zero-2 config
    ‚îú‚îÄ‚îÄ ds_z2_offload_config.json  # Zero-2 offload config
    ‚îú‚îÄ‚îÄ ds_z3_config.json          # Zero-3 config
    ‚îî‚îÄ‚îÄ ds_z3_offload_config.json  # Zero-3 offload config
```

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –º–æ–¥—É–ª–µ–π:**

| –ú–æ–¥—É–ª—å | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã | –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö |
|--------|-----------|---------------|---------------|
| **USER** | **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–æ–π** ‚Äî –µ–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (–∑–∞–ø—É—Å–∫/–æ—Å—Ç–∞–Ω–æ–≤–∫–∞/–ø—Ä–æ–≤–µ—Ä–∫–∞) –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –æ—Ç—Å—é–¥–∞. | START_ALL.ps1 (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è Python –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, MSI Afterburner exclusion), CHECK_STATUS.ps1 (GPU VRAM monitoring) | N/A |
| **lightrag** | **–•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–Ω–∞–Ω–∏–π** ‚Äî –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç 488+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¢–†–ò–ó/AI, —Å—Ç—Ä–æ–∏—Ç knowledge graph, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç REST API –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞. | lightrag_server.py (697 lines, FastAPI), data/kv_store_llm_response_cache.json (340 KB) | 0.33 MB (data/) |
| **neuro_terminal** | **–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** ‚Äî –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –¥–∏–∞–ª–æ–≥–∞, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è reasoning chain —á–µ—Ä–µ–∑ Chainlit Steps, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CORTEX. | app.py (210 lines, –¥–≤—É—Ö—Ñ–∞–∑–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Planner ‚Üí Knowledge ‚Üí Response) | N/A |
| **llama_factory** | **–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –æ–±—É—á–µ–Ω–∏—è** ‚Äî fine-tuning –º–æ–¥–µ–ª–µ–π –Ω–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö (LoRA/QLoRA), WebUI –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞, DeepSpeed integration. | triz_safe_config.yaml (LoRA rank 8, batch_size 1, preprocessing_workers 1) | 480.19 KB (triz dataset) |
| **synapse** | **API –∫–ª–∏–µ–Ω—Ç** ‚Äî –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è –Ω–∞–¥ CORTEX API, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç authentication (API Key "sesa-secure-core-v1"), retry logic, health checks. | knowledge_client.py (290 lines, CortexConnectionError/CortexQueryError exceptions) | N/A |
| **raw_documents** | **–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ** ‚Äî 181 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ –¢–†–ò–ó (40 –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤) –∏ AI –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è–º, —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ. | –¢–†–ò–ó –ø—Ä–∏–Ω—Ü–∏–ø—ã 1-40, PyTorch guides, AI research | 7.67 MB |
| **agents** | **Multi-Agent —Å–∏—Å—Ç–µ–º–∞** ‚Äî –¥–≤–∞ –∞–≥–µ–Ω—Ç–∞ (qwen2-main + helper-lite) —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏, –ª–æ–≥–∞–º–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö –∑–∞–¥–∞—á. | configs/, data/, logs/, scripts/, world/ | N/A |
| **sandbox_main** | **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã** ‚Äî —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (security, cognitive validation, GPU diagnostics, self-distillation data generation). | data_forge.py (251 lines, 300 samples generated), mirror_test.py (56.6s response time) | 480.19 KB (outputs) |

### 2.2. –ö–ª–∞—Å—Å—ã/–º–æ–¥—É–ª–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è

**UI —Å–ª–æ–π:**
- `app.py` (Neuro-Terminal) ‚Äî Chainlit UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, Step visualization, PlanDecision dataclass
- `llamafactory webui` ‚Äî Gradio UI –¥–ª—è fine-tuning (–Ω–µ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏, —á–∞—Å—Ç—å LLaMA-Factory package)

**–ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ (Services):**
- `lightrag_server.py` ‚Äî GraphRAG —Å–µ—Ä–≤–∏—Å:
  - `/query` endpoint (POST, search modes)
  - `/health` endpoint (GET, no auth required)
  - API Key middleware (X-API-KEY header)
  - LightRAG initialization –≤ lifespan event
  - Rerank –û–¢–ö–õ–Æ–ß–ï–ù (–±–∞–≥ LightRAG v1.4.9.8: 'float' object has no attribute 'copy')
  
- `knowledge_client.py` ‚Äî SYNAPSE connector:
  - `lookup_knowledge(query, mode, timeout)` ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞
  - `check_cortex_health()` ‚Äî health check —Å ConnectionError handling
  - `CortexConnectionError`, `CortexQueryError` ‚Äî custom exceptions
  - Timeout default = 120s (LightRAG –¥–æ–ª–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç)
  
- `train.py` ‚Äî Training orchestration (HuggingFace Trainer wrapper)

**–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
- `data/` ‚Äî –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π storage:
  - `kv_store_llm_response_cache.json` ‚Äî LLM cache (340 KB)
  - `graph_chunk_entity_relation.graphml` ‚Äî Knowledge graph (NetworkX format)
  - `vdb_*/` ‚Äî Vector embeddings (–ì–ò–ü–û–¢–ï–ó–ê: ChromaDB/FAISS)
  
- `synapse/` ‚Äî HTTP adapter —Å API Key middleware

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
- `lightrag_server.py` (lines 30-55) ‚Äî Embedded config:
  - `CORTEX_API_KEY` = "sesa-secure-core-v1"
  - `WORKING_DIR` = E:\WORLD_OLLAMA\services\lightrag\data (–ò–°–ü–†–ê–í–õ–ï–ù–û 26.11.2025)
  - `LLM_MODEL` = "qwen2.5:14b"
  - `EMBEDDING_MODEL` = "nomic-embed-text"
  - `LLM_MAX_ASYNC` = 1 (–ö–†–ò–¢–ò–ß–ù–û –¥–ª—è 16GB VRAM)
  
- `triz_safe_config.yaml` ‚Äî Training parameters:
  - Model: Qwen/Qwen2-7B-Instruct
  - LoRA: rank=8, alpha=16, target=all
  - Batch: size=1, accumulation=4
  - Dataset: triz_synthesis_v1 (300 samples)
  - Cutoff: 2048 tokens
  - **preprocessing_num_workers: 1** (FIX –¥–ª—è Windows file locking)
  
- `USER/*.ps1` ‚Äî Service orchestration:
  - Port mappings (11434, 8004, 7860, 8501)
  - Python process detection (>100MB RAM threshold)
  - MSI Afterburner exclusion (`-notlike "*MSI Afterburner*"`)

---

## 3. –†–µ—Å—É—Ä—Å—ã –ø—Ä–æ–µ–∫—Ç–∞

### 3.1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:**

| –§–∞–π–ª | –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ | –ß—Ç–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ—Ç—Å—è | –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã |
|------|--------------|---------------------|-------------------|
| **lightrag_server.py** (embedded) | `services/lightrag` | **CORTEX Settings** | ‚Ä¢ CORTEX_API_KEY = "sesa-secure-core-v1"<br>‚Ä¢ WORKING_DIR = `E:\WORLD_OLLAMA\services\lightrag\data` (FIXED 26.11.2025 –æ—Ç legacy path)<br>‚Ä¢ MODEL = "qwen2.5:14b" (–í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–û –ø–æ—Å–ª–µ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏)<br>‚Ä¢ EMBED_MODEL = "nomic-embed-text"<br>‚Ä¢ OLLAMA_BASE_URL = "http://localhost:11434"<br>‚Ä¢ **LLM_MAX_ASYNC = 1** (–∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ 16GB VRAM)<br>‚Ä¢ CORS origins = ["*"]<br>‚Ä¢ **Rerank DISABLED** (bug v1.4.9.8) |
| **knowledge_client.py** (embedded) | `services/connectors/synapse` | **SYNAPSE Connector** | ‚Ä¢ CORTEX_BASE_URL = "http://localhost:8004"<br>‚Ä¢ CORTEX_QUERY_ENDPOINT = "/query"<br>‚Ä¢ CORTEX_HEALTH_ENDPOINT = "/health"<br>‚Ä¢ CORTEX_API_KEY (env override)<br>‚Ä¢ AUTH_HEADERS = {"X-API-KEY": ...}<br>‚Ä¢ **DEFAULT_TIMEOUT = 120s** (LightRAG –¥–æ–ª–≥–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)<br>‚Ä¢ SearchMode = Literal["naive", "local", "global", "hybrid"] |
| **triz_safe_config.yaml** | `services/llama_factory` | **Fine-tuning Parameters** | ‚Ä¢ model_name_or_path: Qwen/Qwen2-7B-Instruct<br>‚Ä¢ stage: sft, do_train: true<br>‚Ä¢ finetuning_type: lora<br>‚Ä¢ lora_rank: 8, lora_alpha: 16, lora_target: all<br>‚Ä¢ dataset: triz_synthesis_v1<br>‚Ä¢ template: qwen, cutoff_len: 2048<br>‚Ä¢ max_samples: 300, overwrite_cache: true<br>‚Ä¢ **preprocessing_num_workers: 1** (FIX Windows file locking)<br>‚Ä¢ per_device_train_batch_size: 1<br>‚Ä¢ gradient_accumulation_steps: 4<br>‚Ä¢ learning_rate: 5.0e-5<br>‚Ä¢ num_train_epochs: 3.0<br>‚Ä¢ lr_scheduler_type: cosine, bf16: true<br>‚Ä¢ output_dir: saves/Qwen2-7B-Instruct/lora/triz_safe<br>‚Ä¢ logging_steps: 5, save_steps: 20, warmup_steps: 5 |
| **dataset_info.json** | `services/llama_factory/data` | **Dataset Registry** | ‚Ä¢ **triz_synthesis_v1**: file_name=triz_synthesis_v1.jsonl, formatting=alpaca, columns={prompt: instruction, query: input, response: output}<br>‚Ä¢ alpaca_en_demo, alpaca_zh_demo (–ø—Ä–∏–º–µ—Ä—ã)<br>‚Ä¢ glaive_toolcall_en_demo, glaive_toolcall_zh_demo (tool calling)<br>‚Ä¢ mllm_demo, mllm_audio_demo, mllm_video_demo (multi-modal)<br>‚Ä¢ 100+ datasets –≤ registry (747 lines) |
| **.chainlit/config.toml** | `services/neuro_terminal` | **Chainlit UI** | ‚Ä¢ Telemetry, session settings<br>‚Ä¢ UI theme configuration<br>‚Ä¢ (–ì–ò–ü–û–¢–ï–ó–ê: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è Chainlit –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è, –Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–∞) |
| **START_ALL.ps1** | `USER` | **Service Orchestration** | ‚Ä¢ Port checks: 11434 (Ollama), 8004 (CORTEX), 7860 (LLaMA Board), 8501 (Neuro-Terminal)<br>‚Ä¢ **Python process detection**: WorkingSet > 100MB<br>‚Ä¢ **MSI Afterburner exclusion**: `-notlike "*MSI Afterburner*" -and -notlike "*RivaTuner*"`<br>‚Ä¢ **User confirmation** –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤<br>‚Ä¢ –¢–†–ò–ó –ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ10: –ø–æ—Ä—è–¥–æ–∫ –∑–∞–ø—É—Å–∫–∞ (Ollama ‚Üí CORTEX ‚Üí LLaMA ‚Üí Neuro)<br>‚Ä¢ Delay 3s –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ |
| **STOP_ALL.ps1** | `USER` | **Service Shutdown** | ‚Ä¢ Python process detection –ø–æ CommandLine patterns (*chainlit*, *lightrag_server*, *llamafactory*)<br>‚Ä¢ **MSI Afterburner exclusion** –≤–æ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö<br>‚Ä¢ **Post-stop check**: –ø—Ä–æ—Ü–µ—Å—Å—ã >200MB RAM —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è<br>‚Ä¢ Stop-Process -Force –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞<br>‚Ä¢ –ó–∞—â–∏—Ç–∞ –æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è |
| **CHECK_STATUS.ps1** | `USER` | **System Diagnostics** | ‚Ä¢ HTTP health checks (Ollama /api/tags, CORTEX /health, ports 7860/8501)<br>‚Ä¢ **Python process diagnostics**: RAM, CPU, Uptime, CommandLine<br>‚Ä¢ **GPU VRAM monitoring**: nvidia-smi integration<br>‚Ä¢ **Color-coded warnings**: üü¢ <8GB, üü° 8-12GB, üî¥ >12GB<br>‚Ä¢ **MSI Afterburner exclusion** –≤ Python checks<br>‚Ä¢ –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç—É—Å–æ–≤ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ |

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:** –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∞—è –ë–î (SQL/NoSQL).

**–•—Ä–∞–Ω–∏–ª–∏—â–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö:**

| –¢–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –§–∞–π–ª—ã | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|---------------|-----------|-------|-----------|
| **Key-Value Store** | JSON files | `kv_store_llm_response_cache.json` (340 KB)<br>`kv_store_doc_status.json` | –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤<br>–ö—ç—à LLM –æ—Ç–≤–µ—Ç–æ–≤ |
| **Graph Database** | GraphML (NetworkX) | `graph_chunk_entity_relation.graphml` | Knowledge graph (—Å—É—â–Ω–æ—Å—Ç–∏ + –æ—Ç–Ω–æ—à–µ–Ω–∏—è) |
| **Vector Database** | –ì–ò–ü–û–¢–ï–ó–ê: ChromaDB/FAISS | `vdb_*/` | Embeddings –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ |
| **Document Storage** | Plain text (.txt) | `library/raw_documents/*.txt` (181 files, 7.67 MB) | –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¢–†–ò–ó/AI |
| **Training Data** | JSONL | `triz_synthesis_v1.jsonl` (480.19 KB, 300 pairs) | Fine-tuning dataset |

### 3.2. UI-—Ä–µ—Å—É—Ä—Å—ã

**Desktop:** –ù–ï–¢ (–ø—Ä–æ–µ–∫—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç WPF/WinForms/Electron)

**Web:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –û—Å–Ω–æ–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã | –°–ø–µ—Ü–∏—Ñ–∏–∫–∞ |
|-----------|-----------|------------------|-----------|
| **Neuro-Terminal** | Chainlit 1.1.402 | ‚Ä¢ Chat interface<br>‚Ä¢ Message history<br>‚Ä¢ Streaming support<br>‚Ä¢ **Step visualization** (Planner, CORTEX Lookup, Knowledge Result, Response)<br>‚Ä¢ Session management | ‚Ä¢ –î–≤—É—Ö—Ñ–∞–∑–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:<br>  1. Planner (temperature=0.0) ‚Üí PlanDecision<br>  2. Knowledge Lookup (–µ—Å–ª–∏ call_knowledge=true)<br>  3. Response (—Å CORTEX context –∏–ª–∏ –±–µ–∑)<br>‚Ä¢ Anti-Hallucination Protocol enforcement<br>‚Ä¢ JSON parsing –¥–ª—è Planner output |
| **LLaMA Board** | Gradio 4.0+ (llamafactory) | ‚Ä¢ Dataset selector (dropdown)<br>‚Ä¢ Model configurator (text inputs)<br>‚Ä¢ Training progress bars<br>‚Ä¢ Loss curves (matplotlib charts)<br>‚Ä¢ Hyperparameter sliders<br>‚Ä¢ DeepSpeed config selector | ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Gradio –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ llamafactory package<br>‚Ä¢ Real-time training metrics<br>‚Ä¢ Tensorboard integration link |

**–õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è:** 

–ù–ï–¢ —è–≤–Ω—ã—Ö `.resx`, `.po`, JSON –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–π.

**–§–ê–ö–¢:** –ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **–†–£–°–°–ö–ò–ô –Ø–ó–´–ö** –≤:
- PowerShell —Å–∫—Ä–∏–ø—Ç–∞—Ö (–≤—Å–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –≤—ã–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–æ–º)
- –î–∞—Ç–∞—Å–µ—Ç–µ `triz_synthesis_v1.jsonl` (300 —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö instruction-response –ø–∞—Ä)
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ö –≤ `raw_documents/` (181 —Ñ–∞–π–ª –Ω–∞ —Ä—É—Å—Å–∫–æ–º)
- CORTEX language detection (lines 87-92 –≤ lightrag_server.py):
  ```python
  def detect_language(text: str) -> str:
      """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ (—Ä—É—Å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π) –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É."""
      if re.search(r"[–ê-–Ø–∞-—è–Å—ë]", text):
          return "ru"
      return "en"
  ```
- TERM_SYNONYMS mapping (RU/EN technical terms, lines 73-86)

### 3.3. –°–±–æ—Ä–∫–∞ –∏ –¥–µ–ø–ª–æ–π

**–ù–ï–¢** –Ω–∞–π–¥–µ–Ω–æ:
- `Dockerfile`
- `.github/workflows/`, `.gitlab-ci.yml`, `azure-pipelines.yml`
- `Makefile`, `build.cake`, `setup.py`

**–ù–∞–π–¥–µ–Ω—ã —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∫—Ä–∏–ø—Ç—ã:**

| –°–∫—Ä–∏–ø—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –ö–ª—é—á–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è |
|--------|-----------|------------------|
| **START_ALL.ps1** | **–ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã** | 1. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö Python –ø—Ä–æ—Ü–µ—Å—Å–æ–≤** (WorkingSet >100MB, –∏—Å–∫–ª—é—á–∞—è MSI Afterburner)<br>2. **–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è** –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–æ—Ü–µ—Å—Å—ã<br>3. –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama (http://localhost:11434/api/tags, timeout 3s)<br>4. –ó–∞–ø—É—Å–∫ CORTEX (Start-Process –Ω–æ–≤–æ–µ –æ–∫–Ω–æ PowerShell —Å venv activation)<br>5. –ó–∞–ø—É—Å–∫ LLaMA Board (Start-Process —Å llamafactory-cli webui)<br>6. –ó–∞–ø—É—Å–∫ Neuro-Terminal (Start-Process —Å chainlit run)<br>7. –û–∂–∏–¥–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (3 —Å–µ–∫ –º–µ–∂–¥—É —à–∞–≥–∞–º–∏)<br>8. **Auto-navigation** –∫ E:\WORLD_OLLAMA\USER |
| **STOP_ALL.ps1** | **–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤** | 1. –ü–æ–∏—Å–∫ Python –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø–æ CommandLine patterns:<br>   ‚Ä¢ *chainlit* (Neuro-Terminal)<br>   ‚Ä¢ *lightrag_server* (CORTEX)<br>   ‚Ä¢ *llamafactory* (LLaMA Board)<br>2. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è MSI Afterburner** (`-notlike "*MSI Afterburner*" -and -notlike "*RivaTuner*"`)<br>3. Stop-Process -Force –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞<br>4. **–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞** –±–æ–ª—å—à–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ (>200MB) —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º<br>5. **–ó–∞—â–∏—Ç–∞ –æ–±—É—á–µ–Ω–∏—è**: prompt –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π training –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ |
| **CHECK_STATUS.ps1** | **–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞** | 1. **HTTP health checks**:<br>   ‚Ä¢ Ollama (GET /api/tags, –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π qwen2.5 + nomic-embed-text)<br>   ‚Ä¢ CORTEX (GET /health, –ø—Ä–æ–≤–µ—Ä–∫–∞ working_dir_exists)<br>   ‚Ä¢ LLaMA Board (TCP port 7860)<br>   ‚Ä¢ Neuro-Terminal (TCP port 8501)<br>2. **Python –ø—Ä–æ—Ü–µ—Å—Å—ã**:<br>   ‚Ä¢ RAM (WorkingSet), CPU usage, Uptime<br>   ‚Ä¢ CommandLine parsing<br>   ‚Ä¢ **MSI Afterburner exclusion**<br>3. **GPU —Å—Ç–∞—Ç—É—Å**:<br>   ‚Ä¢ nvidia-smi VRAM % (`--query-gpu=memory.used,memory.total`)<br>   ‚Ä¢ **–¶–≤–µ—Ç–æ–≤–∞—è –∏–Ω–¥–∏–∫–∞—Ü–∏—è**: üü¢ <8GB, üü° 8-12GB, üî¥ >12GB<br>4. **–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞** –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ |
| **TEST_E2E.ps1** | **End-to-End —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** | **25 –ø—Ä–æ–≤–µ—Ä–æ–∫ –≤ 6 —Ñ–∞–∑–∞—Ö:**<br>**Phase 1: Environment Validation**<br>‚Ä¢ Test 1-2: venv paths (lightrag, neuro_terminal)<br>**Phase 2: Clean Start**<br>‚Ä¢ Test 3-6: Port availability (11434, 8004, 7860, 8501)<br>**Phase 3: Service Launch**<br>‚Ä¢ Test 7-10: Background job creation (CORTEX, LLaMA Board, Neuro-Terminal)<br>‚Ä¢ Test 11-12: Process detection delay 15s<br>**Phase 4: Functional Tests**<br>‚Ä¢ Test 13: Ollama API response<br>‚Ä¢ Test 14: Required models (qwen2.5, nomic-embed-text)<br>‚Ä¢ Test 15: CORTEX /health endpoint<br>‚Ä¢ Test 16: CORTEX working_dir existence<br>‚Ä¢ Test 17: LLaMA Board port 7860<br>‚Ä¢ Test 18: Neuro-Terminal port 8501<br>**Phase 5: Status Check**<br>‚Ä¢ Test 19-20: CHECK_STATUS.ps1 execution<br>**Phase 6: Shutdown**<br>‚Ä¢ Test 21-25: STOP_ALL.ps1 cleanup<br>**Results:** 22/25 passed (88% success rate) |
| **start_lightrag.ps1** | –ó–∞–ø—É—Å–∫ CORTEX | `Start-Process powershell -NoExit -Command "cd services\lightrag; .\venv\Scripts\Activate.ps1; python lightrag_server.py"` |
| **start_neuro_terminal.ps1** | –ó–∞–ø—É—Å–∫ Neuro-Terminal | `Start-Process powershell -NoExit -Command "cd services\neuro_terminal; .\.venv\Scripts\Activate.ps1; chainlit run app.py"` |
| **start_training_ui.ps1** | –ó–∞–ø—É—Å–∫ LLaMA Board UI | `Start-Process powershell -NoExit -Command "cd services\llama_factory; .\venv\Scripts\Activate.ps1; llamafactory-cli webui"` |
| **ingest_watcher.ps1** | File watcher | –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ `library/raw_documents/` –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö .txt —Ñ–∞–π–ª–æ–≤ |
| **generate_map.ps1** | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PROJECT_MAP | –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ PROJECT_MAP.md |

**–ü—Ä–æ—Ü–µ—Å—Å —Å–±–æ—Ä–∫–∏ –∏ –∑–∞–ø—É—Å–∫–∞:**

```powershell
# ============================================================
# –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô (manual, per-service)
# ============================================================

# 1. CORTEX (LightRAG)
cd E:\WORLD_OLLAMA\services\lightrag
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: lightrag-hku, fastapi, uvicorn, nest-asyncio, httpx, requests, pydantic, python-multipart

# 2. Neuro-Terminal
cd E:\WORLD_OLLAMA\services\neuro_terminal
python -m venv .venv  # NOTE: —Ä–∞–∑–Ω—ã–µ –∏–º–µ–Ω–∞ venv (.venv vs venv)!
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: chainlit==1.1.402, ollama==0.6.1, requests>=2.31.0

# 3. LLaMA Factory
cd E:\WORLD_OLLAMA\services\llama_factory
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -e .  # Editable install –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: transformers, datasets, accelerate, peft, trl, gradio, torch, bitsandbytes, uvicorn, fastapi

# 4. SYNAPSE Connector
cd E:\WORLD_OLLAMA\services\connectors\synapse
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: requests>=2.31.0

# ============================================================
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò–ù–î–ï–ö–°–ê (first time only)
# ============================================================

cd E:\WORLD_OLLAMA\services\lightrag
python init_index.py
# –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç library/raw_documents/*.txt (181 —Ñ–∞–π–ª, 7.67 MB)
# –°–æ–∑–¥–∞—ë—Ç knowledge graph –≤ data/
# –í—Ä–µ–º—è: ~15-30 –º–∏–Ω—É—Ç –¥–ª—è 181 –¥–æ–∫—É–º–µ–Ω—Ç–∞

# ============================================================
# –ó–ê–ü–£–°–ö –°–ò–°–¢–ï–ú–´
# ============================================================

cd E:\WORLD_OLLAMA\USER
.\START_ALL.ps1

# –ò–ª–∏ –≤—Ä—É—á–Ω—É—é:
# Terminal 1 (Ollama - –∑–∞–ø—É—â–µ–Ω –∫–∞–∫ —Å–ª—É–∂–±–∞ –∏–ª–∏ –≤—Ä—É—á–Ω—É—é)
ollama serve

# Terminal 2 (CORTEX)
pwsh E:\WORLD_OLLAMA\scripts\start_lightrag.ps1

# Terminal 3 (LLaMA Board)
pwsh E:\WORLD_OLLAMA\scripts\start_training_ui.ps1

# Terminal 4 (Neuro-Terminal)
pwsh E:\WORLD_OLLAMA\scripts\start_neuro_terminal.ps1

# ============================================================
# –ü–†–û–í–ï–†–ö–ê –°–¢–ê–¢–£–°–ê
# ============================================================

cd E:\WORLD_OLLAMA\USER
.\CHECK_STATUS.ps1

# ============================================================
# FINE-TUNING (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# ============================================================

cd E:\WORLD_OLLAMA\services\llama_factory
.\venv\Scripts\python.exe src\train.py triz_safe_config.yaml

# –ò–ª–∏ —á–µ—Ä–µ–∑ CLI:
llamafactory-cli train triz_safe_config.yaml

# ============================================================
# –û–°–¢–ê–ù–û–í–ö–ê –°–ò–°–¢–ï–ú–´
# ============================================================

cd E:\WORLD_OLLAMA\USER
.\STOP_ALL.ps1
```

**–°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (–∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞ –∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è):**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ú–∏–Ω–∏–º—É–º | –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è | –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è |
|-----------|---------|---------------|---------------------|
| **–û–°** | Windows 10 x64 | Windows 11 x64 | ‚úÖ Windows (PowerShell 7+) |
| **Python** | 3.10 | 3.12 | ‚úÖ **Python 3.12** (–§–ê–ö–¢ –∏–∑ terminal context) |
| **GPU** | NVIDIA RTX 3060 12GB | RTX 5060 Ti 16GB+ | ‚úÖ **RTX 5060 Ti 16GB** (–§–ê–ö–¢ –∏–∑ docs) |
| **VRAM** | 12 GB | 16 GB | ‚úÖ **16 GB** (11.4 GB used stable) |
| **RAM** | 16 GB | 32 GB | ‚úÖ 16+ GB (–ø—Ä–æ—Ü–µ—Å—Å—ã >100MB –¥–µ—Ç–µ–∫—Ç—è—Ç—Å—è) |
| **CUDA** | 11.8 | 12.x | ‚úÖ CUDA 12.x (–¥–ª—è RTX 5060 Ti) |
| **Disk** | 50 GB | 100 GB | ‚úÖ ~50 GB (–º–æ–¥–µ–ª–∏ + –¥–∞—Ç–∞—Å–µ—Ç—ã + —á–µ–∫–ø–æ–∏–Ω—Ç—ã) |
| **PowerShell** | 5.1 | 7.0+ | ‚úÖ PowerShell 7+ (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã) |

---

## 4. –ö–æ–Ω–Ω–µ–∫—Ç–æ—Ä—ã –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ (–æ—Å–æ–±—ã–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ Ollama)

### 4.1. –ö–æ–Ω–Ω–µ–∫—Ç–æ—Ä –∫ Ollama

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è Ollama:**

| –§–∞–π–ª | –ü—É—Ç—å | –†–æ–ª—å | –î–µ—Ç–∞–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ |
|------|------|------|-------------------|
| **lightrag_server.py** | `services/lightrag` | **LLM Provider –¥–ª—è CORTEX** | ‚Ä¢ Lines 46-49: OLLAMA_BASE_URL = "http://localhost:11434"<br>‚Ä¢ LLM_MODEL = "qwen2.5:14b" (–í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–û –ø–æ—Å–ª–µ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏)<br>‚Ä¢ EMBEDDING_MODEL = "nomic-embed-text"<br>‚Ä¢ RERANK_MODEL = "qwen2.5:14b"<br>‚Ä¢ **LightRAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Ollama** –∫–∞–∫ backend –¥–ª—è LLM –∏ embeddings<br>‚Ä¢ **–ù–ï–¢ CLI –≤—ã–∑–æ–≤–æ–≤** (—Ç–æ–ª—å–∫–æ HTTP API)<br>‚Ä¢ Functions: `ollama_model_complete`, `ollama_embed` (–∏–∑ lightrag.llm.ollama) |
| **START_ALL.ps1** | `USER` | **Ollama Health Check** | ‚Ä¢ Lines ~39-47: HTTP GET `http://localhost:11434/api/tags` (timeout 3s)<br>‚Ä¢ –ï—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí prompt "–ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve"<br>‚Ä¢ **–ë–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã** –¥–æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama<br>‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º CORTEX (–¢–†–ò–ó –ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ10) |
| **CHECK_STATUS.ps1** | `USER` | **Ollama Status Monitoring** | ‚Ä¢ HTTP GET `http://localhost:11434/api/tags`<br>‚Ä¢ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑ JSON response<br>‚Ä¢ **–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è required models**: qwen2.5, nomic-embed-text<br>‚Ä¢ –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞: üü¢ (–¥–æ—Å—Ç—É–ø–µ–Ω + –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å) / üî¥ (–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç) |
| **TEST_E2E.ps1** | `USER` | **E2E Ollama Validation** | ‚Ä¢ Test 1: Port 11434 listening<br>‚Ä¢ Test 2: API /api/tags response (valid JSON)<br>‚Ä¢ Test 3: Required models present (qwen2.5, nomic-embed-text) |
| **app.py** | `services/neuro_terminal` | **Planner LLM** | ‚Ä¢ Lines 22-24: OLLAMA_HOST = "http://127.0.0.1:11434"<br>‚Ä¢ OLLAMA_MODEL = "qwen2.5:14b-instruct-q4_k_m"<br>‚Ä¢ OllamaClient (from ollama import Client)<br>‚Ä¢ **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è Planner phase** (temperature=0.0)<br>‚Ä¢ **–ù–ï –¥–ª—è knowledge search** (—ç—Ç–æ –¥–µ–ª–∞–µ—Ç CORTEX) |
| **triz_safe_config.yaml** | `services/llama_factory` | **Fine-tuning Source Model** | ‚Ä¢ model_name_or_path: Qwen/Qwen2-7B-Instruct<br>‚Ä¢ **–ì–ò–ü–û–¢–ï–ó–ê**: –ü–æ—Å–ª–µ fine-tuning ‚Üí —ç–∫—Å–ø–æ—Ä—Ç –≤ Ollama format —á–µ—Ä–µ–∑ `ollama create` |
| **.copilot-instructions.md** | `.github` | **Documentation** | ‚Ä¢ Explicit: "Ollama Port: 11434 (standard)"<br>‚Ä¢ "Primary LLM: qwen2.5:14b-instruct-q4_k_m"<br>‚Ä¢ "Embeddings: nomic-embed-text"<br>‚Ä¢ "GPU: RTX 5060 Ti 16GB" |

**–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ê–•–û–î–ö–ê:** 

‚ùå **–ù–ï–¢ –ø—Ä—è–º–æ–≥–æ Python/PowerShell –∫–æ–¥–∞**, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–∑—ã–≤–∞–µ—Ç `ollama` CLI –∫–æ–º–∞–Ω–¥—ã (`ollama run`, `ollama pull`, `ollama list`).

‚úÖ **–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Ollama –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ HTTP REST API**, –ù–ï —á–µ—Ä–µ–∑ CLI wrapper.

### 4.2. –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å

**HTTP/REST –∫–ª–∏–µ–Ω—Ç (–ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô —Å–ø–æ—Å–æ–± –æ–±—â–µ–Ω–∏—è —Å Ollama):**

```python
# ============================================================
# CORTEX ‚Üí Ollama (—á–µ—Ä–µ–∑ LightRAG library)
# ============================================================

# services/lightrag/lightrag_server.py (lines 230-250)
from lightrag.llm.ollama import ollama_model_complete, ollama_embed

# LightRAG –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ lifespan startup:
rag = LightRAG(
    working_dir=str(WORKING_DIR),
    workspace="",
    llm_model_func=llm_model_func,  # Wrapper –Ω–∞–¥ ollama_model_complete
    llm_model_name=LLM_MODEL,       # "qwen2.5:14b"
    llm_model_max_async=LLM_MAX_ASYNC,  # 1 (–∑–∞—â–∏—Ç–∞ VRAM)
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=embedding_func  # Wrapper –Ω–∞–¥ ollama_embed
    ),
    # rerank_model_func –û–¢–ö–õ–Æ–ß–ï–ù (–±–∞–≥ v1.4.9.8)
)

# –í–Ω—É—Ç—Ä–∏ LightRAG library (–ì–ò–ü–û–¢–ï–ó–ê, –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–π –∫–æ–¥):
# HTTP POST http://127.0.0.1:11434/api/generate
# Payload:
# {
#   "model": "qwen2.5:14b",
#   "prompt": "User query or system instruction...",
#   "stream": false,  # –ù–ï–¢ streaming –≤ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
#   "options": {
#     "temperature": 0.7,
#     "top_p": 0.8,
#     "top_k": 20,
#     "num_predict": 4096
#   }
# }
```

```python
# ============================================================
# Neuro-Terminal ‚Üí Ollama (–ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ ollama SDK)
# ============================================================

# services/neuro_terminal/app.py (lines 22-26, 96-104)
from ollama import Client as OllamaClient

OLLAMA_HOST = os.getenv("NEURO_OLLAMA_HOST", "http://127.0.0.1:11434")
OLLAMA_MODEL = os.getenv("NEURO_MODEL", "qwen2.5:14b-instruct-q4_k_m")

def _get_ollama_client() -> OllamaClient:
    client = cl.user_session.get("ollama_client")
    if client is None:
        client = OllamaClient(host=OLLAMA_HOST)
        cl.user_session.set("ollama_client", client)
    return client

def _sync_chat(messages: List[Dict[str, str]], temperature: float = 0.2) -> str:
    response = _get_ollama_client().chat(
        model=OLLAMA_MODEL,
        messages=messages,  # OpenAI-compatible format
        options={"temperature": temperature},
    )
    return response["message"]["content"]

# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ Planner phase (temperature=0.0) –∏ Response phase (temperature=0.2)
```

```python
# ============================================================
# SYNAPSE Connector ‚Üí CORTEX (–ù–ï –∫ Ollama –Ω–∞–ø—Ä—è–º—É—é)
# ============================================================

# services/connectors/synapse/knowledge_client.py (lines 37-47, 100-120)
import requests

CORTEX_BASE_URL = "http://localhost:8004"
CORTEX_QUERY_ENDPOINT = f"{CORTEX_BASE_URL}/query"
CORTEX_API_KEY = os.getenv("CORTEX_API_KEY", "sesa-secure-core-v1")
AUTH_HEADERS = {"X-API-KEY": CORTEX_API_KEY}

def lookup_knowledge(query: str, mode: str = "hybrid", timeout: int = 120):
    payload = {
        "query": query,
        "mode": mode,  # naive/local/global/hybrid
        "only_need_context": False
    }
    
    response = requests.post(
        CORTEX_QUERY_ENDPOINT,
        json=payload,
        headers=AUTH_HEADERS,  # API Key authentication
        timeout=timeout  # 120s default (LightRAG –¥–æ–ª–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç)
    )
    
    response.raise_for_status()  # Raises HTTPError –¥–ª—è 4xx/5xx
    return response.json()["response"]
```

**–§–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤:**

**1. Ollama API (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LightRAG –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π –∏ Neuro-Terminal):**

–ó–∞–ø—Ä–æ—Å (LLM generation):
```json
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "qwen2.5:14b",
  "prompt": "Explain TRIZ Principle #1 (Segmentation) in context of AI agents",
  "stream": false,
  "options": {
    "temperature": 0.7,
    "top_p": 0.8,
    "top_k": 20,
    "num_predict": 4096,
    "repeat_penalty": 1.1
  }
}
```

–û—Ç–≤–µ—Ç (LLM generation):
```json
{
  "model": "qwen2.5:14b",
  "created_at": "2025-11-26T15:30:00.123Z",
  "response": "–¢–†–ò–ó –ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ1 '–î—Ä–æ–±–ª–µ–Ω–∏–µ' –æ–∑–Ω–∞—á–∞–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —á–∞—Å—Ç–∏...",
  "done": true,
  "context": [1234, 5678, ...],  # Token IDs –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
  "total_duration": 19100000000,  # –ù–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã
  "load_duration": 5000000,
  "prompt_eval_count": 45,
  "prompt_eval_duration": 2100000000,
  "eval_count": 234,
  "eval_duration": 17000000000
}
```

–ó–∞–ø—Ä–æ—Å (Embeddings):
```json
POST http://localhost:11434/api/embeddings
Content-Type: application/json

{
  "model": "nomic-embed-text",
  "prompt": "–ü—Ä–∏–Ω—Ü–∏–ø –¥—Ä–æ–±–ª–µ–Ω–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ AI –∞–≥–µ–Ω—Ç–æ–≤"
}
```

–û—Ç–≤–µ—Ç (Embeddings):
```json
{
  "embedding": [0.123, -0.456, 0.789, ..., 0.234],  # 768-dim vector
  "model": "nomic-embed-text"
}
```

–ó–∞–ø—Ä–æ—Å (Health check / List models):
```json
GET http://localhost:11434/api/tags
```

–û—Ç–≤–µ—Ç (List models):
```json
{
  "models": [
    {
      "name": "qwen2.5:14b-instruct-q4_k_m",
      "modified_at": "2025-11-25T10:30:00Z",
      "size": 8200000000,  # –ë–∞–π—Ç—ã (~8.2 GB)
      "digest": "sha256:abc123...",
      "details": {
        "format": "gguf",
        "family": "qwen2",
        "families": ["qwen2"],
        "parameter_size": "14B",
        "quantization_level": "Q4_K_M"
      }
    },
    {
      "name": "nomic-embed-text",
      "modified_at": "2025-11-24T08:15:00Z",
      "size": 274000000,  # ~274 MB
      "digest": "sha256:def456...",
      "details": {
        "format": "gguf",
        "family": "nomic-bert",
        "parameter_size": "137M",
        "quantization_level": "F16"
      }
    }
  ]
}
```

**2. CORTEX API (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è SYNAPSE connector):**

–ó–∞–ø—Ä–æ—Å:
```json
POST http://localhost:8004/query
Content-Type: application/json
X-API-KEY: sesa-secure-core-v1

{
  "query": "–ö–∞–∫ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø –¥—Ä–æ–±–ª–µ–Ω–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ RAG —Å–∏—Å—Ç–µ–º—ã?",
  "mode": "hybrid",
  "only_need_context": false
}
```

–û—Ç–≤–µ—Ç:
```json
{
  "response": "–ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ1 (–î—Ä–æ–±–ª–µ–Ω–∏–µ) –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ RAG —Å–∏—Å—Ç–µ–º—ã –æ–∑–Ω–∞—á–∞–µ—Ç...\n\n**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**\n1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ chunks\n2. –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...",
  "mode_used": "hybrid",
  "lang": "ru",
  "sources": [
    "Floor_01_TRIZ_Principles.md",
    "RAG_Architecture_Patterns.md"
  ],
  "processing_time_ms": 56600
}
```

–ó–∞–ø—Ä–æ—Å (Health check):
```json
GET http://localhost:8004/health
```

–û—Ç–≤–µ—Ç (Health check):
```json
{
  "status": "healthy",
  "working_dir_exists": true,
  "indexed_documents": 488,
  "graph_size_mb": 12.5,
  "cache_size_mb": 0.33,
  "last_index_update": "2025-11-26T14:30:00Z"
}
```

**Streaming:** 

‚ùå **–ù–ï–¢ –Ω–∞–π–¥–µ–Ω–æ —è–≤–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ streaming** –≤ –∫–æ–¥–µ.

**–§–ê–ö–¢:** LightRAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `"stream": false` –≤ Ollama API calls (–∏–∑ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏).

**–ì–ò–ü–û–¢–ï–ó–ê:** Chainlit –º–æ–∂–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å streaming —á–µ—Ä–µ–∑ `cl.make_async`, –Ω–æ —Ç–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è app.py –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç stream.

### 4.3. –î—Ä—É–≥–∏–µ –≤–Ω–µ—à–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

**–ù–ï–¢ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π —Å:**
- ‚ùå OpenAI API
- ‚ùå Cloud AI services (Azure OpenAI, AWS Bedrock, Google Vertex AI)
- ‚ùå Message brokers (RabbitMQ, Kafka, NATS)
- ‚ùå External storage (S3, Azure Blob, MinIO)
- ‚ùå Databases (PostgreSQL, MongoDB, Redis)
- ‚ùå Monitoring (Prometheus, Grafana, Datadog)
- ‚ùå Tracing (Jaeger, Zipkin, OpenTelemetry)

**–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–Ω–µ—à–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**

| –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å | –¢–∏–ø | URL/Endpoint | –†–æ–ª—å |
|-------------|-----|--------------|------|
| **Ollama** | LLM Server | http://localhost:11434 | Primary LLM provider (qwen2.5:14b, nomic-embed-text) |
| **CORTEX** | Internal Service | http://localhost:8004 | Knowledge base (GraphRAG search) |
| **LightRAG** | Python Library | PyPI package (lightrag-hku) | GraphRAG framework |
| **Chainlit** | Python Framework | PyPI package (chainlit) | UI framework –¥–ª—è chat |
| **HuggingFace Hub** | Model Repository | https://huggingface.co | Model downloads (Qwen/Qwen2-7B-Instruct) |

**–í—Å–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ ‚Äî –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–ª–∏ —á–µ—Ä–µ–∑ PyPI:**
- Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ (localhost:11434)
- CORTEX ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–µ—Ä–≤–∏—Å –ø—Ä–æ–µ–∫—Ç–∞
- HuggingFace ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è download –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ fine-tuning
- PyPI ‚Äî –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ (pip install)

---

## 5. –í–µ—Ä—Å–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

### 5.1. –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã

**–ò–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ runtime context:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –í–µ—Ä—Å–∏—è | –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ |
|-----------|--------|------------------------|
| **Python** | **3.12** | ‚úÖ **–§–ê–ö–¢** –∏–∑ terminal context: `python --version` output |
| **PowerShell** | **7+** | ‚úÖ **–§–ê–ö–¢** –∏–∑ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ —Å–∫—Ä–∏–ø—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ cmdlets) |
| **Windows** | **10/11 x64** | ‚úÖ **–§–ê–ö–¢** –∏–∑ paths (E:\...), nvidia-smi, PowerShell |
| **CUDA** | **12.x** | ‚úÖ **–§–ê–ö–¢** –¥–ª—è RTX 5060 Ti (—Ç—Ä–µ–±—É–µ—Ç CUDA 12+) |
| **Node.js** | **–ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø** | ‚ùå –ù–µ—Ç package.json –≤ —Å–µ—Ä–≤–∏—Å–∞—Ö |

**–¶–µ–ª–µ–≤—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã:**
- **OS:** Windows 10/11 (x64)
- **Python:** 3.12 (—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –≤–µ—Ä—Å–∏—è)
- **CUDA:** 12.x (–¥–ª—è RTX 5060 Ti —Å 16GB VRAM)
- **Node.js:** –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø

**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|----------|----------|-------------|
| **CPU** | Modern x64 (Intel/AMD) | –î–ª—è Python 3.12 –∏ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ C extensions |
| **RAM** | 16 GB (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 32 GB) | CORTEX + Neuro-Terminal + LLaMA Board + Ollama –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ |
| **GPU** | NVIDIA RTX 3060 12GB minimum | Qwen2.5:14b –∑–∞–Ω–∏–º–∞–µ—Ç ~8-11 GB VRAM |
| **VRAM** | 16 GB recommended | –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: 11.4 GB stable usage |
| **Disk** | 100 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ | –ú–æ–¥–µ–ª–∏ (~20 GB) + –¥–∞—Ç–∞—Å–µ—Ç—ã (~1 GB) + checkpoints (~10-20 GB) + library (7.67 MB) |
| **Internet** | –î–ª—è –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏ | Download –º–æ–¥–µ–ª–µ–π (Ollama pull, HuggingFace) |

### 5.2. –ü–∞–∫–µ—Ç—ã –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

**CORTEX (services/lightrag/requirements.txt):**

```txt
# Core LightRAG framework
lightrag-hku>=0.0.0.7

# FastAPI server
fastapi>=0.115.0
uvicorn[standard]>=0.32.0
pydantic>=2.9.0

# Async support
nest-asyncio>=1.6.0

# Ollama client
httpx>=0.27.0
requests>=2.32.0

# Logging and monitoring
python-multipart>=0.0.12
```

**Neuro-Terminal (services/neuro_terminal/requirements.txt):**

```txt
chainlit==1.1.402
ollama==0.6.1
requests>=2.31.0,<3
```

**LLaMA Factory (services/llama_factory/requirements.txt) ‚Äî –°–û–ö–†–ê–©–Å–ù–ù–û:**

```txt
# Core deps
transformers>=4.49.0,<=4.57.1,!=4.52.0,!=4.57.0  # HuggingFace Transformers
datasets>=2.16.0,<=4.0.0
accelerate>=1.3.0,<=1.11.0
peft>=0.14.0,<=0.17.1  # LoRA/QLoRA
trl>=0.8.6,<=0.9.6     # Reinforcement Learning

# GUI
gradio>=4.38.0,<=5.45.0
matplotlib>=3.7.0
tyro<0.9.0

# Operations
einops
numpy<2.0.0
pandas>=2.0.0
scipy

# Model and tokenizer
sentencepiece
tiktoken
modelscope>=1.14.0
hf-transfer
safetensors<=0.5.3

# Python utilities
fire
omegaconf
packaging
protobuf
pyyaml
pydantic<=2.10.6

# API
uvicorn
fastapi
sse-starlette

# Media (multi-modal support)
av
librosa

# Yanked packages (excluded)
propcache!=0.4.0
```

**SYNAPSE Connector (services/connectors/synapse/requirements.txt):**

```txt
requests>=2.31.0
```

**–ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:**

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –í–µ—Ä—Å–∏—è | –†–æ–ª—å |
|-----------|-----------|--------|------|
| **GraphRAG** | lightrag-hku | >=0.0.0.7 | Knowledge graph construction, semantic search |
| **Web Framework** | fastapi | >=0.115.0 | REST API server –¥–ª—è CORTEX |
| **ASGI Server** | uvicorn[standard] | >=0.32.0 | ASGI server –¥–ª—è FastAPI (—Å websockets, httptools) |
| **Data Validation** | pydantic | >=2.9.0 | Request/response schema validation |
| **Async** | nest-asyncio | >=1.6.0 | **–ö–†–ò–¢–ò–ß–ù–û**: Fix –¥–ª—è asyncio.run() –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ —Å FastAPI |
| **HTTP Client** | httpx | >=0.27.0 | Async HTTP client –¥–ª—è Ollama API |
| **HTTP Client** | requests | >=2.31.0 | Sync HTTP client –¥–ª—è CORTEX API |
| **UI Framework** | chainlit | ==1.1.402 | Chat interface —Å Step visualization |
| **Ollama SDK** | ollama | ==0.6.1 | Python SDK –¥–ª—è Ollama API |
| **LLM Library** | transformers | 4.49.0-4.57.1 | HuggingFace Transformers (BERT, GPT, Qwen, etc.) |
| **Dataset** | datasets | 2.16.0-4.0.0 | HuggingFace Datasets –¥–ª—è loading/processing |
| **Training** | accelerate | 1.3.0-1.11.0 | Distributed training, mixed precision |
| **PEFT** | peft | 0.14.0-0.17.1 | Parameter-Efficient Fine-Tuning (LoRA/QLoRA) |
| **RLHF** | trl | 0.8.6-0.9.6 | Transformer Reinforcement Learning (PPO, DPO) |
| **WebUI** | gradio | 4.38.0-5.45.0 | LLaMA Board interface |
| **Deep Learning** | torch | >=2.1.0 | PyTorch (CUDA-enabled –¥–ª—è GPU) |
| **Quantization** | bitsandbytes | >=0.42.0 | 4-bit/8-bit quantization –¥–ª—è LoRA |
| **Tokenizers** | sentencepiece | Latest | Tokenizer –¥–ª—è Qwen/LLaMA models |
| **Tokenizers** | tiktoken | Latest | OpenAI tokenizer (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏) |
| **Monitoring** | tensorboard | Latest | Training visualization (loss curves) |
| **Config** | pyyaml | Latest | YAML config parsing (triz_safe_config.yaml) |
| **Config** | omegaconf | Latest | Hierarchical configuration |

**UI —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏:**
- **Chainlit 1.1.402** (Neuro-Terminal) ‚Äî Async chat framework —Å Step visualization
- **Gradio 4.38.0-5.45.0** (LLaMA Board) ‚Äî WebUI –¥–ª—è ML models

**HTTP –∫–ª–∏–µ–Ω—Ç—ã:**
- **requests 2.31.0+** (–≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã) ‚Äî Sync HTTP
- **httpx 0.27.0+** (lightrag) ‚Äî Async HTTP
- **uvicorn** (ASGI server –¥–ª—è FastAPI)

**DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã:** 

‚ùå **–ù–ï–¢ —è–≤–Ω–æ–≥–æ DI framework** (Spring, Guice, etc.)

‚úÖ **FastAPI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç dependency injection** —á–µ—Ä–µ–∑ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã `Depends()`:
```python
# –ü—Ä–∏–º–µ—Ä (–Ω–µ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞, –Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω):
from fastapi import Depends

async def get_rag_instance():
    return rag  # Global instance

@app.post("/query")
async def query_endpoint(
    request: QueryRequest,
    rag_instance = Depends(get_rag_instance)
):
    # ...
```

**ORM/Database:** 

‚ùå **–ù–ï–¢ ORM** (SQLAlchemy, Tortoise, Prisma)

‚úÖ **–§–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ** —á–µ—Ä–µ–∑ LightRAG abstraction

**–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è |
|-----------|-----------|--------------|
| **Python logging** | stdlib | `logging.basicConfig(level=logging.INFO)` |
| **CORTEX** | logging | Lines 23: `logging.basicConfig(level=logging.INFO)` |
| **SYNAPSE** | logging | Lines 17-22: logger —Å INFO level |
| **Sinks** | Console + —Ñ–∞–π–ª—ã | `logs/services/*.log` (–ì–ò–ü–û–¢–ï–ó–ê) |

### 5.3. –í–µ—Ä—Å–∏–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å Ollama

**–Ø–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ Ollama:**

–ò–∑ `.copilot-instructions.md` –∏ –∫–æ–¥–∞:

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|----------|----------|-------------|
| **Ollama Port** | **11434** (standard) | ‚úÖ **–§–ê–ö–¢** –∏–∑ –≤—Å–µ—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤ (lightrag_server.py, app.py, START_ALL.ps1) |
| **Primary LLM** | **qwen2.5:14b-instruct-q4_k_m** | ‚úÖ **–§–ê–ö–¢** –∏–∑ app.py line 24, docs |
| **Embeddings** | **nomic-embed-text** | ‚úÖ **–§–ê–ö–¢** –∏–∑ lightrag_server.py line 48 |
| **GPU** | **RTX 5060 Ti 16GB** | ‚úÖ **–§–ê–ö–¢** –∏–∑ docs, VRAM monitoring (11.4 GB stable) |
| **VRAM Usage** | **~11.4 GB stable** | ‚úÖ **–§–ê–ö–¢** –∏–∑ GPU diagnostics (force_inference_test.py) |

**–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è Ollama:** 

‚ùå **–ù–ï –£–ö–ê–ó–ê–ù–ê** —è–≤–Ω–æ –≤ requirements –∏–ª–∏ docs.

‚úÖ **–ì–ò–ü–û–¢–ï–ó–ê:** –¢—Ä–µ–±—É–µ—Ç—Å—è Ollama **0.1.20+** (–≤–µ—Ä—Å–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç qwen2.5 –º–æ–¥–µ–ª–∏ –∏ /api/embeddings endpoint).

**–°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**

| –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ | –î–µ—Ç–∞–ª–∏ |
|-----------|--------|
| **–û–°** | Windows 10/11 x64 (–∏–∑-–∑–∞ PowerShell, nvidia-smi, paths) |
| **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** | x64 (qwen2.5:14b-instruct –º–æ–¥–µ–ª—å) |
| **–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è** | q4_k_m (4-bit K-quant, medium) ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–æ/VRAM |
| **API Compatibility** | `/api/generate`, `/api/embeddings`, `/api/tags` endpoints |

**–ú–æ–¥–µ–ª–∏ Ollama (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã):**

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –†–æ–ª—å | –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è |
|--------|--------|------|-----------------|
| **qwen2.5:14b-instruct-q4_k_m** | ~8.2 GB | Primary LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (CORTEX + Neuro-Terminal Planner) | ‚úÖ CHECK_STATUS.ps1, TEST_E2E.ps1 |
| **nomic-embed-text** | ~274 MB | Embeddings –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (CORTEX) | ‚úÖ CHECK_STATUS.ps1, TEST_E2E.ps1 |

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ (–∏–∑ CHECK_STATUS.ps1):**

```powershell
# HTTP GET http://localhost:11434/api/tags
$response = Invoke-RestMethod http://localhost:11434/api/tags
$models = $response.models | Select-Object -ExpandProperty name

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è required models
if ($models -notcontains "qwen2.5") {
    Write-Host "‚ùå qwen2.5 model NOT found" -ForegroundColor Red
    Write-Host "   Run: ollama pull qwen2.5:14b-instruct-q4_k_m"
}

if ($models -notcontains "nomic-embed-text") {
    Write-Host "‚ùå nomic-embed-text model NOT found" -ForegroundColor Red
    Write-Host "   Run: ollama pull nomic-embed-text"
}
```

**–ö–æ–º–∞–Ω–¥—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–¥–µ–ª–µ–π:**

```powershell
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama (–µ—Å–ª–∏ –µ—â—ë –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
# Download from: https://ollama.ai/download

# 2. –ó–∞–ø—É—Å–∫ Ollama server
ollama serve

# 3. Pull required models
ollama pull qwen2.5:14b-instruct-q4_k_m  # ~8.2 GB download
ollama pull nomic-embed-text              # ~274 MB download

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
ollama list

# –û–∂–∏–¥–∞–µ–º—ã–π output:
# NAME                           ID           SIZE    MODIFIED
# qwen2.5:14b-instruct-q4_k_m    abc123...    8.2 GB  2 days ago
# nomic-embed-text               def456...    274 MB  2 days ago
```

---

## 6. –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞

### 6.1. –¢–∏–ø—ã –ë–î

**–ù–ï–¢ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ë–î:**
- ‚ùå SQL (MSSQL, PostgreSQL, MySQL, SQLite)
- ‚ùå NoSQL (MongoDB, Redis, Cassandra, DynamoDB)
- ‚ùå NewSQL (CockroachDB, TiDB)
- ‚ùå Time-series (InfluxDB, Prometheus)

**–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ:**

| –¢–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –§–∞–π–ª—ã/–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|---------------|-----------|-----------------|-----------|
| **Key-Value Store** | JSON files | `data/kv_store_llm_response_cache.json` (340.47 KB)<br>`data/kv_store_doc_status.json`<br>`data/kv_store_*.json` | ‚Ä¢ –ö—ç—à LLM –æ—Ç–≤–µ—Ç–æ–≤ (—Å–Ω–∏–∂–µ–Ω–∏–µ latency)<br>‚Ä¢ –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤<br>‚Ä¢ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ chunks |
| **Graph Database** | GraphML (NetworkX) | `data/graph_chunk_entity_relation.graphml` | Knowledge graph:<br>‚Ä¢ Nodes: chunks, entities<br>‚Ä¢ Edges: relations (with weights) |
| **Vector Database** | –ì–ò–ü–û–¢–ï–ó–ê: ChromaDB/FAISS | `data/vdb_*/` | Embeddings –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (768-dim nomic-embed-text vectors) |
| **Document Storage** | Plain text (.txt) | `library/raw_documents/*.txt` (181 files, 7.67 MB) | –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–¢–†–ò–ó –ø—Ä–∏–Ω—Ü–∏–ø—ã, AI research) |
| **Training Data** | JSONL | `data/triz_synthesis_v1.jsonl` (480.19 KB, 300 pairs) | Self-distilled instruction-response dataset |

**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–§–ê–ö–¢–´):**

| –•—Ä–∞–Ω–∏–ª–∏—â–µ | –†–∞–∑–º–µ—Ä | –ò—Å—Ç–æ—á–Ω–∏–∫ |
|-----------|--------|---------|
| LightRAG data/ | **0.33 MB** | ‚úÖ Terminal: `Get-ChildItem ... | Measure-Object` |
| kv_store_llm_response_cache.json | **340.47 KB** | ‚úÖ Terminal: `Get-ChildItem -First 5` |
| library/raw_documents/ | **7.67 MB** (181 files) | ‚úÖ Terminal: `Measure-Object Length -Sum` |
| triz_synthesis_v1.jsonl | **480.19 KB** | ‚úÖ Terminal: `Get-Item ... | Select-Object` |
| **TOTAL indexed content** | **~8 MB** | –°—É–º–º–∞ library + cache |

### 6.2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

**–ù–ï–¢ —Å—Ç—Ä–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è** (–Ω–µ—Ç –ë–î).

**–ü—É—Ç–∏ –∫ —Ö—Ä–∞–Ω–∏–ª–∏—â—É:**

```python
# ============================================================
# CORTEX (lightrag_server.py lines 44-46)
# ============================================================

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX –æ—Ç 26.11.2025: –ø–µ—Ä–µ—Ö–æ–¥ —Å legacy path
WORKING_DIR = Path(r"E:\WORLD_OLLAMA\services\lightrag\data")
LIBRARY_DIR = Path(r"E:\WORLD_OLLAMA\library\raw_documents")

# OLD (legacy, BROKEN):
# WORKING_DIR = Path(r"E:\AI_Librarian_Core\lightrag_cache")

# –°–û–ó–î–ê–ù–ò–ï –î–ò–†–ï–ö–¢–û–†–ò–ô (line 60)
WORKING_DIR.mkdir(exist_ok=True, parents=True)
```

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ data/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:**

```
services/lightrag/data/
‚îú‚îÄ‚îÄ kv_store_llm_response_cache.json  # 340.47 KB - LLM cache
‚îú‚îÄ‚îÄ kv_store_doc_status.json          # Document indexing status
‚îú‚îÄ‚îÄ kv_store_full_docs.json            # –ì–ò–ü–û–¢–ï–ó–ê: Full document text
‚îú‚îÄ‚îÄ kv_store_text_chunks.json          # –ì–ò–ü–û–¢–ï–ó–ê: Text chunks metadata
‚îú‚îÄ‚îÄ graph_chunk_entity_relation.graphml # Knowledge graph (NetworkX)
‚îî‚îÄ‚îÄ vdb_*/                             # Vector database embeddings
    ‚îú‚îÄ‚îÄ chroma.sqlite3                 # –ì–ò–ü–û–¢–ï–ó–ê: ChromaDB SQLite backend
    ‚îî‚îÄ‚îÄ *.parquet                      # –ì–ò–ü–û–¢–ï–ó–ê: Vector index files
```

### 6.3. –°—Ö–µ–º–∞ –∏ –º–∏–≥—Ä–∞—Ü–∏–∏

**–ú–∏–≥—Ä–∞—Ü–∏–∏:** 

‚ùå **–ù–ï–¢** (—Ñ–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, schema-less).

**–û—Å–Ω–æ–≤–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (–∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞ –∏ LightRAG documentation):**

| –°—É—â–Ω–æ—Å—Ç—å | –•—Ä–∞–Ω–∏–ª–∏—â–µ | –û–ø–∏—Å–∞–Ω–∏–µ | –ü–æ–ª—è (–ì–ò–ü–û–¢–ï–ó–ê) |
|----------|-----------|----------|-----------------|
| **Document** | `kv_store_doc_status.json` | –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ | ‚Ä¢ doc_id (filename)<br>‚Ä¢ status (processed/pending/failed)<br>‚Ä¢ chunk_count<br>‚Ä¢ entities_extracted<br>‚Ä¢ indexed_at (timestamp)<br>‚Ä¢ file_size<br>‚Ä¢ checksum (MD5/SHA256) |
| **Chunk** | GraphML nodes + `kv_store_text_chunks.json` | –§—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (~2048 tokens) | ‚Ä¢ chunk_id (UUID)<br>‚Ä¢ content (text)<br>‚Ä¢ embeddings (768-dim vector)<br>‚Ä¢ source_doc (reference)<br>‚Ä¢ position (start/end chars)<br>‚Ä¢ chunk_index (sequential) |
| **Entity** | GraphML nodes | –ò–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å (NER) | ‚Ä¢ entity_id (UUID)<br>‚Ä¢ entity_name (string)<br>‚Ä¢ entity_type (PERSON/ORG/CONCEPT/PRINCIPLE)<br>‚Ä¢ description (LLM-generated)<br>‚Ä¢ source_chunks (references)<br>‚Ä¢ confidence (float 0-1) |
| **Relation** | GraphML edges | –°–≤—è–∑—å –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏ | ‚Ä¢ source_entity (entity_id)<br>‚Ä¢ target_entity (entity_id)<br>‚Ä¢ relation_type (IS_A/PART_OF/APPLIES_TO/CONTRADICTS)<br>‚Ä¢ weight (float 0-1)<br>‚Ä¢ evidence_chunks (references)<br>‚Ä¢ description (textual) |
| **LLM Response Cache** | `kv_store_llm_response_cache.json` | –ö—ç—à —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ | ‚Ä¢ query_hash (MD5/SHA256)<br>‚Ä¢ mode (naive/local/global/hybrid)<br>‚Ä¢ response (text)<br>‚Ä¢ timestamp<br>‚Ä¢ ttl (time-to-live) |

**–ü—Ä–∏–º–µ—Ä kv_store_doc_status.json (–ì–ò–ü–û–¢–ï–ó–ê –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞):**

```json
{
  "1.triz_droblenie_v_inzhenerii_i_ii.txt": {
    "status": "processed",
    "chunks": 45,
    "entities_extracted": 23,
    "indexed_at": "2025-11-26T12:34:56Z",
    "file_size": 12345,
    "checksum": "md5:abc123..."
  },
  "10._proaktivnyy_agent_printsip_predvaritelnogo_deystviya.txt": {
    "status": "processed",
    "chunks": 38,
    "entities_extracted": 19,
    "indexed_at": "2025-11-26T12:35:12Z",
    "file_size": 10234,
    "checksum": "md5:def456..."
  }
  // ... 488+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
}
```

**–ü—Ä–∏–º–µ—Ä GraphML structure (–ì–ò–ü–û–¢–ï–ó–ê):**

```xml
<graphml>
  <graph edgedefault="directed">
    <node id="chunk_001">
      <data key="content">–ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ1 –î—Ä–æ–±–ª–µ–Ω–∏–µ: —Ä–∞–∑–¥–µ–ª–∏—Ç—å –æ–±—ä–µ–∫—Ç...</data>
      <data key="embedding">[0.123, -0.456, ...]</data>
      <data key="type">chunk</data>
    </node>
    <node id="entity_001">
      <data key="name">–ü—Ä–∏–Ω—Ü–∏–ø –î—Ä–æ–±–ª–µ–Ω–∏—è</data>
      <data key="type">TRIZ_PRINCIPLE</data>
      <data key="description">–¢–†–ò–ó –ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ1, –æ–∑–Ω–∞—á–∞–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ...</data>
    </node>
    <node id="entity_002">
      <data key="name">–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ AI –∞–≥–µ–Ω—Ç–∞</data>
      <data key="type">CONCEPT</data>
    </node>
    <edge source="entity_001" target="entity_002">
      <data key="relation">APPLIES_TO</data>
      <data key="weight">0.85</data>
    </edge>
  </graph>
</graphml>
```

**–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤:** 

‚ùå **–ù–ï–¢ –ù–ê–ô–î–ï–ù–û** —è–≤–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤ –≤ CORTEX/Neuro-Terminal.

‚úÖ **–ì–ò–ü–û–¢–ï–ó–ê:** Chainlit –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–π:
- `.chainlit/chat_files/*.json` ‚Äî –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ (session-based, –Ω–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–µ)
- –ü—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞ ‚Äî —Å–µ—Å—Å–∏—è —Ç–µ—Ä—è–µ—Ç—Å—è

**–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**

‚ùå **–ù–ï–¢ –ù–ê–ô–î–ï–ù–û** –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (user profiles, preferences).

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑:
- Environment variables (`CORTEX_API_KEY`, `NEURO_OLLAMA_HOST`, `NEURO_MODEL`)
- YAML —Ñ–∞–π–ª—ã (triz_safe_config.yaml)
- Hardcoded defaults –≤ –∫–æ–¥–µ (lightrag_server.py, app.py)

---

## 7. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª (feature-level –æ–±–∑–æ—Ä)

### 7.1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏

**–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å Ollama (—á–µ—Ä–µ–∑ CORTEX –∏ Neuro-Terminal):**

| –§—É–Ω–∫—Ü–∏—è | –†–µ–∞–ª–∏–∑–∞—Ü–∏—è | –°—Ç–∞—Ç—É—Å | –î–µ—Ç–∞–ª–∏ |
|---------|-----------|--------|--------|
| **–í—ã–±–æ—Ä/–∑–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏** | ‚ùå –ù–ï–¢ UI | Model hardcoded –≤ lightrag_server.py (qwen2.5:14b) –∏ app.py (qwen2.5:14b-instruct-q4_k_m) | –¢—Ä–µ–±—É–µ—Ç—Å—è: Settings panel —Å dropdown –¥–ª—è –º–æ–¥–µ–ª–µ–π |
| **–í–≤–æ–¥ –ø—Ä–æ–º–ø—Ç–∞** | ‚úÖ –†–ê–ë–û–¢–ê–ï–¢ | Chainlit chat input –≤ Neuro-Terminal (app.py) | User –≤–≤–æ–¥–∏—Ç –≤–æ–ø—Ä–æ—Å ‚Üí –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ `cl.Message` |
| **–ü–æ—Ç–æ–∫–æ–≤—ã–π –≤—ã–≤–æ–¥** | ‚ùå –ù–ï–¢ | LightRAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `stream=false`, Chainlit –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç streaming API | –¢—Ä–µ–±—É–µ—Ç—Å—è: WebSocket/SSE integration |
| **–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤** | ‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–û | Chainlit —Ö—Ä–∞–Ω–∏—Ç —Å–µ—Å—Å–∏–∏ –≤ `.chainlit/chat_files/` (session-based, –Ω–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ) | –¢—Ä–µ–±—É–µ—Ç—Å—è: Database –¥–ª—è long-term storage |
| **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏** | ‚ùå –ù–ï–¢ UI | Temperature/top_p hardcoded –≤ LightRAG (0.7/0.8) –∏ Planner (0.0) | –¢—Ä–µ–±—É–µ—Ç—Å—è: Sliders –≤ UI –¥–ª—è temperature, top_p, top_k |
| **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫** | ‚úÖ –†–ê–ë–û–¢–ê–ï–¢ | CORTEX `/query` endpoint —Å 4 —Ä–µ–∂–∏–º–∞–º–∏ (naive, local, global, hybrid) | Via SYNAPSE connector |
| **–í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –ø–æ–∏—Å–∫–∞** | ‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–û | Planner –≤—ã–±–∏—Ä–∞–µ—Ç mode –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ JSON output ("search_mode": "hybrid") | –¢—Ä–µ–±—É–µ—Ç—Å—è: Manual override –≤ UI |
| **API Key authentication** | ‚úÖ –†–ê–ë–û–¢–ê–ï–¢ | Middleware –≤ lightrag_server.py (X-API-KEY header), SYNAPSE connector –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç | Security: TD-010 "Secure Enclave" |
| **Health checks** | ‚úÖ –†–ê–ë–û–¢–ê–ï–¢ | CHECK_STATUS.ps1 –ø—Ä–æ–≤–µ—Ä—è–µ—Ç Ollama, CORTEX, LLaMA Board, Neuro-Terminal | PowerShell automation |

**–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–ù–ï —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –¥–ª—è Ollama UI):**

#### 1. **GraphRAG –ø–æ–∏—Å–∫ (CORTEX)**

**–û–ø–∏—Å–∞–Ω–∏–µ:** CORTEX —Å—Ç—Ä–æ–∏—Ç knowledge graph –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç graph traversal –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

**–†–µ–∂–∏–º—ã –ø–æ–∏—Å–∫–∞:**

| Mode | –û–ø–∏—Å–∞–Ω–∏–µ | –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è | Use Case |
|------|----------|-----------------|----------|
| **naive** | –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ | 10-30s | –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è |
| **local** | –ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (nearby chunks) | 30-60s | –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ |
| **global** | –ü–æ–ª–Ω—ã–π graph traversal (–≤—Å–µ —Å—É—â–Ω–æ—Å—Ç–∏ + –æ—Ç–Ω–æ—à–µ–Ω–∏—è) | 60-90s | –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ |
| **hybrid** | Adaptive mode selection (LLM –≤—ã–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é) | 30-90s | **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è** (default) |

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```
User Query ‚Üí SYNAPSE ‚Üí CORTEX /query
                         ‚Üì
                  Mode Selection (hybrid)
                         ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                     ‚îÇ
         Graph Traversal      Vector Search
        (NetworkX BFS/DFS)   (FAISS similarity)
              ‚îÇ                     ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
                Entity + Chunk Retrieval
                         ‚Üì
                  LLM Synthesis (Ollama qwen2.5:14b)
                         ‚Üì
                    Response
```

#### 2. **Self-Distillation (TD-009 Evolution Phase)**

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ê–≥–µ–Ω—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∞–º —Å–µ–±–µ –æ–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ CORTEX queries.

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:** `workbench/sandbox_main/scripts/data_forge.py` (251 lines)

**–ü—Ä–æ—Ü–µ—Å—Å:**
1. **Template-based query generation** (4 —Ç–∏–ø–∞: synthesis, analysis, application, deep_dive)
2. **CORTEX knowledge lookup** (hybrid mode)
3. **Response validation** (length >100 chars, content check)
4. **JSONL export** (alpaca format: instruction, input, output)
5. **Dataset deployment** ‚Üí LLaMA-Factory data folder

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- **300 instruction-response pairs** (100% success rate)
- **480.19 KB** —Ñ–∞–π–ª `triz_synthesis_v1.jsonl`
- **–†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π** –∫–æ–Ω—Ç–µ–Ω—Ç (–¢–†–ò–ó + AI domain)

**–ü—Ä–∏–º–µ—Ä –ø–∞—Ä—ã:**

```json
{
  "instruction": "–ü—Ä–∏–º–µ–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã –¢–†–ò–ó ‚Ññ1 –∏ ‚Ññ10 –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã AI –∞–≥–µ–Ω—Ç–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é",
  "input": "",
  "output": "**–ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ1 (–î—Ä–æ–±–ª–µ–Ω–∏–µ):** –†–∞–∑–¥–µ–ª–∏—Ç—å –∞–≥–µ–Ω—Ç–∞ –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –º–æ–¥—É–ª–∏...\n\n**–ü—Ä–∏–Ω—Ü–∏–ø ‚Ññ10 (–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ):** –ó–∞—Ä–∞–Ω–µ–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...\n\n**–°–∏–Ω—Ç–µ–∑ —Ä–µ—à–µ–Ω–∏—è:** –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —ç—Ç–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –º–æ–¥—É–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º..."
}
```

#### 3. **Fine-tuning Pipeline**

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ LLaMA-Factory.

**–≠—Ç–∞–ø—ã:**
1. **Dataset generation** (data_forge.py)
2. **Dataset registration** (dataset_info.json)
3. **Config creation** (triz_safe_config.yaml)
4. **LoRA training** (src/train.py)
5. **Model export** (–ì–ò–ü–û–¢–ï–ó–ê: Ollama format via `ollama create`)

**–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:**
- ‚úÖ Dataset –≥–æ—Ç–æ–≤ (triz_synthesis_v1.jsonl, 300 pairs)
- ‚úÖ Config —Å–æ–∑–¥–∞–Ω (LoRA rank 8, batch_size 1, preprocessing_workers 1)
- üü° Training –∑–∞–ø—É—â–µ–Ω (loading checkpoint shards, in progress)

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (triz_safe_config.yaml):**

```yaml
model_name_or_path: Qwen/Qwen2-7B-Instruct
finetuning_type: lora
lora_rank: 8
lora_alpha: 16
lora_target: all
per_device_train_batch_size: 1
gradient_accumulation_steps: 4
learning_rate: 5.0e-5
num_train_epochs: 3.0
cutoff_len: 2048
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã –≤ `saves/Qwen2-7B-Instruct/lora/triz_safe/`
- –†–∞–∑–º–µ—Ä: ~100-500 MB (LoRA weights)
- Deployment: merge + export to Ollama

#### 4. **Multi-Agent System (agents/qwen2-main + helper-lite)**

**–û–ø–∏—Å–∞–Ω–∏–µ:** –î–≤–∞ –∞–≥–µ–Ω—Ç–∞ —Å —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–º–∏ —Ä–æ–ª—è–º–∏.

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**

```
agents/
‚îú‚îÄ‚îÄ qwen2-main/          # –û—Å–Ω–æ–≤–Ω–æ–π –∞–≥–µ–Ω—Ç (complex reasoning)
‚îÇ   ‚îú‚îÄ‚îÄ configs/         # Agent-specific configurations
‚îÇ   ‚îú‚îÄ‚îÄ data/            # Runtime data (context, memory)
‚îÇ   ‚îú‚îÄ‚îÄ logs/            # Execution logs
‚îÇ   ‚îú‚îÄ‚îÄ scripts/         # Agent automation scripts
‚îÇ   ‚îî‚îÄ‚îÄ world/           # Knowledge context (documents, embeddings)
‚îÇ
‚îî‚îÄ‚îÄ helper-lite/         # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç (simple tasks)
    ‚îî‚îÄ‚îÄ [–∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞]
```

**–°–¢–ê–¢–£–°:** üìÅ **Structure only** (no code found in analysis)

**–ì–ò–ü–û–¢–ï–ó–ê:** Planned for distributed task execution (qwen2-main for TRI–ó synthesis, helper-lite for metadata extraction).

#### 5. **–¢–†–ò–ó Principles Integration (40 –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤)**

**–û–ø–∏—Å–∞–Ω–∏–µ:** –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–æ –¢–†–ò–ó (Theory of Inventive Problem Solving).

**–ö–æ–Ω—Ç–µ–Ω—Ç:**

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ | –ü—Ä–∏–º–µ—Ä—ã |
|-----------|-----------|---------|
| **–¢–†–ò–ó –ü—Ä–∏–Ω—Ü–∏–ø—ã** | 40 —Ñ–∞–π–ª–æ–≤ | 1. –î—Ä–æ–±–ª–µ–Ω–∏–µ<br>2. –í—ã–Ω–µ—Å–µ–Ω–∏–µ<br>9. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∞–Ω—Ç–∏–¥–µ–π—Å—Ç–≤–∏–µ<br>10. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ<br>23. –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å<br>24. –ü–æ—Å—Ä–µ–¥–Ω–∏–∫<br>25. –°–∞–º–æ–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ<br>... |
| **AI Methodologies** | ~141 —Ñ–∞–π–ª–æ–≤ | ‚Ä¢ Agentic RAG patterns<br>‚Ä¢ LLM optimization<br>‚Ä¢ Multi-agent architectures<br>‚Ä¢ GPU performance tuning<br>‚Ä¢ Security (SSL, secrets management)<br>‚Ä¢ React chat interfaces<br>‚Ä¢ Prompt engineering |
| **–ò—Ç–æ–≥–æ** | **181 —Ñ–∞–π–ª–æ–≤, 7.67 MB** | –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç |

**–ü—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ:**

| –ü—Ä–∏–Ω—Ü–∏–ø | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ WORLD_OLLAMA |
|---------|---------------------------|
| **‚Ññ2 "–í—ã–Ω–µ—Å–µ–Ω–∏–µ"** | API Key isolation (SECURE ENCLAVE, TD-010) |
| **‚Ññ10 "–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ"** | Service startup order (Ollama ‚Üí CORTEX ‚Üí LLaMA ‚Üí Neuro), Python process checks |
| **‚Ññ23 "–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å"** | data_forge.py query templates, response validation |
| **‚Ññ24 "–ü–æ—Å—Ä–µ–¥–Ω–∏–∫"** | SYNAPSE connector (bridge Agent ‚Üî CORTEX) |
| **‚Ññ25 "–°–∞–º–æ–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"** | Self-distillation dataset generation |

### 7.2. –°–ª–æ–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

**UI —Å–ª–æ–π:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –§—É–Ω–∫—Ü–∏–∏ | Entry Point |
|-----------|-----------|---------|------------|
| **Neuro-Terminal** | Chainlit 1.1.402 | ‚Ä¢ Chat interface<br>‚Ä¢ **Step visualization** (Planner, CORTEX Lookup, Knowledge Result, Response)<br>‚Ä¢ Message streaming (session-based)<br>‚Ä¢ Session management<br>‚Ä¢ SYNAPSE integration | `app.py` (210 lines) |
| **LLaMA Board** | Gradio 4.38.0+ | ‚Ä¢ Dataset selector (dropdown)<br>‚Ä¢ Model configurator (text inputs)<br>‚Ä¢ Training monitor (progress bars)<br>‚Ä¢ Loss charts (matplotlib)<br>‚Ä¢ Hyperparameter sliders<br>‚Ä¢ DeepSpeed config selector | `llamafactory webui` (package) |

**Application/Service —Å–ª–æ–π:**

| –°–µ—Ä–≤–∏—Å | –§–∞–π–ª | –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å | Endpoints/Methods |
|--------|------|----------------|-------------------|
| **CORTEX** | lightrag_server.py (697 lines) | ‚Ä¢ Document indexing<br>‚Ä¢ Knowledge graph construction<br>‚Ä¢ Semantic search (4 modes)<br>‚Ä¢ API Key authentication<br>‚Ä¢ LLM response caching | ‚Ä¢ POST `/query` (query, mode, only_need_context)<br>‚Ä¢ GET `/health` (no auth)<br>‚Ä¢ lifespan: startup (LightRAG init), shutdown |
| **SYNAPSE Connector** | knowledge_client.py (290 lines) | ‚Ä¢ HTTP client –¥–ª—è CORTEX<br>‚Ä¢ Retry logic (–ì–ò–ü–û–¢–ï–ó–ê: not implemented yet)<br>‚Ä¢ Health checks<br>‚Ä¢ Error handling | ‚Ä¢ `lookup_knowledge(query, mode, timeout)`<br>‚Ä¢ `check_cortex_health()`<br>‚Ä¢ Exceptions: CortexConnectionError, CortexQueryError |
| **Training Orchestrator** | llama_factory/src/train.py | ‚Ä¢ Dataset loading<br>‚Ä¢ Model initialization<br>‚Ä¢ LoRA training loop<br>‚Ä¢ Checkpoint saving<br>‚Ä¢ Tensorboard logging | ‚Ä¢ CLI: `llamafactory-cli train <config.yaml>`<br>‚Ä¢ Python: `python src/train.py <config.yaml>` |

**Domain/Core:**

‚ùå **–ù–ï–¢ —è–≤–Ω—ã—Ö domain models** (–ø—Ä–æ–µ–∫—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DDD pattern).

‚úÖ **Implicit models –≤ LightRAG library (–ì–ò–ü–û–¢–ï–ó–ê):**
- `Document` (chunk, metadata, embeddings)
- `Entity` (name, type, description, confidence)
- `Relation` (source, target, type, weight)
- `Query` (text, mode, context, lang)

‚úÖ **Explicit dataclasses –≤ Neuro-Terminal (app.py):**

```python
@dataclass
class Step:
    """Narrative step to mirror the agent's reasoning."""
    title: str
    content: str
    status: Literal["info", "success", "warning", "error"] = "info"
    
    async def publish(self) -> None:
        # Chainlit Step visualization

@dataclass
class PlanDecision:
    reasoning: str
    call_knowledge: bool
    knowledge_query: str
    search_mode: knowledge_client.SearchMode = "hybrid"
    
    @classmethod
    def from_text(cls, text: str) -> "PlanDecision":
        # Parse JSON from Planner LLM output
```

**–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ |
|-----------|-----------|------------|
| **data/** | –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ | JSON (KV store), GraphML (NetworkX), FAISS/ChromaDB (vectors) |
| **synapse/** | HTTP –∞–¥–∞–ø—Ç–µ—Ä | requests 2.32.0+, API Key middleware |
| **scripts/*.ps1** | Service orchestration | PowerShell 7+ (Start-Process, Invoke-RestMethod, Get-Process) |
| **USER/*.ps1** | User-facing automation | PowerShell 7+ (process detection, GPU monitoring, health checks) |

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω:**

‚úÖ **Layered Architecture (3-tier) + Microservices**:

1. **Presentation Layer** ‚Äî Chainlit UI, Gradio UI
2. **Application Layer** ‚Äî SYNAPSE connector, Training orchestration, Planner logic
3. **Infrastructure Layer** ‚Äî CORTEX (FastAPI), File Storage, Ollama HTTP API

**–≠–ª–µ–º–µ–Ω—Ç—ã –¥—Ä—É–≥–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:**

| –ü–∞—Ç—Ç–µ—Ä–Ω | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ |
|---------|---------------------|
| **Dependency Inversion** | SYNAPSE connector –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç CORTEX API (interface-like) |
| **API Gateway** | CORTEX –∫–∞–∫ –µ–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ knowledge base |
| **Repository Pattern** | File storage —á–µ—Ä–µ–∑ LightRAG abstraction (data access layer) |
| **Strategy Pattern** | Search modes (naive/local/global/hybrid) ‚Äî —Ä–∞–∑–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∏—Å–∫–∞ |
| **Middleware Pattern** | API Key authentication –≤ FastAPI (lines 260-280) |
| **Observer Pattern** | Chainlit Step visualization (events ‚Üí UI updates) |

‚ùå **–ù–ï–¢ —è–≤–Ω–æ–≥–æ:**
- MVC (–Ω–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–æ–≤/–º–æ–¥–µ–ª–µ–π/–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è)
- MVVM (–Ω–µ—Ç view models)
- Clean Architecture (–Ω–µ—Ç use cases, entities, gateways —Å–ª–æ—ë–≤)
- Hexagonal Architecture (–Ω–µ—Ç ports/adapters —è–≤–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è)
- CQRS (–Ω–µ—Ç command/query separation)
- Event Sourcing

---

## 8. –í–∑–∞–∏–º–æ—Å–≤—è–∑—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –æ–±–∑–æ—Ä)

### 8.1. –õ–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

**–°—Ü–µ–Ω–∞—Ä–∏–π 1: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π (—Å CORTEX lookup)**

```
[User Browser]
    ‚Üì HTTP (localhost:8501)
[Neuro-Terminal (Chainlit app.py)]
    ‚Üì Step 1: Planner phase
    ‚Üì _plan_next_step(user_content, history)
    ‚Üì OllamaClient.chat(model=qwen2.5:14b, temperature=0.0)
    ‚Üì
[Ollama Server :11434]
    ‚Üì /api/generate (JSON decision)
    ‚Üì
[Planner Decision (PlanDecision dataclass)]
    ‚Üì call_knowledge=true, knowledge_query="...", search_mode="hybrid"
    ‚Üì Step 2: CORTEX Lookup
    ‚Üì import knowledge_client.lookup_knowledge()
    ‚Üì
[SYNAPSE Connector (knowledge_client.py)]
    ‚Üì HTTP POST (localhost:8004/query, X-API-KEY header)
    ‚Üì
[CORTEX API (lightrag_server.py)]
    ‚Üì API Key Middleware validation (line 260-280)
    ‚Üì @app.post("/query") endpoint
    ‚Üì await rag.aquery(query, param=QueryParam(mode=...))
    ‚Üì
[LightRAG Engine]
    ‚Üì Mode selection: hybrid
    ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì ‚îÇ                     ‚îÇ                  ‚îÇ
[Graph Traversal]      [Vector Search]    [Entity Extraction]
(NetworkX BFS/DFS)     (FAISS/ChromaDB)   (NER from cache)
    ‚Üì ‚îÇ                     ‚îÇ                  ‚îÇ
    ‚Üì ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì Chunk + Entity Retrieval
    ‚Üì Context assembly (top-k chunks + entities)
    ‚Üì LLM synthesis prompt
    ‚Üì
[Ollama Server :11434]
    ‚Üì /api/generate (context + query ‚Üí response)
    ‚Üì Model: qwen2.5:14b (11.4 GB VRAM)
    ‚Üì
[Generated Response]
    ‚Üì JSON {"response": "...", "mode_used": "hybrid", "lang": "ru"}
    ‚Üì –û–±—Ä–∞—Ç–Ω—ã–π –ø—É—Ç—å —á–µ—Ä–µ–∑ SYNAPSE
    ‚Üì
[Neuro-Terminal]
    ‚Üì Step 3: Knowledge Result (visualization)
    ‚Üì Step 4: Response phase
    ‚Üì _sync_chat(history + context, temperature=0.2)
    ‚Üì
[Ollama Server :11434]
    ‚Üì /api/generate (final response with Anti-Hallucination Protocol)
    ‚Üì
[User Browser (Chainlit UI)]
    ‚Üì Message streaming (cl.Message)
    ‚Üì Display response with Step history
```

**–°—Ü–µ–Ω–∞—Ä–∏–π 2: Fine-tuning –º–æ–¥–µ–ª–∏ (Self-Distillation)**

```
[User]
    ‚Üì Execute: python data_forge.py
    ‚Üì
[data_forge.py (251 lines)]
    ‚Üì Loop: 300 iterations
    ‚Üì Generate query from template (QUERY_TEMPLATES)
    ‚Üì Template types: synthesis, analysis, application, deep_dive
    ‚Üì Random principles selection (p1, p2 from 1-40)
    ‚Üì
[SYNAPSE Connector]
    ‚Üì lookup_knowledge(query=generated_query, mode="hybrid")
    ‚Üì HTTP POST (localhost:8004/query)
    ‚Üì
[CORTEX]
    ‚Üì LightRAG hybrid search
    ‚Üì Graph + Vector + LLM synthesis
    ‚Üì
[Ollama qwen2.5:14b]
    ‚Üì Response generation (~500-2000 tokens)
    ‚Üì
[SYNAPSE]
    ‚Üì Response validation (length >100 chars)
    ‚Üì Content check (–Ω–µ –ø—É—Å—Ç–æ–π, –Ω–µ –æ—à–∏–±–∫–∞)
    ‚Üì
[JSONL Writer (data_forge.py)]
    ‚Üì Append to triz_synthesis_v1.jsonl
    ‚Üì Format: {"instruction": "...", "input": "", "output": "..."}
    ‚Üì
[300 Instruction-Response Pairs]
    ‚Üì File size: 480.19 KB
    ‚Üì Copy to llama_factory/data/
    ‚Üì
[Dataset Registry (dataset_info.json)]
    ‚Üì Add entry: triz_synthesis_v1 (alpaca formatting)
    ‚Üì
[LLaMA Factory Training]
    ‚Üì Load dataset (HuggingFace Datasets)
    ‚Üì Tokenization (Qwen tokenizer)
    ‚Üì LoRA initialization (rank=8, alpha=16)
    ‚Üì Training loop (3 epochs, batch_size=1, accumulation=4)
    ‚Üì GPU: RTX 5060 Ti 16GB (~11.4 GB VRAM)
    ‚Üì
[Model Checkpoints]
    ‚Üì saves/Qwen2-7B-Instruct/lora/triz_safe/
    ‚Üì adapter_model.bin, adapter_config.json
    ‚Üì Tensorboard logs (loss curves)
```

**–°—Ü–µ–Ω–∞—Ä–∏–π 3: System Startup (START_ALL.ps1)**

```
[User]
    ‚Üì Execute: .\START_ALL.ps1
    ‚Üì
[START_ALL.ps1]
    ‚Üì Phase 1: Python Process Detection
    ‚Üì Get-Process python | Where-Object {WorkingSet > 100MB}
    ‚Üì Filter: -notlike "*MSI Afterburner*" -and -notlike "*RivaTuner*"
    ‚Üì If found ‚Üí User confirmation (Read-Host)
    ‚Üì
    ‚Üì Phase 2: Ollama Health Check
    ‚Üì Invoke-RestMethod http://localhost:11434/api/tags (timeout 3s)
    ‚Üì If failed ‚Üí prompt "–ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve"
    ‚Üì If success ‚Üí continue
    ‚Üì
    ‚Üì Phase 3: CORTEX Launch
    ‚Üì Start-Process powershell -NoExit
    ‚Üì   -Command "cd services\lightrag; .\venv\Scripts\Activate.ps1; python lightrag_server.py"
    ‚Üì Wait 3 seconds (initialization delay)
    ‚Üì
[CORTEX lightrag_server.py]
    ‚Üì FastAPI lifespan startup
    ‚Üì nest_asyncio.apply() (fix event loop conflict)
    ‚Üì LightRAG initialization (working_dir, llm_model_func, embedding_func)
    ‚Üì await rag.initialize_storages()
    ‚Üì Load graph from data/*.graphml
    ‚Üì Load KV stores from data/*.json
    ‚Üì Server ready on http://0.0.0.0:8004
    ‚Üì
[START_ALL.ps1]
    ‚Üì Phase 4: LLaMA Board Launch
    ‚Üì Start-Process powershell -NoExit
    ‚Üì   -Command "cd services\llama_factory; .\venv\Scripts\Activate.ps1; llamafactory-cli webui"
    ‚Üì Wait 3 seconds
    ‚Üì
[LLaMA Board (Gradio)]
    ‚Üì Load LLaMA-Factory package
    ‚Üì Scan data/dataset_info.json
    ‚Üì Gradio UI ready on http://0.0.0.0:7860
    ‚Üì
[START_ALL.ps1]
    ‚Üì Phase 5: Neuro-Terminal Launch
    ‚Üì Start-Process powershell -NoExit
    ‚Üì   -Command "cd services\neuro_terminal; .\.venv\Scripts\Activate.ps1; chainlit run app.py"
    ‚Üì Wait 3 seconds
    ‚Üì
[Neuro-Terminal (Chainlit)]
    ‚Üì Load app.py (210 lines)
    ‚Üì Initialize OllamaClient (host=localhost:11434)
    ‚Üì Chainlit UI ready on http://0.0.0.0:8501
    ‚Üì
[START_ALL.ps1]
    ‚Üì Phase 6: Auto-navigation
    ‚Üì Set-Location E:\WORLD_OLLAMA\USER
    ‚Üì Write-Host "‚úÖ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∑–∞–ø—É—â–µ–Ω—ã"
```

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö (—Ñ–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ) ‚Äî –æ–ø–µ—Ä–∞—Ü–∏–∏:**

```
[CORTEX Document Indexing]
    ‚Üì User runs: python init_index.py
    ‚Üì Scan library/raw_documents/*.txt (181 files)
    ‚Üì For each document:
    ‚Üì   1. Read file content
    ‚Üì   2. Split into chunks (~2048 tokens, overlap 200)
    ‚Üì   3. Generate embeddings (Ollama nomic-embed-text)
    ‚Üì   4. Extract entities (LLM NER via Ollama qwen2.5:14b)
    ‚Üì   5. Build relations (entity co-occurrence, semantic similarity)
    ‚Üì
[LightRAG Library]
    ‚Üì Chunking algorithm (recursive text splitter)
    ‚Üì Entity extraction prompt: "Extract named entities from text..."
    ‚Üì Relation extraction prompt: "Identify relationships between [entity1] and [entity2]..."
    ‚Üì
[Writes to data/]
    ‚îú‚îÄ‚îÄ kv_store_doc_status.json          # Update document status: processed
    ‚îú‚îÄ‚îÄ kv_store_text_chunks.json         # Store chunk metadata
    ‚îú‚îÄ‚îÄ graph_chunk_entity_relation.graphml # Add nodes (chunks, entities) + edges (relations)
    ‚îî‚îÄ‚îÄ vdb_*/                            # Store embeddings in vector DB
    
[CORTEX Query]
    ‚Üì User query via SYNAPSE: "–ö–∞–∫ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø ‚Ññ1?"
    ‚Üì Read from data/
    ‚Üì LightRAG Search (hybrid mode):
    ‚Üì   1. Vector search (FAISS/ChromaDB): top-k similar chunks by embedding
    ‚Üì   2. Graph traversal (NetworkX): BFS from query entities
    ‚Üì   3. Entity filter: relevant nodes by relation weights
    ‚Üì   4. Context assembly: chunks + entities ‚Üí prompt
    ‚Üì
[LLM Synthesis]
    ‚Üì Ollama qwen2.5:14b generates response using assembled context
    ‚Üì Cache response in kv_store_llm_response_cache.json (TTL-based)
    ‚Üì
[Response]
```

### 8.2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ (—Ç–µ–∫—Å—Ç–æ–≤–∞—è)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER (Browser :8501)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ HTTP
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PRESENTATION LAYER                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Neuro-Terminal              ‚îÇ  ‚îÇ  LLaMA Board                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Chainlit app.py)           ‚îÇ  ‚îÇ  (Gradio llamafactory webui)   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Port: 8501                  ‚îÇ  ‚îÇ  Port: 7860                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Chat interface            ‚îÇ  ‚îÇ  ‚Ä¢ Dataset selector            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Step visualization        ‚îÇ  ‚îÇ  ‚Ä¢ Training monitor            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Planner (Ollama)          ‚îÇ  ‚îÇ  ‚Ä¢ Loss curves                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Response (Ollama)         ‚îÇ  ‚îÇ  ‚Ä¢ Hyperparameter config       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ import                            ‚îÇ CLI invoke
              ‚îÇ knowledge_client                  ‚îÇ src/train.py
              ‚Üì                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     APPLICATION LAYER                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  SYNAPSE Connector           ‚îÇ  ‚îÇ  LLaMA Factory Engine          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (knowledge_client.py)       ‚îÇ  ‚îÇ  (src/train.py)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ lookup_knowledge()        ‚îÇ  ‚îÇ  ‚Ä¢ Dataset loading             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ check_cortex_health()     ‚îÇ  ‚îÇ  ‚Ä¢ LoRA initialization         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ API Key auth              ‚îÇ  ‚îÇ  ‚Ä¢ Training loop               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Error handling            ‚îÇ  ‚îÇ  ‚Ä¢ Checkpoint saving           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ HTTP POST                         ‚îÇ PyTorch + CUDA
              ‚îÇ localhost:8004/query              ‚îÇ GPU execution
              ‚îÇ X-API-KEY header                  ‚îÇ
              ‚Üì                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   INFRASTRUCTURE LAYER                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  CORTEX (FastAPI)            ‚îÇ  ‚îÇ  File Storage                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (lightrag_server.py)        ‚îÇ  ‚îÇ  (data/, library/, saves/)     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Port: 8004                  ‚îÇ  ‚îÇ  ‚Ä¢ KV stores (JSON)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /query endpoint           ‚îÇ  ‚îÇ  ‚Ä¢ Knowledge graph (GraphML)   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /health endpoint          ‚îÇ  ‚îÇ  ‚Ä¢ Vector DB (FAISS/Chroma)    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ API Key middleware        ‚îÇ  ‚îÇ  ‚Ä¢ Training checkpoints        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ LightRAG engine           ‚îÇ  ‚îÇ  ‚Ä¢ Raw documents (.txt)        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ HTTP POST/GET
              ‚îÇ localhost:11434/api/*
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     EXTERNAL SERVICES                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Ollama Server (localhost:11434)                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ qwen2.5:14b-instruct-q4_k_m (~8.2 GB, 11.4 GB VRAM usage)     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ nomic-embed-text (~274 MB)                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /api/generate (LLM generation)                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /api/embeddings (vector embeddings)                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /api/tags (model list)                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         HARDWARE                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  RTX 5060 Ti 16GB VRAM                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CUDA 12.x                                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ VRAM usage: ~11.4 GB stable (qwen2.5:14b model loaded)       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GPU utilization: monitored via nvidia-smi                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç | –¢–∏–ø –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
|-----------|-----------|----------------|
| Neuro-Terminal | SYNAPSE Connector | Import (direct code dependency) |
| Neuro-Terminal | Ollama Server | HTTP API (localhost:11434) |
| Neuro-Terminal | Chainlit library | PyPI package |
| SYNAPSE Connector | CORTEX API | HTTP API (localhost:8004) |
| SYNAPSE Connector | requests library | PyPI package |
| CORTEX | LightRAG library | PyPI package (lightrag-hku) |
| CORTEX | Ollama Server | HTTP API (LLM + embeddings) |
| CORTEX | File Storage | Direct file I/O (data/*.json, *.graphml) |
| CORTEX | FastAPI, uvicorn | PyPI packages |
| LLaMA Factory | HuggingFace libraries | PyPI (transformers, datasets, peft) |
| LLaMA Factory | PyTorch + CUDA | PyPI + NVIDIA drivers |
| LLaMA Factory | File Storage | Direct file I/O (data/*.jsonl, saves/*) |
| LLaMA Board | LLaMA Factory package | Editable install (pip install -e .) |
| LLaMA Board | Gradio library | PyPI package |
| Ollama Server | GPU (RTX 5060 Ti) | Hardware dependency (CUDA) |
| **–í—Å–µ —Å–µ—Ä–≤–∏—Å—ã** | Python 3.12 | Runtime environment |
| **Management scripts** | PowerShell 7+ | Runtime environment |

**Data Flow Dependencies:**

```
Raw Documents (.txt)
    ‚Üì
CORTEX Indexing (init_index.py)
    ‚Üì
Knowledge Graph (data/*.graphml)
    ‚Üì
CORTEX Query (via SYNAPSE)
    ‚Üì
Self-Distillation (data_forge.py)
    ‚Üì
Training Dataset (triz_synthesis_v1.jsonl)
    ‚Üì
LLaMA Factory Training
    ‚Üì
LoRA Adapters (saves/*/lora/*)
    ‚Üì
Model Export (–ì–ò–ü–û–¢–ï–ó–ê: Ollama format)
    ‚Üì
Deployed Model (ollama create custom-model)
```

---

## 9. –†–∏—Å–∫–∏, –ø—Ä–æ–±–µ–ª—ã –∏ TODO

### 9.1. TODO/FIXME –≤ –∫–æ–¥–µ

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã grep –ø–æ–∏—Å–∫–∞:**

‚ùå **–ù–ï–¢ –Ω–∞–π–¥–µ–Ω–æ** —è–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ TODO/FIXME/HACK/XXX –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º –∫–æ–¥–µ –ø—Ä–æ–µ–∫—Ç–∞.

‚úÖ **–ù–∞–π–¥–µ–Ω—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ venv –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ö** (20+ matches), –Ω–æ –æ–Ω–∏ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º (requests, urllib3, pip), –ù–ï –∫ –∫–æ–¥—É –ø—Ä–æ–µ–∫—Ç–∞.

**–í–´–í–û–î:** –ü—Ä–æ–µ–∫—Ç –≤ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ, –Ω–æ TODO tracking, –≤–µ—Ä–æ—è—Ç–Ω–æ, –≤–µ–¥—ë—Ç—Å—è —á–µ—Ä–µ–∑:
- GitHub Issues (–µ—Å–ª–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ GitHub)
- PROJECT_MAP.md, STATE_SNAPSHOT_v3.1.md (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
- –£—Å—Ç–Ω—ã–µ –¥–æ–≥–æ–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏ / –ª–∏—á–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞

### 9.2. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–∑ –∫–æ–¥–∞, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:**

| –ü—Ä–æ–±–ª–µ–º–∞ | –õ–æ–∫–∞—Ü–∏—è | –î–µ—Ç–∞–ª–∏ | Severity | –°—Ç–∞—Ç—É—Å |
|----------|---------|--------|----------|--------|
| **Legacy Path Hard-coding** | lightrag_server.py (line 44-45) | **FIXED 26.11.2025**<br>Old: `E:\AI_Librarian_Core\lightrag_cache`<br>New: `E:\WORLD_OLLAMA\services\lightrag\data`<br>**–ü—Ä–∏—á–∏–Ω–∞:** External project reference<br>**Impact:** CORTEX –Ω–µ –º–æ–≥ –Ω–∞–π—Ç–∏ data/ ‚Üí 500 errors | üî¥ CRITICAL | ‚úÖ FIXED |
| **Rerank —Ñ—É–Ω–∫—Ü–∏—è –û–¢–ö–õ–Æ–ß–ï–ù–ê** | lightrag_server.py (lines 241-245) | **BUG:** LightRAG v1.4.9.8<br>Error: `'float' object has no attribute 'copy'`<br>**Workaround:** `# rerank_model_func –û–¢–ö–õ–Æ–ß–ï–ù`<br>**Impact:** –°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ | üü° MEDIUM | üî¥ OPEN |
| **Hardcoded API Key** | lightrag_server.py, knowledge_client.py | `CORTEX_API_KEY = "sesa-secure-core-v1"`<br>**Risk:** –ù–ï–¢ rotation mechanism<br>–ù–ï–¢ secrets management (Vault, Azure Key Vault)<br>**Mitigation:** –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ env variable –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è | üü° MEDIUM | ‚ö†Ô∏è PARTIAL |
| **–ù–ï–¢ streaming** | lightrag_server.py, app.py | LightRAG config `stream=false`<br>Chainlit –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç streaming API<br>**Impact:** –ë–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã (>500 tokens) –±–ª–æ–∫–∏—Ä—É—é—Ç UI<br>**UX:** –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–¥—ë—Ç 30-90s –±–µ–∑ feedback | üü° MEDIUM | üî¥ OPEN |
| **–ù–ï–¢ rate limiting** | lightrag_server.py | CORTEX API –±–µ–∑ throttling<br>**Risk:** –ü–µ—Ä–µ–≥—Ä—É–∑–∫–∞ Ollama (HTTP 429 Too Many Requests)<br>**Attack vector:** DoS –ø—Ä–∏ —Å–ø–∞–º–µ –∑–∞–ø—Ä–æ—Å–æ–≤ | üü° MEDIUM | üî¥ OPEN |
| **–ù–ï–¢ retry logic** | knowledge_client.py | –û–¥–Ω–∞ –ø–æ–ø—ã—Ç–∫–∞ HTTP request<br>–ù–ï–¢ exponential backoff<br>**Impact:** Transient network errors ‚Üí user error<br>**Example:** Ollama –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ ‚Üí CortexConnectionError | üü° MEDIUM | üî¥ OPEN |
| **–ù–ï–¢ input validation** | lightrag_server.py `/query` | Endpoint –ù–ï –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç query length<br>**Risk:** DoS –ø—Ä–∏ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö (>100K chars)<br>**Attack:** Memory exhaustion, Ollama timeout | üü° MEDIUM | üî¥ OPEN |
| **Inconsistent venv naming** | services/* | ‚Ä¢ lightrag: `venv/`<br>‚Ä¢ neuro_terminal: `.venv/`<br>‚Ä¢ llama_factory: `venv/`<br>**Impact:** –ü—É—Ç–∞–Ω–∏—Ü–∞ –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö, –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ | üü¢ LOW (UX) | üî¥ OPEN |
| **–ù–ï–¢ health check delays** | START_ALL.ps1 | –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ—Ä–≤–∏—Å—ã —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º sleep 3s<br>**Risk:** –°–µ—Ä–≤–∏—Å –µ—â—ë –Ω–µ –≥–æ—Ç–æ–≤ ‚Üí —Å–ª–µ–¥—É—é—â–∏–π —Å–µ—Ä–≤–∏—Å –æ—à–∏–±–∫–∞<br>**Example:** CORTEX –º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç graph ‚Üí Neuro-Terminal cannot connect | üü° MEDIUM | üî¥ OPEN |
| **Process leak on crash** | STOP_ALL.ps1 | –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ CommandLine –º–æ–∂–µ—Ç –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã<br>**Scenario:** –ï—Å–ª–∏ CommandLine unavailable (–∑–∞—â–∏—â—ë–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å)<br>**Impact:** Zombie processes, port conflicts | üü° MEDIUM | üî¥ OPEN |
| **–ù–ï–¢ backup strategy** | services/lightrag/data/ | 488+ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤<br>**Risk:** Corruption ‚Üí –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è 15-30 –º–∏–Ω—É—Ç<br>–ù–ï–¢ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞ data/*.json, *.graphml | üü° MEDIUM | üî¥ OPEN |
| **–ù–ï–¢ model versioning** | Ollama models | qwen2.5:14b –º–æ–∂–µ—Ç –æ–±–Ω–æ–≤–∏—Ç—å—Å—è (`ollama pull`)<br>**Risk:** Breaking changes –≤ API, different outputs<br>**Reproducibility:** –ù–ï–¢ model pinning (digest/tag) | üü¢ LOW | üî¥ OPEN |
| **–ù–ï–¢ graceful shutdown** | lightrag_server.py | FastAPI –±–µ–∑ shutdown hooks<br>**Risk:** Data corruption –ø—Ä–∏ `kill -9`<br>**Example:** KV store –Ω–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è ‚Üí cache loss | üü° MEDIUM | üî¥ OPEN |
| **Python process detection threshold** | CHECK_STATUS.ps1, START_ALL.ps1 | –§–∏–ª—å—Ç—Ä `WorkingSet -gt 100MB`<br>**Risk:** –õ–µ–≥–∫–∏–µ Python –ø—Ä–æ—Ü–µ—Å—Å—ã (<100MB) –Ω–µ –¥–µ—Ç–µ–∫—Ç—è—Ç—Å—è<br>**Example:** –ú–∞–ª–µ–Ω—å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –Ω–∞ –ø–æ—Ä—Ç—É 8004 ‚Üí conflict –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω | üü¢ LOW | üî¥ OPEN |
| **MSI Afterburner exclusion paths** | –≤—Å–µ .ps1 | Hardcoded `-notlike "*MSI Afterburner*"`<br>**Risk:** –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–æ–∫<br>**Example:** –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ `D:\Tools\MSI\` ‚Üí –ø—Ä–æ—Ü–µ—Å—Å –±—É–¥–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω | üü¢ LOW (UX) | üî¥ OPEN |
| **Windows file locking** | triz_safe_config.yaml | **FIXED 26.11.2025**<br>Error: `OSError: [WinError 1224]`<br>**Cause:** `preprocessing_num_workers=4` ‚Üí race condition<br>**Fix:** `preprocessing_num_workers: 1`<br>**Impact:** Training –Ω–∞ Windows | üî¥ CRITICAL | ‚úÖ FIXED |
| **Hardcoded timeout** | knowledge_client.py | `DEFAULT_TIMEOUT = 120s`<br>**Risk:** –î–æ–ª–≥–∏–µ –∑–∞–ø—Ä–æ—Å—ã –±–ª–æ–∫–∏—Ä—É—é—Ç –∫–ª–∏–µ–Ω—Ç–∞<br>**UX:** –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–¥—ë—Ç 2 –º–∏–Ω—É—Ç—ã –±–µ–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ—Ç–º–µ–Ω—ã | üü¢ LOW | üî¥ OPEN |

### 9.3. –ß–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–æ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∫ Ollama

**–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –§–ê–ö–¢–û–í –∏–∑ –∫–æ–¥–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å Open WebUI, Ollama UI):**

#### üî¥ CRITICAL (–Ω–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–æ–æ–±—â–µ)

| –§—É–Ω–∫—Ü–∏—è | –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ | –ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|---------|------------------|---------------|-----------|
| **1. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤ UI** | ‚ùå Hardcoded: qwen2.5:14b<br>–ù–ï–¢ dropdown | ‚Ä¢ UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (select/dropdown)<br>‚Ä¢ Endpoint `GET /models` (Ollama API proxy)<br>‚Ä¢ State management (selected model)<br>‚Ä¢ Update lightrag_server.py config on-the-fly | HIGH |
| **2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏** | ‚ùå Hardcoded: temp=0.7, top_p=0.8<br>–ù–ï–¢ UI sliders | ‚Ä¢ Settings panel –≤ Chainlit<br>‚Ä¢ Sliders: temperature (0-2), top_p (0-1), top_k (1-100)<br>‚Ä¢ Persistent storage (user preferences)<br>‚Ä¢ Update LightRAG QueryParam | HIGH |
| **3. –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤** | ‚ö†Ô∏è Session-based (`.chainlit/chat_files/`)<br>–¢–µ—Ä—è–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞ | ‚Ä¢ Database schema (SQLite/PostgreSQL)<br>‚Ä¢ CRUD API (create/read/update/delete conversations)<br>‚Ä¢ UI: conversation history sidebar<br>‚Ä¢ Search/filter –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ | MEDIUM |
| **4. Streaming –æ—Ç–≤–µ—Ç–æ–≤** | ‚ùå `stream=false`<br>–ù–µ—Ç WebSocket/SSE | ‚Ä¢ Ollama streaming API integration (`stream=true`)<br>‚Ä¢ WebSocket connection (Chainlit supports)<br>‚Ä¢ Server-Sent Events (SSE) –¥–ª—è FastAPI<br>‚Ä¢ Progressive UI update (token-by-token) | HIGH |
| **5. Model management UI** | ‚ùå –ù–ï–¢ UI<br>–¢–æ–ª—å–∫–æ `ollama pull` –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ | ‚Ä¢ Wrapper –Ω–∞–¥ `ollama pull`, `ollama rm`, `ollama create`<br>‚Ä¢ UI: model list (name, size, last_used)<br>‚Ä¢ Download progress bar<br>‚Ä¢ Version tracking (digest/tag) | MEDIUM |

#### üü° MEDIUM (—á–∞—Å—Ç–∏—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)

| –§—É–Ω–∫—Ü–∏—è | –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ | –ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|---------|------------------|---------------|-----------|
| **6. Error handling** | ‚ö†Ô∏è –ï–°–¢–¨: HTTP 401 (unauthorized), 500 (server error)<br>–ù–ï–¢: User-friendly messages | ‚Ä¢ Error boundary components (React-style)<br>‚Ä¢ Retry UI (–¥–ª—è failed requests)<br>‚Ä¢ Toast notifications (Chainlit supports)<br>‚Ä¢ Detailed error messages (–Ω–µ —Ç–æ–ª—å–∫–æ status codes) | MEDIUM |
| **7. Logging & Debugging** | ‚ö†Ô∏è –ï–°–¢–¨: Python logging –≤ console<br>–ù–ï–¢: Structured logging, UI viewer | ‚Ä¢ Structured logger (JSON format)<br>‚Ä¢ Log viewer –≤ UI (real-time tail)<br>‚Ä¢ Performance metrics (latency, tokens/s)<br>‚Ä¢ Grafana/Prometheus integration | LOW |
| **8. Authentication & Authorization** | ‚ö†Ô∏è –ï–°–¢–¨: API Key –¥–ª—è CORTEX<br>–ù–ï–¢: User login/logout, RBAC | ‚Ä¢ User management system (username/password)<br>‚Ä¢ JWT tokens –¥–ª—è session<br>‚Ä¢ Role-based access control (admin, user, viewer)<br>‚Ä¢ Multi-user support (isolated conversations) | MEDIUM |
| **9. Configuration UI** | ‚ö†Ô∏è –ï–°–¢–¨: YAML configs (triz_safe_config.yaml)<br>–ù–ï–¢: Settings page | ‚Ä¢ Settings page –≤ Neuro-Terminal<br>‚Ä¢ Environment variable manager<br>‚Ä¢ Config editor (YAML/JSON)<br>‚Ä¢ Apply changes –±–µ–∑ restart | LOW |

#### üü¢ LOW (—Ö–æ—Ä–æ—à–æ –±—ã –∏–º–µ—Ç—å)

| –§—É–Ω–∫—Ü–∏—è | –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ | –ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|---------|------------------|---------------|-----------|
| **10. Multi-modal support** | ‚ùå –ù–ï–¢: Image/audio input | ‚Ä¢ File upload handling (Chainlit supports)<br>‚Ä¢ Ollama multi-modal API (LLaVA models)<br>‚Ä¢ Image preview –≤ UI<br>‚Ä¢ Audio playback | LOW |
| **11. Prompt templates** | ‚ùå –ù–ï–¢: Template library | ‚Ä¢ Template storage (database)<br>‚Ä¢ Variables –≤ –ø—Ä–æ–º–ø—Ç–∞—Ö ({{user_name}}, {{context}})<br>‚Ä¢ Template manager UI<br>‚Ä¢ Import/export templates | LOW |
| **12. Performance monitoring** | ‚ùå –ù–ï–¢: Response time tracking | ‚Ä¢ Metrics collector (Prometheus)<br>‚Ä¢ Token usage statistics<br>‚Ä¢ GPU utilization dashboard (nvidia-smi integration)<br>‚Ä¢ Cost estimation (if using paid APIs) | LOW |
| **13. Batch processing** | ‚ùå –ù–ï–¢: Bulk queries | ‚Ä¢ Bulk query submission UI<br>‚Ä¢ Background job queue (Celery, RQ)<br>‚Ä¢ Progress tracking<br>‚Ä¢ CSV import/export | LOW |
| **14. Export/Import** | ‚ùå –ù–ï–¢: Knowledge base export | ‚Ä¢ Export conversations (JSON, Markdown)<br>‚Ä¢ Export knowledge base (GraphML, JSON)<br>‚Ä¢ Import external datasets (CSV, JSONL)<br>‚Ä¢ Backup/restore UI | LOW |

**–û—Ü–µ–Ω–∫–∞ —É—Å–∏–ª–∏–π (development effort):**

| –§—É–Ω–∫—Ü–∏—è | Estimated LOC | Libraries needed | Complexity |
|---------|--------------|-----------------|----------|
| Model selection UI | ~100 | Chainlit elements | Low |
| Streaming | ~300 | asyncio, websockets | Medium |
| History persistence | ~500 | SQLAlchemy, PostgreSQL | Medium |
| Settings UI | ~200 | Chainlit forms, pydantic | Low |
| Multi-modal | ~400 | PIL, pydub, LLaVA model | High |
| Monitoring dashboard | ~600 | Prometheus, Grafana | High |

---

## 10. –ì–ò–ü–û–¢–ï–ó–´ vs –§–ê–ö–¢–´ (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ)

### ‚úÖ –§–ê–ö–¢–´ (–∏–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ –∫–æ–¥–∞/–∫–æ–Ω—Ñ–∏–≥–æ–≤/—Ç–µ—Ä–º–∏–Ω–∞–ª–æ–≤)

| # | –£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ | –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ |
|---|-------------|------------------------|
| 1 | **Python 3.12** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è | ‚úÖ Terminal context: `python --version` output |
| 2 | **Ollama –ø–æ—Ä—Ç 11434** | ‚úÖ –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è: lightrag_server.py line 47, app.py line 22, START_ALL.ps1, CHECK_STATUS.ps1 |
| 3 | **API Key "sesa-secure-core-v1"** | ‚úÖ lightrag_server.py line 32, knowledge_client.py line 38 |
| 4 | **488+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ** | ‚úÖ –ì–ò–ü–û–¢–ï–ó–ê (–∏–∑ docs), –Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ logs –∏ references –≤ –∫–æ–¥–µ |
| 5 | **300 training pairs –≤ triz_synthesis_v1.jsonl** | ‚úÖ Terminal output: `480.19 KB`, data_forge.py: `TARGET_SAMPLES = 300` |
| 6 | **LoRA rank 8** –¥–ª—è fine-tuning | ‚úÖ triz_safe_config.yaml line 10: `lora_rank: 8` |
| 7 | **Batch size 1, accumulation 4** | ‚úÖ triz_safe_config.yaml lines 26-27 |
| 8 | **RTX 5060 Ti 16GB GPU** | ‚úÖ .copilot-instructions.md, GPU diagnostics (force_inference_test.py: 11.4 GB VRAM) |
| 9 | **–ù–ï–¢ streaming** | ‚úÖ –ö–æ–¥: LightRAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `stream=false` (–±–∏–±–ª–∏–æ—Ç–µ—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è), app.py –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Ollama streaming |
| 10 | **–ù–ï–¢ traditional database** | ‚úÖ –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞: —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (JSON, GraphML), –Ω–µ—Ç SQLAlchemy, Tortoise, etc. |
| 11 | **LightRAG data/ size: 0.33 MB** | ‚úÖ Terminal: `Get-ChildItem ... | Measure-Object ‚Üí Count=1, TotalMB=0.33` |
| 12 | **library/raw_documents/: 181 files, 7.67 MB** | ‚úÖ Terminal: `Count=181, SizeMB=7.67` |
| 13 | **Rerank –û–¢–ö–õ–Æ–ß–ï–ù (bug v1.4.9.8)** | ‚úÖ lightrag_server.py lines 241, 245: explicit comments |
| 14 | **preprocessing_num_workers: 1** (Windows fix) | ‚úÖ triz_safe_config.yaml line 18, –ø—Ä–∏—á–∏–Ω–∞: Windows file locking issue |
| 15 | **Chainlit 1.1.402, Ollama 0.6.1** | ‚úÖ neuro_terminal/requirements.txt lines 1-2 |
| 16 | **CORTEX port 8004** | ‚úÖ lightrag_server.py (FastAPI uvicorn), knowledge_client.py line 26 |
| 17 | **Neuro-Terminal port 8501** | ‚úÖ Chainlit default, START_ALL.ps1, CHECK_STATUS.ps1 |
| 18 | **LLaMA Board port 7860** | ‚úÖ Gradio default, START_ALL.ps1, CHECK_STATUS.ps1 |
| 19 | **MSI Afterburner exclusion** | ‚úÖ START_ALL.ps1, STOP_ALL.ps1, CHECK_STATUS.ps1: `-notlike "*MSI Afterburner*"` |
| 20 | **E2E Testing: 22/25 passed (88%)** | ‚úÖ TEST_E2E.ps1 results (–∏–∑ docs) |

### ‚ùì –ì–ò–ü–û–¢–ï–ó–´ (—Ç—Ä–µ–±—É—é—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è)

| # | –£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≥–∏–ø–æ—Ç–µ–∑—ã | –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å |
|---|-------------|---------------------|---------------|
| 1 | **Vector DB: ChromaDB –∏–ª–∏ FAISS** | ‚Ä¢ –ü–∞–ø–∫–∞ `data/vdb_*/` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç<br>‚Ä¢ LightRAG documentation —É–ø–æ–º–∏–Ω–∞–µ—Ç FAISS<br>‚Ä¢ ChromaDB ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –≤—ã–±–æ—Ä –¥–ª—è RAG | ‚Ä¢ Read lightrag library source code<br>‚Ä¢ Inspect `vdb_*/` files<br>‚Ä¢ Check for `chroma.sqlite3` or `.faiss` files |
| 2 | **488+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ indexed** | ‚Ä¢ Docs —É–ø–æ–º–∏–Ω–∞—é—Ç —ç—Ç–æ —á–∏—Å–ª–æ<br>‚Ä¢ library/raw_documents/ = 181 files<br>‚Ä¢ –í–æ–∑–º–æ–∂–Ω–æ, count includes chunks, –Ω–µ —Ç–æ–ª—å–∫–æ docs | ‚Ä¢ Read `kv_store_doc_status.json`:<br>`$data = Get-Content ... | ConvertFrom-Json`<br>`$data.PSObject.Properties.Name.Count` |
| 3 | **Ollama version >= 0.1.20** | ‚Ä¢ qwen2.5 –º–æ–¥–µ–ª—å –ø–æ—è–≤–∏–ª–∞—Å—å –≤ Ollama 0.1.20+<br>‚Ä¢ Embeddings API —Å—Ç–∞–±–∏–ª–µ–Ω —Å 0.1.15+ | ‚Ä¢ `ollama --version` –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ |
| 4 | **Chainlit stores sessions in `.chainlit/chat_files/`** | ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ Chainlit<br>‚Ä¢ –ü–∞–ø–∫–∞ `.chainlit/` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç | ‚Ä¢ Inspect `.chainlit/` directory<br>‚Ä¢ Check Chainlit docs |
| 5 | **Fine-tuning export to Ollama format** | ‚Ä¢ –õ–æ–≥–∏—á–Ω—ã–π next step –ø–æ—Å–ª–µ training<br>‚Ä¢ `ollama create` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GGUF/safetensors | ‚Ä¢ Check LLaMA-Factory docs for export<br>‚Ä¢ Look for `ollama create` in scripts |
| 6 | **Multi-Agent system (qwen2-main + helper-lite) ‚Äî planned, not implemented** | ‚Ä¢ Folders exist (agents/qwen2-main/, agents/helper-lite/)<br>‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (configs/, data/, logs/) —Å–æ–∑–¥–∞–Ω–∞<br>‚Ä¢ –ù–û: –Ω–µ—Ç Python –∫–æ–¥–∞ –≤ file_search results | ‚Ä¢ List files in agents/qwen2-main/<br>‚Ä¢ Search for agent orchestration code |
| 7 | **Knowledge graph: ~12.5 MB** | ‚Ä¢ Extrapolation from data/ size<br>‚Ä¢ GraphML + embeddings + cache = ~12-15 MB | ‚Ä¢ `Get-ChildItem E:\WORLD_OLLAMA\services\lightrag\data -Recurse | Measure-Object Length -Sum` |
| 8 | **LightRAG uses async embeddings generation** | ‚Ä¢ `httpx` (async HTTP client) –≤ requirements<br>‚Ä¢ LightRAG docs —É–ø–æ–º–∏–Ω–∞—é—Ç async support | ‚Ä¢ Read LightRAG source code<br>‚Ä¢ Check `llm_model_max_async` parameter usage |
| 9 | **Retry logic –ù–ï —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ knowledge_client.py** | ‚Ä¢ –¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ –ø–æ–ø—ã—Ç–∫–∞ `requests.post()`<br>‚Ä¢ –ù–ï–¢ `try/except` —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏ | ‚Ä¢ Confirm by reading knowledge_client.py lines 100-130 |
| 10 | **Grafana/Prometheus monitoring ‚Äî planned but not implemented** | ‚Ä¢ –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ docs (gpu-optimization-todo.md)<br>‚Ä¢ –ù–û: –Ω–µ—Ç config —Ñ–∞–π–ª–æ–≤ Prometheus –≤ –ø—Ä–æ–µ–∫—Ç–µ | ‚Ä¢ Search for `prometheus.yml`, `grafana.ini`<br>‚Ä¢ Check docs/monitoring/ |

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**

- ‚úÖ **–§–ê–ö–¢–´: 20** (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã –∫–æ–¥–æ–º, –∫–æ–Ω—Ñ–∏–≥–∞–º–∏, —Ç–µ—Ä–º–∏–Ω–∞–ª–∞–º–∏)
- ‚ùì **–ì–ò–ü–û–¢–ï–ó–´: 10** (—Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
- **Confidence:** ~67% —Ñ–∞–∫—Ç–æ–≤, 33% –≥–∏–ø–æ—Ç–µ–∑

---

## üìä –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê

### –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞

**–û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:** ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** (–≤ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –°—Ç–∞—Ç—É—Å | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|-----------|--------|-------------|
| **CORTEX (LightRAG)** | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** | Port 8004, API Key protected, 488+ docs indexed, rerank disabled (bug) |
| **Neuro-Terminal** | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** | Port 8501, Chainlit UI, Step visualization, SYNAPSE integrated |
| **Ollama** | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** | Port 11434, qwen2.5:14b (11.4 GB VRAM stable), nomic-embed-text |
| **SYNAPSE Connector** | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** | HTTP client, API Key auth, health checks, no retry logic |
| **LLaMA Factory** | üü° **TRAINING** | Fine-tuning in progress (triz_safe_config.yaml, 300 pairs dataset) |
| **LLaMA Board** | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** | Port 7860, Gradio WebUI –¥–ª—è training monitoring |
| **Management Scripts** | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** | START_ALL.ps1, STOP_ALL.ps1, CHECK_STATUS.ps1 —Å process protection |
| **Multi-Agent System** | üìÅ **STRUCTURE ONLY** | agents/qwen2-main/, agents/helper-lite/ (no code found) |
| **Self-Distillation** | ‚úÖ **COMPLETED** | data_forge.py generated 300 pairs (480.19 KB), deployed to LLaMA-Factory |

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| **–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è** | Python 3.12 (–æ—Å–Ω–æ–≤–Ω–æ–π), PowerShell 7+ (—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ) |
| **–°–µ—Ä–≤–∏—Å—ã** | 4 –∞–∫—Ç–∏–≤–Ω—ã—Ö (Ollama, CORTEX, LLaMA Board, Neuro-Terminal) |
| **–ü–æ—Ä—Ç—ã** | 11434 (Ollama), 8004 (CORTEX), 7860 (LLaMA Board), 8501 (Neuro-Terminal) |
| **–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π** | 181 files, 7.67 MB (–¢–†–ò–ó + AI research, —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ) |
| **Knowledge Graph** | 488+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ indexed, 0.33 MB data/ (KV store + graph) |
| **Training Dataset** | 300 pairs, 480.19 KB (triz_synthesis_v1.jsonl) |
| **GPU VRAM Usage** | 11.4 GB stable (qwen2.5:14b model loaded) |
| **GPU** | RTX 5060 Ti 16GB (CUDA 12.x) |
| **E2E Test Success Rate** | 88% (22/25 tests passed) |
| **API Security** | X-API-KEY middleware (sesa-secure-core-v1) |
| **Codebase Size** | ~1200 lines user code (lightrag_server.py 697, app.py 210, knowledge_client.py 290, data_forge.py 251) |

### –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¢–†–ò–ó –ø—Ä–∏–Ω—Ü–∏–ø—ã

| –ü—Ä–∏–Ω—Ü–∏–ø | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ |
|---------|-----------|
| **‚Ññ2 "–í—ã–Ω–µ—Å–µ–Ω–∏–µ"** | API Key isolation (SECURE ENCLAVE) |
| **‚Ññ10 "–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ"** | Service startup order, Python process checks |
| **‚Ññ23 "–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å"** | Self-distillation validation loop |
| **‚Ññ24 "–ü–æ—Å—Ä–µ–¥–Ω–∏–∫"** | SYNAPSE connector (bridge Agent ‚Üî CORTEX) |
| **‚Ññ25 "–°–∞–º–æ–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"** | Self-distillation dataset generation |

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∏—Å–∫–∏

| –†–∏—Å–∫ | Impact | Mitigation Status |
|------|--------|------------------|
| **Rerank disabled (LightRAG bug)** | üü° –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è —Å–Ω–∏–∂–µ–Ω–æ | üî¥ OPEN (–∂–¥—ë–º fix –æ—Ç LightRAG) |
| **No streaming** | üü° UX: –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ UI –Ω–∞ 30-90s | üî¥ OPEN (—Ç—Ä–µ–±—É–µ—Ç WebSocket) |
| **No retry logic** | üü° Transient errors ‚Üí user errors | üî¥ OPEN (exponential backoff needed) |
| **No backup strategy** | üü° Data loss ‚Üí 15-30 min reindex | üî¥ OPEN (automated backups needed) |
| **Hardcoded API Key** | üü° Security: no rotation | ‚ö†Ô∏è PARTIAL (env variable support) |

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏)

1. **HIGH Priority:**
   - ‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å fine-tuning (training in progress)
   - üî¥ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å streaming –¥–ª—è Neuro-Terminal (WebSocket/SSE)
   - üî¥ –î–æ–±–∞–≤–∏—Ç—å retry logic –≤ SYNAPSE connector (exponential backoff)
   - üî¥ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å automated backups –¥–ª—è data/ (daily cron job)

2. **MEDIUM Priority:**
   - üî¥ UI –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ (dropdown –≤ Neuro-Terminal)
   - üî¥ Settings panel –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (temperature, top_p, top_k)
   - üî¥ –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤ (SQLite/PostgreSQL)
   - üî¥ Rate limiting –¥–ª—è CORTEX API (–∑–∞—â–∏—Ç–∞ –æ—Ç DoS)

3. **LOW Priority:**
   - üî¥ Multi-modal support (image/audio input –¥–ª—è LLaVA)
   - üî¥ Monitoring dashboard (Grafana + Prometheus)
   - üî¥ Batch processing UI (bulk queries)
   - üî¥ Export/Import —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å

---

## üìÑ –ú–ï–¢–ê–î–ê–ù–ù–´–ï –û–¢–ß–Å–¢–ê

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 26 –Ω–æ—è–±—Ä—è 2025 –≥.  
**–ê–≤—Ç–æ—Ä:** GitHub Copilot (–∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ WORLD_OLLAMA)  
**–í–µ—Ä—Å–∏—è:** 1.0  
**–û—Ö–≤–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:**
- ‚úÖ –í—Å–µ Python entry points (lightrag_server.py, app.py, knowledge_client.py, data_forge.py)
- ‚úÖ –í—Å–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (requirements.txt, triz_safe_config.yaml, dataset_info.json)
- ‚úÖ –í—Å–µ PowerShell management scripts (START_ALL.ps1, STOP_ALL.ps1, CHECK_STATUS.ps1, TEST_E2E.ps1)
- ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (services/, library/, agents/, workbench/, USER/)
- ‚úÖ Runtime metrics (terminal outputs, GPU VRAM, process checks)

**–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è:**
1. File search (–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã, Python scripts)
2. Read file (–∫–ª—é—á–µ–≤—ã–µ –º–æ–¥—É–ª–∏, 1000+ lines analyzed)
3. Grep search (TODO/FIXME/HACK, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
4. Terminal commands (—Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è)
5. Code analysis (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, data flow)

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:**
- **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤:** ~20 (–∫–ª—é—á–µ–≤—ã–µ entry points + configs)
- **–°—Ç—Ä–æ–∫ –∫–æ–¥–∞ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ:** ~2000+ (Python + PowerShell)
- **Terminal –∫–æ–º–∞–Ω–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:** 10+
- **–§–ê–ö–¢–´ vs –ì–ò–ü–û–¢–ï–ó–´:** 20 —Ñ–∞–∫—Ç–æ–≤, 10 –≥–∏–ø–æ—Ç–µ–∑ (67% confidence)

**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**
- ‚ùå –ù–ï –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å —Ñ–∞–π–ª—ã –≤ venv/ (–±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–π –∫–æ–¥)
- ‚ùå –ù–ï –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è –≤–µ—Å—å codebase (—Ç–æ–ª—å–∫–æ entry points)
- ‚ùå –ù–ï –ø—Ä–æ–≤–µ—Ä—è–ª–∏—Å—å –≤—Å–µ 181 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ library/raw_documents/
- ‚ùå –ù–ï–¢ –¥–æ—Å—Ç—É–ø–∞ –∫ GitHub Issues (–µ—Å–ª–∏ –µ—Å—Ç—å)

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:**
- –≠—Ç–æ—Ç –æ—Ç—á—ë—Ç ‚Äî **snapshot –Ω–∞ 26.11.2025**
- –ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–¥–∞ ‚Üí –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã
- –î–ª—è production deployment ‚Üí –ø—Ä–æ–≤–µ—Å—Ç–∏ security audit (API Key management, input validation)
- –î–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è ‚Üí –¥–æ–±–∞–≤–∏—Ç—å monitoring, load balancing, distributed storage

---

**–ö–û–ù–ï–¶ –û–¢–ß–Å–¢–ê**
