# AUTONOMOUS DESKTOP AGENT â€” ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸

**Ğ”Ğ°Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ:** 03.12.2025 16:10  
**ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ:** 03.12.2025 16:32 (Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Current vs Target State)  
**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·  
**Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚:** `FULL_AUTOMATION_ROADMAP.md`

---

## âš ï¸ Ğ¢Ğ•ĞšĞ£Ğ©Ğ•Ğ• Ğ¡ĞĞ¡Ğ¢ĞĞ¯ĞĞ˜Ğ• vs Ğ¦Ğ•Ğ›Ğ•Ğ’ĞĞ• (03.12.2025)

**ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ:** Desktop Automation Agent Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ½Ğ° ÑÑ‚Ğ°Ğ´Ğ¸Ğ¸ **Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ**, Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ **0%**.

### Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²

| ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ | Ğ¦ĞµĞ»ĞµĞ²Ğ¾Ğµ Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ | Gap | Ğ­Ñ‚Ğ°Ğ¿ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ |
|-----------|-------------------|-------------------|-----|-----------------|
| **Desktop Automation MCP Server** | âŒ ĞĞµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ | Rust binary, 12 tools, MCP protocol | 100% | Ğ­Ğ¢ĞĞŸ 1-2 |
| **enigo crate** | âŒ ĞĞµÑ‚ Ğ² Cargo.toml | v0.1.12 ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ | 100% | Ğ­Ğ¢ĞĞŸ 0 |
| **uiautomation crate** | âŒ ĞĞµÑ‚ Ğ² Cargo.toml | v0.5.0 ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ | 100% | Ğ­Ğ¢ĞĞŸ 0 |
| **accesskit crate** | âŒ ĞĞµÑ‚ Ğ² Cargo.toml | v0.12 ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ | 100% | Ğ­Ğ¢ĞĞŸ 0 |
| **notify crate** | âŒ ĞĞµÑ‚ Ğ² Cargo.toml | v6.1 ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ | 100% | Ğ­Ğ¢ĞĞŸ 0 |
| **AI Orchestrator** | âŒ ĞĞµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ | Python, LangChain, 10 scenarios | 100% | Ğ­Ğ¢ĞĞŸ 2 |
| **langchain** | âŒ ĞĞµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ | v0.1.0+ Ğ² venv | 100% | Ğ­Ğ¢ĞĞŸ 0 |
| **Test Scenarios Library** | âŒ ĞĞµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ | 10 YAML scenarios | 100% | Ğ­Ğ¢ĞĞŸ 3 |
| **Error Pattern Database** | âŒ ĞĞµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ | YAML patterns (20+ errors) | 100% | Ğ­Ğ¢ĞĞŸ 2 |
| **CI/CD Pipeline** | âŒ ĞĞµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ | GitHub Actions workflow | 100% | Ğ­Ğ¢ĞĞŸ 3 |
| **Tauri Client** | âœ… v0.3.1 (Ñ€ĞµĞ»Ğ¸Ğ· 02.12.2025) | v0.3.1 (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹) | 0% | Ğ“Ğ¾Ñ‚Ğ¾Ğ² |
| **MCP Shell Server** | âœ… Production | Production (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹) | 0% | Ğ“Ğ¾Ñ‚Ğ¾Ğ² |
| **PowerShell Scripts** | âœ… 38 ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ² | 38+ scripts (Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹) | 0% | Ğ“Ğ¾Ñ‚Ğ¾Ğ² |
| **Ollama** | âœ… qwen2.5:14b Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ | qwen2.5:14b (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹) | 0% | Ğ“Ğ¾Ñ‚Ğ¾Ğ² |

**Ğ›ĞµĞ³ĞµĞ½Ğ´Ğ°:**
- âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ² â€” ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚
- âŒ ĞĞµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½ â€” ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚, Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ñ Ğ½ÑƒĞ»Ñ
- Gap â€” Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹, Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾Ğ¹ Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ³Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ

---

## ğŸ—ï¸ ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AUTONOMOUS QA AGENT (Layer 6)                    â”‚
â”‚  â€¢ Python orchestrator (LangChain + Ollama)                         â”‚
â”‚  â€¢ Test scenario planner                                             â”‚
â”‚  â€¢ Error analyzer                                                    â”‚
â”‚  â€¢ Fix generator & validator                                         â”‚
â”‚  â€¢ Release decision maker                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ MCP Protocol (JSON-RPC over stdio)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               DESKTOP AUTOMATION MCP SERVER (Layer 5)                â”‚
â”‚  â€¢ Rust binary (automation-server)                                  â”‚
â”‚  â€¢ 12 MCP tools (5 original + 7 autonomous)                         â”‚
â”‚  â€¢ Circuit breaker & retry logic                                     â”‚
â”‚  â€¢ Event logging (JSON lines)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚           â”‚            â”‚            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visualizer  â”‚ â”‚  Executor  â”‚ â”‚ Monitor   â”‚ â”‚  Verification Layer    â”‚
â”‚  (Layer 4)  â”‚ â”‚ (Layer 3)  â”‚ â”‚(Layer 2)  â”‚ â”‚     (Layer 1)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Accessibilityâ”‚ â”‚ enigo      â”‚ â”‚ notify    â”‚ â”‚ Screenshot hash        â”‚
â”‚ Tree dump    â”‚ â”‚ (mouse/kbd)â”‚ â”‚ Log tail  â”‚ â”‚ Accessibility diff     â”‚
â”‚ uiautomation â”‚ â”‚ Debounce   â”‚ â”‚ Pattern   â”‚ â”‚ Log correlation        â”‚
â”‚ Screenshot   â”‚ â”‚ (100ms)    â”‚ â”‚ matching  â”‚ â”‚ Code compilation check â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚              â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           WORLD_OLLAMA DESKTOP CLIENT                    â”‚
        â”‚  â€¢ Tauri (Rust backend + Svelte frontend)               â”‚
        â”‚  â€¢ 11 existing modules (commands.rs, flow_manager.rs)   â”‚
        â”‚  â€¢ Logs: orchestrator, cortex, training, mcp, indexationâ”‚
        â”‚  â€¢ IPC bridge (invoke commands from JS)                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… PREREQUISITES CHECKLIST (ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)

**ĞŸĞµÑ€ĞµĞ´ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾Ğ¼ Ğ­Ğ¢ĞĞŸĞ 1 Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ:**

### Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

- [ ] **Ollama Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚:**
  ```powershell
  ollama list | Select-String "qwen2.5:14b"
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: qwen2.5:14b ... 8.7 GB
  ```

- [ ] **CORTEX (LightRAG) Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚:**
  ```powershell
  Invoke-RestMethod http://localhost:8004/health
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: {"status":"healthy"}
  ```

- [ ] **Tauri Client ÑĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ:**
  ```powershell
  cd client
  npm run tauri build
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: *.msi Ğ² src-tauri/target/release/bundle/
  ```

- [ ] **rust-analyzer ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½:**
  ```powershell
  code --list-extensions | Select-String rust-analyzer
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: rust-lang.rust-analyzer
  ```

### Ğ­Ğ¢ĞĞŸ 0 Ğ—Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½

- [ ] **Cargo.toml Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½:**
  ```powershell
  cargo tree | Select-String "enigo|uiautomation|notify"
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: Ğ²ÑĞµ 3 crates Ğ²Ğ¸Ğ´Ğ½Ñ‹
  ```

- [ ] **Python venv ÑĞ¾Ğ·Ğ´Ğ°Ğ½:**
  ```powershell
  cd automation\orchestrator
  .\venv\Scripts\Activate.ps1
  pip list | Select-String langchain
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: langchain 0.1.0, langchain-ollama 0.1.0
  ```

- [ ] **Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°:**
  ```powershell
  Test-Path "client\src-tauri\src\automation"
  Test-Path "automation\orchestrator\src"
  # ĞĞ±Ğ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ: True
  ```

- [ ] **Placeholder Ñ„Ğ°Ğ¹Ğ»Ñ‹ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒÑÑ‚ÑÑ:**
  ```powershell
  cd client\src-tauri
  cargo build
  # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: ÑƒÑĞ¿ĞµÑ… Ğ·Ğ° <2 Ğ¼Ğ¸Ğ½ÑƒÑ‚
  ```

**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ­Ğ¢ĞĞŸĞ 0:**
- Ğ•ÑĞ»Ğ¸ Ğ’Ğ¡Ğ• 8 Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹ â†’ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒ Ğ­Ğ¢ĞĞŸ 1
- Ğ•ÑĞ»Ğ¸ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ 1 Ğ¿ÑƒĞ½ĞºÑ‚ ĞĞ• Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ â†’ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº Ğ­Ğ¢ĞĞŸĞ£ 0 (ÑĞ¼. `FULL_AUTOMATION_ROADMAP.md`)

---

## ğŸ“¦ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞšĞĞœĞŸĞĞĞ•ĞĞ¢Ğ«

### 1. Desktop Automation MCP Server (ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞœĞ¾ÑÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ AI Orchestrator Ğ¸ Desktop Client, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ 12 MCP tools Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ UI Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°.

**Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸:**
- **Ğ¯Ğ·Ñ‹Ğº:** Rust (integration Ñ Tauri, zero overhead)
- **ĞŸÑ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»:** MCP (JSON-RPC over stdio, ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ Ñ Claude Desktop / LangChain)
- **ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:** Multi-module (visualizer, executor, monitor, verifier)

**âš ï¸ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ• ĞĞ“Ğ ĞĞĞ˜Ğ§Ğ•ĞĞ˜Ğ• (Ğ¸Ğ· Ğ¸Ğ½Ğ²ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ 03.12.2025):**
- **ĞĞ• ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚** â€” Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¡Ğ£Ğ©Ğ•Ğ¡Ğ¢Ğ’Ğ£Ğ®Ğ©Ğ˜Ğ™ `client/src-tauri/`
- **Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ:** 11 Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹ ÑƒĞ¶Ğµ ĞµÑÑ‚ÑŒ (commands.rs, flow_manager.rs, training_manager.rs Ğ¸ Ğ´Ñ€.)
- **ĞĞ• Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ:** MCP Shell Server ÑƒĞ¶Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ (logs/mcp/mcp-events.log), Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ»Ñ PowerShell Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²
- **Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ, ĞĞ• Ğ·Ğ°Ğ¼ĞµĞ½Ğ°:** Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ `automation/` Ğ² ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ Cargo workspace

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Rust crates):**

| Crate | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ |
|-------|--------|------------|-------------|
| `enigo` | 0.1.12 | Mouse/keyboard simulation | ğŸ”´ P0 (core functionality) |
| `uiautomation` | 0.5.0 | Windows UI Automation API | ğŸ”´ P0 (Accessibility Tree) |
| `serde_json` | 1.0 | JSON serialization for MCP | ğŸ”´ P0 (protocol) |
| `tokio` | 1.35+ | Async runtime Ğ´Ğ»Ñ MCP stdio | ğŸ”´ P0 (non-blocking I/O) |
| `notify` | 6.1 | File system watcher (logs) | ğŸŸ¡ P1 (monitoring) |
| `image` | 0.24 | Screenshot capture/hashing | ğŸŸ¡ P1 (verification) |
| `reqwest` | 0.11 | HTTP client (health checks) | ğŸŸ¢ P2 (optional) |

**Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°:**
```
client/src-tauri/src/
â”œâ”€â”€ automation_server.rs         (main entry point)
â”œâ”€â”€ automation/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ visualizer.rs            (Accessibility Tree + Screenshot)
â”‚   â”œâ”€â”€ executor.rs              (enigo wrapper with debounce)
â”‚   â”œâ”€â”€ monitor.rs               (notify-based log tailing)
â”‚   â””â”€â”€ verifier.rs              (hash comparison, tree diff)
â”œâ”€â”€ mcp/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ protocol.rs              (JSON-RPC stdio handler)
â”‚   â””â”€â”€ tools.rs                 (12 MCP tools implementation)
â””â”€â”€ utils.rs                     (shared utilities)
```

**Ğ‘Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- âœ… Tauri client Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ (target process Ğ´Ğ»Ñ uiautomation)
- âœ… Ollama Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ (Ğ´Ğ»Ñ AI Orchestrator, qwen2.5:14b)
- âš ï¸ Windows API (uiautomation Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Windows Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ñ„Ğ°Ğ·Ğµ)

---

### 2. AI Orchestrator (ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞœĞ¾Ğ·Ğ³ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ â€” Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµÑÑ‚Ñ‹, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ„Ğ¸ĞºÑÑ‹, Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ¾ Ñ€ĞµĞ»Ğ¸Ğ·Ğµ.

**Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸:**
- **Ğ¯Ğ·Ñ‹Ğº:** Python 3.11+
- **Framework:** LangChain (Ğ´Ğ»Ñ ReAct agent pattern)
- **LLM:** Ollama (qwen2.5:14b) â€” Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, no API calls
- **MCP Client:** Custom implementation (JSON-RPC over subprocess stdio)

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Python packages):**

| Package | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ |
|---------|--------|------------|-------------|
| `langchain` | 0.1.0+ | Agent framework (ReAct) | ğŸ”´ P0 (orchestration) |
| `langchain-ollama` | 0.1.0+ | Ollama integration | ğŸ”´ P0 (local LLM) |
| `pyyaml` | 6.0+ | Config parsing (scenarios) | ğŸ”´ P0 (test definitions) |
| `Pillow` | 10.0+ | Screenshot comparison | ğŸŸ¡ P1 (verification) |
| `imagehash` | 4.3+ | Perceptual hashing | ğŸŸ¡ P1 (diff detection) |
| `psutil` | 5.9+ | Process monitoring | ğŸŸ¢ P2 (health checks) |

**Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°:**
```
automation/orchestrator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                  (CLI entry point)
â”‚   â”œâ”€â”€ agent.py                 (LangChain ReAct agent)
â”‚   â”œâ”€â”€ mcp_client.py            (MCP protocol client)
â”‚   â”œâ”€â”€ scenarios/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ startup_test.py
â”‚   â”‚   â”œâ”€â”€ cortex_query_test.py
â”‚   â”‚   â”œâ”€â”€ training_test.py
â”‚   â”‚   â””â”€â”€ flows_test.py        (10 total scenarios)
â”‚   â”œâ”€â”€ validators/
â”‚   â”‚   â”œâ”€â”€ log_validator.py     (regex pattern matching)
â”‚   â”‚   â””â”€â”€ ui_validator.py      (screenshot/tree diff)
â”‚   â””â”€â”€ fixers/
â”‚       â”œâ”€â”€ code_fixer.py        (LLM-based fix generation)
â”‚       â””â”€â”€ config_fixer.py      (YAML/JSON config adjustments)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ test_suite.yaml          (scenario definitions)
â”‚   â”œâ”€â”€ error_patterns.yaml      (regex patterns for log errors)
â”‚   â””â”€â”€ fix_strategies.yaml      (error â†’ fix mapping)
â”œâ”€â”€ results/                     (test execution artifacts)
â”‚   â”œâ”€â”€ *.json                   (structured results)
â”‚   â””â”€â”€ screenshots/             (before/after images)
â””â”€â”€ requirements.txt
```

**Ğ‘Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- âœ… Desktop Automation MCP Server Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½
- âœ… Ollama Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ qwen2.5:14b Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ (port 11434)
- âš ï¸ Ğ”Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ VRAM (14B Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ ~9 GB)

---

### 3. Verification Layer (ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ Ğ² MCP Server)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Anti-hallucination Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ²ÑĞµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ñ‹ Ñ„Ğ°ĞºÑ‚Ğ°Ğ¼Ğ¸ Ğ¸Ğ· ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹.

**ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹:**

#### 3.1 Screenshot Hash Comparator
```rust
// automation/verifier.rs
use image::{DynamicImage, ImageBuffer};
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

pub struct ScreenshotVerifier {
    last_hash: Option<u64>,
}

impl ScreenshotVerifier {
    pub fn take_screenshot(&self) -> Result<DynamicImage, Error> {
        // Platform-specific implementation
        #[cfg(target_os = "windows")]
        {
            use screenshots::Screen;
            let screens = Screen::all()?;
            let screen = screens[0].capture()?;
            Ok(DynamicImage::ImageRgba8(screen))
        }
    }
    
    pub fn has_changed(&mut self) -> Result<bool, Error> {
        let screenshot = self.take_screenshot()?;
        let hash = self.compute_hash(&screenshot);
        
        if let Some(prev_hash) = self.last_hash {
            self.last_hash = Some(hash);
            Ok(hash != prev_hash)
        } else {
            self.last_hash = Some(hash);
            Ok(false) // First screenshot, nothing to compare
        }
    }
    
    fn compute_hash(&self, image: &DynamicImage) -> u64 {
        let mut hasher = DefaultHasher::new();
        image.as_bytes().hash(&mut hasher);
        hasher.finish()
    }
}
```

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- `screenshots` crate (0.8.5+) â€” cross-platform screenshot
- `image` crate (0.24+) â€” image processing

#### 3.2 Accessibility Tree Differ
```rust
// automation/verifier.rs
use serde_json::Value;

pub struct AccessibilityDiffer {
    last_tree: Option<Value>,
}

impl AccessibilityDiffer {
    pub fn detect_changes(&mut self, current_tree: Value) -> Vec<Change> {
        let Some(ref prev_tree) = self.last_tree else {
            self.last_tree = Some(current_tree);
            return vec![];
        };
        
        let mut changes = vec![];
        
        // Detect added elements
        let current_ids = self.extract_ids(&current_tree);
        let prev_ids = self.extract_ids(prev_tree);
        
        for id in &current_ids {
            if !prev_ids.contains(id) {
                changes.push(Change::ElementAdded(id.clone()));
            }
        }
        
        // Detect removed elements
        for id in &prev_ids {
            if !current_ids.contains(id) {
                changes.push(Change::ElementRemoved(id.clone()));
            }
        }
        
        self.last_tree = Some(current_tree);
        changes
    }
    
    fn extract_ids(&self, tree: &Value) -> Vec<String> {
        let mut ids = vec![];
        if let Some(elements) = tree["elements"].as_array() {
            for element in elements {
                if let Some(id) = element["id"].as_str() {
                    ids.push(id.to_string());
                }
            }
        }
        ids
    }
}

#[derive(Debug)]
pub enum Change {
    ElementAdded(String),
    ElementRemoved(String),
}
```

#### 3.3 Log Correlation Checker
```rust
// automation/verifier.rs
use std::time::{Duration, Instant};

pub struct LogCorrelator {
    monitor: LogMonitor,
}

impl LogCorrelator {
    pub fn verify_action_logged(
        &self, 
        action_name: &str, 
        log_file: &str, 
        timeout: Duration
    ) -> Result<(), Error> {
        let start = Instant::now();
        
        loop {
            if start.elapsed() > timeout {
                return Err(Error::ActionNotLogged(action_name.to_string()));
            }
            
            let logs = self.monitor.get_recent_logs(log_file, 50);
            if logs.iter().any(|line| line.contains(action_name)) {
                return Ok(());
            }
            
            std::thread::sleep(Duration::from_millis(100));
        }
    }
}
```

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:** 
- LogMonitor (Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½ Ğ² Ğ¨Ğ°Ğ³Ğµ 1.5)

---

### 4. Test Scenarios Library (ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Ğ”ĞµĞºĞ»Ğ°Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ E2E Ñ‚ĞµÑÑ‚Ğ¾Ğ² Ğ² YAML Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ.

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ñ:**
```yaml
# automation/orchestrator/config/test_suite.yaml
scenarios:
  - name: "Application Startup"
    id: "startup_test"
    priority: P0  # Critical path
    timeout: 60   # seconds
    
    steps:
      - action: start_process
        command: "npm run tauri dev"
        working_dir: "client"
        background: true
        
      - action: wait_for_window
        window_name: "WORLD_OLLAMA"
        timeout: 30
        
      - action: verify_logs
        log_file: "logs/orchestrator.log"
        pattern: "Step 1: Checking Ollama"
        timeout: 10
        
      - action: get_screen_state
        store_as: "startup_tree"
        
    success_criteria:
      - window_visible: true
      - no_errors_in_logs: ["orchestrator.log", "cortex.log"]
      - element_exists:
          tree_var: "startup_tree"
          element_name: "main-panel"
    
    on_failure:
      - collect_logs: ["orchestrator.log", "cortex.log", "mcp-events.log"]
      - take_screenshot: "failure_startup.png"
      - escalate_to: "github_issue"
```

**Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ĞµĞ²:**
```python
# orchestrator/src/scenario_validator.py
import yaml
from jsonschema import validate

SCENARIO_SCHEMA = {
    "type": "object",
    "required": ["name", "id", "steps", "success_criteria"],
    "properties": {
        "name": {"type": "string"},
        "id": {"type": "string", "pattern": "^[a-z_]+$"},
        "priority": {"enum": ["P0", "P1", "P2"]},
        "timeout": {"type": "integer", "minimum": 1},
        "steps": {
            "type": "array",
            "items": {
                "type": "object",
                "required": ["action"],
                "properties": {
                    "action": {"enum": ["start_process", "wait_for_window", "click_element", 
                                       "type_text", "verify_logs", "get_screen_state"]}
                }
            }
        },
        "success_criteria": {"type": "object"},
        "on_failure": {"type": "array"}
    }
}

def validate_scenario(scenario_yaml):
    scenario = yaml.safe_load(scenario_yaml)
    validate(instance=scenario, schema=SCENARIO_SCHEMA)
    return scenario
```

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- `pyyaml` (YAML parsing)
- `jsonschema` (scenario validation)

---

### 5. Error Pattern Database (ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Ğ‘Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° regex Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ² Ğ»Ğ¾Ğ³Ğ°Ñ….

**Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚:**
```yaml
# automation/orchestrator/config/error_patterns.yaml
patterns:
  - id: "err_001"
    name: "Ollama connection failed"
    category: "INFRASTRUCTURE"
    severity: "CRITICAL"
    regex: '\[ERROR\].*Failed to connect to Ollama|ConnectionRefused.*localhost:11434'
    contexts:
      - log_file: "orchestrator.log"
      - log_file: "cortex.log"
    suggested_fix:
      type: "manual_check"
      command: "ollama list"
      description: "Verify Ollama is running and models are available"
    
  - id: "err_002"
    name: "CORTEX startup timeout"
    category: "SERVICE"
    severity: "HIGH"
    regex: '\[ERROR\].*CORTEX failed to start within \d+s'
    contexts:
      - log_file: "orchestrator.log"
    suggested_fix:
      type: "code_fix"
      target_file: "scripts/START_ALL.ps1"
      description: "Increase CORTEX startup timeout from 30s to 60s"
      search_pattern: '\$cortexTimeout\s*=\s*30'
      replace_with: '$cortexTimeout = 60'
    
  - id: "err_003"
    name: "Training CUDA OOM"
    category: "TRAINING"
    severity: "HIGH"
    regex: 'CUDA out of memory|RuntimeError.*CUDA'
    contexts:
      - log_file: "logs/training/*.log"
    suggested_fix:
      type: "config_fix"
      target_file: "services/llama_factory/config/llama3_lora_sft.yaml"
      description: "Reduce batch_size to avoid VRAM exhaustion"
      yaml_path: "training_args.per_device_train_batch_size"
      transform: "divide_by_2"  # 8 â†’ 4 â†’ 2
```

**ĞŸĞ°Ñ€ÑĞµÑ€:**
```python
# orchestrator/src/validators/log_validator.py
import re
import yaml
from pathlib import Path

class ErrorPatternMatcher:
    def __init__(self, patterns_file: Path):
        with open(patterns_file) as f:
            data = yaml.safe_load(f)
            self.patterns = data['patterns']
    
    def scan_logs(self, log_file: Path, tail_lines: int = 100) -> list[dict]:
        """Scans recent log lines for error patterns."""
        errors = []
        
        with open(log_file) as f:
            lines = f.readlines()[-tail_lines:]
        
        for pattern in self.patterns:
            # Check if this pattern applies to this log file
            if not any(log_file.match(ctx['log_file']) for ctx in pattern['contexts']):
                continue
            
            for line in lines:
                if re.search(pattern['regex'], line):
                    errors.append({
                        'id': pattern['id'],
                        'name': pattern['name'],
                        'category': pattern['category'],
                        'severity': pattern['severity'],
                        'log_line': line.strip(),
                        'suggested_fix': pattern['suggested_fix']
                    })
        
        return errors
```

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- `pyyaml` (pattern definitions)
- `re` (standard library, regex matching)

---

### 6. Code Fix Generator (ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** LLM-based Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ„Ğ¸ĞºÑĞ¾Ğ² Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼.

**ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼:**
```python
# orchestrator/src/fixers/code_fixer.py
from langchain_ollama import ChatOllama
from pathlib import Path
import subprocess

class CodeFixGenerator:
    def __init__(self, llm: ChatOllama):
        self.llm = llm
    
    def generate_fix(self, error: dict, codebase_context: str) -> dict:
        """
        Generates code fix using LLM.
        Returns: {
            'file_path': str,
            'old_code': str,
            'new_code': str,
            'explanation': str
        }
        """
        prompt = f"""
You are a code fixing AI for WORLD_OLLAMA project.

ERROR DETECTED:
- Name: {error['name']}
- Category: {error['category']}
- Log line: {error['log_line']}
- Suggested fix (high-level): {error['suggested_fix']['description']}

CODEBASE CONTEXT:
{codebase_context}

Generate a concrete code fix. Follow these rules:
1. Return EXACT code to replace (with 3 lines context before/after)
2. Match existing code style (indentation, naming)
3. Do NOT hallucinate code that doesn't exist
4. If fix is config change, return YAML/JSON diff

OUTPUT FORMAT:
FILE: <absolute_path>
OLD_CODE:
```
<exact old code>
```
NEW_CODE:
```
<fixed code>
```
EXPLANATION: <why this fixes the error>
"""
        
        response = self.llm.invoke(prompt)
        fix = self._parse_llm_response(response.content)
        
        # Validate fix before returning
        if not self.validate_fix(fix):
            raise ValueError(f"Generated fix failed validation: {fix}")
        
        return fix
    
    def validate_fix(self, fix: dict) -> bool:
        """
        Anti-hallucination validation:
        1. File exists
        2. OLD_CODE exactly matches file content
        3. NEW_CODE compiles/parses
        """
        file_path = Path(fix['file_path'])
        
        # Check 1: File exists
        if not file_path.exists():
            print(f"âŒ Validation failed: {file_path} does not exist")
            return False
        
        # Check 2: OLD_CODE matches
        with open(file_path) as f:
            content = f.read()
            if fix['old_code'] not in content:
                print(f"âŒ Validation failed: OLD_CODE not found in {file_path}")
                return False
        
        # Check 3: NEW_CODE compiles (for Rust)
        if file_path.suffix == '.rs':
            temp_file = self._apply_to_temp(fix)
            result = subprocess.run(
                ['cargo', 'check', '--manifest-path', temp_file.parent / 'Cargo.toml'],
                capture_output=True
            )
            if result.returncode != 0:
                print(f"âŒ Validation failed: NEW_CODE does not compile")
                print(result.stderr.decode())
                return False
        
        # Check 3b: NEW_CODE parses (for YAML)
        elif file_path.suffix in ['.yaml', '.yml']:
            import yaml
            try:
                yaml.safe_load(fix['new_code'])
            except yaml.YAMLError as e:
                print(f"âŒ Validation failed: NEW_CODE is invalid YAML: {e}")
                return False
        
        print(f"âœ… Fix validated: {file_path}")
        return True
    
    def _apply_to_temp(self, fix: dict) -> Path:
        """Creates temporary copy of file with fix applied."""
        import tempfile
        import shutil
        
        original = Path(fix['file_path'])
        temp_dir = Path(tempfile.mkdtemp())
        temp_file = temp_dir / original.name
        
        shutil.copy(original, temp_file)
        
        with open(temp_file, 'r') as f:
            content = f.read()
        
        fixed_content = content.replace(fix['old_code'], fix['new_code'])
        
        with open(temp_file, 'w') as f:
            f.write(fixed_content)
        
        return temp_file
```

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- `langchain-ollama` (LLM integration)
- `subprocess` (cargo check validation)
- `pyyaml` (YAML validation)

---

### 7. CI/CD Pipeline (ĞĞ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚)

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** GitHub Actions workflow Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ² Ğ¸ Ñ€ĞµĞ»Ğ¸Ğ·Ğ¾Ğ².

**Ğ¤Ğ°Ğ¹Ğ»:**
```yaml
# .github/workflows/autonomous-qa.yml
name: Autonomous QA Suite

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  schedule:
    - cron: '0 3 * * *'  # Daily at 3 AM
  workflow_dispatch:     # Manual trigger

env:
  RUST_BACKTRACE: 1
  CARGO_TERM_COLOR: always

jobs:
  build-automation-server:
    runs-on: windows-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          profile: minimal
      
      - name: Cache Cargo
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            client/src-tauri/target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Build Automation Server
        run: |
          cd client/src-tauri
          cargo build --release --bin automation-server
      
      - name: Upload Binary
        uses: actions/upload-artifact@v4
        with:
          name: automation-server
          path: client/src-tauri/target/release/automation-server.exe
  
  run-e2e-tests:
    needs: build-automation-server
    runs-on: windows-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Download Automation Server
        uses: actions/download-artifact@v4
        with:
          name: automation-server
          path: ./bin
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Ollama
        run: |
          Invoke-WebRequest https://ollama.ai/download/OllamaSetup.exe -OutFile ollama.exe
          Start-Process ollama.exe /S -Wait
          Start-Process ollama serve
          Start-Sleep -Seconds 5
          ollama pull qwen2.5:14b
          ollama pull nomic-embed-text
      
      - name: Start CORTEX
        run: |
          cd services/lightrag
          pip install -r requirements.txt
          Start-Process python -ArgumentList "lightrag_server.py" -NoNewWindow
          Start-Sleep -Seconds 30
      
      - name: Build Desktop Client
        run: |
          cd client
          npm install
          npm run tauri build
      
      - name: Run Autonomous Test Suite
        run: |
          cd automation/orchestrator
          pip install -r requirements.txt
          python src/main.py --test-suite config/test_suite.yaml --mode ci
      
      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.sha }}
          path: |
            automation/orchestrator/results/*.json
            automation/orchestrator/results/screenshots/*.png
      
      - name: Report Failures
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('./automation/orchestrator/results/summary.json'));
            
            const issueBody = `
            ## ğŸš¨ Autonomous QA Suite Failed
            
            **Commit:** ${context.sha}
            **Branch:** ${context.ref}
            **Run:** ${context.runId}
            
            ### Failed Tests
            ${results.failed_tests.map(t => `- âŒ ${t.name}: ${t.error}`).join('\n')}
            
            ### Logs
            [View full results](${context.payload.repository.html_url}/actions/runs/${context.runId})
            `;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[AUTO-QA] ${results.failed_tests.length} test(s) failed on ${context.ref}`,
              body: issueBody,
              labels: ['automation', 'bug', 'ci-failure']
            });
```

**Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸:**
- GitHub Actions runners (windows-latest)
- Ollama (downloaded during workflow)
- Python 3.11, Node.js 20, Rust stable

---

## ğŸ”— ĞœĞĞ¢Ğ Ğ˜Ğ¦Ğ Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞĞ¡Ğ¢Ğ•Ğ™

### Inter-Component Dependencies

```
AI Orchestrator
  â”œâ”€ REQUIRES: Desktop Automation MCP Server (running process)
  â”œâ”€ REQUIRES: Ollama (qwen2.5:14b model)
  â”œâ”€ REQUIRES: Test Scenarios Library (YAML configs)
  â”œâ”€ REQUIRES: Error Pattern Database (YAML patterns)
  â””â”€ REQUIRES: Code Fix Generator (LLM integration)

Desktop Automation MCP Server
  â”œâ”€ REQUIRES: Tauri Client (target process for UI Automation)
  â”œâ”€ REQUIRES: Verification Layer (screenshot/tree diff)
  â”œâ”€ REQUIRES: Log Monitor (notify file watcher)
  â””â”€ PROVIDES: 12 MCP tools (stdio JSON-RPC)

Verification Layer
  â”œâ”€ REQUIRES: Screenshots crate (capture)
  â”œâ”€ REQUIRES: uiautomation crate (tree access)
  â””â”€ PROVIDES: Change detection (bool results)

Test Scenarios Library
  â”œâ”€ REQUIRES: YAML validation (jsonschema)
  â””â”€ PROVIDES: Declarative test definitions

Error Pattern Database
  â”œâ”€ REQUIRES: Regex engine (Python re)
  â””â”€ PROVIDES: Error detection results

Code Fix Generator
  â”œâ”€ REQUIRES: LLM (Ollama via langchain)
  â”œâ”€ REQUIRES: Codebase context (semantic search)
  â”œâ”€ REQUIRES: Validation tools (cargo check, YAML parser)
  â””â”€ PROVIDES: Validated code fixes

CI/CD Pipeline
  â”œâ”€ REQUIRES: All above components (built + running)
  â”œâ”€ REQUIRES: GitHub Actions infrastructure
  â””â”€ PROVIDES: Automated testing + reporting
```

### Critical Path

**Minimum components needed for MVP (Phase 1 PoC):**
1. Desktop Automation MCP Server (with 2 tools: `get_screen_state`, `click_element`)
2. Tauri Client (running in dev mode)
3. AI Orchestrator (minimal, 1 scenario: "Click button test")

**Full autonomous operation requires (Phase 3):**
1. All 12 MCP tools implemented
2. All 10 E2E scenarios defined
3. Error Pattern Database (20+ patterns)
4. Code Fix Generator with validation
5. CI/CD Pipeline

---

## ğŸ“Š Ğ Ğ•Ğ¡Ğ£Ğ Ğ¡ĞĞ«Ğ• Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ¯

### Development Environment

| Ğ ĞµÑÑƒÑ€Ñ | ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ | Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ |
|--------|---------|---------------|------------|
| **RAM** | 16 GB | 32 GB | qwen2.5:14b Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ ~9 GB |
| **VRAM** | 8 GB | 16 GB | CUDA Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ |
| **CPU** | 8 cores | 16 cores | ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹ |
| **Disk** | 50 GB free | 100 GB free | Ollama models + logs |
| **OS** | Windows 11 | Windows 11 Pro | uiautomation crate |

### Runtime Dependencies

| ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞŸĞ¾Ñ€Ñ‚ | Startup Time |
|-----------|--------|------|--------------|
| **Ollama** | 0.1.20+ | 11434 | ~5s |
| **CORTEX** | v0.3.1 | 8004 | ~25s (with models loaded) |
| **Tauri Client** | v0.3.1 | N/A (desktop) | ~10s |
| **Automation Server** | v0.4.0 | stdio | <1s |
| **AI Orchestrator** | v0.4.0 | N/A | <2s |

### CI/CD Resources

| Resource | GitHub Actions Limit | Our Usage | Buffer |
|----------|---------------------|-----------|--------|
| **Runner time** | 6 hours | ~15 min (test suite) | 24Ã— |
| **Storage** | 10 GB | ~500 MB (screenshots) | 20Ã— |
| **Concurrent jobs** | 20 | 1-2 | 10Ã— |

---

## âš ï¸ Ğ‘Ğ›ĞĞšĞ•Ğ Ğ« Ğ˜ MITIGATION

| Ğ‘Ğ»Ğ¾ĞºĞµÑ€ | Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ | Impact | Mitigation Strategy |
|--------|-------------|--------|---------------------|
| **enigo Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ² GitHub Actions** | Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ | ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ | Self-hosted runner Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ´Ğ¸ÑĞ¿Ğ»ĞµĞµĞ¼ |
| **uiautomation crate Windows-only** | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ | Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğµ | Phase 1 Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Windows, Phase 3 Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ accesskit (macOS/Linux) |
| **Ollama VRAM exhaustion** | ĞĞ¸Ğ·ĞºĞ°Ñ | Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ | Model offloading (CPU fallback) |
| **Flaky tests (Svelte animations)** | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ | Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğµ | Mandatory 100ms debounce + smart wait |
| **LLM Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ñ„Ğ¸ĞºÑÑ‹** | Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ | ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ | 3-layer validation (file exists + code matches + compiles) |
| **CI timeout (10 min limit)** | ĞĞ¸Ğ·ĞºĞ°Ñ | Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ | ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹ + caching |

---

## ğŸ¯ NEXT ACTIONS

**Ğ”Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ 2 Ğ´Ğ½Ñ):**

```powershell
# 1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹
New-Item -ItemType Directory -Path "client\src-tauri\src\automation" -Force
New-Item -ItemType Directory -Path "client\src-tauri\src\mcp" -Force
New-Item -ItemType Directory -Path "automation\orchestrator\src\scenarios" -Force
New-Item -ItemType Directory -Path "automation\orchestrator\config" -Force

# 2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Cargo.toml patch
@"
[dependencies]
enigo = "0.1.12"
uiautomation = "0.5.0"
serde_json = "1.0"
tokio = { version = "1", features = ["full"] }
notify = "6.1"
image = "0.24"
screenshots = "0.8"
"@ | Out-File -Append client\src-tauri\Cargo.toml

# 3. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ requirements.txt Ğ´Ğ»Ñ orchestrator
@"
langchain==0.1.0
langchain-ollama==0.1.0
pyyaml==6.0
Pillow==10.0
imagehash==4.3
psutil==5.9
jsonschema==4.20
"@ | Out-File automation\orchestrator\requirements.txt

# 4. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
cargo --version
python --version
ollama --version
npm --version
```

**ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸:**
1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ `automation/visualizer.rs` (ĞºĞ¾Ğ´ Ğ¸Ğ· Roadmap Ğ¨Ğ°Ğ³ 1.3)
2. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ `cargo test test_accessibility_tree_dump`
3. Ğ•ÑĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ â†’ MCP Server skeleton Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ

**Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°:**
- GitHub Project: "Desktop Automation Agent v0.4.0"
- Milestones: Phase 1 (2 weeks), Phase 2 (2 weeks), Phase 3 (1 week), Phase 4 (1 week)
- Issues: ĞŸĞ¾ 1 issue Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑˆĞ°Ğ³ Ğ¸Ğ· Roadmap

---

**Ğ’ĞµÑ€ÑĞ¸Ñ:** 1.1  
**Ğ”Ğ°Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ:** 03.12.2025 16:10  
**ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ:** 03.12.2025 16:32  
**ĞĞ²Ñ‚Ğ¾Ñ€:** AI Agent (GitHub Copilot)
