# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è TRIZ –∞–¥–∞–ø—Ç–µ—Ä–∞ (–ù–æ—è–±—Ä—å 2025)

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** 27 –Ω–æ—è–±—Ä—è 2025  
**–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:** RTX 5060 Ti 16GB VRAM  
**–¶–µ–ª—å:** –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è fine-tuning —Å –∞–¥–∞–ø—Ç–µ—Ä–æ–º TRIZ

---

## üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞

1. **VRAM –¥–ª—è training** ‚Äî –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ø–æ–º–µ—â–∞—Ç—å—Å—è –≤ 16GB –ø—Ä–∏ 4-bit QLoRA
2. **–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ** ‚Äî –Ω–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ
3. **Reasoning —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏** ‚Äî —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è TRIZ
4. **–°—Ç–æ–∏–º–æ—Å—Ç—å inference** ‚Äî –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ VRAM –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
5. **Community support** ‚Äî –Ω–∞–ª–∏—á–∏–µ –≥–æ—Ç–æ–≤—ã—Ö –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–π –≤ Ollama
6. **–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å** ‚Äî –º–æ–¥–µ–ª–∏ 2024-2025 –≥–æ–¥–æ–≤

---

## üìä –¢–∞–±–ª–∏—Ü–∞ –º–æ–¥–µ–ª–µ–π (–Ω–æ—è–±—Ä—å 2025)

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | Inference VRAM | Training VRAM (4-bit LoRA) | –†—É—Å—Å–∫–∏–π —è–∑—ã–∫ | Reasoning | Ollama | –°—Ç–∞—Ç—É—Å |
|--------|--------|----------------|---------------------------|--------------|-----------|---------|--------|
| **Qwen2.5:1.5B** | 1.5B | ~2-3 GB | ~4-5 GB | ‚úÖ –û—Ç–ª–∏—á–Ω–æ | ‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ | ‚úÖ –î–∞ | ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢** |
| **Qwen2.5:3B** | 3B | ~3-4 GB | ~6-8 GB | ‚úÖ –û—Ç–ª–∏—á–Ω–æ | ‚≠ê‚≠ê‚≠ê‚≠ê –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ | ‚úÖ –î–∞ | ‚ö†Ô∏è –ì—Ä–∞–Ω–∏—Ü–∞ 16GB |
| **Qwen2.5:7B** | 7B | ~8-9 GB | ~18-20 GB | ‚úÖ –û—Ç–ª–∏—á–Ω–æ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ | ‚úÖ –î–∞ | ‚ùå **OOM –Ω–∞ RTX 5060 Ti** |
| **Qwen2.5:14B** | 14B | ~14-15 GB | ~32-40 GB | ‚úÖ –û—Ç–ª–∏—á–Ω–æ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ | ‚úÖ –î–∞ | ‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ |
| **Llama 3.1:8B** | 8B | ~9-10 GB | ~20-22 GB | ‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ–µ | ‚≠ê‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ | ‚úÖ –î–∞ | ‚ùå OOM + —Å–ª–∞–±—ã–π —Ä—É—Å—Å–∫–∏–π |
| **Phi-3.5:3.8B** | 3.8B | ~4-5 GB | ~8-10 GB | ‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ–µ | ‚≠ê‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ | ‚úÖ –î–∞ | ‚ö†Ô∏è –ì—Ä–∞–Ω–∏—Ü–∞ 16GB |
| **Mistral:7B** | 7B | ~8-9 GB | ~18-20 GB | ‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ–µ | ‚≠ê‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ | ‚úÖ –î–∞ | ‚ùå OOM + —Å–ª–∞–±—ã–π —Ä—É—Å—Å–∫–∏–π |

---

## üî¨ –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–ø-3 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤

### 1. **Qwen2.5:1.5B-Instruct** (–¢–µ–∫—É—â–∏–π —á–µ–º–ø–∏–æ–Ω)

**–ü–ª—é—Å—ã:**
- ‚úÖ –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ 16GB VRAM (training ~4-5 GB)
- ‚úÖ –û—Ç–ª–∏—á–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ (–Ω–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞)
- ‚úÖ **–î–æ–∫–∞–∑–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:** TD-010v2 eval_loss 0.936
- ‚úÖ –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ: 300 samples –∑–∞ 2:16 –º–∏–Ω
- ‚úÖ –ú–∞–ª–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ VRAM –ø—Ä–∏ inference (~2-3 GB)
- ‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞ –≤ Ollama: `ollama pull qwen2.5:1.5b-instruct`

**–ú–∏–Ω—É—Å—ã:**
- ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ reasoning —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å 7B+
- ‚ö†Ô∏è –ú–æ–∂–µ—Ç —É–ø—É—Å–∫–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¢RIZ

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **–õ–£–ß–®–ò–ô –í–´–ë–û–† –¥–ª—è RTX 5060 Ti 16GB**

**–ö–æ–º–∞–Ω–¥–∞:**
```powershell
ollama pull qwen2.5:1.5b-instruct
```

---

### 2. **Qwen2.5:3B-Instruct** (–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∞–ø–≥—Ä–µ–π–¥)

**–ü–ª—é—Å—ã:**
- ‚úÖ –í 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —á–µ–º 1.5B ‚Üí –ª—É—á—à–µ reasoning
- ‚úÖ –û—Ç–ª–∏—á–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
- ‚ö†Ô∏è **–ì—Ä–∞–Ω–∏—á–Ω—ã–π —Å–ª—É—á–∞–π:** training ~6-8 GB (—Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –≤–ª–µ–∑–∞–µ—Ç)
- ‚úÖ Inference ~3-4 GB
- ‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞ –≤ Ollama: `ollama pull qwen2.5:3b-instruct`

**–ú–∏–Ω—É—Å—ã:**
- ‚ö†Ô∏è **–ù–ï –¢–ï–°–¢–ò–†–û–í–ê–õ–ê–°–¨** –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞
- ‚ö†Ô∏è –†–∏—Å–∫ OOM –ø—Ä–∏ —Å–ª–æ–∂–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö (cutoff_len 2048)
- ‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ —á–µ–º 1.5B (~1.5-2x –≤—Ä–µ–º—è)

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚≠ê‚≠ê‚≠ê‚≠ê **–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢** (–Ω—É–∂–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫)

**–¢–µ—Å—Ç–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞:**
```powershell
# 1. –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å
ollama pull qwen2.5:3b-instruct

# 2. –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ñ–∏–≥ —Å mini-–¥–∞—Ç–∞—Å–µ—Ç–æ–º (10 samples)
# 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å VRAM
nvidia-smi --query-gpu=memory.used --format=csv,noheader
```

---

### 3. **Qwen2.5:7B-Instruct** (–ó–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç ‚Äî –ù–û –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω)

**–ü–ª—é—Å—ã:**
- ‚úÖ –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–µ reasoning —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ (‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)
- ‚úÖ –û—Ç–ª–∏—á–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
- ‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω –≤ inference (—Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ)
- ‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω –≤ Ollama: `ollama pull qwen2.5:7b-instruct`

**–ú–∏–Ω—É—Å—ã:**
- ‚ùå **–ö–†–ò–¢–ò–ß–ù–û:** Training —Ç—Ä–µ–±—É–µ—Ç ~18-20 GB VRAM
- ‚ùå **8+ –ø–æ–ø—ã—Ç–æ–∫ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω—ã —Å OOM**
- ‚ùå –î–∞–∂–µ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (rank 4, cutoff 1024) –Ω–µ –ø–æ–º–æ–≥–ª–∞
- ‚ùå –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –Ω–æ –ø–∞–¥–∞–µ—Ç –Ω–∞ –ø–µ—Ä–≤–æ–º forward pass

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** ‚ùå **–ù–ï–í–û–ó–ú–û–ñ–ù–û –Ω–∞ RTX 5060 Ti 16GB**

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ê—Ä–µ–Ω–¥–∞ –æ–±–ª–∞—á–Ω–æ–≥–æ GPU
- **Google Colab Pro:** $10/–º–µ—Å (24GB VRAM T4/P100)
- **RunPod:** $0.34/—á–∞—Å (RTX 3090 24GB)
- **Paperspace Gradient:** $0.76/—á–∞—Å (RTX 5000 16GB)

---

## üÜï –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–∫–æ–Ω–µ—Ü 2024 ‚Äî –Ω–æ—è–±—Ä—å 2025)

### Qwen3-VL (Vision-Language)
- **–†–∞–∑–º–µ—Ä—ã:** 2B, 4B, 32B, 235B
- **–°—Ç–∞—Ç—É—Å:** –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ (Image-Text-to-Text)
- **–î–ª—è TRIZ:** ‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç (–º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å —Ç–µ–∫—Å—Ç–æ–º)

### Qwen3Guard (Moderation)
- **–†–∞–∑–º–µ—Ä—ã:** 0.6B, 4B, 8B
- **–°—Ç–∞—Ç—É—Å:** –ú–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏
- **–î–ª—è TRIZ:** ‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)

### Qwen2.5-Coder (Code-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ)
- **–†–∞–∑–º–µ—Ä—ã:** 1.5B, 3B, 7B, 14B, 32B
- **–°—Ç–∞—Ç—É—Å:** –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –∫–æ–¥–∞
- **–î–ª—è TRIZ:** ‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –±–ª–∏–∑–∫–∏ –∫ –∫–æ–¥—É)
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—Å–ª–∏ Qwen2.5-Instruct –Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç

---

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞ TD-009/TD-010v2

### ‚úÖ –ü–û–î–¢–í–ï–†–ñ–î–Å–ù–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø (1.5B)

**–ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
- Qwen2.5:1.5B-Instruct + LoRA rank 8
- Dataset: 300 samples, 3 epochs
- Batch size 2, gradient accumulation 4
- Cutoff length 2048
- **–†–µ–∑—É–ª—å—Ç–∞—Ç:** eval_loss 0.936 (15% —É–ª—É—á—à–µ–Ω–∏–µ vs TD-009)

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
1. **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞:** –£–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 500-1000 samples
2. **Epoch tuning:** –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å 5-7 epochs –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏–∏
3. **Rank —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å rank 16-32
4. **Merge –≤ base model:** –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è standalone –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

---

### ‚ö†Ô∏è –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø (3B)

**–ü–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Qwen2.5:3B:**

1. **–°–æ–∑–¥–∞—Ç—å mini-–∫–æ–Ω—Ñ–∏–≥:**
   ```yaml
   # triz_qwen3b_test.yaml
   model_name_or_path: Qwen/Qwen2.5-3B-Instruct
   finetuning_type: lora
   lora_rank: 8
   dataset: triz_synthesis_v1
   max_samples: 10  # MINI TEST
   num_train_epochs: 1.0
   per_device_train_batch_size: 1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π batch
   gradient_accumulation_steps: 8
   cutoff_len: 1024  # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
   quantization_bit: 4
   ```

2. **–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º VRAM:**
   ```powershell
   # –£–±–∏—Ç—å Ollama –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è VRAM
   Stop-Process -Name ollama -Force -ErrorAction SilentlyContinue
   wsl --shutdown
   
   # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç
   cd E:\WORLD_OLLAMA\services\llama_factory
   .\venv\Scripts\Activate.ps1
   
   # –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
   while ($true) {
       nvidia-smi --query-gpu=memory.used --format=csv,noheader
       Start-Sleep -Seconds 5
   }
   
   # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Ä–º–∏–Ω–∞–ª ‚Äî –æ–±—É—á–µ–Ω–∏–µ
   python src/train.py triz_qwen3b_test.yaml
   ```

3. **–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**
   - ‚úÖ VRAM –ø—Ä–∏ model loading < 10 GB
   - ‚úÖ VRAM –ø—Ä–∏ –ø–µ—Ä–≤–æ–º training step < 14 GB
   - ‚úÖ –û–±—É—á–µ–Ω–∏–µ 10 samples –∑–∞–≤–µ—Ä—à–µ–Ω–æ –±–µ–∑ OOM
   - ‚Üí –ï—Å–ª–∏ –≤—Å—ë –û–ö ‚Üí —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ full dataset (300 samples)

4. **–ü—Ä–∏ OOM:**
   - –£–º–µ–Ω—å—à–∏—Ç—å cutoff_len 1024 ‚Üí 512
   - –£–º–µ–Ω—å—à–∏—Ç—å lora_rank 8 ‚Üí 4
   - –£–≤–µ–ª–∏—á–∏—Ç—å gradient_accumulation 8 ‚Üí 16
   - –ï—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ OOM ‚Üí –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ 1.5B

---

### ‚ùå –û–ë–õ–ê–ß–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø (7B+)

**–ï—Å–ª–∏ –Ω—É–∂–µ–Ω 7B –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:**

**–í–∞—Ä–∏–∞–Ω—Ç 1: Google Colab Pro ($10/–º–µ—Å)**
- 24GB VRAM (T4/P100)
- Jupyter notebooks
- Upload dataset —á–µ—Ä–µ–∑ Google Drive
- 100 compute units/–º–µ—Å—è—Ü (~30-50 —á–∞—Å–æ–≤ GPU)

**–í–∞—Ä–∏–∞–Ω—Ç 2: RunPod ($0.34/—á–∞—Å RTX 3090)**
- 24GB VRAM
- Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å LLaMA Factory
- Pay-per-use (7B training ~30-40 –º–∏–Ω = $0.20)
- Template: PyTorch + CUDA 12

**–í–∞—Ä–∏–∞–Ω—Ç 3: Paperspace Gradient ($0.76/—á–∞—Å RTX 5000)**
- 16GB VRAM (–∫–∞–∫ —É –Ω–∞—Å, –Ω–æ –±–µ–∑ Ollama –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏)
- Managed Jupyter notebooks
- 7B –≤–æ–∑–º–æ–∂–µ–Ω —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π

**–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±–ª–∞–∫—É:**
1. –£–ø–∞–∫–æ–≤–∞—Ç—å dataset: `triz_synthesis_v1.jsonl`
2. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥: `triz_qwen7b_hybrid.yaml`
3. Upload –Ω–∞ cloud storage (Dropbox/Google Drive)
4. Clone LLaMA Factory –≤ –æ–±–ª–∞–∫–µ
5. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ
6. Download adapter (`adapter_model.safetensors`)

---

## üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ (–ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤)

| –ú–æ–¥–µ–ª—å | MMLU (English) | C-Eval (Chinese) | GSM8K (Math) | HumanEval (Code) | TRIZ Reasoning (–æ—Ü–µ–Ω–∫–∞) |
|--------|----------------|------------------|--------------|------------------|------------------------|
| Qwen2.5:1.5B | 60.9 | 74.1 | 53.7 | 37.2 | ‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ |
| Qwen2.5:3B | 65.6 | 77.8 | 63.8 | 44.5 | ‚≠ê‚≠ê‚≠ê‚≠ê –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ |
| Qwen2.5:7B | 70.3 | 83.1 | 79.7 | 53.7 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ |
| Qwen2.5:14B | 79.9 | 87.4 | 86.2 | 61.6 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê+ –ò–¥–µ–∞–ª—å–Ω–æ |

**–í—ã–≤–æ–¥:** 3B –¥–∞—ë—Ç +15-20% –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞–¥ 1.5B –ø—Ä–∏ +50% VRAM

---

## üéØ –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: "–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ —Å–∫–æ—Ä–æ—Å—Ç—å" ‚úÖ
**–í—ã–±–æ—Ä:** Qwen2.5:1.5B-Instruct  
**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**
- –î–æ–∫–∞–∑–∞–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å (TD-010v2)
- –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ (2-3 –º–∏–Ω—É—Ç—ã)
- –ù—É–ª–µ–≤–æ–π —Ä–∏—Å–∫ OOM
- –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ TRIZ –∑–∞–¥–∞—á

**–î–µ–π—Å—Ç–≤–∏—è:**
1. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å 1.5B
2. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å dataset –¥–æ 500-1000 samples
3. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å epochs –∏ LoRA rank
4. Merge adapter –≤ base model –¥–ª—è production

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: "–ö–∞—á–µ—Å—Ç–≤–æ –≤–∞–∂–Ω–µ–µ —Ä–∏—Å–∫–æ–≤" ‚ö†Ô∏è
**–í—ã–±–æ—Ä:** Qwen2.5:3B-Instruct (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç)  
**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**
- +15-20% –∫–∞—á–µ—Å—Ç–≤–∞ reasoning
- –ì—Ä–∞–Ω–∏—á–Ω—ã–π —Å–ª—É—á–∞–π –¥–ª—è 16GB
- –¢—Ä–µ–±—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**–î–µ–π—Å—Ç–≤–∏—è:**
1. –ó–∞–ø—É—Å—Ç–∏—Ç—å mini-test (10 samples) —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º VRAM
2. –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ ‚Üí full training (300 samples)
3. –°—Ä–∞–≤–Ω–∏—Ç—å eval_loss —Å TD-010v2 (1.5B)
4. –ï—Å–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ >10% ‚Üí –ø—Ä–∏–Ω—è—Ç—å –∫–∞–∫ –Ω–æ–≤—ã–π standard
5. –ï—Å–ª–∏ OOM –∏–ª–∏ <5% —É–ª—É—á—à–µ–Ω–∏—è ‚Üí –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ 1.5B

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ" üí∞
**–í—ã–±–æ—Ä:** Qwen2.5:7B-Instruct (–æ–±–ª–∞–∫–æ)  
**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**
- –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ
- –¢—Ä–µ–±—É–µ—Ç –æ–±–ª–∞—á–Ω–æ–≥–æ GPU
- ~$0.20-1.00 –∑–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É

**–î–µ–π—Å—Ç–≤–∏—è:**
1. –í—ã–±—Ä–∞—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º—É (RunPod/Colab/Paperspace)
2. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å dataset –∏ config
3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –≤ –æ–±–ª–∞–∫–µ
4. Download adapter
5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è inference (8-9 GB)

---

## üìù –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ (—Å–µ–≥–æ–¥–Ω—è):**
   - –†–µ—à–∏—Ç—å: –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ 1.5B –∏–ª–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å 3B?
   - –ï—Å–ª–∏ 3B ‚Üí —Å–æ–∑–¥–∞—Ç—å mini-test –∫–æ–Ω—Ñ–∏–≥
   - –ï—Å–ª–∏ 1.5B ‚Üí –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å dataset –¥–æ 500 samples

2. **–≠—Ç–∞ –Ω–µ–¥–µ–ª—è:**
   - –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
   - –°—Ä–∞–≤–Ω–∏—Ç—å eval_loss —Å TD-010v2
   - –°–æ–∑–¥–∞—Ç—å chat launcher –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

3. **–í –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ:**
   - –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –æ–±–ª–∞—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ 7B (–µ—Å–ª–∏ –±—é–¥–∂–µ—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç)
   - Merge adapter –≤ base model
   - –°–æ–∑–¥–∞—Ç—å benchmark TRIZ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–π –æ—Ü–µ–Ω–∫–∏

---

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- **Qwen2.5 –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –±–ª–æ–≥:** https://qwenlm.github.io/blog/qwen2.5/
- **HuggingFace Qwen:** https://huggingface.co/Qwen
- **Ollama –º–æ–¥–µ–ª–∏:** https://ollama.com/library/qwen2.5
- **LLaMA Factory –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** https://github.com/hiyouga/LLaMA-Factory
- **RunPod GPU –ø—Ä–∞–π—Å–∏–Ω–≥:** https://www.runpod.io/gpu-instance/pricing
- **Google Colab Pro:** https://colab.research.google.com/signup

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 27 –Ω–æ—è–±—Ä—è 2025  
**–ê–≤—Ç–æ—Ä:** GitHub Copilot  
**–í–µ—Ä—Å–∏—è:** 1.0  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
